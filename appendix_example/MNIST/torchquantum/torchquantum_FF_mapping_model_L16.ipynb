{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92f419e93e9400cae8bf93fa87617c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203ee94588984e43a05bb26ccc7f5494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     88\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     89\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tq/lib/python3.9/site-packages/torchvision/transforms/functional.py:169\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    167\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(pic\u001b[38;5;241m.\u001b[39mgetbands()))\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "## Distributed training\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# # Pennylane\n",
    "# import pennylane as qml\n",
    "# from pennylane import numpy as np\n",
    "import torchquantum as tq\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "# OpenMP: number of parallel threads.\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "### Classical target model initialization ###\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 200\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class LewHybridNN(nn.Module):\n",
    "    class QLayer(nn.Module):\n",
    "        def __init__(self, n_blocks):\n",
    "            super().__init__()\n",
    "            self.n_wires = int(np.ceil(np.log2(len(nw_list_normal)))),\n",
    "            self.n_wires = self.n_wires[0]\n",
    "            self.n_blocks = n_blocks\n",
    "            self.u3_layers = tq.QuantumModuleList()\n",
    "            self.cu3_layers = tq.QuantumModuleList()\n",
    "            # self.measure = tq.MeasureAll(tq.PauliZ)\n",
    "            for _ in range(self.n_blocks):\n",
    "                self.u3_layers.append(\n",
    "                    tq.Op1QAllLayer(\n",
    "                        op=tq.U3,\n",
    "                        n_wires=self.n_wires,\n",
    "                        has_params=True,\n",
    "                        trainable=True,\n",
    "                    )\n",
    "                )\n",
    "                self.cu3_layers.append(\n",
    "                    tq.Op2QAllLayer(\n",
    "                        op=tq.CU3,\n",
    "                        n_wires=self.n_wires,\n",
    "                        has_params=True,\n",
    "                        trainable=True,\n",
    "                        circular=True,\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "        def forward(self):\n",
    "            qdev = tq.QuantumDevice(\n",
    "                n_wires=self.n_wires, bsz=1, device=next(self.parameters()).device\n",
    "            )\n",
    "            easy_scale_coeff = 2**(n_qubit-1)\n",
    "            gamma = 0.1\n",
    "            beta  = 0.8\n",
    "            alpha = 0.3\n",
    "            for k in range(self.n_blocks):\n",
    "                self.u3_layers[k](qdev)\n",
    "                self.cu3_layers[k](qdev)\n",
    "                \n",
    "            state_mag = qdev.get_states_1d().abs()[0] \n",
    "            state_mag = state_mag[:len(nw_list_normal)]\n",
    "            x = torch.abs(state_mag) ** 2\n",
    "            # x = torch.log(x)\n",
    "            x = x.reshape(len(nw_list_normal),1)\n",
    "            x = (beta*torch.tanh(gamma*easy_scale_coeff*x))**(alpha) \n",
    "            x = x - torch.mean(x)\n",
    "            x.to(device)\n",
    "            return x\n",
    "\n",
    "        \n",
    "        \n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [4, 20, 4], 1).to(device)  \n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        self.QuantumNN = self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        probs_ = self.QuantumNN()\n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  249\n",
      "# of trainable parameter in QNN model:  1248\n",
      "# of trainable parameter in full model:  1497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "\n",
    "step = 1e-4                 # Learning rate\n",
    "batch_size = 128       # Number of samples for each training step\n",
    "num_epochs = 50             # Number of training epochs\n",
    "q_depth = 16             # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.1              # Initial spread of random quantum weights\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "model = LewHybridNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=step, weight_decay=1e-5, eps=1e-6)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.MappingModel(n_qubit+1,  [4, 20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in QNN model: \", num_trainable_params - num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/469], Loss: 57.0685, batch time: 2.51, accuracy:  10.94%\n",
      "Epoch [1/50], Step [2/469], Loss: 53.8196, batch time: 0.39, accuracy:  10.16%\n",
      "Epoch [1/50], Step [3/469], Loss: 53.5766, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [1/50], Step [4/469], Loss: 50.4533, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [5/469], Loss: 49.1523, batch time: 0.45, accuracy:  12.50%\n",
      "Epoch [1/50], Step [6/469], Loss: 48.9086, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [7/469], Loss: 47.2169, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [8/469], Loss: 44.2363, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [9/469], Loss: 42.1409, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [10/469], Loss: 41.4216, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [11/469], Loss: 38.9811, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [12/469], Loss: 35.4134, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [13/469], Loss: 38.3278, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [14/469], Loss: 33.2217, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [1/50], Step [15/469], Loss: 35.6584, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [16/469], Loss: 35.6255, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [1/50], Step [17/469], Loss: 32.1882, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [18/469], Loss: 31.7054, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [19/469], Loss: 30.6124, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [20/469], Loss: 26.3365, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [21/469], Loss: 27.1298, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [1/50], Step [22/469], Loss: 29.9551, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [1/50], Step [23/469], Loss: 26.5733, batch time: 0.50, accuracy:  17.19%\n",
      "Epoch [1/50], Step [24/469], Loss: 24.6850, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [25/469], Loss: 21.6721, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [26/469], Loss: 22.8512, batch time: 0.43, accuracy:  9.38%\n",
      "Epoch [1/50], Step [27/469], Loss: 22.1269, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [28/469], Loss: 22.6933, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [29/469], Loss: 19.4490, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [1/50], Step [30/469], Loss: 19.8992, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [31/469], Loss: 21.2742, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [32/469], Loss: 19.6938, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [33/469], Loss: 16.9514, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [34/469], Loss: 17.8504, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [35/469], Loss: 16.9839, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [36/469], Loss: 17.7411, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [37/469], Loss: 16.6680, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [38/469], Loss: 15.4706, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [39/469], Loss: 15.3601, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [40/469], Loss: 14.0888, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [41/469], Loss: 14.6450, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [42/469], Loss: 14.7521, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [43/469], Loss: 14.1309, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [44/469], Loss: 12.8290, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [45/469], Loss: 13.3946, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [46/469], Loss: 13.4627, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [47/469], Loss: 12.6594, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [48/469], Loss: 12.3393, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [49/469], Loss: 11.2468, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [50/469], Loss: 11.0070, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [51/469], Loss: 10.0076, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [52/469], Loss: 9.5367, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [1/50], Step [53/469], Loss: 8.9834, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [54/469], Loss: 9.0351, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [55/469], Loss: 9.1767, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [1/50], Step [56/469], Loss: 8.7644, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [57/469], Loss: 7.3897, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [1/50], Step [58/469], Loss: 8.3747, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [59/469], Loss: 7.3024, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [60/469], Loss: 7.3282, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [61/469], Loss: 7.7754, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [1/50], Step [62/469], Loss: 7.3163, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [63/469], Loss: 6.7023, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [1/50], Step [64/469], Loss: 6.1842, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [1/50], Step [65/469], Loss: 6.1927, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [66/469], Loss: 6.4478, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [67/469], Loss: 6.2636, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [68/469], Loss: 5.8723, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [69/469], Loss: 6.0417, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [70/469], Loss: 5.9205, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [71/469], Loss: 5.2720, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [72/469], Loss: 4.8898, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [1/50], Step [73/469], Loss: 5.2650, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [74/469], Loss: 4.8299, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [1/50], Step [75/469], Loss: 4.5599, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [76/469], Loss: 4.9680, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [77/469], Loss: 4.0611, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [78/469], Loss: 4.4109, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [79/469], Loss: 4.3297, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [1/50], Step [80/469], Loss: 4.2756, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [81/469], Loss: 4.0698, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [82/469], Loss: 4.1769, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [83/469], Loss: 4.2994, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [1/50], Step [84/469], Loss: 4.2275, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [85/469], Loss: 3.9704, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [86/469], Loss: 3.9603, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [1/50], Step [87/469], Loss: 3.6946, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [1/50], Step [88/469], Loss: 3.8493, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [89/469], Loss: 3.8687, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [90/469], Loss: 3.5819, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [91/469], Loss: 3.8467, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [92/469], Loss: 3.3050, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [93/469], Loss: 3.4647, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [1/50], Step [94/469], Loss: 3.3924, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [95/469], Loss: 3.1414, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [1/50], Step [96/469], Loss: 3.5209, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [97/469], Loss: 3.3688, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [98/469], Loss: 3.4237, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [99/469], Loss: 3.4144, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [100/469], Loss: 3.3868, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [101/469], Loss: 3.3288, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [102/469], Loss: 3.1500, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [103/469], Loss: 3.2529, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [104/469], Loss: 3.0674, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [105/469], Loss: 3.0352, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [106/469], Loss: 3.1964, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [107/469], Loss: 3.3214, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [108/469], Loss: 2.8626, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [1/50], Step [109/469], Loss: 3.0388, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [110/469], Loss: 3.0238, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [111/469], Loss: 3.0124, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [112/469], Loss: 3.1214, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [1/50], Step [113/469], Loss: 3.0307, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [114/469], Loss: 2.7526, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [115/469], Loss: 2.9367, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [116/469], Loss: 2.9460, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [117/469], Loss: 2.8870, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [118/469], Loss: 2.9018, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [119/469], Loss: 2.7966, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [1/50], Step [120/469], Loss: 2.7639, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [121/469], Loss: 2.9104, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [122/469], Loss: 2.8479, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [123/469], Loss: 2.9205, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [1/50], Step [124/469], Loss: 2.7718, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [125/469], Loss: 2.8201, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [126/469], Loss: 2.7440, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [127/469], Loss: 3.0200, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [128/469], Loss: 2.8024, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [129/469], Loss: 2.8142, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [130/469], Loss: 2.7633, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [131/469], Loss: 2.9137, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [132/469], Loss: 2.6705, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [133/469], Loss: 2.7435, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [134/469], Loss: 2.5042, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [135/469], Loss: 2.5896, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [136/469], Loss: 2.6405, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [137/469], Loss: 2.6971, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [138/469], Loss: 2.6338, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [139/469], Loss: 2.6396, batch time: 0.42, accuracy:  7.03%\n",
      "Epoch [1/50], Step [140/469], Loss: 2.6464, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [141/469], Loss: 2.7317, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [142/469], Loss: 2.7163, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [143/469], Loss: 2.7230, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [144/469], Loss: 2.7318, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [145/469], Loss: 2.6425, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [146/469], Loss: 2.6592, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [147/469], Loss: 2.5493, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [148/469], Loss: 2.6588, batch time: 0.47, accuracy:  10.16%\n",
      "Epoch [1/50], Step [149/469], Loss: 2.5462, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [150/469], Loss: 2.6500, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [151/469], Loss: 2.7117, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [152/469], Loss: 2.6287, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [153/469], Loss: 2.6444, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [154/469], Loss: 2.6704, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [155/469], Loss: 2.6141, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [156/469], Loss: 2.6327, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [157/469], Loss: 2.6003, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [158/469], Loss: 2.5782, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [159/469], Loss: 2.5148, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [160/469], Loss: 2.6272, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [1/50], Step [161/469], Loss: 2.6087, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [162/469], Loss: 2.6208, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [163/469], Loss: 2.6358, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [164/469], Loss: 2.6300, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [165/469], Loss: 2.6598, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [166/469], Loss: 2.6443, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [1/50], Step [167/469], Loss: 2.5658, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [1/50], Step [168/469], Loss: 2.6227, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [169/469], Loss: 2.6515, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [1/50], Step [170/469], Loss: 2.5548, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [171/469], Loss: 2.5681, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [172/469], Loss: 2.5879, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [173/469], Loss: 2.6062, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [174/469], Loss: 2.5732, batch time: 0.42, accuracy:  4.69%\n",
      "Epoch [1/50], Step [175/469], Loss: 2.6229, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [176/469], Loss: 2.6971, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [1/50], Step [177/469], Loss: 2.5967, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [178/469], Loss: 2.5105, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [179/469], Loss: 2.5439, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [180/469], Loss: 2.6838, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [181/469], Loss: 2.5406, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [1/50], Step [182/469], Loss: 2.4147, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [183/469], Loss: 2.5746, batch time: 0.39, accuracy:  10.94%\n",
      "Epoch [1/50], Step [184/469], Loss: 2.5313, batch time: 0.39, accuracy:  6.25%\n",
      "Epoch [1/50], Step [185/469], Loss: 2.5281, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [186/469], Loss: 2.5484, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [187/469], Loss: 2.6583, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [188/469], Loss: 2.5556, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [189/469], Loss: 2.6214, batch time: 0.40, accuracy:  3.91%\n",
      "Epoch [1/50], Step [190/469], Loss: 2.6123, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [191/469], Loss: 2.5708, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [192/469], Loss: 2.4904, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [193/469], Loss: 2.4705, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [1/50], Step [194/469], Loss: 2.5098, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [195/469], Loss: 2.4508, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [196/469], Loss: 2.5274, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [1/50], Step [197/469], Loss: 2.4791, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [198/469], Loss: 2.4088, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [199/469], Loss: 2.5534, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [1/50], Step [200/469], Loss: 2.5547, batch time: 0.39, accuracy:  8.59%\n",
      "Epoch [1/50], Step [201/469], Loss: 2.5868, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [202/469], Loss: 2.5903, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [203/469], Loss: 2.5213, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [204/469], Loss: 2.5085, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [1/50], Step [205/469], Loss: 2.4394, batch time: 0.39, accuracy:  13.28%\n",
      "Epoch [1/50], Step [206/469], Loss: 2.4211, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [207/469], Loss: 2.4701, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [208/469], Loss: 2.5286, batch time: 0.39, accuracy:  8.59%\n",
      "Epoch [1/50], Step [209/469], Loss: 2.5651, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [210/469], Loss: 2.5285, batch time: 0.42, accuracy:  6.25%\n",
      "Epoch [1/50], Step [211/469], Loss: 2.5498, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [1/50], Step [212/469], Loss: 2.4895, batch time: 0.39, accuracy:  7.03%\n",
      "Epoch [1/50], Step [213/469], Loss: 2.5269, batch time: 0.43, accuracy:  8.59%\n",
      "Epoch [1/50], Step [214/469], Loss: 2.5587, batch time: 0.42, accuracy:  7.81%\n",
      "Epoch [1/50], Step [215/469], Loss: 2.5212, batch time: 0.43, accuracy:  6.25%\n",
      "Epoch [1/50], Step [216/469], Loss: 2.5567, batch time: 0.42, accuracy:  5.47%\n",
      "Epoch [1/50], Step [217/469], Loss: 2.5114, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [218/469], Loss: 2.4431, batch time: 0.39, accuracy:  11.72%\n",
      "Epoch [1/50], Step [219/469], Loss: 2.4100, batch time: 0.39, accuracy:  10.16%\n",
      "Epoch [1/50], Step [220/469], Loss: 2.4814, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [221/469], Loss: 2.4261, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [1/50], Step [222/469], Loss: 2.5400, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [223/469], Loss: 2.5052, batch time: 0.40, accuracy:  3.12%\n",
      "Epoch [1/50], Step [224/469], Loss: 2.4381, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [225/469], Loss: 2.3621, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [226/469], Loss: 2.3817, batch time: 0.46, accuracy:  8.59%\n",
      "Epoch [1/50], Step [227/469], Loss: 2.4497, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [228/469], Loss: 2.5092, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [1/50], Step [229/469], Loss: 2.5213, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [230/469], Loss: 2.4530, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [231/469], Loss: 2.4471, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [1/50], Step [232/469], Loss: 2.4592, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [233/469], Loss: 2.4861, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [234/469], Loss: 2.4392, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [235/469], Loss: 2.3957, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [236/469], Loss: 2.4894, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [237/469], Loss: 2.4406, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [238/469], Loss: 2.4280, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [1/50], Step [239/469], Loss: 2.4199, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [240/469], Loss: 2.4658, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [241/469], Loss: 2.4597, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [242/469], Loss: 2.5013, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [243/469], Loss: 2.4807, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [244/469], Loss: 2.4574, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [245/469], Loss: 2.4551, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [246/469], Loss: 2.4801, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [1/50], Step [247/469], Loss: 2.4227, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [248/469], Loss: 2.4652, batch time: 0.39, accuracy:  10.16%\n",
      "Epoch [1/50], Step [249/469], Loss: 2.4064, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [250/469], Loss: 2.4021, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [251/469], Loss: 2.5267, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [1/50], Step [252/469], Loss: 2.4171, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [253/469], Loss: 2.5875, batch time: 0.41, accuracy:  2.34%\n",
      "Epoch [1/50], Step [254/469], Loss: 2.3877, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [255/469], Loss: 2.4886, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [256/469], Loss: 2.3713, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [1/50], Step [257/469], Loss: 2.3812, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [258/469], Loss: 2.3978, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [259/469], Loss: 2.4627, batch time: 0.39, accuracy:  7.81%\n",
      "Epoch [1/50], Step [260/469], Loss: 2.4897, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [261/469], Loss: 2.4564, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [262/469], Loss: 2.4607, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [263/469], Loss: 2.4342, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [264/469], Loss: 2.4445, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [265/469], Loss: 2.4162, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [1/50], Step [266/469], Loss: 2.4373, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [267/469], Loss: 2.4312, batch time: 0.39, accuracy:  7.03%\n",
      "Epoch [1/50], Step [268/469], Loss: 2.4196, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [269/469], Loss: 2.4324, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [1/50], Step [270/469], Loss: 2.4490, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [271/469], Loss: 2.3713, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [272/469], Loss: 2.3743, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [273/469], Loss: 2.4448, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [274/469], Loss: 2.3781, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [275/469], Loss: 2.3575, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [276/469], Loss: 2.4510, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [277/469], Loss: 2.4168, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [278/469], Loss: 2.4527, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [279/469], Loss: 2.3971, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [280/469], Loss: 2.4139, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [281/469], Loss: 2.3345, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [282/469], Loss: 2.4639, batch time: 0.46, accuracy:  12.50%\n",
      "Epoch [1/50], Step [283/469], Loss: 2.3914, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [284/469], Loss: 2.4719, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [285/469], Loss: 2.4130, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [286/469], Loss: 2.4898, batch time: 0.42, accuracy:  5.47%\n",
      "Epoch [1/50], Step [287/469], Loss: 2.4149, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [288/469], Loss: 2.3456, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [289/469], Loss: 2.3662, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [290/469], Loss: 2.4120, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [291/469], Loss: 2.4188, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [292/469], Loss: 2.4490, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [293/469], Loss: 2.4221, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [1/50], Step [294/469], Loss: 2.4238, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [295/469], Loss: 2.3803, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [296/469], Loss: 2.3985, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [297/469], Loss: 2.3026, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [1/50], Step [298/469], Loss: 2.3882, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [299/469], Loss: 2.4102, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [300/469], Loss: 2.4158, batch time: 0.42, accuracy:  5.47%\n",
      "Epoch [1/50], Step [301/469], Loss: 2.4456, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [302/469], Loss: 2.3992, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [303/469], Loss: 2.3722, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [304/469], Loss: 2.3943, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [1/50], Step [305/469], Loss: 2.4083, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [306/469], Loss: 2.3290, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [307/469], Loss: 2.3978, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [308/469], Loss: 2.3632, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [309/469], Loss: 2.4284, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [310/469], Loss: 2.3780, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [311/469], Loss: 2.3920, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [1/50], Step [312/469], Loss: 2.3780, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [313/469], Loss: 2.4384, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [314/469], Loss: 2.4047, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [315/469], Loss: 2.3767, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [316/469], Loss: 2.4410, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [317/469], Loss: 2.4701, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [1/50], Step [318/469], Loss: 2.3880, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [319/469], Loss: 2.4037, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [320/469], Loss: 2.3194, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [321/469], Loss: 2.4851, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [322/469], Loss: 2.4446, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [323/469], Loss: 2.4533, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [324/469], Loss: 2.3929, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [325/469], Loss: 2.4744, batch time: 0.42, accuracy:  6.25%\n",
      "Epoch [1/50], Step [326/469], Loss: 2.4100, batch time: 0.46, accuracy:  10.94%\n",
      "Epoch [1/50], Step [327/469], Loss: 2.3947, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [328/469], Loss: 2.4104, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [329/469], Loss: 2.3263, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [330/469], Loss: 2.3445, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [331/469], Loss: 2.4262, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [332/469], Loss: 2.3346, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [1/50], Step [333/469], Loss: 2.4814, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [1/50], Step [334/469], Loss: 2.3694, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [335/469], Loss: 2.4287, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [336/469], Loss: 2.3727, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [1/50], Step [337/469], Loss: 2.3909, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [338/469], Loss: 2.4221, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [339/469], Loss: 2.3284, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [1/50], Step [340/469], Loss: 2.3741, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [341/469], Loss: 2.4509, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [342/469], Loss: 2.3291, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [1/50], Step [343/469], Loss: 2.3954, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [344/469], Loss: 2.4529, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [345/469], Loss: 2.4061, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [346/469], Loss: 2.4039, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [347/469], Loss: 2.4235, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [348/469], Loss: 2.3572, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [349/469], Loss: 2.3885, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [350/469], Loss: 2.3044, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [351/469], Loss: 2.3714, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [352/469], Loss: 2.4689, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [353/469], Loss: 2.3610, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [1/50], Step [354/469], Loss: 2.3181, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [355/469], Loss: 2.4579, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [356/469], Loss: 2.3941, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [357/469], Loss: 2.3939, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [358/469], Loss: 2.4442, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [359/469], Loss: 2.4000, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [360/469], Loss: 2.3893, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [361/469], Loss: 2.4029, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [362/469], Loss: 2.3726, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [363/469], Loss: 2.3815, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [364/469], Loss: 2.3873, batch time: 0.46, accuracy:  11.72%\n",
      "Epoch [1/50], Step [365/469], Loss: 2.3530, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [366/469], Loss: 2.4401, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [1/50], Step [367/469], Loss: 2.4036, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [368/469], Loss: 2.4094, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [369/469], Loss: 2.4033, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [370/469], Loss: 2.3659, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [371/469], Loss: 2.3597, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [372/469], Loss: 2.3772, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [373/469], Loss: 2.4169, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [374/469], Loss: 2.3832, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [1/50], Step [375/469], Loss: 2.3269, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [376/469], Loss: 2.4205, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [377/469], Loss: 2.3956, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [378/469], Loss: 2.3374, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [379/469], Loss: 2.4013, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [380/469], Loss: 2.3858, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [381/469], Loss: 2.3667, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [382/469], Loss: 2.3544, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [383/469], Loss: 2.4403, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [384/469], Loss: 2.3579, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [385/469], Loss: 2.3519, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [386/469], Loss: 2.3882, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [387/469], Loss: 2.3943, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [388/469], Loss: 2.4235, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [389/469], Loss: 2.4005, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [390/469], Loss: 2.4438, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [1/50], Step [391/469], Loss: 2.3794, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [392/469], Loss: 2.3880, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [1/50], Step [393/469], Loss: 2.3874, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [394/469], Loss: 2.3823, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [395/469], Loss: 2.4363, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [396/469], Loss: 2.3813, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [397/469], Loss: 2.3758, batch time: 0.46, accuracy:  10.16%\n",
      "Epoch [1/50], Step [398/469], Loss: 2.3964, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [399/469], Loss: 2.3367, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [400/469], Loss: 2.3736, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [401/469], Loss: 2.3972, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [402/469], Loss: 2.3874, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [403/469], Loss: 2.3846, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [404/469], Loss: 2.3829, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [405/469], Loss: 2.3233, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [406/469], Loss: 2.3840, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [407/469], Loss: 2.3587, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [408/469], Loss: 2.3768, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [1/50], Step [409/469], Loss: 2.3236, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [1/50], Step [410/469], Loss: 2.3907, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [411/469], Loss: 2.3662, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [1/50], Step [412/469], Loss: 2.3061, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [1/50], Step [413/469], Loss: 2.3438, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [414/469], Loss: 2.4234, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [415/469], Loss: 2.4064, batch time: 0.41, accuracy:  3.91%\n",
      "Epoch [1/50], Step [416/469], Loss: 2.4067, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [1/50], Step [417/469], Loss: 2.3530, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [418/469], Loss: 2.3437, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [419/469], Loss: 2.4000, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [420/469], Loss: 2.3347, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [1/50], Step [421/469], Loss: 2.3755, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [422/469], Loss: 2.4158, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [423/469], Loss: 2.3223, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [424/469], Loss: 2.3451, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [425/469], Loss: 2.3910, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [1/50], Step [426/469], Loss: 2.3719, batch time: 0.42, accuracy:  7.81%\n",
      "Epoch [1/50], Step [427/469], Loss: 2.3681, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [1/50], Step [428/469], Loss: 2.3893, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [1/50], Step [429/469], Loss: 2.3518, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [430/469], Loss: 2.3593, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [431/469], Loss: 2.3134, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [432/469], Loss: 2.3536, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [1/50], Step [433/469], Loss: 2.4272, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [434/469], Loss: 2.4162, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [435/469], Loss: 2.3410, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [436/469], Loss: 2.3615, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [1/50], Step [437/469], Loss: 2.3441, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [438/469], Loss: 2.3036, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [439/469], Loss: 2.3404, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [440/469], Loss: 2.3609, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [1/50], Step [441/469], Loss: 2.3733, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [1/50], Step [442/469], Loss: 2.3779, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [443/469], Loss: 2.3308, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [1/50], Step [444/469], Loss: 2.3785, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [1/50], Step [445/469], Loss: 2.3401, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [446/469], Loss: 2.3525, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [447/469], Loss: 2.3547, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [448/469], Loss: 2.4039, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [1/50], Step [449/469], Loss: 2.3312, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [1/50], Step [450/469], Loss: 2.3443, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [1/50], Step [451/469], Loss: 2.3383, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [1/50], Step [452/469], Loss: 2.3360, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [1/50], Step [453/469], Loss: 2.3975, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [1/50], Step [454/469], Loss: 2.4073, batch time: 0.42, accuracy:  5.47%\n",
      "Epoch [1/50], Step [455/469], Loss: 2.3614, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [1/50], Step [456/469], Loss: 2.3735, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [1/50], Step [457/469], Loss: 2.3518, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [1/50], Step [458/469], Loss: 2.3783, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [1/50], Step [459/469], Loss: 2.3653, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [1/50], Step [460/469], Loss: 2.3769, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [1/50], Step [461/469], Loss: 2.3859, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [1/50], Step [462/469], Loss: 2.3747, batch time: 0.41, accuracy:  3.12%\n",
      "Epoch [1/50], Step [463/469], Loss: 2.3591, batch time: 0.42, accuracy:  7.03%\n",
      "Epoch [1/50], Step [464/469], Loss: 2.3518, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [465/469], Loss: 2.3732, batch time: 0.41, accuracy:  3.91%\n",
      "Epoch [1/50], Step [466/469], Loss: 2.3272, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [1/50], Step [467/469], Loss: 2.3444, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [1/50], Step [468/469], Loss: 2.3564, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [1/50], Step [469/469], Loss: 2.3421, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [2/50], Step [1/469], Loss: 2.3902, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [2/50], Step [2/469], Loss: 2.3553, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [2/50], Step [3/469], Loss: 2.2850, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [2/50], Step [4/469], Loss: 2.3510, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [5/469], Loss: 2.4174, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [6/469], Loss: 2.3451, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [7/469], Loss: 2.3697, batch time: 0.43, accuracy:  8.59%\n",
      "Epoch [2/50], Step [8/469], Loss: 2.3612, batch time: 0.46, accuracy:  10.94%\n",
      "Epoch [2/50], Step [9/469], Loss: 2.3324, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [2/50], Step [10/469], Loss: 2.3863, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [11/469], Loss: 2.3952, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [12/469], Loss: 2.3683, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [13/469], Loss: 2.3892, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [2/50], Step [14/469], Loss: 2.3397, batch time: 0.42, accuracy:  7.81%\n",
      "Epoch [2/50], Step [15/469], Loss: 2.3381, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [2/50], Step [16/469], Loss: 2.3517, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [17/469], Loss: 2.3543, batch time: 0.39, accuracy:  10.16%\n",
      "Epoch [2/50], Step [18/469], Loss: 2.3572, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [19/469], Loss: 2.3877, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [2/50], Step [20/469], Loss: 2.3601, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [21/469], Loss: 2.3890, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [2/50], Step [22/469], Loss: 2.3287, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [23/469], Loss: 2.3532, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [24/469], Loss: 2.3219, batch time: 0.39, accuracy:  12.50%\n",
      "Epoch [2/50], Step [25/469], Loss: 2.3806, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [2/50], Step [26/469], Loss: 2.3576, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [2/50], Step [27/469], Loss: 2.3923, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [28/469], Loss: 2.3911, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [29/469], Loss: 2.3295, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [30/469], Loss: 2.3774, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [31/469], Loss: 2.4181, batch time: 0.39, accuracy:  7.03%\n",
      "Epoch [2/50], Step [32/469], Loss: 2.3826, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [2/50], Step [33/469], Loss: 2.3498, batch time: 0.39, accuracy:  8.59%\n",
      "Epoch [2/50], Step [34/469], Loss: 2.3557, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [35/469], Loss: 2.3264, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [36/469], Loss: 2.4176, batch time: 0.39, accuracy:  10.16%\n",
      "Epoch [2/50], Step [37/469], Loss: 2.3778, batch time: 0.42, accuracy:  7.03%\n",
      "Epoch [2/50], Step [38/469], Loss: 2.3292, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [2/50], Step [39/469], Loss: 2.3720, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [40/469], Loss: 2.3723, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [41/469], Loss: 2.3148, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [2/50], Step [42/469], Loss: 2.3968, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [43/469], Loss: 2.3562, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [44/469], Loss: 2.3615, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [2/50], Step [45/469], Loss: 2.3583, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [2/50], Step [46/469], Loss: 2.3486, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [47/469], Loss: 2.3503, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [48/469], Loss: 2.2927, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [49/469], Loss: 2.3129, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [50/469], Loss: 2.3510, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [2/50], Step [51/469], Loss: 2.3182, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [52/469], Loss: 2.3529, batch time: 0.47, accuracy:  8.59%\n",
      "Epoch [2/50], Step [53/469], Loss: 2.3400, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [54/469], Loss: 2.3167, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [55/469], Loss: 2.3559, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [2/50], Step [56/469], Loss: 2.3278, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [57/469], Loss: 2.3088, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [58/469], Loss: 2.3594, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [59/469], Loss: 2.3536, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [60/469], Loss: 2.3461, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [61/469], Loss: 2.3611, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [62/469], Loss: 2.3188, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [63/469], Loss: 2.3896, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [2/50], Step [64/469], Loss: 2.3253, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [65/469], Loss: 2.2963, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [66/469], Loss: 2.3300, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [67/469], Loss: 2.3850, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [2/50], Step [68/469], Loss: 2.3211, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [69/469], Loss: 2.3883, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [70/469], Loss: 2.3675, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [71/469], Loss: 2.3194, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [72/469], Loss: 2.3475, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [73/469], Loss: 2.3132, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [74/469], Loss: 2.3278, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [75/469], Loss: 2.3489, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [76/469], Loss: 2.3647, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [77/469], Loss: 2.3733, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [2/50], Step [78/469], Loss: 2.3477, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [79/469], Loss: 2.3101, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [80/469], Loss: 2.3669, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [2/50], Step [81/469], Loss: 2.3102, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [82/469], Loss: 2.3565, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [83/469], Loss: 2.3631, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [84/469], Loss: 2.3496, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [85/469], Loss: 2.3308, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [86/469], Loss: 2.3501, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [87/469], Loss: 2.3627, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [88/469], Loss: 2.3227, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [2/50], Step [89/469], Loss: 2.3260, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [90/469], Loss: 2.3546, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [91/469], Loss: 2.3759, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [2/50], Step [92/469], Loss: 2.3045, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [93/469], Loss: 2.3693, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [94/469], Loss: 2.3222, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [95/469], Loss: 2.3070, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [96/469], Loss: 2.3562, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [97/469], Loss: 2.3612, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [2/50], Step [98/469], Loss: 2.3321, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [99/469], Loss: 2.3249, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [100/469], Loss: 2.3871, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [2/50], Step [101/469], Loss: 2.3062, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [102/469], Loss: 2.3327, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [103/469], Loss: 2.3586, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [2/50], Step [104/469], Loss: 2.3563, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [105/469], Loss: 2.3086, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [106/469], Loss: 2.3290, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [107/469], Loss: 2.3854, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [108/469], Loss: 2.3322, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [109/469], Loss: 2.3289, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [110/469], Loss: 2.3305, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [111/469], Loss: 2.3629, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [112/469], Loss: 2.3572, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [113/469], Loss: 2.3527, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [114/469], Loss: 2.3448, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [115/469], Loss: 2.3627, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [116/469], Loss: 2.3245, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [117/469], Loss: 2.3411, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [118/469], Loss: 2.3031, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [119/469], Loss: 2.3971, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [2/50], Step [120/469], Loss: 2.3401, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [121/469], Loss: 2.3611, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [2/50], Step [122/469], Loss: 2.3633, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [2/50], Step [123/469], Loss: 2.3414, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [124/469], Loss: 2.2905, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [125/469], Loss: 2.3587, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [2/50], Step [126/469], Loss: 2.3666, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [127/469], Loss: 2.3265, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [128/469], Loss: 2.3021, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [129/469], Loss: 2.3406, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [130/469], Loss: 2.3218, batch time: 0.46, accuracy:  14.84%\n",
      "Epoch [2/50], Step [131/469], Loss: 2.3692, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [132/469], Loss: 2.3565, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [133/469], Loss: 2.3977, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [2/50], Step [134/469], Loss: 2.3359, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [135/469], Loss: 2.3296, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [136/469], Loss: 2.3099, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [137/469], Loss: 2.3125, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [138/469], Loss: 2.3216, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [139/469], Loss: 2.3725, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [140/469], Loss: 2.3242, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [141/469], Loss: 2.3327, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [142/469], Loss: 2.3432, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [143/469], Loss: 2.3153, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [144/469], Loss: 2.3586, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [145/469], Loss: 2.3204, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [146/469], Loss: 2.3558, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [147/469], Loss: 2.3543, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [148/469], Loss: 2.3506, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [149/469], Loss: 2.3564, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [150/469], Loss: 2.3128, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [151/469], Loss: 2.3196, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [2/50], Step [152/469], Loss: 2.3828, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [153/469], Loss: 2.3247, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [2/50], Step [154/469], Loss: 2.3037, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [155/469], Loss: 2.2757, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [156/469], Loss: 2.3131, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [157/469], Loss: 2.3294, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [158/469], Loss: 2.3167, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [159/469], Loss: 2.3579, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [2/50], Step [160/469], Loss: 2.3072, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [161/469], Loss: 2.3133, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [162/469], Loss: 2.3118, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [163/469], Loss: 2.3432, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [164/469], Loss: 2.3484, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [2/50], Step [165/469], Loss: 2.3333, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [166/469], Loss: 2.3126, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [167/469], Loss: 2.3243, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [2/50], Step [168/469], Loss: 2.3214, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [169/469], Loss: 2.3454, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [170/469], Loss: 2.3450, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [171/469], Loss: 2.3372, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [172/469], Loss: 2.3294, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [173/469], Loss: 2.4096, batch time: 0.40, accuracy:  3.12%\n",
      "Epoch [2/50], Step [174/469], Loss: 2.3395, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [175/469], Loss: 2.3231, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [176/469], Loss: 2.3467, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [177/469], Loss: 2.3380, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [178/469], Loss: 2.3824, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [179/469], Loss: 2.3200, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [180/469], Loss: 2.3067, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [181/469], Loss: 2.3676, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [182/469], Loss: 2.3468, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [183/469], Loss: 2.3378, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [184/469], Loss: 2.3389, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [185/469], Loss: 2.3154, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [186/469], Loss: 2.3066, batch time: 0.46, accuracy:  14.84%\n",
      "Epoch [2/50], Step [187/469], Loss: 2.3480, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [188/469], Loss: 2.3424, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [189/469], Loss: 2.3567, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [190/469], Loss: 2.3122, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [191/469], Loss: 2.3426, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [192/469], Loss: 2.3701, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [2/50], Step [193/469], Loss: 2.3236, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [194/469], Loss: 2.3541, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [195/469], Loss: 2.3963, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [2/50], Step [196/469], Loss: 2.3202, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [197/469], Loss: 2.2993, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [198/469], Loss: 2.3369, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [199/469], Loss: 2.3208, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [200/469], Loss: 2.3446, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [201/469], Loss: 2.3241, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [202/469], Loss: 2.3142, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [203/469], Loss: 2.3469, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [204/469], Loss: 2.3444, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [205/469], Loss: 2.3351, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [206/469], Loss: 2.3046, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [207/469], Loss: 2.3672, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [2/50], Step [208/469], Loss: 2.3334, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [209/469], Loss: 2.3176, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [210/469], Loss: 2.3584, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [211/469], Loss: 2.3656, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [2/50], Step [212/469], Loss: 2.3308, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [213/469], Loss: 2.3353, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [214/469], Loss: 2.3283, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [2/50], Step [215/469], Loss: 2.3147, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [216/469], Loss: 2.3101, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [217/469], Loss: 2.3420, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [2/50], Step [218/469], Loss: 2.3357, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [2/50], Step [219/469], Loss: 2.3422, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [220/469], Loss: 2.3398, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [221/469], Loss: 2.3363, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [222/469], Loss: 2.3154, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [2/50], Step [223/469], Loss: 2.3320, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [224/469], Loss: 2.3338, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [225/469], Loss: 2.3564, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [226/469], Loss: 2.3361, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [227/469], Loss: 2.3573, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [2/50], Step [228/469], Loss: 2.2809, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [2/50], Step [229/469], Loss: 2.3283, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [230/469], Loss: 2.3460, batch time: 0.46, accuracy:  7.03%\n",
      "Epoch [2/50], Step [231/469], Loss: 2.3354, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [232/469], Loss: 2.3284, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [233/469], Loss: 2.3329, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [234/469], Loss: 2.3063, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [235/469], Loss: 2.3197, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [236/469], Loss: 2.3249, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [237/469], Loss: 2.3387, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [2/50], Step [238/469], Loss: 2.3614, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [2/50], Step [239/469], Loss: 2.3458, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [240/469], Loss: 2.3303, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [241/469], Loss: 2.3073, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [242/469], Loss: 2.3287, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [243/469], Loss: 2.3224, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [244/469], Loss: 2.3489, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [245/469], Loss: 2.3329, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [246/469], Loss: 2.3443, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [247/469], Loss: 2.3300, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [2/50], Step [248/469], Loss: 2.3235, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [249/469], Loss: 2.3486, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [250/469], Loss: 2.3207, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [251/469], Loss: 2.3292, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [252/469], Loss: 2.3518, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [253/469], Loss: 2.3284, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [254/469], Loss: 2.3517, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [255/469], Loss: 2.3216, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [256/469], Loss: 2.3204, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [257/469], Loss: 2.3136, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [258/469], Loss: 2.3653, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [2/50], Step [259/469], Loss: 2.3075, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [260/469], Loss: 2.3216, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [261/469], Loss: 2.3640, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [262/469], Loss: 2.3238, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [263/469], Loss: 2.3407, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [264/469], Loss: 2.3574, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [265/469], Loss: 2.3069, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [266/469], Loss: 2.3440, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [267/469], Loss: 2.3159, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [268/469], Loss: 2.3025, batch time: 0.46, accuracy:  10.94%\n",
      "Epoch [2/50], Step [269/469], Loss: 2.3069, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [270/469], Loss: 2.3299, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [271/469], Loss: 2.3313, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [272/469], Loss: 2.3195, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [273/469], Loss: 2.3436, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [274/469], Loss: 2.3001, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [275/469], Loss: 2.3317, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [276/469], Loss: 2.3231, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [2/50], Step [277/469], Loss: 2.3097, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [2/50], Step [278/469], Loss: 2.3281, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [279/469], Loss: 2.3078, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [280/469], Loss: 2.3493, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [2/50], Step [281/469], Loss: 2.2973, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [282/469], Loss: 2.3382, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [2/50], Step [283/469], Loss: 2.3189, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [2/50], Step [284/469], Loss: 2.3205, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [2/50], Step [285/469], Loss: 2.3420, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [2/50], Step [286/469], Loss: 2.3466, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [2/50], Step [287/469], Loss: 2.3241, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [2/50], Step [288/469], Loss: 2.3164, batch time: 0.39, accuracy:  9.38%\n",
      "Epoch [2/50], Step [289/469], Loss: 2.3300, batch time: 0.47, accuracy:  11.72%\n",
      "Epoch [2/50], Step [290/469], Loss: 2.3298, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [291/469], Loss: 2.3114, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [292/469], Loss: 2.3398, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [2/50], Step [293/469], Loss: 2.3270, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [294/469], Loss: 2.3244, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [295/469], Loss: 2.3376, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [2/50], Step [296/469], Loss: 2.3084, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [2/50], Step [297/469], Loss: 2.3492, batch time: 0.43, accuracy:  8.59%\n",
      "Epoch [2/50], Step [298/469], Loss: 2.3360, batch time: 0.42, accuracy:  7.81%\n",
      "Epoch [2/50], Step [299/469], Loss: 2.3326, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [300/469], Loss: 2.3419, batch time: 0.44, accuracy:  10.16%\n",
      "Epoch [2/50], Step [301/469], Loss: 2.3761, batch time: 0.47, accuracy:  9.38%\n",
      "Epoch [2/50], Step [302/469], Loss: 2.3239, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [2/50], Step [303/469], Loss: 2.3476, batch time: 0.44, accuracy:  8.59%\n",
      "Epoch [2/50], Step [304/469], Loss: 2.3415, batch time: 0.47, accuracy:  8.59%\n",
      "Epoch [2/50], Step [305/469], Loss: 2.3164, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [306/469], Loss: 2.3151, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [307/469], Loss: 2.3176, batch time: 0.46, accuracy:  5.47%\n",
      "Epoch [2/50], Step [308/469], Loss: 2.3038, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [309/469], Loss: 2.3115, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [2/50], Step [310/469], Loss: 2.3256, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [2/50], Step [311/469], Loss: 2.3041, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [2/50], Step [312/469], Loss: 2.3158, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [2/50], Step [313/469], Loss: 2.3211, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [314/469], Loss: 2.3359, batch time: 0.39, accuracy:  11.72%\n",
      "Epoch [2/50], Step [315/469], Loss: 2.3178, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [316/469], Loss: 2.3127, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [2/50], Step [317/469], Loss: 2.2987, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [2/50], Step [318/469], Loss: 2.2854, batch time: 0.39, accuracy:  19.53%\n",
      "Epoch [2/50], Step [319/469], Loss: 2.3064, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [320/469], Loss: 2.3138, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [321/469], Loss: 2.3117, batch time: 0.39, accuracy:  11.72%\n",
      "Epoch [2/50], Step [322/469], Loss: 2.3362, batch time: 0.47, accuracy:  10.94%\n",
      "Epoch [2/50], Step [323/469], Loss: 2.3264, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [324/469], Loss: 2.2898, batch time: 0.39, accuracy:  17.19%\n",
      "Epoch [2/50], Step [325/469], Loss: 2.3236, batch time: 0.39, accuracy:  14.84%\n",
      "Epoch [2/50], Step [326/469], Loss: 2.3211, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [2/50], Step [327/469], Loss: 2.3433, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [328/469], Loss: 2.3350, batch time: 0.39, accuracy:  10.16%\n",
      "Epoch [2/50], Step [329/469], Loss: 2.3033, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [330/469], Loss: 2.3386, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [2/50], Step [331/469], Loss: 2.3119, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [332/469], Loss: 2.3224, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [333/469], Loss: 2.3426, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [334/469], Loss: 2.3275, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [2/50], Step [335/469], Loss: 2.3162, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [336/469], Loss: 2.3054, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [337/469], Loss: 2.2918, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [338/469], Loss: 2.3073, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [339/469], Loss: 2.3250, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [340/469], Loss: 2.3190, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [341/469], Loss: 2.3165, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [342/469], Loss: 2.3011, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [343/469], Loss: 2.3538, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [2/50], Step [344/469], Loss: 2.3212, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [2/50], Step [345/469], Loss: 2.3273, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [346/469], Loss: 2.2728, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [2/50], Step [347/469], Loss: 2.3297, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [2/50], Step [348/469], Loss: 2.2912, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [2/50], Step [349/469], Loss: 2.3200, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [350/469], Loss: 2.2925, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [351/469], Loss: 2.3233, batch time: 0.46, accuracy:  15.62%\n",
      "Epoch [2/50], Step [352/469], Loss: 2.3104, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [353/469], Loss: 2.3187, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [2/50], Step [354/469], Loss: 2.3650, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [355/469], Loss: 2.3287, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [356/469], Loss: 2.3336, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [357/469], Loss: 2.3328, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [358/469], Loss: 2.3128, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [359/469], Loss: 2.2909, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [360/469], Loss: 2.2998, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [361/469], Loss: 2.3260, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [362/469], Loss: 2.3144, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [363/469], Loss: 2.3308, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [2/50], Step [364/469], Loss: 2.3225, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [365/469], Loss: 2.2929, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [366/469], Loss: 2.3056, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [367/469], Loss: 2.3115, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [2/50], Step [368/469], Loss: 2.3261, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [369/469], Loss: 2.3210, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [370/469], Loss: 2.3254, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [371/469], Loss: 2.3109, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [372/469], Loss: 2.3484, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [373/469], Loss: 2.3199, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [374/469], Loss: 2.3197, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [375/469], Loss: 2.3198, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [376/469], Loss: 2.3073, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [2/50], Step [377/469], Loss: 2.3245, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [2/50], Step [378/469], Loss: 2.3284, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [379/469], Loss: 2.3005, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [380/469], Loss: 2.3505, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [381/469], Loss: 2.3209, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [382/469], Loss: 2.3301, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [383/469], Loss: 2.3378, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [384/469], Loss: 2.3407, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [2/50], Step [385/469], Loss: 2.3134, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [386/469], Loss: 2.3301, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [387/469], Loss: 2.3026, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [388/469], Loss: 2.3210, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [389/469], Loss: 2.3058, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [390/469], Loss: 2.3277, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [2/50], Step [391/469], Loss: 2.3118, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [392/469], Loss: 2.3468, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [393/469], Loss: 2.3137, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [394/469], Loss: 2.3162, batch time: 0.46, accuracy:  13.28%\n",
      "Epoch [2/50], Step [395/469], Loss: 2.2847, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [2/50], Step [396/469], Loss: 2.3352, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [397/469], Loss: 2.3052, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [398/469], Loss: 2.3154, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [399/469], Loss: 2.3164, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [400/469], Loss: 2.3065, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [401/469], Loss: 2.3091, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [402/469], Loss: 2.3101, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [403/469], Loss: 2.3018, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [404/469], Loss: 2.3004, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [2/50], Step [405/469], Loss: 2.3472, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [406/469], Loss: 2.2997, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [407/469], Loss: 2.3149, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [408/469], Loss: 2.2958, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [409/469], Loss: 2.3401, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [410/469], Loss: 2.3206, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [411/469], Loss: 2.2843, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [2/50], Step [412/469], Loss: 2.2753, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [2/50], Step [413/469], Loss: 2.3108, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [414/469], Loss: 2.2984, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [415/469], Loss: 2.3025, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [2/50], Step [416/469], Loss: 2.2932, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [417/469], Loss: 2.3232, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [418/469], Loss: 2.3341, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [419/469], Loss: 2.3257, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [2/50], Step [420/469], Loss: 2.3280, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [421/469], Loss: 2.3481, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [2/50], Step [422/469], Loss: 2.3134, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [423/469], Loss: 2.3198, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [424/469], Loss: 2.3095, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [425/469], Loss: 2.3072, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [2/50], Step [426/469], Loss: 2.3114, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [427/469], Loss: 2.3231, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [2/50], Step [428/469], Loss: 2.2917, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [2/50], Step [429/469], Loss: 2.3060, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [2/50], Step [430/469], Loss: 2.3472, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [431/469], Loss: 2.3351, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [432/469], Loss: 2.3369, batch time: 0.42, accuracy:  5.47%\n",
      "Epoch [2/50], Step [433/469], Loss: 2.3346, batch time: 0.42, accuracy:  7.03%\n",
      "Epoch [2/50], Step [434/469], Loss: 2.3099, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [2/50], Step [435/469], Loss: 2.2969, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [2/50], Step [436/469], Loss: 2.3110, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [437/469], Loss: 2.3044, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [2/50], Step [438/469], Loss: 2.3147, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [439/469], Loss: 2.3279, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [440/469], Loss: 2.3256, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [2/50], Step [441/469], Loss: 2.3028, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [442/469], Loss: 2.2755, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [2/50], Step [443/469], Loss: 2.2833, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [2/50], Step [444/469], Loss: 2.3175, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [2/50], Step [445/469], Loss: 2.3403, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [2/50], Step [446/469], Loss: 2.3123, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [447/469], Loss: 2.3363, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [2/50], Step [448/469], Loss: 2.3137, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [2/50], Step [449/469], Loss: 2.2954, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [450/469], Loss: 2.3250, batch time: 0.46, accuracy:  9.38%\n",
      "Epoch [2/50], Step [451/469], Loss: 2.3261, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [2/50], Step [452/469], Loss: 2.3248, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [453/469], Loss: 2.3273, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [454/469], Loss: 2.3336, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [2/50], Step [455/469], Loss: 2.3034, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [456/469], Loss: 2.3559, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [2/50], Step [457/469], Loss: 2.3287, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [458/469], Loss: 2.3343, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [2/50], Step [459/469], Loss: 2.3323, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [2/50], Step [460/469], Loss: 2.2866, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [2/50], Step [461/469], Loss: 2.3313, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [2/50], Step [462/469], Loss: 2.2952, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [2/50], Step [463/469], Loss: 2.3261, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [464/469], Loss: 2.3276, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [2/50], Step [465/469], Loss: 2.3348, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [466/469], Loss: 2.3108, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [2/50], Step [467/469], Loss: 2.2910, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [2/50], Step [468/469], Loss: 2.2952, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [2/50], Step [469/469], Loss: 2.3095, batch time: 0.41, accuracy:  10.42%\n",
      "Epoch [3/50], Step [1/469], Loss: 2.2955, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [2/469], Loss: 2.3067, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [3/469], Loss: 2.3196, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [4/469], Loss: 2.3368, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [5/469], Loss: 2.3139, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [6/469], Loss: 2.3112, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [7/469], Loss: 2.3264, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [8/469], Loss: 2.3050, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [9/469], Loss: 2.3058, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [10/469], Loss: 2.3060, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [11/469], Loss: 2.2978, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [3/50], Step [12/469], Loss: 2.3408, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [13/469], Loss: 2.3309, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [14/469], Loss: 2.3316, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [3/50], Step [15/469], Loss: 2.2989, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [16/469], Loss: 2.3148, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [17/469], Loss: 2.3387, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [18/469], Loss: 2.3133, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [3/50], Step [19/469], Loss: 2.3099, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [20/469], Loss: 2.2965, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [21/469], Loss: 2.3159, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [22/469], Loss: 2.2989, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [23/469], Loss: 2.3418, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [24/469], Loss: 2.3080, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [25/469], Loss: 2.3155, batch time: 0.46, accuracy:  7.81%\n",
      "Epoch [3/50], Step [26/469], Loss: 2.3369, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [27/469], Loss: 2.3097, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [28/469], Loss: 2.2757, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [29/469], Loss: 2.3460, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [30/469], Loss: 2.3139, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [31/469], Loss: 2.2957, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [3/50], Step [32/469], Loss: 2.3048, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [3/50], Step [33/469], Loss: 2.3092, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [34/469], Loss: 2.3129, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [35/469], Loss: 2.2979, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [36/469], Loss: 2.3168, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [37/469], Loss: 2.3224, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [38/469], Loss: 2.3360, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [39/469], Loss: 2.3310, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [40/469], Loss: 2.3099, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [41/469], Loss: 2.3161, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [42/469], Loss: 2.3094, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [43/469], Loss: 2.2995, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [44/469], Loss: 2.3058, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [45/469], Loss: 2.3012, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [46/469], Loss: 2.3030, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [47/469], Loss: 2.3143, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [48/469], Loss: 2.3019, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [49/469], Loss: 2.2938, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [50/469], Loss: 2.3161, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [51/469], Loss: 2.3064, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [52/469], Loss: 2.3420, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [53/469], Loss: 2.3256, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [3/50], Step [54/469], Loss: 2.3075, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [55/469], Loss: 2.3291, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [56/469], Loss: 2.3355, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [57/469], Loss: 2.2975, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [58/469], Loss: 2.2790, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [59/469], Loss: 2.3078, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [60/469], Loss: 2.3222, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [61/469], Loss: 2.3125, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [62/469], Loss: 2.3164, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [63/469], Loss: 2.3363, batch time: 0.46, accuracy:  10.16%\n",
      "Epoch [3/50], Step [64/469], Loss: 2.3220, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [65/469], Loss: 2.3230, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [66/469], Loss: 2.3171, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [67/469], Loss: 2.2993, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [68/469], Loss: 2.2805, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [3/50], Step [69/469], Loss: 2.3105, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [70/469], Loss: 2.3188, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [71/469], Loss: 2.3155, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [72/469], Loss: 2.3291, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [73/469], Loss: 2.2943, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [3/50], Step [74/469], Loss: 2.3127, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [75/469], Loss: 2.3061, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [76/469], Loss: 2.3343, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [77/469], Loss: 2.3015, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [78/469], Loss: 2.3139, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [79/469], Loss: 2.2913, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [3/50], Step [80/469], Loss: 2.3092, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [3/50], Step [81/469], Loss: 2.3325, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [82/469], Loss: 2.2946, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [83/469], Loss: 2.2784, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [84/469], Loss: 2.3010, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [85/469], Loss: 2.2880, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [86/469], Loss: 2.3000, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [87/469], Loss: 2.3046, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [88/469], Loss: 2.2997, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [89/469], Loss: 2.3473, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [90/469], Loss: 2.3145, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [91/469], Loss: 2.3090, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [92/469], Loss: 2.3078, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [93/469], Loss: 2.3289, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [3/50], Step [94/469], Loss: 2.3157, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [95/469], Loss: 2.2918, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [3/50], Step [96/469], Loss: 2.2802, batch time: 0.47, accuracy:  16.41%\n",
      "Epoch [3/50], Step [97/469], Loss: 2.2889, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [3/50], Step [98/469], Loss: 2.3213, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [3/50], Step [99/469], Loss: 2.2958, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [100/469], Loss: 2.3192, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [3/50], Step [101/469], Loss: 2.3369, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [3/50], Step [102/469], Loss: 2.3257, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [103/469], Loss: 2.3022, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [3/50], Step [104/469], Loss: 2.3125, batch time: 0.46, accuracy:  12.50%\n",
      "Epoch [3/50], Step [105/469], Loss: 2.3078, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [106/469], Loss: 2.3123, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [3/50], Step [107/469], Loss: 2.3186, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [3/50], Step [108/469], Loss: 2.3377, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [3/50], Step [109/469], Loss: 2.3093, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [3/50], Step [110/469], Loss: 2.3017, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [3/50], Step [111/469], Loss: 2.3178, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [112/469], Loss: 2.3287, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [3/50], Step [113/469], Loss: 2.3154, batch time: 0.45, accuracy:  13.28%\n",
      "Epoch [3/50], Step [114/469], Loss: 2.2840, batch time: 0.46, accuracy:  14.84%\n",
      "Epoch [3/50], Step [115/469], Loss: 2.2988, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [116/469], Loss: 2.3126, batch time: 0.45, accuracy:  13.28%\n",
      "Epoch [3/50], Step [117/469], Loss: 2.3123, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [118/469], Loss: 2.3242, batch time: 0.43, accuracy:  9.38%\n",
      "Epoch [3/50], Step [119/469], Loss: 2.3077, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [3/50], Step [120/469], Loss: 2.2978, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [121/469], Loss: 2.2866, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [122/469], Loss: 2.3015, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [123/469], Loss: 2.3129, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [3/50], Step [124/469], Loss: 2.3300, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [3/50], Step [125/469], Loss: 2.3068, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [3/50], Step [126/469], Loss: 2.3079, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [3/50], Step [127/469], Loss: 2.2900, batch time: 0.39, accuracy:  13.28%\n",
      "Epoch [3/50], Step [128/469], Loss: 2.3071, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [129/469], Loss: 2.3366, batch time: 0.44, accuracy:  8.59%\n",
      "Epoch [3/50], Step [130/469], Loss: 2.3373, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [131/469], Loss: 2.3154, batch time: 0.39, accuracy:  15.62%\n",
      "Epoch [3/50], Step [132/469], Loss: 2.3032, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [3/50], Step [133/469], Loss: 2.3177, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [134/469], Loss: 2.3120, batch time: 0.39, accuracy:  11.72%\n",
      "Epoch [3/50], Step [135/469], Loss: 2.3233, batch time: 0.43, accuracy:  8.59%\n",
      "Epoch [3/50], Step [136/469], Loss: 2.3099, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [137/469], Loss: 2.2789, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [3/50], Step [138/469], Loss: 2.3175, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [139/469], Loss: 2.3307, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [3/50], Step [140/469], Loss: 2.3108, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [3/50], Step [141/469], Loss: 2.3193, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [3/50], Step [142/469], Loss: 2.3179, batch time: 0.47, accuracy:  12.50%\n",
      "Epoch [3/50], Step [143/469], Loss: 2.3126, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [3/50], Step [144/469], Loss: 2.3027, batch time: 0.46, accuracy:  14.06%\n",
      "Epoch [3/50], Step [145/469], Loss: 2.2992, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [3/50], Step [146/469], Loss: 2.3139, batch time: 0.45, accuracy:  12.50%\n",
      "Epoch [3/50], Step [147/469], Loss: 2.3017, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [148/469], Loss: 2.3064, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [149/469], Loss: 2.3225, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [150/469], Loss: 2.2957, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [3/50], Step [151/469], Loss: 2.3136, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [152/469], Loss: 2.3074, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [153/469], Loss: 2.3323, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [154/469], Loss: 2.2889, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [155/469], Loss: 2.3025, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [3/50], Step [156/469], Loss: 2.3185, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [157/469], Loss: 2.3273, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [158/469], Loss: 2.2969, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [159/469], Loss: 2.3033, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [160/469], Loss: 2.2967, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [161/469], Loss: 2.2973, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [3/50], Step [162/469], Loss: 2.3020, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [163/469], Loss: 2.3072, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [164/469], Loss: 2.3075, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [165/469], Loss: 2.2772, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [3/50], Step [166/469], Loss: 2.2862, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [167/469], Loss: 2.2682, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [3/50], Step [168/469], Loss: 2.2941, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [169/469], Loss: 2.2859, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [170/469], Loss: 2.3244, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [171/469], Loss: 2.3010, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [172/469], Loss: 2.2889, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [3/50], Step [173/469], Loss: 2.2932, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [174/469], Loss: 2.2809, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [3/50], Step [175/469], Loss: 2.3041, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [176/469], Loss: 2.2983, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [177/469], Loss: 2.3203, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [178/469], Loss: 2.3301, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [179/469], Loss: 2.3090, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [180/469], Loss: 2.3013, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [181/469], Loss: 2.2846, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [3/50], Step [182/469], Loss: 2.3190, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [183/469], Loss: 2.3165, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [184/469], Loss: 2.2880, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [185/469], Loss: 2.3258, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [186/469], Loss: 2.3169, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [3/50], Step [187/469], Loss: 2.2589, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [188/469], Loss: 2.3219, batch time: 0.41, accuracy:  4.69%\n",
      "Epoch [3/50], Step [189/469], Loss: 2.3089, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [190/469], Loss: 2.3014, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [191/469], Loss: 2.2880, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [192/469], Loss: 2.3145, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [193/469], Loss: 2.2978, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [194/469], Loss: 2.3046, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [3/50], Step [195/469], Loss: 2.2986, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [196/469], Loss: 2.2943, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [197/469], Loss: 2.3172, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [198/469], Loss: 2.3110, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [199/469], Loss: 2.3035, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [200/469], Loss: 2.3046, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [201/469], Loss: 2.3028, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [202/469], Loss: 2.2932, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [3/50], Step [203/469], Loss: 2.3355, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [204/469], Loss: 2.2904, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [205/469], Loss: 2.3006, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [3/50], Step [206/469], Loss: 2.3358, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [3/50], Step [207/469], Loss: 2.2942, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [208/469], Loss: 2.3065, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [209/469], Loss: 2.2999, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [210/469], Loss: 2.3154, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [211/469], Loss: 2.2983, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [212/469], Loss: 2.2967, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [213/469], Loss: 2.2936, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [214/469], Loss: 2.3139, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [3/50], Step [215/469], Loss: 2.3053, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [216/469], Loss: 2.2981, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [217/469], Loss: 2.3310, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [218/469], Loss: 2.3004, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [219/469], Loss: 2.2989, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [220/469], Loss: 2.2776, batch time: 0.46, accuracy:  14.06%\n",
      "Epoch [3/50], Step [221/469], Loss: 2.2873, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [3/50], Step [222/469], Loss: 2.3028, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [223/469], Loss: 2.2961, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [224/469], Loss: 2.3135, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [3/50], Step [225/469], Loss: 2.2984, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [226/469], Loss: 2.3232, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [227/469], Loss: 2.3170, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [228/469], Loss: 2.3061, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [229/469], Loss: 2.2960, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [230/469], Loss: 2.2946, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [231/469], Loss: 2.3385, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [232/469], Loss: 2.3093, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [233/469], Loss: 2.3037, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [3/50], Step [234/469], Loss: 2.3361, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [235/469], Loss: 2.3026, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [236/469], Loss: 2.3022, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [237/469], Loss: 2.2967, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [238/469], Loss: 2.2982, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [239/469], Loss: 2.2900, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [240/469], Loss: 2.3153, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [241/469], Loss: 2.3079, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [242/469], Loss: 2.3094, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [243/469], Loss: 2.3244, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [244/469], Loss: 2.2929, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [245/469], Loss: 2.3046, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [246/469], Loss: 2.3059, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [247/469], Loss: 2.3415, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [248/469], Loss: 2.2951, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [249/469], Loss: 2.3140, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [250/469], Loss: 2.2860, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [251/469], Loss: 2.3056, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [252/469], Loss: 2.3043, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [253/469], Loss: 2.3038, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [254/469], Loss: 2.3090, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [255/469], Loss: 2.2854, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [3/50], Step [256/469], Loss: 2.3282, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [257/469], Loss: 2.2835, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [258/469], Loss: 2.3118, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [259/469], Loss: 2.2971, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [260/469], Loss: 2.3041, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [261/469], Loss: 2.3185, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [3/50], Step [262/469], Loss: 2.2834, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [263/469], Loss: 2.3158, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [3/50], Step [264/469], Loss: 2.3016, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [265/469], Loss: 2.3227, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [266/469], Loss: 2.2861, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [267/469], Loss: 2.3038, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [268/469], Loss: 2.3082, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [3/50], Step [269/469], Loss: 2.3155, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [270/469], Loss: 2.3077, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [271/469], Loss: 2.2847, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [3/50], Step [272/469], Loss: 2.2920, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [273/469], Loss: 2.3115, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [274/469], Loss: 2.2690, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [275/469], Loss: 2.3152, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [276/469], Loss: 2.3012, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [277/469], Loss: 2.2881, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [278/469], Loss: 2.2594, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [3/50], Step [279/469], Loss: 2.2940, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [280/469], Loss: 2.2917, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [3/50], Step [281/469], Loss: 2.3058, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [282/469], Loss: 2.3052, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [283/469], Loss: 2.2846, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [284/469], Loss: 2.3004, batch time: 0.46, accuracy:  15.62%\n",
      "Epoch [3/50], Step [285/469], Loss: 2.2990, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [286/469], Loss: 2.2925, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [287/469], Loss: 2.3090, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [288/469], Loss: 2.2968, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [289/469], Loss: 2.3002, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [290/469], Loss: 2.3086, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [291/469], Loss: 2.3047, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [3/50], Step [292/469], Loss: 2.3121, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [293/469], Loss: 2.2953, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [294/469], Loss: 2.3004, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [295/469], Loss: 2.3250, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [296/469], Loss: 2.3158, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [297/469], Loss: 2.2804, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [298/469], Loss: 2.2960, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [299/469], Loss: 2.3057, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [3/50], Step [300/469], Loss: 2.2933, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [301/469], Loss: 2.3190, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [302/469], Loss: 2.2849, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [3/50], Step [303/469], Loss: 2.3127, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [304/469], Loss: 2.3174, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [305/469], Loss: 2.2787, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [3/50], Step [306/469], Loss: 2.3268, batch time: 0.42, accuracy:  6.25%\n",
      "Epoch [3/50], Step [307/469], Loss: 2.3026, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [308/469], Loss: 2.2813, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [309/469], Loss: 2.3102, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [310/469], Loss: 2.2949, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [3/50], Step [311/469], Loss: 2.3142, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [312/469], Loss: 2.3074, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [313/469], Loss: 2.2979, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [3/50], Step [314/469], Loss: 2.3054, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [315/469], Loss: 2.3083, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [316/469], Loss: 2.3021, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [317/469], Loss: 2.3012, batch time: 0.46, accuracy:  13.28%\n",
      "Epoch [3/50], Step [318/469], Loss: 2.2966, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [319/469], Loss: 2.2729, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [3/50], Step [320/469], Loss: 2.3171, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [321/469], Loss: 2.3100, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [3/50], Step [322/469], Loss: 2.3212, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [3/50], Step [323/469], Loss: 2.2888, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [324/469], Loss: 2.2831, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [325/469], Loss: 2.3129, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [3/50], Step [326/469], Loss: 2.2671, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [327/469], Loss: 2.3161, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [3/50], Step [328/469], Loss: 2.2993, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [329/469], Loss: 2.3097, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [330/469], Loss: 2.2987, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [331/469], Loss: 2.3073, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [332/469], Loss: 2.3067, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [333/469], Loss: 2.2830, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [334/469], Loss: 2.2967, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [335/469], Loss: 2.3112, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [336/469], Loss: 2.2804, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [337/469], Loss: 2.3037, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [338/469], Loss: 2.2968, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [339/469], Loss: 2.3054, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [340/469], Loss: 2.3129, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [341/469], Loss: 2.2961, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [342/469], Loss: 2.3022, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [343/469], Loss: 2.3045, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [344/469], Loss: 2.2873, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [3/50], Step [345/469], Loss: 2.3043, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [346/469], Loss: 2.2974, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [347/469], Loss: 2.3115, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [3/50], Step [348/469], Loss: 2.2975, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [349/469], Loss: 2.3156, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [350/469], Loss: 2.3119, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [3/50], Step [351/469], Loss: 2.2946, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [352/469], Loss: 2.3238, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [3/50], Step [353/469], Loss: 2.3105, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [354/469], Loss: 2.3054, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [355/469], Loss: 2.2999, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [3/50], Step [356/469], Loss: 2.2709, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [3/50], Step [357/469], Loss: 2.3011, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [358/469], Loss: 2.3025, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [359/469], Loss: 2.3063, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [360/469], Loss: 2.3362, batch time: 0.40, accuracy:  4.69%\n",
      "Epoch [3/50], Step [361/469], Loss: 2.3068, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [362/469], Loss: 2.2972, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [363/469], Loss: 2.3069, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [364/469], Loss: 2.3073, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [3/50], Step [365/469], Loss: 2.3174, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [366/469], Loss: 2.3064, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [367/469], Loss: 2.3279, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [368/469], Loss: 2.2977, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [369/469], Loss: 2.2831, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [370/469], Loss: 2.3082, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [371/469], Loss: 2.2923, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [372/469], Loss: 2.2743, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [373/469], Loss: 2.3040, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [374/469], Loss: 2.2901, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [375/469], Loss: 2.2890, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [376/469], Loss: 2.3113, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [377/469], Loss: 2.3051, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [3/50], Step [378/469], Loss: 2.2892, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [379/469], Loss: 2.2950, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [380/469], Loss: 2.2857, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [381/469], Loss: 2.2818, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [382/469], Loss: 2.2899, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [3/50], Step [383/469], Loss: 2.2861, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [3/50], Step [384/469], Loss: 2.3025, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [3/50], Step [385/469], Loss: 2.2721, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [3/50], Step [386/469], Loss: 2.2782, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [387/469], Loss: 2.3069, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [388/469], Loss: 2.2876, batch time: 0.46, accuracy:  15.62%\n",
      "Epoch [3/50], Step [389/469], Loss: 2.2913, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [390/469], Loss: 2.2767, batch time: 0.45, accuracy:  11.72%\n",
      "Epoch [3/50], Step [391/469], Loss: 2.3029, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [3/50], Step [392/469], Loss: 2.2946, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [3/50], Step [393/469], Loss: 2.3066, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [394/469], Loss: 2.3055, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [395/469], Loss: 2.2882, batch time: 0.45, accuracy:  16.41%\n",
      "Epoch [3/50], Step [396/469], Loss: 2.3106, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [3/50], Step [397/469], Loss: 2.3072, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [3/50], Step [398/469], Loss: 2.3089, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [399/469], Loss: 2.3183, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [400/469], Loss: 2.3017, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [3/50], Step [401/469], Loss: 2.2878, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [3/50], Step [402/469], Loss: 2.2995, batch time: 0.46, accuracy:  11.72%\n",
      "Epoch [3/50], Step [403/469], Loss: 2.3193, batch time: 0.40, accuracy:  3.91%\n",
      "Epoch [3/50], Step [404/469], Loss: 2.2936, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [405/469], Loss: 2.3044, batch time: 0.42, accuracy:  6.25%\n",
      "Epoch [3/50], Step [406/469], Loss: 2.2983, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [3/50], Step [407/469], Loss: 2.3167, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [3/50], Step [408/469], Loss: 2.3062, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [409/469], Loss: 2.3045, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [3/50], Step [410/469], Loss: 2.2938, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [3/50], Step [411/469], Loss: 2.3030, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [3/50], Step [412/469], Loss: 2.2802, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [3/50], Step [413/469], Loss: 2.3134, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [414/469], Loss: 2.3095, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [3/50], Step [415/469], Loss: 2.2836, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [3/50], Step [416/469], Loss: 2.3097, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [417/469], Loss: 2.3105, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [418/469], Loss: 2.3113, batch time: 0.42, accuracy:  7.81%\n",
      "Epoch [3/50], Step [419/469], Loss: 2.2874, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [420/469], Loss: 2.2782, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [3/50], Step [421/469], Loss: 2.3051, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [3/50], Step [422/469], Loss: 2.3182, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [423/469], Loss: 2.3160, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [424/469], Loss: 2.2797, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [3/50], Step [425/469], Loss: 2.3100, batch time: 0.42, accuracy:  6.25%\n",
      "Epoch [3/50], Step [426/469], Loss: 2.3001, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [427/469], Loss: 2.2790, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [3/50], Step [428/469], Loss: 2.2953, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [3/50], Step [429/469], Loss: 2.3110, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [430/469], Loss: 2.2994, batch time: 0.39, accuracy:  11.72%\n",
      "Epoch [3/50], Step [431/469], Loss: 2.2879, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [432/469], Loss: 2.2885, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [433/469], Loss: 2.3015, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [434/469], Loss: 2.2952, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [3/50], Step [435/469], Loss: 2.2932, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [436/469], Loss: 2.2914, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [437/469], Loss: 2.2820, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [3/50], Step [438/469], Loss: 2.2968, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [439/469], Loss: 2.2792, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [3/50], Step [440/469], Loss: 2.2794, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [441/469], Loss: 2.2820, batch time: 0.47, accuracy:  12.50%\n",
      "Epoch [3/50], Step [442/469], Loss: 2.2986, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [443/469], Loss: 2.2939, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [444/469], Loss: 2.3127, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [445/469], Loss: 2.2878, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [446/469], Loss: 2.2889, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [447/469], Loss: 2.3043, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [448/469], Loss: 2.2980, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [449/469], Loss: 2.2924, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [3/50], Step [450/469], Loss: 2.2865, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [451/469], Loss: 2.3016, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [3/50], Step [452/469], Loss: 2.3016, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [3/50], Step [453/469], Loss: 2.3023, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [454/469], Loss: 2.3048, batch time: 0.40, accuracy:  5.47%\n",
      "Epoch [3/50], Step [455/469], Loss: 2.3237, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [456/469], Loss: 2.3171, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [3/50], Step [457/469], Loss: 2.3033, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [3/50], Step [458/469], Loss: 2.2860, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [3/50], Step [459/469], Loss: 2.2769, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [3/50], Step [460/469], Loss: 2.2827, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [3/50], Step [461/469], Loss: 2.2828, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [3/50], Step [462/469], Loss: 2.3060, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [3/50], Step [463/469], Loss: 2.2833, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [464/469], Loss: 2.2878, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [3/50], Step [465/469], Loss: 2.2955, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [3/50], Step [466/469], Loss: 2.3047, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [3/50], Step [467/469], Loss: 2.2776, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [3/50], Step [468/469], Loss: 2.2846, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [3/50], Step [469/469], Loss: 2.3114, batch time: 0.41, accuracy:  10.42%\n",
      "Epoch [4/50], Step [1/469], Loss: 2.2714, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [2/469], Loss: 2.2857, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [3/469], Loss: 2.3000, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [4/469], Loss: 2.2911, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [5/469], Loss: 2.2967, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [6/469], Loss: 2.3023, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [7/469], Loss: 2.3218, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [8/469], Loss: 2.2843, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [4/50], Step [9/469], Loss: 2.2871, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [10/469], Loss: 2.3035, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [4/50], Step [11/469], Loss: 2.2828, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [12/469], Loss: 2.2912, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [4/50], Step [13/469], Loss: 2.2892, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [14/469], Loss: 2.2870, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [15/469], Loss: 2.3006, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [16/469], Loss: 2.2914, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [17/469], Loss: 2.2919, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [18/469], Loss: 2.2839, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [19/469], Loss: 2.2837, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [4/50], Step [20/469], Loss: 2.3088, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [21/469], Loss: 2.3125, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [4/50], Step [22/469], Loss: 2.2906, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [23/469], Loss: 2.3026, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [24/469], Loss: 2.2902, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [25/469], Loss: 2.3216, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [26/469], Loss: 2.2953, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [27/469], Loss: 2.3013, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [28/469], Loss: 2.2998, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [4/50], Step [29/469], Loss: 2.3068, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [4/50], Step [30/469], Loss: 2.2881, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [31/469], Loss: 2.2921, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [32/469], Loss: 2.2872, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [4/50], Step [33/469], Loss: 2.3135, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [34/469], Loss: 2.2804, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [35/469], Loss: 2.3288, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [4/50], Step [36/469], Loss: 2.3011, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [37/469], Loss: 2.3175, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [38/469], Loss: 2.2737, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [4/50], Step [39/469], Loss: 2.2841, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [40/469], Loss: 2.2819, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [41/469], Loss: 2.2930, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [42/469], Loss: 2.3029, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [43/469], Loss: 2.2937, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [4/50], Step [44/469], Loss: 2.2852, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [45/469], Loss: 2.2997, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [46/469], Loss: 2.2959, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [4/50], Step [47/469], Loss: 2.2875, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [48/469], Loss: 2.3191, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [4/50], Step [49/469], Loss: 2.3036, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [50/469], Loss: 2.3139, batch time: 0.46, accuracy:  7.81%\n",
      "Epoch [4/50], Step [51/469], Loss: 2.3087, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [52/469], Loss: 2.2998, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [53/469], Loss: 2.2803, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [54/469], Loss: 2.2990, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [55/469], Loss: 2.2929, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [4/50], Step [56/469], Loss: 2.2924, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [57/469], Loss: 2.2868, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [4/50], Step [58/469], Loss: 2.2920, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [59/469], Loss: 2.2982, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [60/469], Loss: 2.2845, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [4/50], Step [61/469], Loss: 2.3136, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [4/50], Step [62/469], Loss: 2.3067, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [63/469], Loss: 2.3037, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [64/469], Loss: 2.3101, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [65/469], Loss: 2.2832, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [66/469], Loss: 2.3018, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [4/50], Step [67/469], Loss: 2.2978, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [68/469], Loss: 2.2939, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [69/469], Loss: 2.2831, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [70/469], Loss: 2.2830, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [71/469], Loss: 2.2885, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [72/469], Loss: 2.3029, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [73/469], Loss: 2.3239, batch time: 0.41, accuracy:  6.25%\n",
      "Epoch [4/50], Step [74/469], Loss: 2.3005, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [75/469], Loss: 2.2896, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [76/469], Loss: 2.2763, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [77/469], Loss: 2.2914, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [78/469], Loss: 2.2910, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [4/50], Step [79/469], Loss: 2.2913, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [80/469], Loss: 2.2978, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [81/469], Loss: 2.3032, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [4/50], Step [82/469], Loss: 2.3040, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [83/469], Loss: 2.3050, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [4/50], Step [84/469], Loss: 2.2964, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [4/50], Step [85/469], Loss: 2.2883, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [86/469], Loss: 2.2798, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [4/50], Step [87/469], Loss: 2.2961, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [88/469], Loss: 2.3018, batch time: 0.40, accuracy:  6.25%\n",
      "Epoch [4/50], Step [89/469], Loss: 2.2960, batch time: 0.41, accuracy:  5.47%\n",
      "Epoch [4/50], Step [90/469], Loss: 2.2821, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [91/469], Loss: 2.2912, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [4/50], Step [92/469], Loss: 2.3006, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [4/50], Step [93/469], Loss: 2.2820, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [4/50], Step [94/469], Loss: 2.2732, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [95/469], Loss: 2.2841, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [96/469], Loss: 2.3025, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [97/469], Loss: 2.2693, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [4/50], Step [98/469], Loss: 2.3035, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [4/50], Step [99/469], Loss: 2.2875, batch time: 0.41, accuracy:  7.03%\n",
      "Epoch [4/50], Step [100/469], Loss: 2.2774, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [4/50], Step [101/469], Loss: 2.3200, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [4/50], Step [102/469], Loss: 2.2920, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [103/469], Loss: 2.3013, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [104/469], Loss: 2.2859, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [4/50], Step [105/469], Loss: 2.3026, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [4/50], Step [106/469], Loss: 2.2987, batch time: 0.47, accuracy:  14.06%\n",
      "Epoch [4/50], Step [107/469], Loss: 2.3003, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [108/469], Loss: 2.2724, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [109/469], Loss: 2.3081, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [110/469], Loss: 2.3069, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [111/469], Loss: 2.2899, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [112/469], Loss: 2.2919, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [113/469], Loss: 2.2931, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [114/469], Loss: 2.2964, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [115/469], Loss: 2.3140, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [4/50], Step [116/469], Loss: 2.2908, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [4/50], Step [117/469], Loss: 2.3227, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [118/469], Loss: 2.3015, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [119/469], Loss: 2.2649, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [120/469], Loss: 2.2837, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [121/469], Loss: 2.3019, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [122/469], Loss: 2.2786, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [123/469], Loss: 2.2687, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [4/50], Step [124/469], Loss: 2.3094, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [125/469], Loss: 2.2861, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [126/469], Loss: 2.3052, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [4/50], Step [127/469], Loss: 2.2790, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [128/469], Loss: 2.2856, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [129/469], Loss: 2.2862, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [130/469], Loss: 2.3044, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [4/50], Step [131/469], Loss: 2.2806, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [4/50], Step [132/469], Loss: 2.3017, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [133/469], Loss: 2.2934, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [4/50], Step [134/469], Loss: 2.2748, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [135/469], Loss: 2.3031, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [4/50], Step [136/469], Loss: 2.2860, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [4/50], Step [137/469], Loss: 2.2962, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [138/469], Loss: 2.2973, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [139/469], Loss: 2.3072, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [4/50], Step [140/469], Loss: 2.2821, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [141/469], Loss: 2.2542, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [4/50], Step [142/469], Loss: 2.2742, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [143/469], Loss: 2.2934, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [4/50], Step [144/469], Loss: 2.3130, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [145/469], Loss: 2.2976, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [146/469], Loss: 2.2897, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [147/469], Loss: 2.2922, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [4/50], Step [148/469], Loss: 2.2915, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [149/469], Loss: 2.2806, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [150/469], Loss: 2.2998, batch time: 0.46, accuracy:  7.81%\n",
      "Epoch [4/50], Step [151/469], Loss: 2.2711, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [152/469], Loss: 2.2899, batch time: 0.40, accuracy:  7.03%\n",
      "Epoch [4/50], Step [153/469], Loss: 2.3000, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [154/469], Loss: 2.3058, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [155/469], Loss: 2.2914, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [4/50], Step [156/469], Loss: 2.2795, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [4/50], Step [157/469], Loss: 2.2970, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [158/469], Loss: 2.2964, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [159/469], Loss: 2.2873, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [160/469], Loss: 2.2724, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [4/50], Step [161/469], Loss: 2.3178, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [162/469], Loss: 2.3150, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [4/50], Step [163/469], Loss: 2.3121, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [164/469], Loss: 2.2957, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [165/469], Loss: 2.2934, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [4/50], Step [166/469], Loss: 2.2867, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [167/469], Loss: 2.2831, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [4/50], Step [168/469], Loss: 2.3142, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [169/469], Loss: 2.3167, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [170/469], Loss: 2.2866, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [4/50], Step [171/469], Loss: 2.2769, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [4/50], Step [172/469], Loss: 2.3023, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [173/469], Loss: 2.2998, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [174/469], Loss: 2.2992, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [175/469], Loss: 2.2905, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [4/50], Step [176/469], Loss: 2.2908, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [177/469], Loss: 2.3158, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [178/469], Loss: 2.2902, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [179/469], Loss: 2.3063, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [4/50], Step [180/469], Loss: 2.2813, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [4/50], Step [181/469], Loss: 2.3039, batch time: 0.40, accuracy:  7.81%\n",
      "Epoch [4/50], Step [182/469], Loss: 2.2729, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [4/50], Step [183/469], Loss: 2.2724, batch time: 0.40, accuracy:  18.75%\n",
      "Epoch [4/50], Step [184/469], Loss: 2.2988, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [4/50], Step [185/469], Loss: 2.2875, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [186/469], Loss: 2.2878, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [187/469], Loss: 2.3034, batch time: 0.41, accuracy:  3.91%\n",
      "Epoch [4/50], Step [188/469], Loss: 2.3074, batch time: 0.45, accuracy:  9.38%\n",
      "Epoch [4/50], Step [189/469], Loss: 2.2949, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [190/469], Loss: 2.2942, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [4/50], Step [191/469], Loss: 2.2813, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [192/469], Loss: 2.2926, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [193/469], Loss: 2.2853, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [4/50], Step [194/469], Loss: 2.2914, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [195/469], Loss: 2.2870, batch time: 0.45, accuracy:  12.50%\n",
      "Epoch [4/50], Step [196/469], Loss: 2.3000, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [197/469], Loss: 2.3049, batch time: 0.42, accuracy:  6.25%\n",
      "Epoch [4/50], Step [198/469], Loss: 2.3238, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [199/469], Loss: 2.2983, batch time: 0.42, accuracy:  7.81%\n",
      "Epoch [4/50], Step [200/469], Loss: 2.2847, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [201/469], Loss: 2.2881, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [4/50], Step [202/469], Loss: 2.2926, batch time: 0.42, accuracy:  7.03%\n",
      "Epoch [4/50], Step [203/469], Loss: 2.2819, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [204/469], Loss: 2.3017, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [4/50], Step [205/469], Loss: 2.2922, batch time: 0.41, accuracy:  7.81%\n",
      "Epoch [4/50], Step [206/469], Loss: 2.2985, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [4/50], Step [207/469], Loss: 2.2745, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [4/50], Step [208/469], Loss: 2.2780, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [4/50], Step [209/469], Loss: 2.2819, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [4/50], Step [210/469], Loss: 2.3021, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [4/50], Step [211/469], Loss: 2.2973, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [4/50], Step [212/469], Loss: 2.3049, batch time: 0.42, accuracy:  5.47%\n",
      "Epoch [4/50], Step [213/469], Loss: 2.2776, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [4/50], Step [214/469], Loss: 2.2876, batch time: 0.43, accuracy:  7.81%\n",
      "Epoch [4/50], Step [215/469], Loss: 2.2927, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [4/50], Step [216/469], Loss: 2.2907, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [4/50], Step [217/469], Loss: 2.3035, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [218/469], Loss: 2.3003, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [4/50], Step [219/469], Loss: 2.2931, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [220/469], Loss: 2.2907, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [221/469], Loss: 2.2876, batch time: 0.49, accuracy:  12.50%\n",
      "Epoch [4/50], Step [222/469], Loss: 2.2903, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [4/50], Step [223/469], Loss: 2.3018, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [4/50], Step [224/469], Loss: 2.2739, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [4/50], Step [225/469], Loss: 2.2779, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [4/50], Step [226/469], Loss: 2.2957, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [4/50], Step [227/469], Loss: 2.2953, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [4/50], Step [228/469], Loss: 2.2757, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [4/50], Step [229/469], Loss: 2.3044, batch time: 0.43, accuracy:  7.81%\n",
      "Epoch [4/50], Step [230/469], Loss: 2.2727, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [231/469], Loss: 2.3111, batch time: 0.42, accuracy:  7.81%\n",
      "Epoch [4/50], Step [232/469], Loss: 2.2820, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [4/50], Step [233/469], Loss: 2.2817, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [4/50], Step [234/469], Loss: 2.2791, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [4/50], Step [235/469], Loss: 2.2946, batch time: 0.43, accuracy:  9.38%\n",
      "Epoch [4/50], Step [236/469], Loss: 2.2926, batch time: 0.44, accuracy:  10.16%\n",
      "Epoch [4/50], Step [237/469], Loss: 2.2842, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [238/469], Loss: 2.2858, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [4/50], Step [239/469], Loss: 2.3134, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [240/469], Loss: 2.2937, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [241/469], Loss: 2.2642, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [4/50], Step [242/469], Loss: 2.3145, batch time: 0.45, accuracy:  13.28%\n",
      "Epoch [4/50], Step [243/469], Loss: 2.3015, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [244/469], Loss: 2.2780, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [4/50], Step [245/469], Loss: 2.3024, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [4/50], Step [246/469], Loss: 2.3014, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [4/50], Step [247/469], Loss: 2.3155, batch time: 0.43, accuracy:  9.38%\n",
      "Epoch [4/50], Step [248/469], Loss: 2.2949, batch time: 0.45, accuracy:  12.50%\n",
      "Epoch [4/50], Step [249/469], Loss: 2.2721, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [4/50], Step [250/469], Loss: 2.2964, batch time: 0.40, accuracy:  10.94%\n",
      "Epoch [4/50], Step [251/469], Loss: 2.2754, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [4/50], Step [252/469], Loss: 2.2830, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [4/50], Step [253/469], Loss: 2.3027, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [254/469], Loss: 2.2854, batch time: 0.44, accuracy:  10.16%\n",
      "Epoch [4/50], Step [255/469], Loss: 2.2899, batch time: 0.43, accuracy:  9.38%\n",
      "Epoch [4/50], Step [256/469], Loss: 2.2901, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [4/50], Step [257/469], Loss: 2.2881, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [258/469], Loss: 2.2831, batch time: 0.45, accuracy:  14.06%\n",
      "Epoch [4/50], Step [259/469], Loss: 2.3098, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [260/469], Loss: 2.2877, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [4/50], Step [261/469], Loss: 2.2735, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [4/50], Step [262/469], Loss: 2.2983, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [4/50], Step [263/469], Loss: 2.2907, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [4/50], Step [264/469], Loss: 2.2942, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [4/50], Step [265/469], Loss: 2.2857, batch time: 0.45, accuracy:  13.28%\n",
      "Epoch [4/50], Step [266/469], Loss: 2.2945, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [267/469], Loss: 2.2849, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [4/50], Step [268/469], Loss: 2.2933, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [4/50], Step [269/469], Loss: 2.2644, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [270/469], Loss: 2.2929, batch time: 0.45, accuracy:  15.62%\n",
      "Epoch [4/50], Step [271/469], Loss: 2.2640, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [4/50], Step [272/469], Loss: 2.2711, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [4/50], Step [273/469], Loss: 2.2888, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [274/469], Loss: 2.2889, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [4/50], Step [275/469], Loss: 2.2782, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [276/469], Loss: 2.3061, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [4/50], Step [277/469], Loss: 2.2953, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [278/469], Loss: 2.3097, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [279/469], Loss: 2.2926, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [4/50], Step [280/469], Loss: 2.2782, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [4/50], Step [281/469], Loss: 2.2857, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [282/469], Loss: 2.2901, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [4/50], Step [283/469], Loss: 2.2910, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [4/50], Step [284/469], Loss: 2.2583, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [4/50], Step [285/469], Loss: 2.2728, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [4/50], Step [286/469], Loss: 2.2869, batch time: 0.43, accuracy:  8.59%\n",
      "Epoch [4/50], Step [287/469], Loss: 2.2670, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [4/50], Step [288/469], Loss: 2.2851, batch time: 0.42, accuracy:  9.38%\n",
      "Epoch [4/50], Step [289/469], Loss: 2.2843, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [4/50], Step [290/469], Loss: 2.2707, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [4/50], Step [291/469], Loss: 2.2919, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [292/469], Loss: 2.3065, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [293/469], Loss: 2.2654, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [4/50], Step [294/469], Loss: 2.2793, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [4/50], Step [295/469], Loss: 2.3234, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [296/469], Loss: 2.2765, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [297/469], Loss: 2.2706, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [4/50], Step [298/469], Loss: 2.2924, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [4/50], Step [299/469], Loss: 2.2875, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [300/469], Loss: 2.3118, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [301/469], Loss: 2.2783, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [302/469], Loss: 2.2872, batch time: 0.40, accuracy:  9.38%\n",
      "Epoch [4/50], Step [303/469], Loss: 2.3106, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [304/469], Loss: 2.2859, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [4/50], Step [305/469], Loss: 2.2909, batch time: 0.45, accuracy:  13.28%\n",
      "Epoch [4/50], Step [306/469], Loss: 2.2930, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [4/50], Step [307/469], Loss: 2.2962, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [4/50], Step [308/469], Loss: 2.2802, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [4/50], Step [309/469], Loss: 2.2953, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [4/50], Step [310/469], Loss: 2.2891, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [4/50], Step [311/469], Loss: 2.2782, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [4/50], Step [312/469], Loss: 2.2998, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [4/50], Step [313/469], Loss: 2.2984, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [4/50], Step [314/469], Loss: 2.3043, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [4/50], Step [315/469], Loss: 2.2651, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [4/50], Step [316/469], Loss: 2.2816, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [4/50], Step [317/469], Loss: 2.2949, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [4/50], Step [318/469], Loss: 2.2989, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [4/50], Step [319/469], Loss: 2.2865, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [320/469], Loss: 2.2949, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [4/50], Step [321/469], Loss: 2.2889, batch time: 0.45, accuracy:  14.06%\n",
      "Epoch [4/50], Step [322/469], Loss: 2.2933, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [323/469], Loss: 2.2902, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [4/50], Step [324/469], Loss: 2.2757, batch time: 0.45, accuracy:  14.84%\n",
      "Epoch [4/50], Step [325/469], Loss: 2.2949, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [4/50], Step [326/469], Loss: 2.2848, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [4/50], Step [327/469], Loss: 2.2711, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [4/50], Step [328/469], Loss: 2.2942, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [4/50], Step [329/469], Loss: 2.2769, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [330/469], Loss: 2.2964, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [331/469], Loss: 2.2679, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [4/50], Step [332/469], Loss: 2.2974, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [333/469], Loss: 2.3071, batch time: 0.44, accuracy:  9.38%\n",
      "Epoch [4/50], Step [334/469], Loss: 2.2890, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [4/50], Step [335/469], Loss: 2.2763, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [4/50], Step [336/469], Loss: 2.2990, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [4/50], Step [337/469], Loss: 2.2907, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [4/50], Step [338/469], Loss: 2.2938, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [339/469], Loss: 2.2835, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [4/50], Step [340/469], Loss: 2.2770, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [341/469], Loss: 2.2991, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [4/50], Step [342/469], Loss: 2.2935, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [4/50], Step [343/469], Loss: 2.2928, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [4/50], Step [344/469], Loss: 2.2928, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [4/50], Step [345/469], Loss: 2.2932, batch time: 0.47, accuracy:  15.62%\n",
      "Epoch [4/50], Step [346/469], Loss: 2.2848, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [4/50], Step [347/469], Loss: 2.2884, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [4/50], Step [348/469], Loss: 2.2915, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [4/50], Step [349/469], Loss: 2.3115, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [350/469], Loss: 2.2993, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [4/50], Step [351/469], Loss: 2.2995, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [4/50], Step [352/469], Loss: 2.2831, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [4/50], Step [353/469], Loss: 2.2824, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [4/50], Step [354/469], Loss: 2.2923, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [355/469], Loss: 2.2880, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [4/50], Step [356/469], Loss: 2.2873, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [4/50], Step [357/469], Loss: 2.2832, batch time: 0.44, accuracy:  10.16%\n",
      "Epoch [4/50], Step [358/469], Loss: 2.2854, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [4/50], Step [359/469], Loss: 2.2811, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [4/50], Step [360/469], Loss: 2.2827, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [4/50], Step [361/469], Loss: 2.2764, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [4/50], Step [362/469], Loss: 2.2882, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [363/469], Loss: 2.2935, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [4/50], Step [364/469], Loss: 2.2830, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [365/469], Loss: 2.2937, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [366/469], Loss: 2.2787, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [367/469], Loss: 2.2948, batch time: 0.41, accuracy:  8.59%\n",
      "Epoch [4/50], Step [368/469], Loss: 2.2900, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [4/50], Step [369/469], Loss: 2.3047, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [4/50], Step [370/469], Loss: 2.2919, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [4/50], Step [371/469], Loss: 2.2842, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [4/50], Step [372/469], Loss: 2.2720, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [373/469], Loss: 2.2617, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [4/50], Step [374/469], Loss: 2.2946, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [4/50], Step [375/469], Loss: 2.2958, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [376/469], Loss: 2.2778, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [4/50], Step [377/469], Loss: 2.2824, batch time: 0.45, accuracy:  15.62%\n",
      "Epoch [4/50], Step [378/469], Loss: 2.3060, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [4/50], Step [379/469], Loss: 2.3053, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [4/50], Step [380/469], Loss: 2.2730, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [4/50], Step [381/469], Loss: 2.3006, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [4/50], Step [382/469], Loss: 2.2713, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [4/50], Step [383/469], Loss: 2.2689, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [4/50], Step [384/469], Loss: 2.2913, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [4/50], Step [385/469], Loss: 2.2928, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [4/50], Step [386/469], Loss: 2.2878, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [4/50], Step [387/469], Loss: 2.2982, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [4/50], Step [388/469], Loss: 2.2886, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [4/50], Step [389/469], Loss: 2.2864, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [4/50], Step [390/469], Loss: 2.2863, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [4/50], Step [391/469], Loss: 2.2910, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [4/50], Step [392/469], Loss: 2.2653, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [4/50], Step [393/469], Loss: 2.2744, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [4/50], Step [394/469], Loss: 2.2758, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [4/50], Step [395/469], Loss: 2.3030, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [4/50], Step [396/469], Loss: 2.2775, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [4/50], Step [397/469], Loss: 2.2730, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [4/50], Step [398/469], Loss: 2.2834, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [399/469], Loss: 2.2716, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [4/50], Step [400/469], Loss: 2.2870, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [4/50], Step [401/469], Loss: 2.2725, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [4/50], Step [402/469], Loss: 2.2738, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [4/50], Step [403/469], Loss: 2.2881, batch time: 0.45, accuracy:  14.84%\n",
      "Epoch [4/50], Step [404/469], Loss: 2.2883, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [405/469], Loss: 2.2892, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [4/50], Step [406/469], Loss: 2.2715, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [407/469], Loss: 2.2897, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [408/469], Loss: 2.2965, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [409/469], Loss: 2.2621, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [4/50], Step [410/469], Loss: 2.2778, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [4/50], Step [411/469], Loss: 2.2821, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [4/50], Step [412/469], Loss: 2.2853, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [4/50], Step [413/469], Loss: 2.2839, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [4/50], Step [414/469], Loss: 2.2849, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [4/50], Step [415/469], Loss: 2.2799, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [4/50], Step [416/469], Loss: 2.2752, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [4/50], Step [417/469], Loss: 2.2884, batch time: 0.43, accuracy:  11.72%\n",
      "Epoch [4/50], Step [418/469], Loss: 2.2707, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [4/50], Step [419/469], Loss: 2.2637, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [420/469], Loss: 2.3011, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [421/469], Loss: 2.2998, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [422/469], Loss: 2.2927, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [4/50], Step [423/469], Loss: 2.3155, batch time: 0.49, accuracy:  9.38%\n",
      "Epoch [4/50], Step [424/469], Loss: 2.3046, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [4/50], Step [425/469], Loss: 2.2732, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [4/50], Step [426/469], Loss: 2.2680, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [4/50], Step [427/469], Loss: 2.2827, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [4/50], Step [428/469], Loss: 2.2928, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [4/50], Step [429/469], Loss: 2.2955, batch time: 0.40, accuracy:  8.59%\n",
      "Epoch [4/50], Step [430/469], Loss: 2.2755, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [4/50], Step [431/469], Loss: 2.3073, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [4/50], Step [432/469], Loss: 2.2852, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [433/469], Loss: 2.2946, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [4/50], Step [434/469], Loss: 2.2991, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [435/469], Loss: 2.2888, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [4/50], Step [436/469], Loss: 2.2938, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [4/50], Step [437/469], Loss: 2.3013, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [4/50], Step [438/469], Loss: 2.3032, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [439/469], Loss: 2.2881, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [4/50], Step [440/469], Loss: 2.2742, batch time: 0.40, accuracy:  18.75%\n",
      "Epoch [4/50], Step [441/469], Loss: 2.2706, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [4/50], Step [442/469], Loss: 2.2824, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [443/469], Loss: 2.2889, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [4/50], Step [444/469], Loss: 2.2864, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [4/50], Step [445/469], Loss: 2.2932, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [4/50], Step [446/469], Loss: 2.2704, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [4/50], Step [447/469], Loss: 2.2929, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [4/50], Step [448/469], Loss: 2.2755, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [4/50], Step [449/469], Loss: 2.2996, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [4/50], Step [450/469], Loss: 2.3043, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [4/50], Step [451/469], Loss: 2.2918, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [4/50], Step [452/469], Loss: 2.2785, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [4/50], Step [453/469], Loss: 2.2831, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [4/50], Step [454/469], Loss: 2.2994, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [4/50], Step [455/469], Loss: 2.2822, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [4/50], Step [456/469], Loss: 2.3020, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [4/50], Step [457/469], Loss: 2.3020, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [4/50], Step [458/469], Loss: 2.2844, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [4/50], Step [459/469], Loss: 2.2954, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [4/50], Step [460/469], Loss: 2.2838, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [4/50], Step [461/469], Loss: 2.3009, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [4/50], Step [462/469], Loss: 2.3004, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [4/50], Step [463/469], Loss: 2.3000, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [4/50], Step [464/469], Loss: 2.2816, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [4/50], Step [465/469], Loss: 2.2635, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [4/50], Step [466/469], Loss: 2.2867, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [4/50], Step [467/469], Loss: 2.2715, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [4/50], Step [468/469], Loss: 2.2807, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [4/50], Step [469/469], Loss: 2.2823, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [5/50], Step [1/469], Loss: 2.3055, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [5/50], Step [2/469], Loss: 2.2898, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [5/50], Step [3/469], Loss: 2.2815, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [5/50], Step [4/469], Loss: 2.2938, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [5/50], Step [5/469], Loss: 2.2849, batch time: 0.42, accuracy:  8.59%\n",
      "Epoch [5/50], Step [6/469], Loss: 2.2687, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [5/50], Step [7/469], Loss: 2.2473, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [8/469], Loss: 2.2739, batch time: 0.44, accuracy:  10.16%\n",
      "Epoch [5/50], Step [9/469], Loss: 2.2846, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [10/469], Loss: 2.2955, batch time: 0.49, accuracy:  14.06%\n",
      "Epoch [5/50], Step [11/469], Loss: 2.2754, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [12/469], Loss: 2.2915, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [5/50], Step [13/469], Loss: 2.2729, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [14/469], Loss: 2.2789, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [5/50], Step [15/469], Loss: 2.2718, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [16/469], Loss: 2.2984, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [5/50], Step [17/469], Loss: 2.2968, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [5/50], Step [18/469], Loss: 2.2878, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [5/50], Step [19/469], Loss: 2.2529, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [20/469], Loss: 2.2980, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [5/50], Step [21/469], Loss: 2.2716, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [22/469], Loss: 2.2872, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [5/50], Step [23/469], Loss: 2.2822, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [24/469], Loss: 2.2982, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [5/50], Step [25/469], Loss: 2.2769, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [26/469], Loss: 2.2812, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [5/50], Step [27/469], Loss: 2.2859, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [28/469], Loss: 2.2867, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [5/50], Step [29/469], Loss: 2.2815, batch time: 0.45, accuracy:  18.75%\n",
      "Epoch [5/50], Step [30/469], Loss: 2.2742, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [5/50], Step [31/469], Loss: 2.2782, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [32/469], Loss: 2.3004, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [5/50], Step [33/469], Loss: 2.2779, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [5/50], Step [34/469], Loss: 2.3014, batch time: 0.40, accuracy:  10.16%\n",
      "Epoch [5/50], Step [35/469], Loss: 2.2805, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [5/50], Step [36/469], Loss: 2.2862, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [5/50], Step [37/469], Loss: 2.2902, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [5/50], Step [38/469], Loss: 2.2861, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [5/50], Step [39/469], Loss: 2.2878, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [5/50], Step [40/469], Loss: 2.2931, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [5/50], Step [41/469], Loss: 2.2968, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [42/469], Loss: 2.2913, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [5/50], Step [43/469], Loss: 2.2833, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [5/50], Step [44/469], Loss: 2.3039, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [5/50], Step [45/469], Loss: 2.2751, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [5/50], Step [46/469], Loss: 2.2884, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [47/469], Loss: 2.2722, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [5/50], Step [48/469], Loss: 2.2877, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [49/469], Loss: 2.2853, batch time: 0.45, accuracy:  15.62%\n",
      "Epoch [5/50], Step [50/469], Loss: 2.3056, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [5/50], Step [51/469], Loss: 2.2982, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [52/469], Loss: 2.2906, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [53/469], Loss: 2.3191, batch time: 0.44, accuracy:  10.16%\n",
      "Epoch [5/50], Step [54/469], Loss: 2.2797, batch time: 0.50, accuracy:  18.75%\n",
      "Epoch [5/50], Step [55/469], Loss: 2.2819, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [5/50], Step [56/469], Loss: 2.3194, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [5/50], Step [57/469], Loss: 2.2790, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [5/50], Step [58/469], Loss: 2.2812, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [5/50], Step [59/469], Loss: 2.2992, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [60/469], Loss: 2.2903, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [5/50], Step [61/469], Loss: 2.2827, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [5/50], Step [62/469], Loss: 2.2737, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [63/469], Loss: 2.2723, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [5/50], Step [64/469], Loss: 2.2710, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [5/50], Step [65/469], Loss: 2.2918, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [5/50], Step [66/469], Loss: 2.2768, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [67/469], Loss: 2.2848, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [68/469], Loss: 2.2981, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [69/469], Loss: 2.2958, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [70/469], Loss: 2.2802, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [71/469], Loss: 2.3067, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [72/469], Loss: 2.2850, batch time: 0.43, accuracy:  10.16%\n",
      "Epoch [5/50], Step [73/469], Loss: 2.2748, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [5/50], Step [74/469], Loss: 2.2703, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [5/50], Step [75/469], Loss: 2.2816, batch time: 0.45, accuracy:  13.28%\n",
      "Epoch [5/50], Step [76/469], Loss: 2.2871, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [77/469], Loss: 2.2904, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [5/50], Step [78/469], Loss: 2.3062, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [5/50], Step [79/469], Loss: 2.2601, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [5/50], Step [80/469], Loss: 2.2826, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [81/469], Loss: 2.3037, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [5/50], Step [82/469], Loss: 2.2872, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [83/469], Loss: 2.2780, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [84/469], Loss: 2.2702, batch time: 0.40, accuracy:  21.09%\n",
      "Epoch [5/50], Step [85/469], Loss: 2.2724, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [5/50], Step [86/469], Loss: 2.2832, batch time: 0.43, accuracy:  8.59%\n",
      "Epoch [5/50], Step [87/469], Loss: 2.2864, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [5/50], Step [88/469], Loss: 2.2963, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [5/50], Step [89/469], Loss: 2.2794, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [5/50], Step [90/469], Loss: 2.2652, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [5/50], Step [91/469], Loss: 2.2705, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [5/50], Step [92/469], Loss: 2.2947, batch time: 0.46, accuracy:  8.59%\n",
      "Epoch [5/50], Step [93/469], Loss: 2.2773, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [5/50], Step [94/469], Loss: 2.2870, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [5/50], Step [95/469], Loss: 2.2823, batch time: 0.43, accuracy:  9.38%\n",
      "Epoch [5/50], Step [96/469], Loss: 2.2737, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [97/469], Loss: 2.2887, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [98/469], Loss: 2.2831, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [5/50], Step [99/469], Loss: 2.2859, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [5/50], Step [100/469], Loss: 2.3025, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [5/50], Step [101/469], Loss: 2.2989, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [5/50], Step [102/469], Loss: 2.2705, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [5/50], Step [103/469], Loss: 2.2754, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [104/469], Loss: 2.2755, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [105/469], Loss: 2.2684, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [106/469], Loss: 2.2958, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [5/50], Step [107/469], Loss: 2.2716, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [5/50], Step [108/469], Loss: 2.2819, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [109/469], Loss: 2.2824, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [5/50], Step [110/469], Loss: 2.2902, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [5/50], Step [111/469], Loss: 2.2741, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [112/469], Loss: 2.2853, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [5/50], Step [113/469], Loss: 2.2916, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [5/50], Step [114/469], Loss: 2.2822, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [115/469], Loss: 2.2861, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [5/50], Step [116/469], Loss: 2.2958, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [5/50], Step [117/469], Loss: 2.2670, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [118/469], Loss: 2.2775, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [5/50], Step [119/469], Loss: 2.2824, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [120/469], Loss: 2.2639, batch time: 0.47, accuracy:  16.41%\n",
      "Epoch [5/50], Step [121/469], Loss: 2.2826, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [122/469], Loss: 2.2883, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [123/469], Loss: 2.3047, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [124/469], Loss: 2.2779, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [125/469], Loss: 2.2940, batch time: 0.48, accuracy:  16.41%\n",
      "Epoch [5/50], Step [126/469], Loss: 2.2649, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [5/50], Step [127/469], Loss: 2.2780, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [128/469], Loss: 2.2692, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [129/469], Loss: 2.2862, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [130/469], Loss: 2.2628, batch time: 0.46, accuracy:  25.00%\n",
      "Epoch [5/50], Step [131/469], Loss: 2.2876, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [5/50], Step [132/469], Loss: 2.2668, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [5/50], Step [133/469], Loss: 2.2869, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [5/50], Step [134/469], Loss: 2.2898, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [135/469], Loss: 2.2484, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [136/469], Loss: 2.3120, batch time: 0.44, accuracy:  10.16%\n",
      "Epoch [5/50], Step [137/469], Loss: 2.2939, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [138/469], Loss: 2.2528, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [5/50], Step [139/469], Loss: 2.2628, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [140/469], Loss: 2.2933, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [141/469], Loss: 2.2600, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [5/50], Step [142/469], Loss: 2.2723, batch time: 0.45, accuracy:  15.62%\n",
      "Epoch [5/50], Step [143/469], Loss: 2.2810, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [144/469], Loss: 2.3029, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [5/50], Step [145/469], Loss: 2.2780, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [146/469], Loss: 2.2603, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [5/50], Step [147/469], Loss: 2.2732, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [5/50], Step [148/469], Loss: 2.2638, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [149/469], Loss: 2.2692, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [150/469], Loss: 2.2514, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [5/50], Step [151/469], Loss: 2.2947, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [152/469], Loss: 2.2835, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [153/469], Loss: 2.2749, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [5/50], Step [154/469], Loss: 2.2744, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [155/469], Loss: 2.2848, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [156/469], Loss: 2.2897, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [157/469], Loss: 2.2871, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [158/469], Loss: 2.3018, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [159/469], Loss: 2.2718, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [160/469], Loss: 2.2727, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [5/50], Step [161/469], Loss: 2.3029, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [162/469], Loss: 2.2790, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [5/50], Step [163/469], Loss: 2.2842, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [164/469], Loss: 2.2705, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [165/469], Loss: 2.2829, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [5/50], Step [166/469], Loss: 2.2571, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [167/469], Loss: 2.2892, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [168/469], Loss: 2.2962, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [5/50], Step [169/469], Loss: 2.2801, batch time: 0.49, accuracy:  15.62%\n",
      "Epoch [5/50], Step [170/469], Loss: 2.2808, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [171/469], Loss: 2.2811, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [172/469], Loss: 2.2881, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [173/469], Loss: 2.2837, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [174/469], Loss: 2.2860, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [5/50], Step [175/469], Loss: 2.2733, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [5/50], Step [176/469], Loss: 2.2913, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [5/50], Step [177/469], Loss: 2.2845, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [5/50], Step [178/469], Loss: 2.2793, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [179/469], Loss: 2.2914, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [180/469], Loss: 2.2752, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [5/50], Step [181/469], Loss: 2.2625, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [5/50], Step [182/469], Loss: 2.2731, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [5/50], Step [183/469], Loss: 2.2763, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [5/50], Step [184/469], Loss: 2.3106, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [5/50], Step [185/469], Loss: 2.2848, batch time: 0.45, accuracy:  14.84%\n",
      "Epoch [5/50], Step [186/469], Loss: 2.2730, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [187/469], Loss: 2.2765, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [5/50], Step [188/469], Loss: 2.2866, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [5/50], Step [189/469], Loss: 2.2796, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [5/50], Step [190/469], Loss: 2.2844, batch time: 0.40, accuracy:  11.72%\n",
      "Epoch [5/50], Step [191/469], Loss: 2.2748, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [5/50], Step [192/469], Loss: 2.2790, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [193/469], Loss: 2.2769, batch time: 0.40, accuracy:  21.09%\n",
      "Epoch [5/50], Step [194/469], Loss: 2.2806, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [5/50], Step [195/469], Loss: 2.2639, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [5/50], Step [196/469], Loss: 2.2519, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [197/469], Loss: 2.2842, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [198/469], Loss: 2.2729, batch time: 0.48, accuracy:  25.78%\n",
      "Epoch [5/50], Step [199/469], Loss: 2.2686, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [5/50], Step [200/469], Loss: 2.2939, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [5/50], Step [201/469], Loss: 2.2934, batch time: 0.44, accuracy:  8.59%\n",
      "Epoch [5/50], Step [202/469], Loss: 2.2707, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [203/469], Loss: 2.2998, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [204/469], Loss: 2.2979, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [205/469], Loss: 2.2800, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [5/50], Step [206/469], Loss: 2.2884, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [207/469], Loss: 2.2877, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [5/50], Step [208/469], Loss: 2.2936, batch time: 0.49, accuracy:  19.53%\n",
      "Epoch [5/50], Step [209/469], Loss: 2.2980, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [210/469], Loss: 2.2959, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [5/50], Step [211/469], Loss: 2.3029, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [5/50], Step [212/469], Loss: 2.2704, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [213/469], Loss: 2.2644, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [5/50], Step [214/469], Loss: 2.2876, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [5/50], Step [215/469], Loss: 2.3087, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [5/50], Step [216/469], Loss: 2.2674, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [5/50], Step [217/469], Loss: 2.2604, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [5/50], Step [218/469], Loss: 2.2674, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [5/50], Step [219/469], Loss: 2.2744, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [220/469], Loss: 2.2805, batch time: 0.40, accuracy:  21.88%\n",
      "Epoch [5/50], Step [221/469], Loss: 2.2698, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [5/50], Step [222/469], Loss: 2.2723, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [223/469], Loss: 2.2926, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [224/469], Loss: 2.2803, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [5/50], Step [225/469], Loss: 2.2678, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [226/469], Loss: 2.2740, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [5/50], Step [227/469], Loss: 2.2639, batch time: 0.40, accuracy:  18.75%\n",
      "Epoch [5/50], Step [228/469], Loss: 2.2875, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [229/469], Loss: 2.2839, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [230/469], Loss: 2.2809, batch time: 0.44, accuracy:  24.22%\n",
      "Epoch [5/50], Step [231/469], Loss: 2.2772, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [232/469], Loss: 2.2769, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [5/50], Step [233/469], Loss: 2.2611, batch time: 0.44, accuracy:  25.00%\n",
      "Epoch [5/50], Step [234/469], Loss: 2.2936, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [235/469], Loss: 2.2716, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [5/50], Step [236/469], Loss: 2.2771, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [237/469], Loss: 2.2921, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [5/50], Step [238/469], Loss: 2.2783, batch time: 0.40, accuracy:  25.00%\n",
      "Epoch [5/50], Step [239/469], Loss: 2.2778, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [5/50], Step [240/469], Loss: 2.2681, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [241/469], Loss: 2.2736, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [5/50], Step [242/469], Loss: 2.2708, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [5/50], Step [243/469], Loss: 2.2843, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [5/50], Step [244/469], Loss: 2.2721, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [5/50], Step [245/469], Loss: 2.2852, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [246/469], Loss: 2.2626, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [5/50], Step [247/469], Loss: 2.2753, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [248/469], Loss: 2.2930, batch time: 0.45, accuracy:  13.28%\n",
      "Epoch [5/50], Step [249/469], Loss: 2.2914, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [5/50], Step [250/469], Loss: 2.2855, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [5/50], Step [251/469], Loss: 2.2835, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [252/469], Loss: 2.2912, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [253/469], Loss: 2.2731, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [5/50], Step [254/469], Loss: 2.2592, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [5/50], Step [255/469], Loss: 2.2554, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [5/50], Step [256/469], Loss: 2.2710, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [5/50], Step [257/469], Loss: 2.2905, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [258/469], Loss: 2.2515, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [259/469], Loss: 2.2812, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [5/50], Step [260/469], Loss: 2.2771, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [261/469], Loss: 2.2783, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [5/50], Step [262/469], Loss: 2.2707, batch time: 0.40, accuracy:  18.75%\n",
      "Epoch [5/50], Step [263/469], Loss: 2.2995, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [5/50], Step [264/469], Loss: 2.2619, batch time: 0.48, accuracy:  24.22%\n",
      "Epoch [5/50], Step [265/469], Loss: 2.2865, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [5/50], Step [266/469], Loss: 2.2891, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [5/50], Step [267/469], Loss: 2.2534, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [5/50], Step [268/469], Loss: 2.2632, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [269/469], Loss: 2.2670, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [5/50], Step [270/469], Loss: 2.2711, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [5/50], Step [271/469], Loss: 2.2695, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [5/50], Step [272/469], Loss: 2.2594, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [5/50], Step [273/469], Loss: 2.2786, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [5/50], Step [274/469], Loss: 2.2655, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [5/50], Step [275/469], Loss: 2.2887, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [5/50], Step [276/469], Loss: 2.2828, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [5/50], Step [277/469], Loss: 2.2836, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [5/50], Step [278/469], Loss: 2.2759, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [5/50], Step [279/469], Loss: 2.2591, batch time: 0.44, accuracy:  25.00%\n",
      "Epoch [5/50], Step [280/469], Loss: 2.2545, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [5/50], Step [281/469], Loss: 2.2557, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [282/469], Loss: 2.2821, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [283/469], Loss: 2.2909, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [5/50], Step [284/469], Loss: 2.2907, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [285/469], Loss: 2.2668, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [286/469], Loss: 2.2837, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [5/50], Step [287/469], Loss: 2.2784, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [5/50], Step [288/469], Loss: 2.2508, batch time: 0.48, accuracy:  26.56%\n",
      "Epoch [5/50], Step [289/469], Loss: 2.2868, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [5/50], Step [290/469], Loss: 2.2784, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [291/469], Loss: 2.2802, batch time: 0.45, accuracy:  11.72%\n",
      "Epoch [5/50], Step [292/469], Loss: 2.2446, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [293/469], Loss: 2.2811, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [5/50], Step [294/469], Loss: 2.2581, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [5/50], Step [295/469], Loss: 2.2898, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [5/50], Step [296/469], Loss: 2.2822, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [297/469], Loss: 2.2665, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [298/469], Loss: 2.2855, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [299/469], Loss: 2.2822, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [5/50], Step [300/469], Loss: 2.2953, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [5/50], Step [301/469], Loss: 2.2523, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [302/469], Loss: 2.2966, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [303/469], Loss: 2.2676, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [5/50], Step [304/469], Loss: 2.2655, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [305/469], Loss: 2.2960, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [306/469], Loss: 2.2548, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [5/50], Step [307/469], Loss: 2.2902, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [308/469], Loss: 2.2763, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [5/50], Step [309/469], Loss: 2.2576, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [310/469], Loss: 2.2879, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [311/469], Loss: 2.2491, batch time: 0.40, accuracy:  22.66%\n",
      "Epoch [5/50], Step [312/469], Loss: 2.2592, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [313/469], Loss: 2.2689, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [314/469], Loss: 2.2633, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [5/50], Step [315/469], Loss: 2.3005, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [316/469], Loss: 2.2730, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [5/50], Step [317/469], Loss: 2.2946, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [5/50], Step [318/469], Loss: 2.2736, batch time: 0.45, accuracy:  20.31%\n",
      "Epoch [5/50], Step [319/469], Loss: 2.2592, batch time: 0.44, accuracy:  24.22%\n",
      "Epoch [5/50], Step [320/469], Loss: 2.2780, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [5/50], Step [321/469], Loss: 2.2783, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [322/469], Loss: 2.2919, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [5/50], Step [323/469], Loss: 2.2822, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [5/50], Step [324/469], Loss: 2.2529, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [5/50], Step [325/469], Loss: 2.2807, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [5/50], Step [326/469], Loss: 2.2767, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [5/50], Step [327/469], Loss: 2.2899, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [5/50], Step [328/469], Loss: 2.2765, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [5/50], Step [329/469], Loss: 2.2634, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [5/50], Step [330/469], Loss: 2.2619, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [5/50], Step [331/469], Loss: 2.2737, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [5/50], Step [332/469], Loss: 2.2787, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [333/469], Loss: 2.2692, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [334/469], Loss: 2.2547, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [5/50], Step [335/469], Loss: 2.2460, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [336/469], Loss: 2.2731, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [337/469], Loss: 2.2774, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [5/50], Step [338/469], Loss: 2.2931, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [5/50], Step [339/469], Loss: 2.2734, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [5/50], Step [340/469], Loss: 2.2792, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [5/50], Step [341/469], Loss: 2.2249, batch time: 0.43, accuracy:  27.34%\n",
      "Epoch [5/50], Step [342/469], Loss: 2.2817, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [343/469], Loss: 2.2753, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [344/469], Loss: 2.2731, batch time: 0.48, accuracy:  18.75%\n",
      "Epoch [5/50], Step [345/469], Loss: 2.2912, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [5/50], Step [346/469], Loss: 2.2868, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [5/50], Step [347/469], Loss: 2.2925, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [5/50], Step [348/469], Loss: 2.2585, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [5/50], Step [349/469], Loss: 2.2655, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [5/50], Step [350/469], Loss: 2.2457, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [5/50], Step [351/469], Loss: 2.2870, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [5/50], Step [352/469], Loss: 2.2839, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [5/50], Step [353/469], Loss: 2.2844, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [5/50], Step [354/469], Loss: 2.2851, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [355/469], Loss: 2.2561, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [5/50], Step [356/469], Loss: 2.2810, batch time: 0.45, accuracy:  17.97%\n",
      "Epoch [5/50], Step [357/469], Loss: 2.2886, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [5/50], Step [358/469], Loss: 2.2728, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [359/469], Loss: 2.2886, batch time: 0.43, accuracy:  9.38%\n",
      "Epoch [5/50], Step [360/469], Loss: 2.2770, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [361/469], Loss: 2.3001, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [5/50], Step [362/469], Loss: 2.3243, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [5/50], Step [363/469], Loss: 2.2730, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [364/469], Loss: 2.2579, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [5/50], Step [365/469], Loss: 2.2695, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [5/50], Step [366/469], Loss: 2.2758, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [367/469], Loss: 2.2639, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [368/469], Loss: 2.2809, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [5/50], Step [369/469], Loss: 2.2860, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [5/50], Step [370/469], Loss: 2.2620, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [5/50], Step [371/469], Loss: 2.2899, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [372/469], Loss: 2.2640, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [373/469], Loss: 2.2849, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [374/469], Loss: 2.2823, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [375/469], Loss: 2.2933, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [376/469], Loss: 2.2723, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [5/50], Step [377/469], Loss: 2.2942, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [5/50], Step [378/469], Loss: 2.2677, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [379/469], Loss: 2.2547, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [5/50], Step [380/469], Loss: 2.2732, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [381/469], Loss: 2.2660, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [5/50], Step [382/469], Loss: 2.2827, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [383/469], Loss: 2.2751, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [384/469], Loss: 2.2476, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [5/50], Step [385/469], Loss: 2.2544, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [5/50], Step [386/469], Loss: 2.2865, batch time: 0.45, accuracy:  17.19%\n",
      "Epoch [5/50], Step [387/469], Loss: 2.2732, batch time: 0.45, accuracy:  16.41%\n",
      "Epoch [5/50], Step [388/469], Loss: 2.2820, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [5/50], Step [389/469], Loss: 2.2664, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [5/50], Step [390/469], Loss: 2.2560, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [5/50], Step [391/469], Loss: 2.2511, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [5/50], Step [392/469], Loss: 2.2590, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [393/469], Loss: 2.2699, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [5/50], Step [394/469], Loss: 2.2602, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [5/50], Step [395/469], Loss: 2.2666, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [5/50], Step [396/469], Loss: 2.2670, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [5/50], Step [397/469], Loss: 2.2813, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [5/50], Step [398/469], Loss: 2.2639, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [399/469], Loss: 2.2475, batch time: 0.44, accuracy:  25.00%\n",
      "Epoch [5/50], Step [400/469], Loss: 2.2683, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [5/50], Step [401/469], Loss: 2.2978, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [402/469], Loss: 2.2712, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [403/469], Loss: 2.2721, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [404/469], Loss: 2.2731, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [405/469], Loss: 2.2527, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [5/50], Step [406/469], Loss: 2.2903, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [407/469], Loss: 2.2504, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [408/469], Loss: 2.2485, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [409/469], Loss: 2.2630, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [410/469], Loss: 2.2515, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [5/50], Step [411/469], Loss: 2.2512, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [5/50], Step [412/469], Loss: 2.2352, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [5/50], Step [413/469], Loss: 2.2876, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [5/50], Step [414/469], Loss: 2.2543, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [5/50], Step [415/469], Loss: 2.2761, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [5/50], Step [416/469], Loss: 2.2647, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [5/50], Step [417/469], Loss: 2.2554, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [5/50], Step [418/469], Loss: 2.2882, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [5/50], Step [419/469], Loss: 2.2384, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [5/50], Step [420/469], Loss: 2.2834, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [5/50], Step [421/469], Loss: 2.2276, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [5/50], Step [422/469], Loss: 2.2528, batch time: 0.49, accuracy:  23.44%\n",
      "Epoch [5/50], Step [423/469], Loss: 2.2764, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [424/469], Loss: 2.2572, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [425/469], Loss: 2.2594, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [5/50], Step [426/469], Loss: 2.2621, batch time: 0.43, accuracy:  14.06%\n",
      "Epoch [5/50], Step [427/469], Loss: 2.2946, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [5/50], Step [428/469], Loss: 2.2729, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [5/50], Step [429/469], Loss: 2.2623, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [5/50], Step [430/469], Loss: 2.2777, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [5/50], Step [431/469], Loss: 2.2713, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [5/50], Step [432/469], Loss: 2.2475, batch time: 0.44, accuracy:  26.56%\n",
      "Epoch [5/50], Step [433/469], Loss: 2.2577, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [434/469], Loss: 2.2656, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [435/469], Loss: 2.2823, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [436/469], Loss: 2.2926, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [5/50], Step [437/469], Loss: 2.2714, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [5/50], Step [438/469], Loss: 2.2991, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [5/50], Step [439/469], Loss: 2.2684, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [5/50], Step [440/469], Loss: 2.2654, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [441/469], Loss: 2.2597, batch time: 0.45, accuracy:  17.19%\n",
      "Epoch [5/50], Step [442/469], Loss: 2.2553, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [5/50], Step [443/469], Loss: 2.2672, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [5/50], Step [444/469], Loss: 2.2720, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [5/50], Step [445/469], Loss: 2.2615, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [5/50], Step [446/469], Loss: 2.2573, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [5/50], Step [447/469], Loss: 2.2898, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [5/50], Step [448/469], Loss: 2.2900, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [5/50], Step [449/469], Loss: 2.2358, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [5/50], Step [450/469], Loss: 2.2526, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [5/50], Step [451/469], Loss: 2.2968, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [5/50], Step [452/469], Loss: 2.2755, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [453/469], Loss: 2.2903, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [5/50], Step [454/469], Loss: 2.2168, batch time: 0.47, accuracy:  28.91%\n",
      "Epoch [5/50], Step [455/469], Loss: 2.2501, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [456/469], Loss: 2.2461, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [5/50], Step [457/469], Loss: 2.2686, batch time: 0.45, accuracy:  16.41%\n",
      "Epoch [5/50], Step [458/469], Loss: 2.2616, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [5/50], Step [459/469], Loss: 2.2514, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [5/50], Step [460/469], Loss: 2.2682, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [5/50], Step [461/469], Loss: 2.2452, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [5/50], Step [462/469], Loss: 2.2845, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [463/469], Loss: 2.2653, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [5/50], Step [464/469], Loss: 2.2773, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [5/50], Step [465/469], Loss: 2.2671, batch time: 0.47, accuracy:  23.44%\n",
      "Epoch [5/50], Step [466/469], Loss: 2.2886, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [5/50], Step [467/469], Loss: 2.2694, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [5/50], Step [468/469], Loss: 2.2674, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [5/50], Step [469/469], Loss: 2.2658, batch time: 0.42, accuracy:  13.54%\n",
      "Epoch [6/50], Step [1/469], Loss: 2.2922, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [6/50], Step [2/469], Loss: 2.2570, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [6/50], Step [3/469], Loss: 2.2880, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [6/50], Step [4/469], Loss: 2.2747, batch time: 0.45, accuracy:  14.84%\n",
      "Epoch [6/50], Step [5/469], Loss: 2.2729, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [6/469], Loss: 2.2679, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [7/469], Loss: 2.2618, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [6/50], Step [8/469], Loss: 2.2414, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [6/50], Step [9/469], Loss: 2.2925, batch time: 0.40, accuracy:  13.28%\n",
      "Epoch [6/50], Step [10/469], Loss: 2.2634, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [6/50], Step [11/469], Loss: 2.2802, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [6/50], Step [12/469], Loss: 2.2612, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [13/469], Loss: 2.2456, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [6/50], Step [14/469], Loss: 2.2642, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [15/469], Loss: 2.2853, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [16/469], Loss: 2.2710, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [6/50], Step [17/469], Loss: 2.2547, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [18/469], Loss: 2.2672, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [19/469], Loss: 2.2300, batch time: 0.40, accuracy:  27.34%\n",
      "Epoch [6/50], Step [20/469], Loss: 2.2705, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [6/50], Step [21/469], Loss: 2.2676, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [6/50], Step [22/469], Loss: 2.2958, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [23/469], Loss: 2.2570, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [24/469], Loss: 2.2863, batch time: 0.45, accuracy:  17.19%\n",
      "Epoch [6/50], Step [25/469], Loss: 2.2461, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [26/469], Loss: 2.2670, batch time: 0.45, accuracy:  17.97%\n",
      "Epoch [6/50], Step [27/469], Loss: 2.2538, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [28/469], Loss: 2.2341, batch time: 0.47, accuracy:  30.47%\n",
      "Epoch [6/50], Step [29/469], Loss: 2.2389, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [6/50], Step [30/469], Loss: 2.2748, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [31/469], Loss: 2.2604, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [32/469], Loss: 2.2418, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [33/469], Loss: 2.2724, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [34/469], Loss: 2.2593, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [6/50], Step [35/469], Loss: 2.2767, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [36/469], Loss: 2.2560, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [6/50], Step [37/469], Loss: 2.3015, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [6/50], Step [38/469], Loss: 2.2794, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [6/50], Step [39/469], Loss: 2.2824, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [6/50], Step [40/469], Loss: 2.2497, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [6/50], Step [41/469], Loss: 2.2880, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [6/50], Step [42/469], Loss: 2.2904, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [6/50], Step [43/469], Loss: 2.2665, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [6/50], Step [44/469], Loss: 2.3129, batch time: 0.42, accuracy:  10.16%\n",
      "Epoch [6/50], Step [45/469], Loss: 2.2836, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [6/50], Step [46/469], Loss: 2.2337, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [47/469], Loss: 2.2525, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [48/469], Loss: 2.2625, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [6/50], Step [49/469], Loss: 2.2869, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [50/469], Loss: 2.2756, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [51/469], Loss: 2.2724, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [52/469], Loss: 2.2577, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [53/469], Loss: 2.2609, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [6/50], Step [54/469], Loss: 2.2804, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [6/50], Step [55/469], Loss: 2.2676, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [6/50], Step [56/469], Loss: 2.2895, batch time: 0.51, accuracy:  14.84%\n",
      "Epoch [6/50], Step [57/469], Loss: 2.3035, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [58/469], Loss: 2.2308, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [59/469], Loss: 2.2461, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [60/469], Loss: 2.2385, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [61/469], Loss: 2.2562, batch time: 0.44, accuracy:  24.22%\n",
      "Epoch [6/50], Step [62/469], Loss: 2.2598, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [6/50], Step [63/469], Loss: 2.2329, batch time: 0.43, accuracy:  29.69%\n",
      "Epoch [6/50], Step [64/469], Loss: 2.2507, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [65/469], Loss: 2.2623, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [6/50], Step [66/469], Loss: 2.2528, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [6/50], Step [67/469], Loss: 2.2837, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [68/469], Loss: 2.2644, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [69/469], Loss: 2.2728, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [6/50], Step [70/469], Loss: 2.2437, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [6/50], Step [71/469], Loss: 2.2872, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [6/50], Step [72/469], Loss: 2.2149, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [6/50], Step [73/469], Loss: 2.2566, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [6/50], Step [74/469], Loss: 2.2694, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [6/50], Step [75/469], Loss: 2.2838, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [6/50], Step [76/469], Loss: 2.2688, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [77/469], Loss: 2.2869, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [78/469], Loss: 2.2538, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [79/469], Loss: 2.2676, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [80/469], Loss: 2.2677, batch time: 0.45, accuracy:  17.19%\n",
      "Epoch [6/50], Step [81/469], Loss: 2.2718, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [6/50], Step [82/469], Loss: 2.2810, batch time: 0.45, accuracy:  15.62%\n",
      "Epoch [6/50], Step [83/469], Loss: 2.2246, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [84/469], Loss: 2.3233, batch time: 0.44, accuracy:  10.94%\n",
      "Epoch [6/50], Step [85/469], Loss: 2.2420, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [86/469], Loss: 2.2649, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [6/50], Step [87/469], Loss: 2.2785, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [6/50], Step [88/469], Loss: 2.2726, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [6/50], Step [89/469], Loss: 2.2440, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [90/469], Loss: 2.2912, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [91/469], Loss: 2.2778, batch time: 0.45, accuracy:  17.97%\n",
      "Epoch [6/50], Step [92/469], Loss: 2.2819, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [6/50], Step [93/469], Loss: 2.2631, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [6/50], Step [94/469], Loss: 2.2875, batch time: 0.46, accuracy:  14.84%\n",
      "Epoch [6/50], Step [95/469], Loss: 2.2733, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [6/50], Step [96/469], Loss: 2.2691, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [6/50], Step [97/469], Loss: 2.2554, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [6/50], Step [98/469], Loss: 2.2601, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [6/50], Step [99/469], Loss: 2.2296, batch time: 0.42, accuracy:  27.34%\n",
      "Epoch [6/50], Step [100/469], Loss: 2.2446, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [6/50], Step [101/469], Loss: 2.2557, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [6/50], Step [102/469], Loss: 2.2680, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [103/469], Loss: 2.2231, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [6/50], Step [104/469], Loss: 2.2644, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [105/469], Loss: 2.2360, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [6/50], Step [106/469], Loss: 2.2494, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [6/50], Step [107/469], Loss: 2.2755, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [6/50], Step [108/469], Loss: 2.2396, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [6/50], Step [109/469], Loss: 2.2480, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [110/469], Loss: 2.2768, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [6/50], Step [111/469], Loss: 2.2500, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [6/50], Step [112/469], Loss: 2.2654, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [113/469], Loss: 2.2824, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [6/50], Step [114/469], Loss: 2.2697, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [6/50], Step [115/469], Loss: 2.2446, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [116/469], Loss: 2.2747, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [6/50], Step [117/469], Loss: 2.2569, batch time: 0.40, accuracy:  20.31%\n",
      "Epoch [6/50], Step [118/469], Loss: 2.2720, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [6/50], Step [119/469], Loss: 2.2699, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [6/50], Step [120/469], Loss: 2.2766, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [6/50], Step [121/469], Loss: 2.2776, batch time: 0.40, accuracy:  21.09%\n",
      "Epoch [6/50], Step [122/469], Loss: 2.2706, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [123/469], Loss: 2.2503, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [6/50], Step [124/469], Loss: 2.2318, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [6/50], Step [125/469], Loss: 2.2558, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [6/50], Step [126/469], Loss: 2.2812, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [6/50], Step [127/469], Loss: 2.2480, batch time: 0.46, accuracy:  21.88%\n",
      "Epoch [6/50], Step [128/469], Loss: 2.2887, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [6/50], Step [129/469], Loss: 2.2916, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [130/469], Loss: 2.2483, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [6/50], Step [131/469], Loss: 2.2442, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [132/469], Loss: 2.2276, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [133/469], Loss: 2.2669, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [134/469], Loss: 2.2664, batch time: 0.45, accuracy:  15.62%\n",
      "Epoch [6/50], Step [135/469], Loss: 2.2510, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [136/469], Loss: 2.2657, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [6/50], Step [137/469], Loss: 2.2647, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [6/50], Step [138/469], Loss: 2.2762, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [6/50], Step [139/469], Loss: 2.2840, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [6/50], Step [140/469], Loss: 2.2629, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [141/469], Loss: 2.2651, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [6/50], Step [142/469], Loss: 2.2541, batch time: 0.45, accuracy:  18.75%\n",
      "Epoch [6/50], Step [143/469], Loss: 2.2738, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [6/50], Step [144/469], Loss: 2.2701, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [6/50], Step [145/469], Loss: 2.2306, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [6/50], Step [146/469], Loss: 2.2613, batch time: 0.45, accuracy:  20.31%\n",
      "Epoch [6/50], Step [147/469], Loss: 2.2756, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [148/469], Loss: 2.2503, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [149/469], Loss: 2.2496, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [150/469], Loss: 2.2575, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [151/469], Loss: 2.2681, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [152/469], Loss: 2.2591, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [153/469], Loss: 2.2520, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [154/469], Loss: 2.2348, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [6/50], Step [155/469], Loss: 2.2541, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [6/50], Step [156/469], Loss: 2.2811, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [6/50], Step [157/469], Loss: 2.2612, batch time: 0.40, accuracy:  12.50%\n",
      "Epoch [6/50], Step [158/469], Loss: 2.2902, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [159/469], Loss: 2.2758, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [6/50], Step [160/469], Loss: 2.2521, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [161/469], Loss: 2.2620, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [162/469], Loss: 2.2753, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [163/469], Loss: 2.2657, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [6/50], Step [164/469], Loss: 2.2545, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [6/50], Step [165/469], Loss: 2.2477, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [166/469], Loss: 2.2237, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [167/469], Loss: 2.2827, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [6/50], Step [168/469], Loss: 2.2345, batch time: 0.43, accuracy:  26.56%\n",
      "Epoch [6/50], Step [169/469], Loss: 2.2731, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [6/50], Step [170/469], Loss: 2.2664, batch time: 0.44, accuracy:  25.78%\n",
      "Epoch [6/50], Step [171/469], Loss: 2.2811, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [172/469], Loss: 2.2805, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [173/469], Loss: 2.2687, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [174/469], Loss: 2.2820, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [175/469], Loss: 2.2547, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [176/469], Loss: 2.2669, batch time: 0.45, accuracy:  16.41%\n",
      "Epoch [6/50], Step [177/469], Loss: 2.2728, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [6/50], Step [178/469], Loss: 2.2322, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [6/50], Step [179/469], Loss: 2.2316, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [180/469], Loss: 2.2664, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [6/50], Step [181/469], Loss: 2.2620, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [6/50], Step [182/469], Loss: 2.2923, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [6/50], Step [183/469], Loss: 2.2549, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [184/469], Loss: 2.3023, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [6/50], Step [185/469], Loss: 2.2622, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [6/50], Step [186/469], Loss: 2.2560, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [6/50], Step [187/469], Loss: 2.2592, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [188/469], Loss: 2.2570, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [189/469], Loss: 2.2817, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [190/469], Loss: 2.2631, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [191/469], Loss: 2.2708, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [6/50], Step [192/469], Loss: 2.3123, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [193/469], Loss: 2.2359, batch time: 0.44, accuracy:  24.22%\n",
      "Epoch [6/50], Step [194/469], Loss: 2.2732, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [6/50], Step [195/469], Loss: 2.2649, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [6/50], Step [196/469], Loss: 2.2359, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [6/50], Step [197/469], Loss: 2.2746, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [198/469], Loss: 2.2750, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [199/469], Loss: 2.2380, batch time: 0.43, accuracy:  25.78%\n",
      "Epoch [6/50], Step [200/469], Loss: 2.2525, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [201/469], Loss: 2.2656, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [202/469], Loss: 2.2305, batch time: 0.44, accuracy:  25.78%\n",
      "Epoch [6/50], Step [203/469], Loss: 2.2434, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [204/469], Loss: 2.2371, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [6/50], Step [205/469], Loss: 2.2308, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [6/50], Step [206/469], Loss: 2.2589, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [6/50], Step [207/469], Loss: 2.2559, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [6/50], Step [208/469], Loss: 2.2548, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [6/50], Step [209/469], Loss: 2.2886, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [6/50], Step [210/469], Loss: 2.2356, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [6/50], Step [211/469], Loss: 2.2774, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [6/50], Step [212/469], Loss: 2.2609, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [6/50], Step [213/469], Loss: 2.2651, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [6/50], Step [214/469], Loss: 2.2768, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [215/469], Loss: 2.2669, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [216/469], Loss: 2.2702, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [6/50], Step [217/469], Loss: 2.2450, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [6/50], Step [218/469], Loss: 2.2932, batch time: 0.45, accuracy:  14.84%\n",
      "Epoch [6/50], Step [219/469], Loss: 2.2559, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [6/50], Step [220/469], Loss: 2.2087, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [6/50], Step [221/469], Loss: 2.2938, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [222/469], Loss: 2.2202, batch time: 0.44, accuracy:  26.56%\n",
      "Epoch [6/50], Step [223/469], Loss: 2.2656, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [224/469], Loss: 2.2779, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [6/50], Step [225/469], Loss: 2.2602, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [226/469], Loss: 2.2618, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [6/50], Step [227/469], Loss: 2.2580, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [228/469], Loss: 2.2481, batch time: 0.45, accuracy:  18.75%\n",
      "Epoch [6/50], Step [229/469], Loss: 2.2432, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [6/50], Step [230/469], Loss: 2.2327, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [6/50], Step [231/469], Loss: 2.2358, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [232/469], Loss: 2.2480, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [6/50], Step [233/469], Loss: 2.2389, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [6/50], Step [234/469], Loss: 2.2323, batch time: 0.40, accuracy:  21.09%\n",
      "Epoch [6/50], Step [235/469], Loss: 2.2817, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [236/469], Loss: 2.3051, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [237/469], Loss: 2.2676, batch time: 0.42, accuracy:  13.28%\n",
      "Epoch [6/50], Step [238/469], Loss: 2.2334, batch time: 0.43, accuracy:  25.00%\n",
      "Epoch [6/50], Step [239/469], Loss: 2.2582, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [6/50], Step [240/469], Loss: 2.2937, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [6/50], Step [241/469], Loss: 2.2604, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [242/469], Loss: 2.2541, batch time: 0.45, accuracy:  14.06%\n",
      "Epoch [6/50], Step [243/469], Loss: 2.2683, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [6/50], Step [244/469], Loss: 2.2403, batch time: 0.42, accuracy:  30.47%\n",
      "Epoch [6/50], Step [245/469], Loss: 2.2905, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [6/50], Step [246/469], Loss: 2.2430, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [247/469], Loss: 2.2616, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [248/469], Loss: 2.2404, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [249/469], Loss: 2.2859, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [250/469], Loss: 2.2374, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [6/50], Step [251/469], Loss: 2.2668, batch time: 0.49, accuracy:  14.06%\n",
      "Epoch [6/50], Step [252/469], Loss: 2.2436, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [253/469], Loss: 2.2479, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [254/469], Loss: 2.2419, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [255/469], Loss: 2.2264, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [6/50], Step [256/469], Loss: 2.2476, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [6/50], Step [257/469], Loss: 2.2817, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [6/50], Step [258/469], Loss: 2.2674, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [259/469], Loss: 2.2446, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [260/469], Loss: 2.2609, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [261/469], Loss: 2.2304, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [6/50], Step [262/469], Loss: 2.2124, batch time: 0.45, accuracy:  20.31%\n",
      "Epoch [6/50], Step [263/469], Loss: 2.2279, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [6/50], Step [264/469], Loss: 2.2291, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [6/50], Step [265/469], Loss: 2.2721, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [266/469], Loss: 2.2499, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [6/50], Step [267/469], Loss: 2.2423, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [6/50], Step [268/469], Loss: 2.2422, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [269/469], Loss: 2.2439, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [270/469], Loss: 2.2521, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [271/469], Loss: 2.2200, batch time: 0.40, accuracy:  23.44%\n",
      "Epoch [6/50], Step [272/469], Loss: 2.2569, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [273/469], Loss: 2.2874, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [6/50], Step [274/469], Loss: 2.2205, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [6/50], Step [275/469], Loss: 2.2652, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [6/50], Step [276/469], Loss: 2.2375, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [277/469], Loss: 2.2761, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [278/469], Loss: 2.2693, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [279/469], Loss: 2.2513, batch time: 0.45, accuracy:  17.97%\n",
      "Epoch [6/50], Step [280/469], Loss: 2.2617, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [281/469], Loss: 2.2407, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [282/469], Loss: 2.2183, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [283/469], Loss: 2.2514, batch time: 0.45, accuracy:  14.06%\n",
      "Epoch [6/50], Step [284/469], Loss: 2.2803, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [285/469], Loss: 2.2085, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [6/50], Step [286/469], Loss: 2.2215, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [6/50], Step [287/469], Loss: 2.2415, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [6/50], Step [288/469], Loss: 2.2180, batch time: 0.42, accuracy:  26.56%\n",
      "Epoch [6/50], Step [289/469], Loss: 2.2549, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [6/50], Step [290/469], Loss: 2.2165, batch time: 0.40, accuracy:  17.19%\n",
      "Epoch [6/50], Step [291/469], Loss: 2.2655, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [6/50], Step [292/469], Loss: 2.2438, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [6/50], Step [293/469], Loss: 2.2164, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [6/50], Step [294/469], Loss: 2.2858, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [6/50], Step [295/469], Loss: 2.2706, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [296/469], Loss: 2.2288, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [297/469], Loss: 2.2500, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [298/469], Loss: 2.2504, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [299/469], Loss: 2.2729, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [6/50], Step [300/469], Loss: 2.2498, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [6/50], Step [301/469], Loss: 2.2528, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [302/469], Loss: 2.2390, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [6/50], Step [303/469], Loss: 2.2724, batch time: 0.43, accuracy:  12.50%\n",
      "Epoch [6/50], Step [304/469], Loss: 2.2442, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [305/469], Loss: 2.2255, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [6/50], Step [306/469], Loss: 2.3005, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [307/469], Loss: 2.2039, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [6/50], Step [308/469], Loss: 2.2785, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [6/50], Step [309/469], Loss: 2.2516, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [6/50], Step [310/469], Loss: 2.2403, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [311/469], Loss: 2.2125, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [312/469], Loss: 2.2375, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [6/50], Step [313/469], Loss: 2.2020, batch time: 0.40, accuracy:  27.34%\n",
      "Epoch [6/50], Step [314/469], Loss: 2.1941, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [6/50], Step [315/469], Loss: 2.2510, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [6/50], Step [316/469], Loss: 2.2348, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [6/50], Step [317/469], Loss: 2.2565, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [6/50], Step [318/469], Loss: 2.2651, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [6/50], Step [319/469], Loss: 2.2515, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [320/469], Loss: 2.2539, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [321/469], Loss: 2.2209, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [6/50], Step [322/469], Loss: 2.2217, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [6/50], Step [323/469], Loss: 2.2811, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [6/50], Step [324/469], Loss: 2.1979, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [325/469], Loss: 2.2652, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [6/50], Step [326/469], Loss: 2.2775, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [6/50], Step [327/469], Loss: 2.2632, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [328/469], Loss: 2.2475, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [329/469], Loss: 2.2794, batch time: 0.51, accuracy:  17.97%\n",
      "Epoch [6/50], Step [330/469], Loss: 2.2641, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [331/469], Loss: 2.2506, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [332/469], Loss: 2.2292, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [6/50], Step [333/469], Loss: 2.2447, batch time: 0.46, accuracy:  14.84%\n",
      "Epoch [6/50], Step [334/469], Loss: 2.2577, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [6/50], Step [335/469], Loss: 2.2558, batch time: 0.45, accuracy:  18.75%\n",
      "Epoch [6/50], Step [336/469], Loss: 2.2737, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [337/469], Loss: 2.2727, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [6/50], Step [338/469], Loss: 2.2214, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [6/50], Step [339/469], Loss: 2.1929, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [340/469], Loss: 2.2748, batch time: 0.40, accuracy:  18.75%\n",
      "Epoch [6/50], Step [341/469], Loss: 2.2423, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [6/50], Step [342/469], Loss: 2.2185, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [343/469], Loss: 2.2424, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [344/469], Loss: 2.2981, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [6/50], Step [345/469], Loss: 2.2687, batch time: 0.45, accuracy:  17.19%\n",
      "Epoch [6/50], Step [346/469], Loss: 2.2797, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [347/469], Loss: 2.1941, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [6/50], Step [348/469], Loss: 2.2398, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [349/469], Loss: 2.2212, batch time: 0.43, accuracy:  25.00%\n",
      "Epoch [6/50], Step [350/469], Loss: 2.2352, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [6/50], Step [351/469], Loss: 2.2029, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [352/469], Loss: 2.2263, batch time: 0.45, accuracy:  17.97%\n",
      "Epoch [6/50], Step [353/469], Loss: 2.2302, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [354/469], Loss: 2.2564, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [355/469], Loss: 2.2420, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [6/50], Step [356/469], Loss: 2.2703, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [357/469], Loss: 2.2529, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [358/469], Loss: 2.2231, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [359/469], Loss: 2.2358, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [6/50], Step [360/469], Loss: 2.2341, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [361/469], Loss: 2.2423, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [362/469], Loss: 2.2482, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [363/469], Loss: 2.2376, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [6/50], Step [364/469], Loss: 2.2334, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [6/50], Step [365/469], Loss: 2.2473, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [366/469], Loss: 2.2584, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [6/50], Step [367/469], Loss: 2.2471, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [6/50], Step [368/469], Loss: 2.2399, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [369/469], Loss: 2.2616, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [370/469], Loss: 2.2173, batch time: 0.40, accuracy:  24.22%\n",
      "Epoch [6/50], Step [371/469], Loss: 2.2614, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [6/50], Step [372/469], Loss: 2.2530, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [373/469], Loss: 2.2324, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [374/469], Loss: 2.2619, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [6/50], Step [375/469], Loss: 2.2535, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [376/469], Loss: 2.2086, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [377/469], Loss: 2.2527, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [378/469], Loss: 2.2839, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [6/50], Step [379/469], Loss: 2.2776, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [6/50], Step [380/469], Loss: 2.2544, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [6/50], Step [381/469], Loss: 2.2544, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [382/469], Loss: 2.2144, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [6/50], Step [383/469], Loss: 2.2470, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [384/469], Loss: 2.2833, batch time: 0.42, accuracy:  12.50%\n",
      "Epoch [6/50], Step [385/469], Loss: 2.2299, batch time: 0.48, accuracy:  25.78%\n",
      "Epoch [6/50], Step [386/469], Loss: 2.2416, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [387/469], Loss: 2.2531, batch time: 0.40, accuracy:  21.88%\n",
      "Epoch [6/50], Step [388/469], Loss: 2.2405, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [6/50], Step [389/469], Loss: 2.2625, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [6/50], Step [390/469], Loss: 2.2221, batch time: 0.40, accuracy:  25.00%\n",
      "Epoch [6/50], Step [391/469], Loss: 2.2415, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [6/50], Step [392/469], Loss: 2.2387, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [6/50], Step [393/469], Loss: 2.2068, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [6/50], Step [394/469], Loss: 2.1850, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [395/469], Loss: 2.2587, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [396/469], Loss: 2.2269, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [397/469], Loss: 2.2544, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [6/50], Step [398/469], Loss: 2.2375, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [399/469], Loss: 2.2820, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [6/50], Step [400/469], Loss: 2.2078, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [6/50], Step [401/469], Loss: 2.2599, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [6/50], Step [402/469], Loss: 2.1992, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [6/50], Step [403/469], Loss: 2.2467, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [6/50], Step [404/469], Loss: 2.2442, batch time: 0.40, accuracy:  14.84%\n",
      "Epoch [6/50], Step [405/469], Loss: 2.2842, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [6/50], Step [406/469], Loss: 2.2140, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [6/50], Step [407/469], Loss: 2.2621, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [6/50], Step [408/469], Loss: 2.2760, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [409/469], Loss: 2.2102, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [410/469], Loss: 2.2735, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [411/469], Loss: 2.2854, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [6/50], Step [412/469], Loss: 2.2064, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [413/469], Loss: 2.2977, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [6/50], Step [414/469], Loss: 2.2340, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [415/469], Loss: 2.2568, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [6/50], Step [416/469], Loss: 2.2262, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [6/50], Step [417/469], Loss: 2.2631, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [6/50], Step [418/469], Loss: 2.2361, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [419/469], Loss: 2.2385, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [420/469], Loss: 2.2405, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [421/469], Loss: 2.2105, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [6/50], Step [422/469], Loss: 2.2539, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [423/469], Loss: 2.2076, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [6/50], Step [424/469], Loss: 2.2410, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [6/50], Step [425/469], Loss: 2.2718, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [426/469], Loss: 2.2697, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [427/469], Loss: 2.2073, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [428/469], Loss: 2.2154, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [429/469], Loss: 2.2358, batch time: 0.50, accuracy:  20.31%\n",
      "Epoch [6/50], Step [430/469], Loss: 2.2743, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [6/50], Step [431/469], Loss: 2.2269, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [6/50], Step [432/469], Loss: 2.2550, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [433/469], Loss: 2.2477, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [6/50], Step [434/469], Loss: 2.2595, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [6/50], Step [435/469], Loss: 2.2752, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [436/469], Loss: 2.2185, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [6/50], Step [437/469], Loss: 2.2227, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [6/50], Step [438/469], Loss: 2.2690, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [6/50], Step [439/469], Loss: 2.2298, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [6/50], Step [440/469], Loss: 2.2501, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [6/50], Step [441/469], Loss: 2.2306, batch time: 0.40, accuracy:  22.66%\n",
      "Epoch [6/50], Step [442/469], Loss: 2.2093, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [6/50], Step [443/469], Loss: 2.2315, batch time: 0.45, accuracy:  17.97%\n",
      "Epoch [6/50], Step [444/469], Loss: 2.2716, batch time: 0.43, accuracy:  14.84%\n",
      "Epoch [6/50], Step [445/469], Loss: 2.2569, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [6/50], Step [446/469], Loss: 2.2411, batch time: 0.45, accuracy:  14.84%\n",
      "Epoch [6/50], Step [447/469], Loss: 2.2449, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [448/469], Loss: 2.2589, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [449/469], Loss: 2.2391, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [450/469], Loss: 2.2439, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [6/50], Step [451/469], Loss: 2.1932, batch time: 0.44, accuracy:  28.91%\n",
      "Epoch [6/50], Step [452/469], Loss: 2.2613, batch time: 0.43, accuracy:  10.94%\n",
      "Epoch [6/50], Step [453/469], Loss: 2.2536, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [6/50], Step [454/469], Loss: 2.2278, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [6/50], Step [455/469], Loss: 2.2438, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [6/50], Step [456/469], Loss: 2.2383, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [6/50], Step [457/469], Loss: 2.1919, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [6/50], Step [458/469], Loss: 2.2185, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [6/50], Step [459/469], Loss: 2.2476, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [6/50], Step [460/469], Loss: 2.2463, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [6/50], Step [461/469], Loss: 2.2296, batch time: 0.40, accuracy:  18.75%\n",
      "Epoch [6/50], Step [462/469], Loss: 2.2458, batch time: 0.45, accuracy:  14.06%\n",
      "Epoch [6/50], Step [463/469], Loss: 2.2369, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [6/50], Step [464/469], Loss: 2.2160, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [6/50], Step [465/469], Loss: 2.2176, batch time: 0.44, accuracy:  18.75%\n",
      "Epoch [6/50], Step [466/469], Loss: 2.2286, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [6/50], Step [467/469], Loss: 2.2933, batch time: 0.46, accuracy:  15.62%\n",
      "Epoch [6/50], Step [468/469], Loss: 2.2221, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [6/50], Step [469/469], Loss: 2.2276, batch time: 0.43, accuracy:  22.92%\n",
      "Epoch [7/50], Step [1/469], Loss: 2.2359, batch time: 0.45, accuracy:  18.75%\n",
      "Epoch [7/50], Step [2/469], Loss: 2.2637, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [7/50], Step [3/469], Loss: 2.2247, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [7/50], Step [4/469], Loss: 2.2212, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [7/50], Step [5/469], Loss: 2.2406, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [7/50], Step [6/469], Loss: 2.2400, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [7/50], Step [7/469], Loss: 2.2666, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [7/50], Step [8/469], Loss: 2.2561, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [9/469], Loss: 2.2772, batch time: 0.40, accuracy:  19.53%\n",
      "Epoch [7/50], Step [10/469], Loss: 2.1943, batch time: 0.40, accuracy:  28.91%\n",
      "Epoch [7/50], Step [11/469], Loss: 2.2291, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [12/469], Loss: 2.1981, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [13/469], Loss: 2.2250, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [7/50], Step [14/469], Loss: 2.2302, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [15/469], Loss: 2.2271, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [7/50], Step [16/469], Loss: 2.2308, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [7/50], Step [17/469], Loss: 2.2295, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [7/50], Step [18/469], Loss: 2.2785, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [7/50], Step [19/469], Loss: 2.2076, batch time: 0.45, accuracy:  24.22%\n",
      "Epoch [7/50], Step [20/469], Loss: 2.2387, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [21/469], Loss: 2.1988, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [7/50], Step [22/469], Loss: 2.2712, batch time: 0.45, accuracy:  12.50%\n",
      "Epoch [7/50], Step [23/469], Loss: 2.2205, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [24/469], Loss: 2.2397, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [7/50], Step [25/469], Loss: 2.2310, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [7/50], Step [26/469], Loss: 2.2803, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [7/50], Step [27/469], Loss: 2.2484, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [7/50], Step [28/469], Loss: 2.2256, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [7/50], Step [29/469], Loss: 2.2160, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [7/50], Step [30/469], Loss: 2.2450, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [7/50], Step [31/469], Loss: 2.2012, batch time: 0.50, accuracy:  25.78%\n",
      "Epoch [7/50], Step [32/469], Loss: 2.1842, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [33/469], Loss: 2.2397, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [7/50], Step [34/469], Loss: 2.2115, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [7/50], Step [35/469], Loss: 2.2646, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [7/50], Step [36/469], Loss: 2.2103, batch time: 0.44, accuracy:  25.00%\n",
      "Epoch [7/50], Step [37/469], Loss: 2.2678, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [7/50], Step [38/469], Loss: 2.1963, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [7/50], Step [39/469], Loss: 2.2502, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [7/50], Step [40/469], Loss: 2.2113, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [7/50], Step [41/469], Loss: 2.2731, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [7/50], Step [42/469], Loss: 2.2214, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [7/50], Step [43/469], Loss: 2.2666, batch time: 0.44, accuracy:  14.06%\n",
      "Epoch [7/50], Step [44/469], Loss: 2.2460, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [7/50], Step [45/469], Loss: 2.2714, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [7/50], Step [46/469], Loss: 2.2571, batch time: 0.44, accuracy:  17.97%\n",
      "Epoch [7/50], Step [47/469], Loss: 2.2048, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [7/50], Step [48/469], Loss: 2.3058, batch time: 0.43, accuracy:  13.28%\n",
      "Epoch [7/50], Step [49/469], Loss: 2.1837, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [7/50], Step [50/469], Loss: 2.2377, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [7/50], Step [51/469], Loss: 2.2618, batch time: 0.44, accuracy:  13.28%\n",
      "Epoch [7/50], Step [52/469], Loss: 2.2605, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [7/50], Step [53/469], Loss: 2.2587, batch time: 0.44, accuracy:  19.53%\n",
      "Epoch [7/50], Step [54/469], Loss: 2.1909, batch time: 0.44, accuracy:  25.00%\n",
      "Epoch [7/50], Step [55/469], Loss: 2.2233, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [7/50], Step [56/469], Loss: 2.2542, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [7/50], Step [57/469], Loss: 2.2547, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [7/50], Step [58/469], Loss: 2.2764, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [7/50], Step [59/469], Loss: 2.2438, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [60/469], Loss: 2.2330, batch time: 0.40, accuracy:  21.88%\n",
      "Epoch [7/50], Step [61/469], Loss: 2.2030, batch time: 0.40, accuracy:  21.09%\n",
      "Epoch [7/50], Step [62/469], Loss: 2.2062, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [7/50], Step [63/469], Loss: 2.2110, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [7/50], Step [64/469], Loss: 2.2089, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [7/50], Step [65/469], Loss: 2.2324, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [66/469], Loss: 2.2331, batch time: 0.40, accuracy:  23.44%\n",
      "Epoch [7/50], Step [67/469], Loss: 2.2290, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [68/469], Loss: 2.2877, batch time: 0.42, accuracy:  10.94%\n",
      "Epoch [7/50], Step [69/469], Loss: 2.2454, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [70/469], Loss: 2.2357, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [7/50], Step [71/469], Loss: 2.2372, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [72/469], Loss: 2.1901, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [7/50], Step [73/469], Loss: 2.2938, batch time: 0.44, accuracy:  12.50%\n",
      "Epoch [7/50], Step [74/469], Loss: 2.2219, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [7/50], Step [75/469], Loss: 2.2453, batch time: 0.44, accuracy:  21.09%\n",
      "Epoch [7/50], Step [76/469], Loss: 2.2229, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [7/50], Step [77/469], Loss: 2.2771, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [78/469], Loss: 2.2326, batch time: 0.40, accuracy:  16.41%\n",
      "Epoch [7/50], Step [79/469], Loss: 2.2664, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [80/469], Loss: 2.1895, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [7/50], Step [81/469], Loss: 2.1636, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [7/50], Step [82/469], Loss: 2.2509, batch time: 0.44, accuracy:  11.72%\n",
      "Epoch [7/50], Step [83/469], Loss: 2.2162, batch time: 0.45, accuracy:  19.53%\n",
      "Epoch [7/50], Step [84/469], Loss: 2.1954, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [7/50], Step [85/469], Loss: 2.2103, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [7/50], Step [86/469], Loss: 2.1897, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [7/50], Step [87/469], Loss: 2.2057, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [7/50], Step [88/469], Loss: 2.2104, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [7/50], Step [89/469], Loss: 2.2511, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [7/50], Step [90/469], Loss: 2.2832, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [7/50], Step [91/469], Loss: 2.2667, batch time: 0.40, accuracy:  15.62%\n",
      "Epoch [7/50], Step [92/469], Loss: 2.2287, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [7/50], Step [93/469], Loss: 2.2003, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [7/50], Step [94/469], Loss: 2.2157, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [7/50], Step [95/469], Loss: 2.2256, batch time: 0.45, accuracy:  24.22%\n",
      "Epoch [7/50], Step [96/469], Loss: 2.1942, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [7/50], Step [97/469], Loss: 2.2461, batch time: 0.43, accuracy:  16.41%\n",
      "Epoch [7/50], Step [98/469], Loss: 2.1579, batch time: 0.44, accuracy:  27.34%\n",
      "Epoch [7/50], Step [99/469], Loss: 2.2107, batch time: 0.43, accuracy:  21.09%\n",
      "Epoch [7/50], Step [100/469], Loss: 2.2514, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [7/50], Step [101/469], Loss: 2.2141, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [7/50], Step [102/469], Loss: 2.2526, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [7/50], Step [103/469], Loss: 2.1678, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [7/50], Step [104/469], Loss: 2.2374, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [7/50], Step [105/469], Loss: 2.2109, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [7/50], Step [106/469], Loss: 2.1894, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [7/50], Step [107/469], Loss: 2.2730, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [7/50], Step [108/469], Loss: 2.2190, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [7/50], Step [109/469], Loss: 2.1847, batch time: 0.43, accuracy:  23.44%\n",
      "Epoch [7/50], Step [110/469], Loss: 2.2365, batch time: 0.44, accuracy:  15.62%\n",
      "Epoch [7/50], Step [111/469], Loss: 2.2793, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [7/50], Step [112/469], Loss: 2.2513, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [7/50], Step [113/469], Loss: 2.1956, batch time: 0.44, accuracy:  23.44%\n",
      "Epoch [7/50], Step [114/469], Loss: 2.2445, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [7/50], Step [115/469], Loss: 2.2510, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [116/469], Loss: 2.2332, batch time: 0.40, accuracy:  14.06%\n",
      "Epoch [7/50], Step [117/469], Loss: 2.2322, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [7/50], Step [118/469], Loss: 2.2546, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [7/50], Step [119/469], Loss: 2.2238, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [120/469], Loss: 2.1995, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [121/469], Loss: 2.2345, batch time: 0.43, accuracy:  19.53%\n",
      "Epoch [7/50], Step [122/469], Loss: 2.2467, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [7/50], Step [123/469], Loss: 2.2569, batch time: 0.43, accuracy:  17.97%\n",
      "Epoch [7/50], Step [124/469], Loss: 2.2427, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [7/50], Step [125/469], Loss: 2.2295, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [7/50], Step [126/469], Loss: 2.2121, batch time: 0.43, accuracy:  21.88%\n",
      "Epoch [7/50], Step [127/469], Loss: 2.2476, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [7/50], Step [128/469], Loss: 2.2333, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [7/50], Step [129/469], Loss: 2.2233, batch time: 0.45, accuracy:  15.62%\n",
      "Epoch [7/50], Step [130/469], Loss: 2.2199, batch time: 0.44, accuracy:  22.66%\n",
      "Epoch [7/50], Step [131/469], Loss: 2.2052, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [7/50], Step [132/469], Loss: 2.2413, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [7/50], Step [133/469], Loss: 2.2693, batch time: 0.44, accuracy:  16.41%\n",
      "Epoch [7/50], Step [134/469], Loss: 2.2678, batch time: 0.44, accuracy:  17.19%\n",
      "Epoch [7/50], Step [135/469], Loss: 2.1972, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [7/50], Step [136/469], Loss: 2.2414, batch time: 0.44, accuracy:  21.88%\n",
      "Epoch [7/50], Step [137/469], Loss: 2.2283, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [138/469], Loss: 2.2746, batch time: 0.44, accuracy:  14.84%\n",
      "Epoch [7/50], Step [139/469], Loss: 2.2284, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [7/50], Step [140/469], Loss: 2.2441, batch time: 0.40, accuracy:  22.66%\n",
      "Epoch [7/50], Step [141/469], Loss: 2.2246, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [7/50], Step [142/469], Loss: 2.2431, batch time: 0.43, accuracy:  17.19%\n",
      "Epoch [7/50], Step [143/469], Loss: 2.1952, batch time: 0.45, accuracy:  21.88%\n",
      "Epoch [7/50], Step [144/469], Loss: 2.1394, batch time: 0.44, accuracy:  29.69%\n",
      "Epoch [7/50], Step [145/469], Loss: 2.2288, batch time: 0.44, accuracy:  20.31%\n",
      "Epoch [7/50], Step [146/469], Loss: 2.1800, batch time: 0.44, accuracy:  28.91%\n",
      "Epoch [7/50], Step [147/469], Loss: 2.2123, batch time: 0.45, accuracy:  25.00%\n",
      "Epoch [7/50], Step [148/469], Loss: 2.2478, batch time: 0.45, accuracy:  21.09%\n",
      "Epoch [7/50], Step [149/469], Loss: 2.2583, batch time: 0.43, accuracy:  20.31%\n",
      "Epoch [7/50], Step [150/469], Loss: 2.2073, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [151/469], Loss: 2.2214, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [152/469], Loss: 2.1701, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [153/469], Loss: 2.2500, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [154/469], Loss: 2.2290, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [155/469], Loss: 2.2540, batch time: 0.47, accuracy:  17.19%\n",
      "Epoch [7/50], Step [156/469], Loss: 2.2097, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [157/469], Loss: 2.1561, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [7/50], Step [158/469], Loss: 2.2582, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [159/469], Loss: 2.2057, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [160/469], Loss: 2.1905, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [161/469], Loss: 2.2087, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [162/469], Loss: 2.2054, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [163/469], Loss: 2.2155, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [164/469], Loss: 2.2351, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [7/50], Step [165/469], Loss: 2.2250, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [7/50], Step [166/469], Loss: 2.2105, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [167/469], Loss: 2.1678, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [168/469], Loss: 2.2689, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [169/469], Loss: 2.2418, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [170/469], Loss: 2.2606, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [7/50], Step [171/469], Loss: 2.1659, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [7/50], Step [172/469], Loss: 2.2453, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [7/50], Step [173/469], Loss: 2.2201, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [174/469], Loss: 2.2246, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [175/469], Loss: 2.2550, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [7/50], Step [176/469], Loss: 2.2150, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [177/469], Loss: 2.2200, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [178/469], Loss: 2.2181, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [179/469], Loss: 2.2128, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [7/50], Step [180/469], Loss: 2.1915, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [181/469], Loss: 2.2445, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [182/469], Loss: 2.2612, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [7/50], Step [183/469], Loss: 2.1850, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [184/469], Loss: 2.1753, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [185/469], Loss: 2.2735, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [186/469], Loss: 2.1897, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [187/469], Loss: 2.2238, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [188/469], Loss: 2.2321, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [189/469], Loss: 2.1431, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [190/469], Loss: 2.2315, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [191/469], Loss: 2.1878, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [192/469], Loss: 2.2482, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [193/469], Loss: 2.1751, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [194/469], Loss: 2.2322, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [195/469], Loss: 2.3026, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [196/469], Loss: 2.2465, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [197/469], Loss: 2.1994, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [198/469], Loss: 2.2744, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [199/469], Loss: 2.1982, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [7/50], Step [200/469], Loss: 2.2885, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [7/50], Step [201/469], Loss: 2.2477, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [202/469], Loss: 2.2349, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [7/50], Step [203/469], Loss: 2.2367, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [7/50], Step [204/469], Loss: 2.2896, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [205/469], Loss: 2.1978, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [206/469], Loss: 2.2046, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [207/469], Loss: 2.1939, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [208/469], Loss: 2.2517, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [209/469], Loss: 2.2055, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [210/469], Loss: 2.2228, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [7/50], Step [211/469], Loss: 2.2251, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [212/469], Loss: 2.2287, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [213/469], Loss: 2.2265, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [214/469], Loss: 2.2397, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [215/469], Loss: 2.1921, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [216/469], Loss: 2.2239, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [217/469], Loss: 2.2486, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [7/50], Step [218/469], Loss: 2.2365, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [7/50], Step [219/469], Loss: 2.2090, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [7/50], Step [220/469], Loss: 2.2306, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [221/469], Loss: 2.2056, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [7/50], Step [222/469], Loss: 2.2764, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [223/469], Loss: 2.2689, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [224/469], Loss: 2.2809, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [225/469], Loss: 2.2315, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [226/469], Loss: 2.2826, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [7/50], Step [227/469], Loss: 2.2972, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [228/469], Loss: 2.2121, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [229/469], Loss: 2.2609, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [7/50], Step [230/469], Loss: 2.2216, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [231/469], Loss: 2.2161, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [232/469], Loss: 2.2069, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [233/469], Loss: 2.2305, batch time: 0.46, accuracy:  21.88%\n",
      "Epoch [7/50], Step [234/469], Loss: 2.1500, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [235/469], Loss: 2.1979, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [236/469], Loss: 2.1830, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [237/469], Loss: 2.1922, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [238/469], Loss: 2.2268, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [239/469], Loss: 2.1981, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [240/469], Loss: 2.3122, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [7/50], Step [241/469], Loss: 2.2254, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [242/469], Loss: 2.1839, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [243/469], Loss: 2.2200, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [244/469], Loss: 2.2749, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [7/50], Step [245/469], Loss: 2.1632, batch time: 0.42, accuracy:  28.12%\n",
      "Epoch [7/50], Step [246/469], Loss: 2.2483, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [247/469], Loss: 2.2287, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [7/50], Step [248/469], Loss: 2.2070, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [249/469], Loss: 2.2669, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [250/469], Loss: 2.1752, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [7/50], Step [251/469], Loss: 2.2043, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [252/469], Loss: 2.2059, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [253/469], Loss: 2.1914, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [254/469], Loss: 2.1720, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [255/469], Loss: 2.2575, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [7/50], Step [256/469], Loss: 2.1822, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [257/469], Loss: 2.1540, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [258/469], Loss: 2.2247, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [259/469], Loss: 2.2011, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [7/50], Step [260/469], Loss: 2.2201, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [261/469], Loss: 2.1356, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [262/469], Loss: 2.2446, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [263/469], Loss: 2.2003, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [264/469], Loss: 2.1978, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [265/469], Loss: 2.2348, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [266/469], Loss: 2.1975, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [7/50], Step [267/469], Loss: 2.2007, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [268/469], Loss: 2.1530, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [7/50], Step [269/469], Loss: 2.2784, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [7/50], Step [270/469], Loss: 2.1913, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [271/469], Loss: 2.2556, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [7/50], Step [272/469], Loss: 2.2380, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [7/50], Step [273/469], Loss: 2.2494, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [274/469], Loss: 2.1907, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [275/469], Loss: 2.2283, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [7/50], Step [276/469], Loss: 2.2892, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [7/50], Step [277/469], Loss: 2.2387, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [278/469], Loss: 2.1998, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [279/469], Loss: 2.1634, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [280/469], Loss: 2.1989, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [7/50], Step [281/469], Loss: 2.1850, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [282/469], Loss: 2.2184, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [283/469], Loss: 2.1611, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [284/469], Loss: 2.1753, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [285/469], Loss: 2.1900, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [7/50], Step [286/469], Loss: 2.2245, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [287/469], Loss: 2.2144, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [288/469], Loss: 2.1960, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [289/469], Loss: 2.1711, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [7/50], Step [290/469], Loss: 2.2545, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [291/469], Loss: 2.1589, batch time: 0.47, accuracy:  22.66%\n",
      "Epoch [7/50], Step [292/469], Loss: 2.2420, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [293/469], Loss: 2.2574, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [294/469], Loss: 2.1640, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [295/469], Loss: 2.1335, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [296/469], Loss: 2.2545, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [297/469], Loss: 2.2225, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [298/469], Loss: 2.2363, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [7/50], Step [299/469], Loss: 2.2415, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [300/469], Loss: 2.2105, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [301/469], Loss: 2.1985, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [302/469], Loss: 2.2057, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [303/469], Loss: 2.2490, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [304/469], Loss: 2.1362, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [7/50], Step [305/469], Loss: 2.1959, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [306/469], Loss: 2.2457, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [307/469], Loss: 2.1980, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [308/469], Loss: 2.2942, batch time: 0.41, accuracy:  9.38%\n",
      "Epoch [7/50], Step [309/469], Loss: 2.1646, batch time: 0.42, accuracy:  25.78%\n",
      "Epoch [7/50], Step [310/469], Loss: 2.1652, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [7/50], Step [311/469], Loss: 2.1544, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [312/469], Loss: 2.2093, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [313/469], Loss: 2.2794, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [314/469], Loss: 2.1652, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [315/469], Loss: 2.1940, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [316/469], Loss: 2.2270, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [7/50], Step [317/469], Loss: 2.2133, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [318/469], Loss: 2.2018, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [319/469], Loss: 2.2792, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [320/469], Loss: 2.2793, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [321/469], Loss: 2.1136, batch time: 0.45, accuracy:  31.25%\n",
      "Epoch [7/50], Step [322/469], Loss: 2.1685, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [323/469], Loss: 2.2580, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [324/469], Loss: 2.2340, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [325/469], Loss: 2.1993, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [326/469], Loss: 2.1719, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [327/469], Loss: 2.2369, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [328/469], Loss: 2.2122, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [329/469], Loss: 2.1861, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [330/469], Loss: 2.2870, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [7/50], Step [331/469], Loss: 2.1869, batch time: 0.40, accuracy:  21.88%\n",
      "Epoch [7/50], Step [332/469], Loss: 2.2208, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [333/469], Loss: 2.2406, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [334/469], Loss: 2.2299, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [335/469], Loss: 2.2134, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [336/469], Loss: 2.1917, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [337/469], Loss: 2.1689, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [7/50], Step [338/469], Loss: 2.2389, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [339/469], Loss: 2.2149, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [7/50], Step [340/469], Loss: 2.0996, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [7/50], Step [341/469], Loss: 2.2120, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [342/469], Loss: 2.1488, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [7/50], Step [343/469], Loss: 2.2822, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [7/50], Step [344/469], Loss: 2.1894, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [345/469], Loss: 2.2127, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [346/469], Loss: 2.2424, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [347/469], Loss: 2.2305, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [348/469], Loss: 2.2086, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [349/469], Loss: 2.1935, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [350/469], Loss: 2.2849, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [351/469], Loss: 2.2055, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [352/469], Loss: 2.2275, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [353/469], Loss: 2.2380, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [7/50], Step [354/469], Loss: 2.2051, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [355/469], Loss: 2.2070, batch time: 0.40, accuracy:  22.66%\n",
      "Epoch [7/50], Step [356/469], Loss: 2.2883, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [7/50], Step [357/469], Loss: 2.1394, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [358/469], Loss: 2.1423, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [7/50], Step [359/469], Loss: 2.2277, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [360/469], Loss: 2.2263, batch time: 0.46, accuracy:  19.53%\n",
      "Epoch [7/50], Step [361/469], Loss: 2.1789, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [362/469], Loss: 2.1908, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [363/469], Loss: 2.2318, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [364/469], Loss: 2.2139, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [365/469], Loss: 2.2283, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [7/50], Step [366/469], Loss: 2.2050, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [367/469], Loss: 2.1645, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [368/469], Loss: 2.1606, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [7/50], Step [369/469], Loss: 2.2036, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [370/469], Loss: 2.2204, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [371/469], Loss: 2.1833, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [372/469], Loss: 2.1720, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [373/469], Loss: 2.2431, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [374/469], Loss: 2.1770, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [375/469], Loss: 2.2056, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [7/50], Step [376/469], Loss: 2.2087, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [377/469], Loss: 2.2051, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [378/469], Loss: 2.2258, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [379/469], Loss: 2.1451, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [380/469], Loss: 2.2467, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [381/469], Loss: 2.2225, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [382/469], Loss: 2.2114, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [383/469], Loss: 2.2188, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [7/50], Step [384/469], Loss: 2.1598, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [7/50], Step [385/469], Loss: 2.1876, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [386/469], Loss: 2.2136, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [387/469], Loss: 2.1932, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [388/469], Loss: 2.2004, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [389/469], Loss: 2.1257, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [7/50], Step [390/469], Loss: 2.2510, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [391/469], Loss: 2.1819, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [392/469], Loss: 2.2108, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [393/469], Loss: 2.2286, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [394/469], Loss: 2.1846, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [395/469], Loss: 2.2779, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [396/469], Loss: 2.1705, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [397/469], Loss: 2.1511, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [7/50], Step [398/469], Loss: 2.2473, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [399/469], Loss: 2.1082, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [7/50], Step [400/469], Loss: 2.2594, batch time: 0.41, accuracy:  11.72%\n",
      "Epoch [7/50], Step [401/469], Loss: 2.2113, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [7/50], Step [402/469], Loss: 2.2365, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [403/469], Loss: 2.1891, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [7/50], Step [404/469], Loss: 2.2381, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [405/469], Loss: 2.1899, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [406/469], Loss: 2.2127, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [407/469], Loss: 2.1813, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [408/469], Loss: 2.1629, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [7/50], Step [409/469], Loss: 2.1832, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [410/469], Loss: 2.1927, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [7/50], Step [411/469], Loss: 2.1270, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [412/469], Loss: 2.2444, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [7/50], Step [413/469], Loss: 2.2060, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [414/469], Loss: 2.1713, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [415/469], Loss: 2.1960, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [7/50], Step [416/469], Loss: 2.1575, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [417/469], Loss: 2.2978, batch time: 0.42, accuracy:  14.06%\n",
      "Epoch [7/50], Step [418/469], Loss: 2.2037, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [419/469], Loss: 2.2205, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [420/469], Loss: 2.1645, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [421/469], Loss: 2.2362, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [422/469], Loss: 2.1936, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [423/469], Loss: 2.1903, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [424/469], Loss: 2.1862, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [7/50], Step [425/469], Loss: 2.2477, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [7/50], Step [426/469], Loss: 2.2026, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [427/469], Loss: 2.2543, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [428/469], Loss: 2.2706, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [7/50], Step [429/469], Loss: 2.1980, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [430/469], Loss: 2.2853, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [7/50], Step [431/469], Loss: 2.2376, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [432/469], Loss: 2.1645, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [433/469], Loss: 2.1401, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [434/469], Loss: 2.1982, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [7/50], Step [435/469], Loss: 2.2472, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [436/469], Loss: 2.1811, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [7/50], Step [437/469], Loss: 2.1648, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [438/469], Loss: 2.2101, batch time: 0.47, accuracy:  19.53%\n",
      "Epoch [7/50], Step [439/469], Loss: 2.2398, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [7/50], Step [440/469], Loss: 2.2016, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [441/469], Loss: 2.2071, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [442/469], Loss: 2.1855, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [443/469], Loss: 2.2027, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [7/50], Step [444/469], Loss: 2.2948, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [7/50], Step [445/469], Loss: 2.1559, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [446/469], Loss: 2.2147, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [447/469], Loss: 2.1967, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [448/469], Loss: 2.2563, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [7/50], Step [449/469], Loss: 2.2496, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [7/50], Step [450/469], Loss: 2.2032, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [451/469], Loss: 2.2749, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [452/469], Loss: 2.1862, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [7/50], Step [453/469], Loss: 2.1863, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [454/469], Loss: 2.2260, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [7/50], Step [455/469], Loss: 2.2281, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [456/469], Loss: 2.2326, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [7/50], Step [457/469], Loss: 2.1623, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [7/50], Step [458/469], Loss: 2.2659, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [459/469], Loss: 2.2085, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [7/50], Step [460/469], Loss: 2.1754, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [7/50], Step [461/469], Loss: 2.2840, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [7/50], Step [462/469], Loss: 2.2449, batch time: 0.42, accuracy:  14.84%\n",
      "Epoch [7/50], Step [463/469], Loss: 2.2103, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [7/50], Step [464/469], Loss: 2.1573, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [7/50], Step [465/469], Loss: 2.1717, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [7/50], Step [466/469], Loss: 2.1939, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [7/50], Step [467/469], Loss: 2.1680, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [7/50], Step [468/469], Loss: 2.1614, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [7/50], Step [469/469], Loss: 2.1937, batch time: 0.41, accuracy:  17.71%\n",
      "Epoch [8/50], Step [1/469], Loss: 2.2150, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [8/50], Step [2/469], Loss: 2.1499, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [3/469], Loss: 2.2233, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [4/469], Loss: 2.1688, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [5/469], Loss: 2.1400, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [8/50], Step [6/469], Loss: 2.1869, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [7/469], Loss: 2.2037, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [8/469], Loss: 2.2384, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [9/469], Loss: 2.1888, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [10/469], Loss: 2.1832, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [11/469], Loss: 2.1445, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [12/469], Loss: 2.1790, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [13/469], Loss: 2.1243, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [8/50], Step [14/469], Loss: 2.1719, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [15/469], Loss: 2.2117, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [8/50], Step [16/469], Loss: 2.1864, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [17/469], Loss: 2.1801, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [18/469], Loss: 2.2172, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [19/469], Loss: 2.1771, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [20/469], Loss: 2.1780, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [21/469], Loss: 2.1726, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [22/469], Loss: 2.1560, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [23/469], Loss: 2.1694, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [24/469], Loss: 2.1611, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [25/469], Loss: 2.1644, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [26/469], Loss: 2.1720, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [27/469], Loss: 2.1668, batch time: 0.47, accuracy:  25.00%\n",
      "Epoch [8/50], Step [28/469], Loss: 2.2072, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [29/469], Loss: 2.2550, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [8/50], Step [30/469], Loss: 2.2310, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [8/50], Step [31/469], Loss: 2.2361, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [32/469], Loss: 2.2112, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [33/469], Loss: 2.1956, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [34/469], Loss: 2.1897, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [35/469], Loss: 2.1900, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [36/469], Loss: 2.1781, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [8/50], Step [37/469], Loss: 2.2198, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [38/469], Loss: 2.2136, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [39/469], Loss: 2.2558, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [40/469], Loss: 2.2116, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [41/469], Loss: 2.1729, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [42/469], Loss: 2.1239, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [43/469], Loss: 2.1949, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [8/50], Step [44/469], Loss: 2.1635, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [45/469], Loss: 2.1615, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [46/469], Loss: 2.1778, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [47/469], Loss: 2.1783, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [8/50], Step [48/469], Loss: 2.1985, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [49/469], Loss: 2.0664, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [8/50], Step [50/469], Loss: 2.1720, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [51/469], Loss: 2.1965, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [52/469], Loss: 2.2018, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [53/469], Loss: 2.1966, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [54/469], Loss: 2.1615, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [55/469], Loss: 2.1915, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [56/469], Loss: 2.1830, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [57/469], Loss: 2.2398, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [58/469], Loss: 2.1549, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [59/469], Loss: 2.1971, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [60/469], Loss: 2.1902, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [61/469], Loss: 2.1727, batch time: 0.40, accuracy:  24.22%\n",
      "Epoch [8/50], Step [62/469], Loss: 2.1856, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [63/469], Loss: 2.1726, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [64/469], Loss: 2.2764, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [65/469], Loss: 2.1615, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [66/469], Loss: 2.1698, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [67/469], Loss: 2.1536, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [68/469], Loss: 2.2194, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [69/469], Loss: 2.1849, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [70/469], Loss: 2.1486, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [71/469], Loss: 2.1894, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [8/50], Step [72/469], Loss: 2.1985, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [73/469], Loss: 2.1842, batch time: 0.53, accuracy:  18.75%\n",
      "Epoch [8/50], Step [74/469], Loss: 2.2191, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [75/469], Loss: 2.2132, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [76/469], Loss: 2.1628, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [77/469], Loss: 2.1597, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [78/469], Loss: 2.2238, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [8/50], Step [79/469], Loss: 2.2445, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [80/469], Loss: 2.1708, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [81/469], Loss: 2.1781, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [82/469], Loss: 2.2224, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [83/469], Loss: 2.1728, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [84/469], Loss: 2.2233, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [8/50], Step [85/469], Loss: 2.1884, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [86/469], Loss: 2.1714, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [87/469], Loss: 2.2080, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [88/469], Loss: 2.1915, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [89/469], Loss: 2.1336, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [8/50], Step [90/469], Loss: 2.1010, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [91/469], Loss: 2.1919, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [92/469], Loss: 2.2385, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [8/50], Step [93/469], Loss: 2.2123, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [94/469], Loss: 2.1203, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [95/469], Loss: 2.2293, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [96/469], Loss: 2.1341, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [8/50], Step [97/469], Loss: 2.1510, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [98/469], Loss: 2.1549, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [99/469], Loss: 2.1984, batch time: 0.43, accuracy:  24.22%\n",
      "Epoch [8/50], Step [100/469], Loss: 2.2154, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [101/469], Loss: 2.1590, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [102/469], Loss: 2.2039, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [103/469], Loss: 2.1827, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [8/50], Step [104/469], Loss: 2.1733, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [105/469], Loss: 2.1584, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [106/469], Loss: 2.2002, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [107/469], Loss: 2.1797, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [108/469], Loss: 2.2969, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [8/50], Step [109/469], Loss: 2.2173, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [110/469], Loss: 2.2010, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [111/469], Loss: 2.1292, batch time: 0.47, accuracy:  21.09%\n",
      "Epoch [8/50], Step [112/469], Loss: 2.1858, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [113/469], Loss: 2.1780, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [114/469], Loss: 2.2320, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [8/50], Step [115/469], Loss: 2.2464, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [116/469], Loss: 2.1064, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [117/469], Loss: 2.1982, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [118/469], Loss: 2.2061, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [119/469], Loss: 2.1937, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [120/469], Loss: 2.1869, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [8/50], Step [121/469], Loss: 2.2557, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [122/469], Loss: 2.2182, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [8/50], Step [123/469], Loss: 2.2026, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [124/469], Loss: 2.1945, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [8/50], Step [125/469], Loss: 2.1193, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [126/469], Loss: 2.1787, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [127/469], Loss: 2.1421, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [8/50], Step [128/469], Loss: 2.1420, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [129/469], Loss: 2.1784, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [130/469], Loss: 2.2280, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [131/469], Loss: 2.2286, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [132/469], Loss: 2.2228, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [133/469], Loss: 2.1228, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [8/50], Step [134/469], Loss: 2.2049, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [8/50], Step [135/469], Loss: 2.2147, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [136/469], Loss: 2.2682, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [8/50], Step [137/469], Loss: 2.2128, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [138/469], Loss: 2.1192, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [139/469], Loss: 2.1444, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [140/469], Loss: 2.2462, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [141/469], Loss: 2.1820, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [142/469], Loss: 2.1878, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [143/469], Loss: 2.1863, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [144/469], Loss: 2.1431, batch time: 0.46, accuracy:  21.88%\n",
      "Epoch [8/50], Step [145/469], Loss: 2.1659, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [146/469], Loss: 2.2055, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [147/469], Loss: 2.1167, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [148/469], Loss: 2.2021, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [149/469], Loss: 2.2039, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [150/469], Loss: 2.1376, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [8/50], Step [151/469], Loss: 2.1764, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [152/469], Loss: 2.1490, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [153/469], Loss: 2.1606, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [154/469], Loss: 2.1298, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [155/469], Loss: 2.1368, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [8/50], Step [156/469], Loss: 2.1618, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [157/469], Loss: 2.1907, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [158/469], Loss: 2.1928, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [159/469], Loss: 2.2146, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [8/50], Step [160/469], Loss: 2.2610, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [161/469], Loss: 2.1801, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [162/469], Loss: 2.1072, batch time: 0.42, accuracy:  26.56%\n",
      "Epoch [8/50], Step [163/469], Loss: 2.1888, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [164/469], Loss: 2.1528, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [165/469], Loss: 2.1749, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [166/469], Loss: 2.2017, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [8/50], Step [167/469], Loss: 2.2174, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [168/469], Loss: 2.2070, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [169/469], Loss: 2.1858, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [170/469], Loss: 2.1663, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [8/50], Step [171/469], Loss: 2.1172, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [172/469], Loss: 2.2322, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [173/469], Loss: 2.1709, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [174/469], Loss: 2.2318, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [175/469], Loss: 2.1739, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [176/469], Loss: 2.2136, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [8/50], Step [177/469], Loss: 2.1565, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [8/50], Step [178/469], Loss: 2.2207, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [8/50], Step [179/469], Loss: 2.1499, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [180/469], Loss: 2.1686, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [181/469], Loss: 2.2199, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [182/469], Loss: 2.2325, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [183/469], Loss: 2.1613, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [184/469], Loss: 2.1803, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [8/50], Step [185/469], Loss: 2.1465, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [186/469], Loss: 2.1597, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [187/469], Loss: 2.2199, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [188/469], Loss: 2.1597, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [189/469], Loss: 2.1772, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [190/469], Loss: 2.2260, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [191/469], Loss: 2.1870, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [192/469], Loss: 2.2043, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [193/469], Loss: 2.1431, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [194/469], Loss: 2.1747, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [195/469], Loss: 2.1852, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [196/469], Loss: 2.1753, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [197/469], Loss: 2.1508, batch time: 0.42, accuracy:  27.34%\n",
      "Epoch [8/50], Step [198/469], Loss: 2.1802, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [199/469], Loss: 2.1974, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [200/469], Loss: 2.1500, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [8/50], Step [201/469], Loss: 2.1656, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [202/469], Loss: 2.1754, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [8/50], Step [203/469], Loss: 2.2742, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [204/469], Loss: 2.0832, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [8/50], Step [205/469], Loss: 2.1521, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [206/469], Loss: 2.1827, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [207/469], Loss: 2.2090, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [208/469], Loss: 2.2319, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [209/469], Loss: 2.1931, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [210/469], Loss: 2.2088, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [211/469], Loss: 2.1653, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [212/469], Loss: 2.2217, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [213/469], Loss: 2.1754, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [214/469], Loss: 2.1710, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [215/469], Loss: 2.2003, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [216/469], Loss: 2.1911, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [217/469], Loss: 2.1875, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [218/469], Loss: 2.2065, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [219/469], Loss: 2.1798, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [8/50], Step [220/469], Loss: 2.1327, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [221/469], Loss: 2.1395, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [222/469], Loss: 2.2219, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [223/469], Loss: 2.2066, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [224/469], Loss: 2.1088, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [225/469], Loss: 2.2438, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [226/469], Loss: 2.1365, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [227/469], Loss: 2.1513, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [228/469], Loss: 2.1445, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [8/50], Step [229/469], Loss: 2.1424, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [230/469], Loss: 2.1375, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [231/469], Loss: 2.1582, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [232/469], Loss: 2.1877, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [233/469], Loss: 2.2068, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [234/469], Loss: 2.1355, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [235/469], Loss: 2.1152, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [236/469], Loss: 2.1886, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [237/469], Loss: 2.1760, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [238/469], Loss: 2.0800, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [239/469], Loss: 2.1410, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [240/469], Loss: 2.2107, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [241/469], Loss: 2.1932, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [242/469], Loss: 2.0909, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [243/469], Loss: 2.1662, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [244/469], Loss: 2.2077, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [8/50], Step [245/469], Loss: 2.1427, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [246/469], Loss: 2.1768, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [247/469], Loss: 2.0957, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [248/469], Loss: 2.1884, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [249/469], Loss: 2.1924, batch time: 0.40, accuracy:  17.97%\n",
      "Epoch [8/50], Step [250/469], Loss: 2.2180, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [251/469], Loss: 2.1554, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [252/469], Loss: 2.1813, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [253/469], Loss: 2.2234, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [254/469], Loss: 2.1738, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [255/469], Loss: 2.1451, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [8/50], Step [256/469], Loss: 2.1997, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [8/50], Step [257/469], Loss: 2.1725, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [258/469], Loss: 2.2263, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [259/469], Loss: 2.1088, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [260/469], Loss: 2.1752, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [261/469], Loss: 2.1118, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [262/469], Loss: 2.2081, batch time: 0.43, accuracy:  15.62%\n",
      "Epoch [8/50], Step [263/469], Loss: 2.0903, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [264/469], Loss: 2.1405, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [265/469], Loss: 2.1098, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [266/469], Loss: 2.1469, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [8/50], Step [267/469], Loss: 2.1332, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [268/469], Loss: 2.1771, batch time: 0.47, accuracy:  21.09%\n",
      "Epoch [8/50], Step [269/469], Loss: 2.1363, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [270/469], Loss: 2.1663, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [271/469], Loss: 2.1356, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [272/469], Loss: 2.1540, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [273/469], Loss: 2.1701, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [274/469], Loss: 2.1825, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [275/469], Loss: 2.1933, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [276/469], Loss: 2.1443, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [277/469], Loss: 2.2639, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [278/469], Loss: 2.2314, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [279/469], Loss: 2.2163, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [8/50], Step [280/469], Loss: 2.1914, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [281/469], Loss: 2.1810, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [282/469], Loss: 2.2326, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [283/469], Loss: 2.1816, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [284/469], Loss: 2.1489, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [285/469], Loss: 2.1658, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [8/50], Step [286/469], Loss: 2.1778, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [287/469], Loss: 2.1719, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [288/469], Loss: 2.1296, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [289/469], Loss: 2.2049, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [290/469], Loss: 2.1533, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [291/469], Loss: 2.1825, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [292/469], Loss: 2.0879, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [8/50], Step [293/469], Loss: 2.1941, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [294/469], Loss: 2.2471, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [8/50], Step [295/469], Loss: 2.1803, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [296/469], Loss: 2.2047, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [297/469], Loss: 2.2303, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [298/469], Loss: 2.2337, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [299/469], Loss: 2.1624, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [300/469], Loss: 2.0783, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [301/469], Loss: 2.1551, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [302/469], Loss: 2.2080, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [303/469], Loss: 2.1159, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [304/469], Loss: 2.2225, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [305/469], Loss: 2.0907, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [306/469], Loss: 2.1194, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [307/469], Loss: 2.1971, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [308/469], Loss: 2.1157, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [309/469], Loss: 2.1856, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [310/469], Loss: 2.1879, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [311/469], Loss: 2.1568, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [312/469], Loss: 2.1983, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [313/469], Loss: 2.2462, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [314/469], Loss: 2.1714, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [315/469], Loss: 2.1798, batch time: 0.43, accuracy:  22.66%\n",
      "Epoch [8/50], Step [316/469], Loss: 2.1500, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [317/469], Loss: 2.1160, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [318/469], Loss: 2.1426, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [319/469], Loss: 2.0755, batch time: 0.42, accuracy:  26.56%\n",
      "Epoch [8/50], Step [320/469], Loss: 2.1628, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [321/469], Loss: 2.1980, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [322/469], Loss: 2.1785, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [323/469], Loss: 2.1467, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [324/469], Loss: 2.1444, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [325/469], Loss: 2.1433, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [326/469], Loss: 2.1981, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [8/50], Step [327/469], Loss: 2.1288, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [328/469], Loss: 2.1418, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [329/469], Loss: 2.1483, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [330/469], Loss: 2.1414, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [331/469], Loss: 2.1196, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [332/469], Loss: 2.0819, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [8/50], Step [333/469], Loss: 2.2483, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [8/50], Step [334/469], Loss: 2.2632, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [8/50], Step [335/469], Loss: 2.1418, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [8/50], Step [336/469], Loss: 2.1127, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [337/469], Loss: 2.1233, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [338/469], Loss: 2.1252, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [339/469], Loss: 2.1203, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [8/50], Step [340/469], Loss: 2.2223, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [341/469], Loss: 2.1989, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [342/469], Loss: 2.2327, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [343/469], Loss: 2.2739, batch time: 0.41, accuracy:  10.94%\n",
      "Epoch [8/50], Step [344/469], Loss: 2.1290, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [345/469], Loss: 2.1172, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [346/469], Loss: 2.2048, batch time: 0.47, accuracy:  13.28%\n",
      "Epoch [8/50], Step [347/469], Loss: 2.1962, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [348/469], Loss: 2.1467, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [349/469], Loss: 2.0631, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [350/469], Loss: 2.2326, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [351/469], Loss: 2.2120, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [352/469], Loss: 2.1842, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [353/469], Loss: 2.0696, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [8/50], Step [354/469], Loss: 2.1878, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [355/469], Loss: 2.1276, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [356/469], Loss: 2.2073, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [357/469], Loss: 2.1624, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [358/469], Loss: 2.1703, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [8/50], Step [359/469], Loss: 2.2260, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [360/469], Loss: 2.1202, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [361/469], Loss: 2.1631, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [362/469], Loss: 2.2091, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [363/469], Loss: 2.1412, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [364/469], Loss: 2.0883, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [365/469], Loss: 2.1430, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [366/469], Loss: 2.2264, batch time: 0.42, accuracy:  16.41%\n",
      "Epoch [8/50], Step [367/469], Loss: 2.1700, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [368/469], Loss: 2.1498, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [369/469], Loss: 2.0761, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [8/50], Step [370/469], Loss: 2.1708, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [371/469], Loss: 2.1029, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [372/469], Loss: 2.2082, batch time: 0.41, accuracy:  12.50%\n",
      "Epoch [8/50], Step [373/469], Loss: 2.1495, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [374/469], Loss: 2.0927, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [375/469], Loss: 2.1245, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [376/469], Loss: 2.1433, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [377/469], Loss: 2.1361, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [378/469], Loss: 2.1487, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [379/469], Loss: 2.0713, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [380/469], Loss: 2.1732, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [381/469], Loss: 2.0828, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [382/469], Loss: 2.1472, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [383/469], Loss: 2.1158, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [384/469], Loss: 2.1488, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [8/50], Step [385/469], Loss: 2.1378, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [386/469], Loss: 2.2369, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [387/469], Loss: 2.1409, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [388/469], Loss: 2.1506, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [8/50], Step [389/469], Loss: 2.2205, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [390/469], Loss: 2.1586, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [391/469], Loss: 2.2072, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [392/469], Loss: 2.1522, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [393/469], Loss: 2.1433, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [394/469], Loss: 2.1275, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [395/469], Loss: 2.1529, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [396/469], Loss: 2.1793, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [397/469], Loss: 2.0982, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [398/469], Loss: 2.1952, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [8/50], Step [399/469], Loss: 2.1965, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [400/469], Loss: 2.1407, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [401/469], Loss: 2.1943, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [8/50], Step [402/469], Loss: 2.0652, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [8/50], Step [403/469], Loss: 2.0625, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [8/50], Step [404/469], Loss: 2.1594, batch time: 0.47, accuracy:  20.31%\n",
      "Epoch [8/50], Step [405/469], Loss: 2.1778, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [406/469], Loss: 2.0456, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [8/50], Step [407/469], Loss: 2.1188, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [408/469], Loss: 2.0982, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [409/469], Loss: 2.2005, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [410/469], Loss: 2.2073, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [8/50], Step [411/469], Loss: 2.1825, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [412/469], Loss: 2.0892, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [413/469], Loss: 2.1429, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [414/469], Loss: 2.2309, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [415/469], Loss: 2.1439, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [416/469], Loss: 2.1450, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [8/50], Step [417/469], Loss: 2.1922, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [418/469], Loss: 2.1360, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [419/469], Loss: 2.1556, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [420/469], Loss: 2.2180, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [421/469], Loss: 2.2022, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [8/50], Step [422/469], Loss: 2.1301, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [8/50], Step [423/469], Loss: 2.1027, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [8/50], Step [424/469], Loss: 2.1822, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [425/469], Loss: 2.1047, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [426/469], Loss: 2.1886, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [8/50], Step [427/469], Loss: 2.1921, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [428/469], Loss: 2.1896, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [429/469], Loss: 2.1090, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [430/469], Loss: 2.1609, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [8/50], Step [431/469], Loss: 2.1347, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [432/469], Loss: 2.1084, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [433/469], Loss: 2.1780, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [434/469], Loss: 2.1168, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [8/50], Step [435/469], Loss: 2.0772, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [436/469], Loss: 2.1502, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [437/469], Loss: 2.1282, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [438/469], Loss: 2.2111, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [439/469], Loss: 2.1100, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [440/469], Loss: 2.1382, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [8/50], Step [441/469], Loss: 2.1619, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [8/50], Step [442/469], Loss: 2.1610, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [443/469], Loss: 2.1159, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [444/469], Loss: 2.1849, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [8/50], Step [445/469], Loss: 2.1221, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [446/469], Loss: 2.1190, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [447/469], Loss: 2.0275, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [8/50], Step [448/469], Loss: 2.1527, batch time: 0.43, accuracy:  18.75%\n",
      "Epoch [8/50], Step [449/469], Loss: 2.1732, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [8/50], Step [450/469], Loss: 2.0377, batch time: 0.46, accuracy:  26.56%\n",
      "Epoch [8/50], Step [451/469], Loss: 2.0787, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [8/50], Step [452/469], Loss: 2.1970, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [8/50], Step [453/469], Loss: 2.1680, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [454/469], Loss: 2.1864, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [8/50], Step [455/469], Loss: 2.0883, batch time: 0.42, accuracy:  25.78%\n",
      "Epoch [8/50], Step [456/469], Loss: 2.1464, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [8/50], Step [457/469], Loss: 2.2563, batch time: 0.41, accuracy:  13.28%\n",
      "Epoch [8/50], Step [458/469], Loss: 2.1502, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [8/50], Step [459/469], Loss: 2.1624, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [460/469], Loss: 2.1436, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [8/50], Step [461/469], Loss: 2.1534, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [462/469], Loss: 2.1873, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [8/50], Step [463/469], Loss: 2.2241, batch time: 0.42, accuracy:  11.72%\n",
      "Epoch [8/50], Step [464/469], Loss: 2.1626, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [8/50], Step [465/469], Loss: 2.1143, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [8/50], Step [466/469], Loss: 2.1904, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [8/50], Step [467/469], Loss: 2.1232, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [8/50], Step [468/469], Loss: 2.1110, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [8/50], Step [469/469], Loss: 2.1419, batch time: 0.41, accuracy:  20.83%\n",
      "Epoch [9/50], Step [1/469], Loss: 2.1833, batch time: 0.42, accuracy:  15.62%\n",
      "Epoch [9/50], Step [2/469], Loss: 2.2392, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [9/50], Step [3/469], Loss: 2.0790, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [4/469], Loss: 2.1256, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [5/469], Loss: 2.1293, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [6/469], Loss: 2.1800, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [7/469], Loss: 2.1934, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [8/469], Loss: 2.1581, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [9/469], Loss: 2.0440, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [10/469], Loss: 2.1148, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [9/50], Step [11/469], Loss: 2.0927, batch time: 0.42, accuracy:  25.78%\n",
      "Epoch [9/50], Step [12/469], Loss: 2.1221, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [13/469], Loss: 2.1435, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [9/50], Step [14/469], Loss: 2.1639, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [9/50], Step [15/469], Loss: 2.1390, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [9/50], Step [16/469], Loss: 2.1495, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [17/469], Loss: 2.1739, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [18/469], Loss: 2.1671, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [9/50], Step [19/469], Loss: 2.0494, batch time: 0.47, accuracy:  25.78%\n",
      "Epoch [9/50], Step [20/469], Loss: 2.1371, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [21/469], Loss: 2.0070, batch time: 0.42, accuracy:  28.91%\n",
      "Epoch [9/50], Step [22/469], Loss: 2.1442, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [9/50], Step [23/469], Loss: 2.1156, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [24/469], Loss: 2.0720, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [25/469], Loss: 2.0901, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [26/469], Loss: 2.1153, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [27/469], Loss: 2.1724, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [28/469], Loss: 2.1412, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [9/50], Step [29/469], Loss: 2.1000, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [30/469], Loss: 2.1743, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [31/469], Loss: 2.1511, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [9/50], Step [32/469], Loss: 2.0990, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [33/469], Loss: 2.1693, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [34/469], Loss: 2.1336, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [35/469], Loss: 2.0984, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [36/469], Loss: 2.1547, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [37/469], Loss: 2.0780, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [38/469], Loss: 2.1427, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [39/469], Loss: 2.1564, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [40/469], Loss: 2.1208, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [41/469], Loss: 2.0898, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [42/469], Loss: 2.0794, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [9/50], Step [43/469], Loss: 2.0303, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [44/469], Loss: 2.0825, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [45/469], Loss: 2.1158, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [9/50], Step [46/469], Loss: 2.1348, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [9/50], Step [47/469], Loss: 2.0866, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [48/469], Loss: 2.3013, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [49/469], Loss: 2.0433, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [50/469], Loss: 2.1273, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [51/469], Loss: 2.1248, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [52/469], Loss: 2.1257, batch time: 0.47, accuracy:  17.19%\n",
      "Epoch [9/50], Step [53/469], Loss: 2.1844, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [54/469], Loss: 2.1271, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [55/469], Loss: 2.1576, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [9/50], Step [56/469], Loss: 2.1477, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [57/469], Loss: 2.1201, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [58/469], Loss: 2.1080, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [59/469], Loss: 2.1367, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [60/469], Loss: 2.1606, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [9/50], Step [61/469], Loss: 2.1445, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [62/469], Loss: 2.1078, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [63/469], Loss: 2.1551, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [64/469], Loss: 2.2031, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [65/469], Loss: 2.0993, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [66/469], Loss: 2.1330, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [67/469], Loss: 2.0075, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [9/50], Step [68/469], Loss: 2.1144, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [69/469], Loss: 2.0741, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [9/50], Step [70/469], Loss: 2.0532, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [71/469], Loss: 2.1060, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [72/469], Loss: 2.1839, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [73/469], Loss: 2.1264, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [74/469], Loss: 2.1457, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [9/50], Step [75/469], Loss: 2.0673, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [9/50], Step [76/469], Loss: 2.1130, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [77/469], Loss: 2.1166, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [78/469], Loss: 2.1755, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [79/469], Loss: 2.1521, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [80/469], Loss: 2.1157, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [81/469], Loss: 2.1495, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [82/469], Loss: 2.1309, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [83/469], Loss: 2.0993, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [84/469], Loss: 2.1766, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [9/50], Step [85/469], Loss: 2.0971, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [86/469], Loss: 2.1716, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [87/469], Loss: 2.1521, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [88/469], Loss: 2.1205, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [89/469], Loss: 2.2286, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [9/50], Step [90/469], Loss: 2.0704, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [91/469], Loss: 2.1445, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [9/50], Step [92/469], Loss: 2.2049, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [93/469], Loss: 2.1351, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [94/469], Loss: 2.1157, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [95/469], Loss: 2.1001, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [96/469], Loss: 2.0712, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [97/469], Loss: 2.1217, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [98/469], Loss: 2.0968, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [99/469], Loss: 2.2755, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [100/469], Loss: 2.0847, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [101/469], Loss: 2.1741, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [102/469], Loss: 2.1205, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [103/469], Loss: 2.1790, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [104/469], Loss: 2.1176, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [105/469], Loss: 2.1970, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [9/50], Step [106/469], Loss: 2.0823, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [107/469], Loss: 2.0779, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [108/469], Loss: 2.0833, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [109/469], Loss: 2.1300, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [110/469], Loss: 2.1832, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [9/50], Step [111/469], Loss: 2.1631, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [112/469], Loss: 2.1831, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [113/469], Loss: 2.1228, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [114/469], Loss: 2.2132, batch time: 0.41, accuracy:  10.16%\n",
      "Epoch [9/50], Step [115/469], Loss: 2.1187, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [116/469], Loss: 2.0802, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [117/469], Loss: 2.1130, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [118/469], Loss: 2.0605, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [119/469], Loss: 2.1272, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [9/50], Step [120/469], Loss: 2.1789, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [121/469], Loss: 2.0967, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [122/469], Loss: 2.0652, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [9/50], Step [123/469], Loss: 2.0827, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [124/469], Loss: 2.0916, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [125/469], Loss: 2.1075, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [126/469], Loss: 2.1309, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [9/50], Step [127/469], Loss: 2.1244, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [128/469], Loss: 2.2216, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [129/469], Loss: 2.1338, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [130/469], Loss: 2.0381, batch time: 0.42, accuracy:  27.34%\n",
      "Epoch [9/50], Step [131/469], Loss: 2.1711, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [132/469], Loss: 2.1156, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [133/469], Loss: 2.0896, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [134/469], Loss: 2.1201, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [135/469], Loss: 2.1513, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [136/469], Loss: 2.1122, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [137/469], Loss: 2.0519, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [138/469], Loss: 2.2225, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [9/50], Step [139/469], Loss: 2.0313, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [140/469], Loss: 2.0807, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [141/469], Loss: 1.9705, batch time: 0.46, accuracy:  32.81%\n",
      "Epoch [9/50], Step [142/469], Loss: 2.1904, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [143/469], Loss: 2.0715, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [9/50], Step [144/469], Loss: 2.0772, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [9/50], Step [145/469], Loss: 2.1579, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [146/469], Loss: 2.1443, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [147/469], Loss: 2.0903, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [148/469], Loss: 2.1358, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [149/469], Loss: 2.1370, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [150/469], Loss: 1.9956, batch time: 0.47, accuracy:  25.00%\n",
      "Epoch [9/50], Step [151/469], Loss: 2.1417, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [152/469], Loss: 2.0658, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [153/469], Loss: 2.1062, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [154/469], Loss: 2.1249, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [155/469], Loss: 2.1460, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [156/469], Loss: 2.0736, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [157/469], Loss: 2.2816, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [9/50], Step [158/469], Loss: 2.1231, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [159/469], Loss: 2.0507, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [160/469], Loss: 2.1150, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [161/469], Loss: 2.1800, batch time: 0.42, accuracy:  17.97%\n",
      "Epoch [9/50], Step [162/469], Loss: 2.1189, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [163/469], Loss: 2.1026, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [164/469], Loss: 2.0967, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [165/469], Loss: 2.0158, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [9/50], Step [166/469], Loss: 2.1100, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [167/469], Loss: 2.1275, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [168/469], Loss: 2.0332, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [169/469], Loss: 2.0990, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [170/469], Loss: 2.0144, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [9/50], Step [171/469], Loss: 2.0701, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [172/469], Loss: 2.1362, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [173/469], Loss: 2.0902, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [174/469], Loss: 2.0638, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [175/469], Loss: 2.0882, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [9/50], Step [176/469], Loss: 2.1494, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [9/50], Step [177/469], Loss: 2.1401, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [178/469], Loss: 2.0648, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [9/50], Step [179/469], Loss: 2.0327, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [180/469], Loss: 2.1320, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [181/469], Loss: 1.9680, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [182/469], Loss: 2.0308, batch time: 0.42, accuracy:  26.56%\n",
      "Epoch [9/50], Step [183/469], Loss: 2.0993, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [184/469], Loss: 2.0829, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [185/469], Loss: 2.1367, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [186/469], Loss: 2.0992, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [187/469], Loss: 2.0778, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [188/469], Loss: 2.1274, batch time: 0.48, accuracy:  21.09%\n",
      "Epoch [9/50], Step [189/469], Loss: 2.0751, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [9/50], Step [190/469], Loss: 2.1069, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [191/469], Loss: 2.1202, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [192/469], Loss: 2.1611, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [193/469], Loss: 2.2066, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [194/469], Loss: 2.0749, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [195/469], Loss: 2.1298, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [196/469], Loss: 2.0742, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [197/469], Loss: 2.0176, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [198/469], Loss: 2.1692, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [199/469], Loss: 2.1364, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [200/469], Loss: 2.1365, batch time: 0.42, accuracy:  17.19%\n",
      "Epoch [9/50], Step [201/469], Loss: 2.1044, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [202/469], Loss: 2.0305, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [203/469], Loss: 1.9939, batch time: 0.42, accuracy:  28.12%\n",
      "Epoch [9/50], Step [204/469], Loss: 2.1281, batch time: 0.41, accuracy:  15.62%\n",
      "Epoch [9/50], Step [205/469], Loss: 2.0508, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [206/469], Loss: 2.0819, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [207/469], Loss: 2.1340, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [208/469], Loss: 2.1227, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [209/469], Loss: 2.0756, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [9/50], Step [210/469], Loss: 2.1916, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [211/469], Loss: 2.1262, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [212/469], Loss: 2.0320, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [213/469], Loss: 2.0690, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [9/50], Step [214/469], Loss: 2.0128, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [215/469], Loss: 2.1037, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [216/469], Loss: 2.0607, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [217/469], Loss: 2.0638, batch time: 0.42, accuracy:  27.34%\n",
      "Epoch [9/50], Step [218/469], Loss: 2.1719, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [219/469], Loss: 2.1490, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [220/469], Loss: 2.1215, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [221/469], Loss: 2.0843, batch time: 0.47, accuracy:  25.78%\n",
      "Epoch [9/50], Step [222/469], Loss: 2.1045, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [9/50], Step [223/469], Loss: 2.1096, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [224/469], Loss: 2.0519, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [225/469], Loss: 2.0397, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [226/469], Loss: 2.0336, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [9/50], Step [227/469], Loss: 2.0551, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [228/469], Loss: 2.1453, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [229/469], Loss: 2.0802, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [230/469], Loss: 2.0929, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [9/50], Step [231/469], Loss: 2.1287, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [232/469], Loss: 1.9830, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [233/469], Loss: 2.1107, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [234/469], Loss: 2.0153, batch time: 0.42, accuracy:  25.78%\n",
      "Epoch [9/50], Step [235/469], Loss: 2.0460, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [236/469], Loss: 2.0750, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [237/469], Loss: 2.1930, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [238/469], Loss: 2.0763, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [239/469], Loss: 2.1149, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [240/469], Loss: 2.0222, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [9/50], Step [241/469], Loss: 2.1088, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [242/469], Loss: 2.0181, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [243/469], Loss: 2.0149, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [244/469], Loss: 2.1129, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [245/469], Loss: 2.1236, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [246/469], Loss: 2.1376, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [247/469], Loss: 2.0660, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [248/469], Loss: 2.1039, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [249/469], Loss: 2.0573, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [250/469], Loss: 2.1023, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [251/469], Loss: 2.1187, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [252/469], Loss: 2.0632, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [253/469], Loss: 2.0553, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [254/469], Loss: 2.0213, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [9/50], Step [255/469], Loss: 2.1112, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [256/469], Loss: 2.0629, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [257/469], Loss: 2.0507, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [9/50], Step [258/469], Loss: 2.1085, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [259/469], Loss: 2.0957, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [260/469], Loss: 2.0509, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [261/469], Loss: 2.0580, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [262/469], Loss: 2.0993, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [263/469], Loss: 2.0412, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [264/469], Loss: 2.1280, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [265/469], Loss: 2.0479, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [266/469], Loss: 2.0284, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [267/469], Loss: 2.1453, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [268/469], Loss: 2.0129, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [269/469], Loss: 2.0128, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [9/50], Step [270/469], Loss: 2.0619, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [271/469], Loss: 2.0988, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [272/469], Loss: 1.9947, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [273/469], Loss: 2.0822, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [274/469], Loss: 2.0406, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [275/469], Loss: 2.0050, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [276/469], Loss: 2.0733, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [277/469], Loss: 2.0664, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [278/469], Loss: 2.1657, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [279/469], Loss: 2.0963, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [280/469], Loss: 2.0285, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [281/469], Loss: 2.2594, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [282/469], Loss: 2.1602, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [283/469], Loss: 2.0898, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [284/469], Loss: 2.0584, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [285/469], Loss: 2.1256, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [286/469], Loss: 2.0882, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [287/469], Loss: 1.9804, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [288/469], Loss: 2.1031, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [289/469], Loss: 2.0728, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [290/469], Loss: 2.0384, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [291/469], Loss: 2.1429, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [292/469], Loss: 2.1008, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [9/50], Step [293/469], Loss: 2.0642, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [294/469], Loss: 2.0826, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [295/469], Loss: 1.9914, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [296/469], Loss: 2.0272, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [297/469], Loss: 2.1052, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [298/469], Loss: 1.9902, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [299/469], Loss: 2.1174, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [300/469], Loss: 2.1310, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [301/469], Loss: 2.0932, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [302/469], Loss: 2.0381, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [303/469], Loss: 2.1847, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [304/469], Loss: 2.0409, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [305/469], Loss: 2.1152, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [9/50], Step [306/469], Loss: 2.0060, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [307/469], Loss: 2.1651, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [9/50], Step [308/469], Loss: 2.1050, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [309/469], Loss: 2.0419, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [9/50], Step [310/469], Loss: 2.0584, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [311/469], Loss: 2.0934, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [312/469], Loss: 1.9983, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [313/469], Loss: 2.0614, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [314/469], Loss: 2.1473, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [315/469], Loss: 2.1143, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [316/469], Loss: 2.1217, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [317/469], Loss: 2.0071, batch time: 0.42, accuracy:  31.25%\n",
      "Epoch [9/50], Step [318/469], Loss: 2.0478, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [9/50], Step [319/469], Loss: 1.9794, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [9/50], Step [320/469], Loss: 2.0864, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [321/469], Loss: 1.9559, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [9/50], Step [322/469], Loss: 2.0777, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [9/50], Step [323/469], Loss: 2.0950, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [324/469], Loss: 2.0784, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [325/469], Loss: 2.1146, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [326/469], Loss: 2.0481, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [9/50], Step [327/469], Loss: 1.9829, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [9/50], Step [328/469], Loss: 1.9893, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [9/50], Step [329/469], Loss: 2.0261, batch time: 0.44, accuracy:  28.12%\n",
      "Epoch [9/50], Step [330/469], Loss: 2.0908, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [331/469], Loss: 2.0675, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [332/469], Loss: 2.0970, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [333/469], Loss: 1.9691, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [9/50], Step [334/469], Loss: 2.1257, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [335/469], Loss: 1.9837, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [9/50], Step [336/469], Loss: 2.0205, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [337/469], Loss: 2.0043, batch time: 0.42, accuracy:  26.56%\n",
      "Epoch [9/50], Step [338/469], Loss: 2.0028, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [339/469], Loss: 2.0751, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [340/469], Loss: 2.0572, batch time: 0.42, accuracy:  28.12%\n",
      "Epoch [9/50], Step [341/469], Loss: 2.1447, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [342/469], Loss: 2.0986, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [343/469], Loss: 2.0602, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [344/469], Loss: 1.9708, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [345/469], Loss: 2.1322, batch time: 0.47, accuracy:  21.88%\n",
      "Epoch [9/50], Step [346/469], Loss: 1.9380, batch time: 0.45, accuracy:  35.16%\n",
      "Epoch [9/50], Step [347/469], Loss: 2.1306, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [348/469], Loss: 2.0845, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [349/469], Loss: 2.0936, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [350/469], Loss: 2.0263, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [351/469], Loss: 2.1336, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [352/469], Loss: 2.0654, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [353/469], Loss: 2.1082, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [354/469], Loss: 2.1507, batch time: 0.42, accuracy:  18.75%\n",
      "Epoch [9/50], Step [355/469], Loss: 2.1096, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [356/469], Loss: 2.0655, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [357/469], Loss: 1.9569, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [9/50], Step [358/469], Loss: 2.0982, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [359/469], Loss: 1.9564, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [360/469], Loss: 2.1058, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [9/50], Step [361/469], Loss: 2.0104, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [9/50], Step [362/469], Loss: 1.9305, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [9/50], Step [363/469], Loss: 2.0943, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [364/469], Loss: 2.0452, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [365/469], Loss: 2.0852, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [366/469], Loss: 2.1006, batch time: 0.41, accuracy:  14.06%\n",
      "Epoch [9/50], Step [367/469], Loss: 2.0839, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [9/50], Step [368/469], Loss: 2.0000, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [369/469], Loss: 2.1717, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [370/469], Loss: 2.0529, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [371/469], Loss: 2.0258, batch time: 0.42, accuracy:  25.00%\n",
      "Epoch [9/50], Step [372/469], Loss: 2.0641, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [373/469], Loss: 2.0275, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [374/469], Loss: 2.0822, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [375/469], Loss: 2.0070, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [376/469], Loss: 2.0313, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [377/469], Loss: 1.9911, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [378/469], Loss: 1.9745, batch time: 0.42, accuracy:  27.34%\n",
      "Epoch [9/50], Step [379/469], Loss: 2.0121, batch time: 0.47, accuracy:  22.66%\n",
      "Epoch [9/50], Step [380/469], Loss: 2.0260, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [9/50], Step [381/469], Loss: 2.0571, batch time: 0.42, accuracy:  19.53%\n",
      "Epoch [9/50], Step [382/469], Loss: 2.0133, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [9/50], Step [383/469], Loss: 2.0020, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [9/50], Step [384/469], Loss: 2.0848, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [385/469], Loss: 1.9745, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [386/469], Loss: 2.1199, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [387/469], Loss: 2.0530, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [388/469], Loss: 2.0173, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [389/469], Loss: 2.0671, batch time: 0.42, accuracy:  20.31%\n",
      "Epoch [9/50], Step [390/469], Loss: 1.9961, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [391/469], Loss: 2.1178, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [392/469], Loss: 2.0702, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [393/469], Loss: 1.9752, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [9/50], Step [394/469], Loss: 2.0246, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [395/469], Loss: 2.0888, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [396/469], Loss: 1.9756, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [397/469], Loss: 2.0487, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [9/50], Step [398/469], Loss: 2.0916, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [399/469], Loss: 2.0850, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [400/469], Loss: 2.0455, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [401/469], Loss: 1.9431, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [9/50], Step [402/469], Loss: 2.0287, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [403/469], Loss: 1.9708, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [9/50], Step [404/469], Loss: 1.9999, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [9/50], Step [405/469], Loss: 2.0413, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [406/469], Loss: 2.1067, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [407/469], Loss: 1.9217, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [408/469], Loss: 2.0097, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [409/469], Loss: 2.1055, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [410/469], Loss: 1.9216, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [9/50], Step [411/469], Loss: 2.0360, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [412/469], Loss: 2.0269, batch time: 0.46, accuracy:  19.53%\n",
      "Epoch [9/50], Step [413/469], Loss: 2.1110, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [414/469], Loss: 2.1260, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [415/469], Loss: 2.0010, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [416/469], Loss: 2.1168, batch time: 0.41, accuracy:  16.41%\n",
      "Epoch [9/50], Step [417/469], Loss: 1.9481, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [9/50], Step [418/469], Loss: 2.1558, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [419/469], Loss: 1.9166, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [9/50], Step [420/469], Loss: 2.0310, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [9/50], Step [421/469], Loss: 2.1162, batch time: 0.42, accuracy:  22.66%\n",
      "Epoch [9/50], Step [422/469], Loss: 2.0359, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [9/50], Step [423/469], Loss: 2.0012, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [424/469], Loss: 2.0695, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [425/469], Loss: 2.0042, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [426/469], Loss: 2.0483, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [427/469], Loss: 2.0797, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [428/469], Loss: 2.0717, batch time: 0.41, accuracy:  14.84%\n",
      "Epoch [9/50], Step [429/469], Loss: 2.0405, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [9/50], Step [430/469], Loss: 2.0028, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [9/50], Step [431/469], Loss: 1.9376, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [432/469], Loss: 2.0387, batch time: 0.42, accuracy:  21.09%\n",
      "Epoch [9/50], Step [433/469], Loss: 1.9844, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [434/469], Loss: 2.0057, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [435/469], Loss: 2.0141, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [436/469], Loss: 2.1115, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [437/469], Loss: 2.1180, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [438/469], Loss: 2.0211, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [439/469], Loss: 2.0011, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [440/469], Loss: 1.9421, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [9/50], Step [441/469], Loss: 2.0503, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [9/50], Step [442/469], Loss: 2.0637, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [443/469], Loss: 1.9771, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [444/469], Loss: 1.9872, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [445/469], Loss: 2.0368, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [446/469], Loss: 1.9958, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [447/469], Loss: 2.0848, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [448/469], Loss: 1.9950, batch time: 0.42, accuracy:  24.22%\n",
      "Epoch [9/50], Step [449/469], Loss: 2.1150, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [450/469], Loss: 1.9777, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [9/50], Step [451/469], Loss: 1.9431, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [452/469], Loss: 2.0437, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [453/469], Loss: 2.0343, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [9/50], Step [454/469], Loss: 2.0488, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [455/469], Loss: 1.9538, batch time: 0.42, accuracy:  31.25%\n",
      "Epoch [9/50], Step [456/469], Loss: 1.9497, batch time: 0.42, accuracy:  25.78%\n",
      "Epoch [9/50], Step [457/469], Loss: 2.0666, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [458/469], Loss: 2.1007, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [9/50], Step [459/469], Loss: 2.0270, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [9/50], Step [460/469], Loss: 2.0799, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [9/50], Step [461/469], Loss: 1.9448, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [9/50], Step [462/469], Loss: 2.0733, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [463/469], Loss: 1.9513, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [9/50], Step [464/469], Loss: 1.9594, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [9/50], Step [465/469], Loss: 1.9953, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [9/50], Step [466/469], Loss: 2.0031, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [9/50], Step [467/469], Loss: 2.0343, batch time: 0.42, accuracy:  21.88%\n",
      "Epoch [9/50], Step [468/469], Loss: 1.9887, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [9/50], Step [469/469], Loss: 1.9972, batch time: 0.41, accuracy:  26.04%\n",
      "Epoch [10/50], Step [1/469], Loss: 2.0194, batch time: 0.43, accuracy:  25.00%\n",
      "Epoch [10/50], Step [2/469], Loss: 2.0143, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [10/50], Step [3/469], Loss: 1.9403, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [4/469], Loss: 1.9696, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [5/469], Loss: 2.0753, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [6/469], Loss: 1.9141, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [7/469], Loss: 2.0613, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [8/469], Loss: 2.0394, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [9/469], Loss: 1.9920, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [10/469], Loss: 2.0533, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [10/50], Step [11/469], Loss: 2.0959, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [12/469], Loss: 2.0146, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [13/469], Loss: 2.0582, batch time: 0.41, accuracy:  18.75%\n",
      "Epoch [10/50], Step [14/469], Loss: 2.0435, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [10/50], Step [15/469], Loss: 1.8944, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [16/469], Loss: 2.0399, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [17/469], Loss: 2.0480, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [18/469], Loss: 1.9589, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [19/469], Loss: 2.0299, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [20/469], Loss: 2.0507, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [21/469], Loss: 1.9966, batch time: 0.42, accuracy:  25.78%\n",
      "Epoch [10/50], Step [22/469], Loss: 1.9165, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [23/469], Loss: 1.9480, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [24/469], Loss: 1.9682, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [25/469], Loss: 2.0268, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [26/469], Loss: 2.0143, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [10/50], Step [27/469], Loss: 2.0774, batch time: 0.41, accuracy:  17.97%\n",
      "Epoch [10/50], Step [28/469], Loss: 1.9941, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [10/50], Step [29/469], Loss: 2.0268, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [10/50], Step [30/469], Loss: 2.0666, batch time: 0.41, accuracy:  21.09%\n",
      "Epoch [10/50], Step [31/469], Loss: 1.9183, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [32/469], Loss: 1.9270, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [33/469], Loss: 1.8850, batch time: 0.42, accuracy:  29.69%\n",
      "Epoch [10/50], Step [34/469], Loss: 1.9343, batch time: 0.44, accuracy:  35.94%\n",
      "Epoch [10/50], Step [35/469], Loss: 1.8747, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [36/469], Loss: 1.9669, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [10/50], Step [37/469], Loss: 1.9161, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [38/469], Loss: 2.0869, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [10/50], Step [39/469], Loss: 1.8738, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [40/469], Loss: 1.9367, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [41/469], Loss: 1.9802, batch time: 0.41, accuracy:  21.88%\n",
      "Epoch [10/50], Step [42/469], Loss: 2.0001, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [43/469], Loss: 1.8592, batch time: 0.46, accuracy:  28.12%\n",
      "Epoch [10/50], Step [44/469], Loss: 1.9308, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [45/469], Loss: 1.9640, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [10/50], Step [46/469], Loss: 1.8831, batch time: 0.42, accuracy:  35.16%\n",
      "Epoch [10/50], Step [47/469], Loss: 1.9468, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [48/469], Loss: 1.9956, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [10/50], Step [49/469], Loss: 2.0426, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [10/50], Step [50/469], Loss: 1.8884, batch time: 0.45, accuracy:  36.72%\n",
      "Epoch [10/50], Step [51/469], Loss: 2.1252, batch time: 0.41, accuracy:  17.19%\n",
      "Epoch [10/50], Step [52/469], Loss: 1.9486, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [53/469], Loss: 1.9615, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [54/469], Loss: 1.9688, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [10/50], Step [55/469], Loss: 1.9414, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [56/469], Loss: 1.9351, batch time: 0.41, accuracy:  19.53%\n",
      "Epoch [10/50], Step [57/469], Loss: 1.9362, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [58/469], Loss: 1.9186, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [59/469], Loss: 1.9487, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [10/50], Step [60/469], Loss: 1.9936, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [10/50], Step [61/469], Loss: 2.0712, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [62/469], Loss: 1.8702, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [63/469], Loss: 2.0699, batch time: 0.41, accuracy:  20.31%\n",
      "Epoch [10/50], Step [64/469], Loss: 1.8646, batch time: 0.42, accuracy:  35.16%\n",
      "Epoch [10/50], Step [65/469], Loss: 2.0514, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [10/50], Step [66/469], Loss: 1.9979, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [67/469], Loss: 1.8921, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [68/469], Loss: 1.9965, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [69/469], Loss: 2.0050, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [70/469], Loss: 1.8865, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [71/469], Loss: 1.8847, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [72/469], Loss: 2.0098, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [10/50], Step [73/469], Loss: 1.9425, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [74/469], Loss: 1.9821, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [75/469], Loss: 1.9744, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [76/469], Loss: 1.9239, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [77/469], Loss: 1.9757, batch time: 0.41, accuracy:  22.66%\n",
      "Epoch [10/50], Step [78/469], Loss: 1.8623, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [10/50], Step [79/469], Loss: 2.0229, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [80/469], Loss: 1.9676, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [81/469], Loss: 1.8814, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [82/469], Loss: 1.9695, batch time: 0.42, accuracy:  28.91%\n",
      "Epoch [10/50], Step [83/469], Loss: 2.0724, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [84/469], Loss: 1.9524, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [85/469], Loss: 1.9036, batch time: 0.42, accuracy:  31.25%\n",
      "Epoch [10/50], Step [86/469], Loss: 1.9055, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [87/469], Loss: 2.0058, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [88/469], Loss: 1.8233, batch time: 0.42, accuracy:  35.16%\n",
      "Epoch [10/50], Step [89/469], Loss: 1.8713, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [90/469], Loss: 1.8818, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [91/469], Loss: 1.9637, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [10/50], Step [92/469], Loss: 1.9625, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [10/50], Step [93/469], Loss: 1.9288, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [94/469], Loss: 1.9367, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [95/469], Loss: 1.9894, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [96/469], Loss: 1.9953, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [97/469], Loss: 1.9732, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [98/469], Loss: 1.9345, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [99/469], Loss: 1.8577, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [100/469], Loss: 1.9185, batch time: 0.42, accuracy:  30.47%\n",
      "Epoch [10/50], Step [101/469], Loss: 1.9744, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [102/469], Loss: 1.9989, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [103/469], Loss: 1.9239, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [104/469], Loss: 1.9786, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [105/469], Loss: 2.0024, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [106/469], Loss: 1.8600, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [107/469], Loss: 1.9048, batch time: 0.42, accuracy:  25.78%\n",
      "Epoch [10/50], Step [108/469], Loss: 2.0396, batch time: 0.47, accuracy:  24.22%\n",
      "Epoch [10/50], Step [109/469], Loss: 2.0552, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [10/50], Step [110/469], Loss: 1.9329, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [111/469], Loss: 1.9246, batch time: 0.44, accuracy:  37.50%\n",
      "Epoch [10/50], Step [112/469], Loss: 1.8782, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [10/50], Step [113/469], Loss: 1.8893, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [114/469], Loss: 2.0871, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [10/50], Step [115/469], Loss: 1.9738, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [116/469], Loss: 1.9655, batch time: 0.42, accuracy:  30.47%\n",
      "Epoch [10/50], Step [117/469], Loss: 1.9185, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [118/469], Loss: 1.9054, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [119/469], Loss: 1.9331, batch time: 0.42, accuracy:  28.91%\n",
      "Epoch [10/50], Step [120/469], Loss: 1.8648, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [121/469], Loss: 1.8829, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [10/50], Step [122/469], Loss: 1.9753, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [123/469], Loss: 1.9099, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [124/469], Loss: 1.8493, batch time: 0.45, accuracy:  39.06%\n",
      "Epoch [10/50], Step [125/469], Loss: 1.9805, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [126/469], Loss: 1.8627, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [127/469], Loss: 1.9351, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [128/469], Loss: 1.8708, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [129/469], Loss: 2.0219, batch time: 0.41, accuracy:  25.00%\n",
      "Epoch [10/50], Step [130/469], Loss: 2.0377, batch time: 0.41, accuracy:  23.44%\n",
      "Epoch [10/50], Step [131/469], Loss: 2.0108, batch time: 0.42, accuracy:  23.44%\n",
      "Epoch [10/50], Step [132/469], Loss: 1.8729, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [133/469], Loss: 1.7999, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [134/469], Loss: 2.0411, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [135/469], Loss: 1.9373, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [136/469], Loss: 1.8811, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [137/469], Loss: 1.8814, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [138/469], Loss: 1.8489, batch time: 0.46, accuracy:  32.81%\n",
      "Epoch [10/50], Step [139/469], Loss: 1.9417, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [140/469], Loss: 1.8985, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [141/469], Loss: 1.9667, batch time: 0.42, accuracy:  29.69%\n",
      "Epoch [10/50], Step [142/469], Loss: 1.8161, batch time: 0.43, accuracy:  33.59%\n",
      "Epoch [10/50], Step [143/469], Loss: 1.7988, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [144/469], Loss: 1.9506, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [145/469], Loss: 1.9502, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [146/469], Loss: 1.8697, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [147/469], Loss: 1.9416, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [148/469], Loss: 1.8820, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [149/469], Loss: 1.9001, batch time: 0.41, accuracy:  28.91%\n",
      "Epoch [10/50], Step [150/469], Loss: 1.8659, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [10/50], Step [151/469], Loss: 1.8507, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [152/469], Loss: 1.7951, batch time: 0.42, accuracy:  35.94%\n",
      "Epoch [10/50], Step [153/469], Loss: 1.7846, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [154/469], Loss: 1.8395, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [155/469], Loss: 1.8333, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [156/469], Loss: 1.9152, batch time: 0.41, accuracy:  26.56%\n",
      "Epoch [10/50], Step [157/469], Loss: 1.8093, batch time: 0.45, accuracy:  40.62%\n",
      "Epoch [10/50], Step [158/469], Loss: 1.8861, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [159/469], Loss: 1.9251, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [160/469], Loss: 1.7541, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [161/469], Loss: 1.9029, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [162/469], Loss: 1.9545, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [163/469], Loss: 1.9043, batch time: 0.41, accuracy:  25.78%\n",
      "Epoch [10/50], Step [164/469], Loss: 1.8495, batch time: 0.40, accuracy:  29.69%\n",
      "Epoch [10/50], Step [165/469], Loss: 1.8828, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [10/50], Step [166/469], Loss: 1.8366, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [167/469], Loss: 1.8169, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [168/469], Loss: 1.9927, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [169/469], Loss: 1.8408, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [170/469], Loss: 1.8840, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [10/50], Step [171/469], Loss: 1.9800, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [172/469], Loss: 1.8638, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [173/469], Loss: 1.9118, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [174/469], Loss: 1.9246, batch time: 0.40, accuracy:  32.81%\n",
      "Epoch [10/50], Step [175/469], Loss: 1.9045, batch time: 0.40, accuracy:  28.91%\n",
      "Epoch [10/50], Step [176/469], Loss: 2.0328, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [177/469], Loss: 1.8604, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [178/469], Loss: 1.9635, batch time: 0.40, accuracy:  29.69%\n",
      "Epoch [10/50], Step [179/469], Loss: 1.8558, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [180/469], Loss: 1.9361, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [181/469], Loss: 1.9135, batch time: 0.40, accuracy:  33.59%\n",
      "Epoch [10/50], Step [182/469], Loss: 1.8935, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [10/50], Step [183/469], Loss: 1.8243, batch time: 0.41, accuracy:  30.47%\n",
      "Epoch [10/50], Step [184/469], Loss: 1.9205, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [185/469], Loss: 1.7559, batch time: 0.45, accuracy:  41.41%\n",
      "Epoch [10/50], Step [186/469], Loss: 1.8927, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [187/469], Loss: 1.7741, batch time: 0.46, accuracy:  39.84%\n",
      "Epoch [10/50], Step [188/469], Loss: 1.8441, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [10/50], Step [189/469], Loss: 1.8527, batch time: 0.40, accuracy:  32.03%\n",
      "Epoch [10/50], Step [190/469], Loss: 1.8159, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [191/469], Loss: 1.8500, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [192/469], Loss: 1.9376, batch time: 0.41, accuracy:  29.69%\n",
      "Epoch [10/50], Step [193/469], Loss: 1.7345, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [194/469], Loss: 1.8301, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [10/50], Step [195/469], Loss: 1.8361, batch time: 0.40, accuracy:  34.38%\n",
      "Epoch [10/50], Step [196/469], Loss: 1.9841, batch time: 0.40, accuracy:  31.25%\n",
      "Epoch [10/50], Step [197/469], Loss: 1.9104, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [198/469], Loss: 1.7675, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [199/469], Loss: 1.8772, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [200/469], Loss: 1.9886, batch time: 0.40, accuracy:  28.91%\n",
      "Epoch [10/50], Step [201/469], Loss: 1.7533, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [10/50], Step [202/469], Loss: 1.7589, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [10/50], Step [203/469], Loss: 1.9416, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [10/50], Step [204/469], Loss: 1.8217, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [205/469], Loss: 1.8535, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [206/469], Loss: 1.7666, batch time: 0.44, accuracy:  42.97%\n",
      "Epoch [10/50], Step [207/469], Loss: 1.8797, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [208/469], Loss: 1.8954, batch time: 0.41, accuracy:  27.34%\n",
      "Epoch [10/50], Step [209/469], Loss: 2.0277, batch time: 0.40, accuracy:  34.38%\n",
      "Epoch [10/50], Step [210/469], Loss: 1.7643, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [10/50], Step [211/469], Loss: 1.9678, batch time: 0.40, accuracy:  31.25%\n",
      "Epoch [10/50], Step [212/469], Loss: 1.9085, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [213/469], Loss: 1.8445, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [214/469], Loss: 1.7540, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [215/469], Loss: 1.7222, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [216/469], Loss: 1.7925, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [217/469], Loss: 1.8521, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [218/469], Loss: 1.8384, batch time: 0.40, accuracy:  29.69%\n",
      "Epoch [10/50], Step [219/469], Loss: 1.8027, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [220/469], Loss: 2.0433, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [221/469], Loss: 1.8485, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [10/50], Step [222/469], Loss: 2.0106, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [223/469], Loss: 1.8600, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [224/469], Loss: 1.8919, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [225/469], Loss: 1.9030, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [10/50], Step [226/469], Loss: 1.9360, batch time: 0.42, accuracy:  30.47%\n",
      "Epoch [10/50], Step [227/469], Loss: 1.8075, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [228/469], Loss: 1.8730, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [10/50], Step [229/469], Loss: 1.9530, batch time: 0.40, accuracy:  32.81%\n",
      "Epoch [10/50], Step [230/469], Loss: 1.9338, batch time: 0.41, accuracy:  28.12%\n",
      "Epoch [10/50], Step [231/469], Loss: 1.8166, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [10/50], Step [232/469], Loss: 1.8122, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [10/50], Step [233/469], Loss: 1.8393, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [234/469], Loss: 1.8580, batch time: 0.42, accuracy:  35.16%\n",
      "Epoch [10/50], Step [235/469], Loss: 1.8566, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [236/469], Loss: 1.9072, batch time: 0.40, accuracy:  30.47%\n",
      "Epoch [10/50], Step [237/469], Loss: 1.9647, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [238/469], Loss: 1.7679, batch time: 0.47, accuracy:  34.38%\n",
      "Epoch [10/50], Step [239/469], Loss: 1.9562, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [240/469], Loss: 1.8204, batch time: 0.41, accuracy:  31.25%\n",
      "Epoch [10/50], Step [241/469], Loss: 1.8082, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [242/469], Loss: 1.9358, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [243/469], Loss: 1.8518, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [244/469], Loss: 1.7051, batch time: 0.43, accuracy:  44.53%\n",
      "Epoch [10/50], Step [245/469], Loss: 1.9707, batch time: 0.40, accuracy:  27.34%\n",
      "Epoch [10/50], Step [246/469], Loss: 1.8693, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [247/469], Loss: 1.8731, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [248/469], Loss: 1.8076, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [249/469], Loss: 1.7309, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [10/50], Step [250/469], Loss: 1.8487, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [251/469], Loss: 1.7869, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [10/50], Step [252/469], Loss: 1.8495, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [253/469], Loss: 1.9086, batch time: 0.40, accuracy:  31.25%\n",
      "Epoch [10/50], Step [254/469], Loss: 1.7576, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [255/469], Loss: 1.7953, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [256/469], Loss: 1.6724, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [257/469], Loss: 1.8701, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [258/469], Loss: 1.8754, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [259/469], Loss: 1.7908, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [260/469], Loss: 1.7423, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [261/469], Loss: 1.7017, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [262/469], Loss: 1.8440, batch time: 0.40, accuracy:  32.81%\n",
      "Epoch [10/50], Step [263/469], Loss: 1.7903, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [264/469], Loss: 1.8792, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [265/469], Loss: 1.9135, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [266/469], Loss: 1.9427, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [267/469], Loss: 1.7808, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [268/469], Loss: 1.8145, batch time: 0.40, accuracy:  29.69%\n",
      "Epoch [10/50], Step [269/469], Loss: 1.8165, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [270/469], Loss: 1.7882, batch time: 0.42, accuracy:  34.38%\n",
      "Epoch [10/50], Step [271/469], Loss: 1.8222, batch time: 0.47, accuracy:  39.84%\n",
      "Epoch [10/50], Step [272/469], Loss: 1.8367, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [273/469], Loss: 1.9242, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [274/469], Loss: 1.7853, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [275/469], Loss: 1.7409, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [276/469], Loss: 1.9377, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [277/469], Loss: 1.8436, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [278/469], Loss: 1.7951, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [10/50], Step [279/469], Loss: 1.8698, batch time: 0.40, accuracy:  33.59%\n",
      "Epoch [10/50], Step [280/469], Loss: 1.8466, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [281/469], Loss: 1.8789, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [282/469], Loss: 1.8798, batch time: 0.40, accuracy:  26.56%\n",
      "Epoch [10/50], Step [283/469], Loss: 1.8635, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [284/469], Loss: 1.7013, batch time: 0.42, accuracy:  39.06%\n",
      "Epoch [10/50], Step [285/469], Loss: 1.7659, batch time: 0.43, accuracy:  36.72%\n",
      "Epoch [10/50], Step [286/469], Loss: 1.8827, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [287/469], Loss: 1.8354, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [288/469], Loss: 1.7955, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [289/469], Loss: 1.8120, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [290/469], Loss: 1.7326, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [10/50], Step [291/469], Loss: 1.7410, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [292/469], Loss: 1.8047, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [293/469], Loss: 1.8390, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [294/469], Loss: 1.7363, batch time: 0.40, accuracy:  33.59%\n",
      "Epoch [10/50], Step [295/469], Loss: 1.7551, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [296/469], Loss: 1.7850, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [297/469], Loss: 1.8299, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [10/50], Step [298/469], Loss: 1.7009, batch time: 0.42, accuracy:  43.75%\n",
      "Epoch [10/50], Step [299/469], Loss: 1.8118, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [10/50], Step [300/469], Loss: 1.6473, batch time: 0.44, accuracy:  46.88%\n",
      "Epoch [10/50], Step [301/469], Loss: 1.7910, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [10/50], Step [302/469], Loss: 1.8167, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [303/469], Loss: 1.9366, batch time: 0.40, accuracy:  32.03%\n",
      "Epoch [10/50], Step [304/469], Loss: 1.6647, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [10/50], Step [305/469], Loss: 1.7620, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [10/50], Step [306/469], Loss: 1.8022, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [307/469], Loss: 1.8708, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [308/469], Loss: 1.8568, batch time: 0.41, accuracy:  32.81%\n",
      "Epoch [10/50], Step [309/469], Loss: 1.6657, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [310/469], Loss: 1.6456, batch time: 0.44, accuracy:  47.66%\n",
      "Epoch [10/50], Step [311/469], Loss: 1.7332, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [10/50], Step [312/469], Loss: 1.7012, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [313/469], Loss: 1.7342, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [314/469], Loss: 1.7907, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [10/50], Step [315/469], Loss: 1.8633, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [316/469], Loss: 1.7925, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [10/50], Step [317/469], Loss: 1.8413, batch time: 0.42, accuracy:  35.16%\n",
      "Epoch [10/50], Step [318/469], Loss: 1.7478, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [10/50], Step [319/469], Loss: 1.7667, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [10/50], Step [320/469], Loss: 1.6284, batch time: 0.42, accuracy:  47.66%\n",
      "Epoch [10/50], Step [321/469], Loss: 1.8789, batch time: 0.41, accuracy:  24.22%\n",
      "Epoch [10/50], Step [322/469], Loss: 1.9159, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [323/469], Loss: 1.7429, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [324/469], Loss: 1.8010, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [325/469], Loss: 1.8547, batch time: 0.40, accuracy:  32.03%\n",
      "Epoch [10/50], Step [326/469], Loss: 1.9114, batch time: 0.47, accuracy:  39.84%\n",
      "Epoch [10/50], Step [327/469], Loss: 1.9236, batch time: 0.42, accuracy:  34.38%\n",
      "Epoch [10/50], Step [328/469], Loss: 1.6104, batch time: 0.44, accuracy:  48.44%\n",
      "Epoch [10/50], Step [329/469], Loss: 1.8291, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [330/469], Loss: 1.6822, batch time: 0.42, accuracy:  39.06%\n",
      "Epoch [10/50], Step [331/469], Loss: 1.7749, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [332/469], Loss: 1.6485, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [10/50], Step [333/469], Loss: 1.7246, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [10/50], Step [334/469], Loss: 1.7915, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [335/469], Loss: 1.7351, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [336/469], Loss: 1.8573, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [337/469], Loss: 1.7005, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [10/50], Step [338/469], Loss: 1.8240, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [339/469], Loss: 1.7574, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [10/50], Step [340/469], Loss: 1.7881, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [10/50], Step [341/469], Loss: 1.8246, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [10/50], Step [342/469], Loss: 1.8103, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [343/469], Loss: 1.9028, batch time: 0.40, accuracy:  34.38%\n",
      "Epoch [10/50], Step [344/469], Loss: 1.8256, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [345/469], Loss: 1.8230, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [346/469], Loss: 1.7892, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [10/50], Step [347/469], Loss: 1.6788, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [348/469], Loss: 1.8203, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [10/50], Step [349/469], Loss: 1.7707, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [350/469], Loss: 1.6896, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [10/50], Step [351/469], Loss: 1.7553, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [10/50], Step [352/469], Loss: 1.7263, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [353/469], Loss: 1.9102, batch time: 0.40, accuracy:  29.69%\n",
      "Epoch [10/50], Step [354/469], Loss: 1.8651, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [10/50], Step [355/469], Loss: 1.7005, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [356/469], Loss: 1.7914, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [357/469], Loss: 1.7561, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [10/50], Step [358/469], Loss: 1.7871, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [10/50], Step [359/469], Loss: 1.6561, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [360/469], Loss: 1.7177, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [361/469], Loss: 1.6883, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [362/469], Loss: 1.6462, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [10/50], Step [363/469], Loss: 1.6982, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [10/50], Step [364/469], Loss: 1.8174, batch time: 0.40, accuracy:  32.81%\n",
      "Epoch [10/50], Step [365/469], Loss: 1.8168, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [366/469], Loss: 1.8216, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [10/50], Step [367/469], Loss: 1.8307, batch time: 0.40, accuracy:  31.25%\n",
      "Epoch [10/50], Step [368/469], Loss: 1.7770, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [369/469], Loss: 1.8270, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [10/50], Step [370/469], Loss: 1.6642, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [10/50], Step [371/469], Loss: 1.7067, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [10/50], Step [372/469], Loss: 1.7613, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [373/469], Loss: 1.7226, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [10/50], Step [374/469], Loss: 1.7840, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [375/469], Loss: 1.8147, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [10/50], Step [376/469], Loss: 1.6792, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [377/469], Loss: 1.7436, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [378/469], Loss: 1.6518, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [10/50], Step [379/469], Loss: 1.8645, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [10/50], Step [380/469], Loss: 1.9212, batch time: 0.40, accuracy:  31.25%\n",
      "Epoch [10/50], Step [381/469], Loss: 1.7211, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [10/50], Step [382/469], Loss: 1.6368, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [10/50], Step [383/469], Loss: 1.8551, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [384/469], Loss: 1.6769, batch time: 0.44, accuracy:  49.22%\n",
      "Epoch [10/50], Step [385/469], Loss: 1.7581, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [386/469], Loss: 1.7142, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [387/469], Loss: 1.6903, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [388/469], Loss: 1.6589, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [10/50], Step [389/469], Loss: 1.8488, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [10/50], Step [390/469], Loss: 1.6659, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [391/469], Loss: 1.7699, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [392/469], Loss: 1.5991, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [10/50], Step [393/469], Loss: 1.7763, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [394/469], Loss: 1.7122, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [10/50], Step [395/469], Loss: 1.7138, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [10/50], Step [396/469], Loss: 1.7463, batch time: 0.46, accuracy:  42.19%\n",
      "Epoch [10/50], Step [397/469], Loss: 1.7915, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [398/469], Loss: 1.7934, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [399/469], Loss: 1.6695, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [10/50], Step [400/469], Loss: 1.6896, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [401/469], Loss: 1.8001, batch time: 0.42, accuracy:  34.38%\n",
      "Epoch [10/50], Step [402/469], Loss: 1.6756, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [403/469], Loss: 1.8120, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [404/469], Loss: 1.7341, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [405/469], Loss: 1.6192, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [10/50], Step [406/469], Loss: 1.8005, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [407/469], Loss: 1.6649, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [10/50], Step [408/469], Loss: 1.7469, batch time: 0.44, accuracy:  50.00%\n",
      "Epoch [10/50], Step [409/469], Loss: 1.7242, batch time: 0.42, accuracy:  40.62%\n",
      "Epoch [10/50], Step [410/469], Loss: 1.7075, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [411/469], Loss: 1.6473, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [10/50], Step [412/469], Loss: 1.6616, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [413/469], Loss: 1.7410, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [10/50], Step [414/469], Loss: 1.7350, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [10/50], Step [415/469], Loss: 1.5206, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [10/50], Step [416/469], Loss: 1.6896, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [10/50], Step [417/469], Loss: 1.7303, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [10/50], Step [418/469], Loss: 1.7468, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [10/50], Step [419/469], Loss: 1.7933, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [420/469], Loss: 1.8468, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [10/50], Step [421/469], Loss: 1.6452, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [422/469], Loss: 1.5617, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [423/469], Loss: 1.6858, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [424/469], Loss: 1.5473, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [10/50], Step [425/469], Loss: 1.5188, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [10/50], Step [426/469], Loss: 1.7823, batch time: 0.41, accuracy:  33.59%\n",
      "Epoch [10/50], Step [427/469], Loss: 1.8378, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [10/50], Step [428/469], Loss: 1.6719, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [429/469], Loss: 1.6637, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [10/50], Step [430/469], Loss: 1.7454, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [431/469], Loss: 1.7496, batch time: 0.47, accuracy:  38.28%\n",
      "Epoch [10/50], Step [432/469], Loss: 1.8161, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [433/469], Loss: 1.6649, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [10/50], Step [434/469], Loss: 1.6339, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [10/50], Step [435/469], Loss: 1.6327, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [10/50], Step [436/469], Loss: 1.6236, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [10/50], Step [437/469], Loss: 1.6970, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [438/469], Loss: 1.6081, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [10/50], Step [439/469], Loss: 1.8660, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [440/469], Loss: 1.6477, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [441/469], Loss: 1.7013, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [442/469], Loss: 1.8148, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [443/469], Loss: 1.7925, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [444/469], Loss: 1.6415, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [10/50], Step [445/469], Loss: 1.6790, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [446/469], Loss: 1.7369, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [447/469], Loss: 1.7084, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [10/50], Step [448/469], Loss: 1.6977, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [449/469], Loss: 1.9213, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [10/50], Step [450/469], Loss: 1.6240, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [10/50], Step [451/469], Loss: 1.6615, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [10/50], Step [452/469], Loss: 1.4887, batch time: 0.42, accuracy:  45.31%\n",
      "Epoch [10/50], Step [453/469], Loss: 1.7137, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [10/50], Step [454/469], Loss: 1.6125, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [10/50], Step [455/469], Loss: 1.6126, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [456/469], Loss: 1.7350, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [10/50], Step [457/469], Loss: 1.7631, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [458/469], Loss: 1.7518, batch time: 0.41, accuracy:  32.03%\n",
      "Epoch [10/50], Step [459/469], Loss: 1.6828, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [460/469], Loss: 1.7923, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [10/50], Step [461/469], Loss: 1.6187, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [10/50], Step [462/469], Loss: 1.5834, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [10/50], Step [463/469], Loss: 1.6489, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [10/50], Step [464/469], Loss: 1.6299, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [10/50], Step [465/469], Loss: 1.6970, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [10/50], Step [466/469], Loss: 1.8067, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [10/50], Step [467/469], Loss: 1.7227, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [10/50], Step [468/469], Loss: 1.7041, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [10/50], Step [469/469], Loss: 1.9215, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [11/50], Step [1/469], Loss: 1.6223, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [2/469], Loss: 1.8422, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [11/50], Step [3/469], Loss: 1.5397, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [4/469], Loss: 1.5196, batch time: 0.44, accuracy:  51.56%\n",
      "Epoch [11/50], Step [5/469], Loss: 1.7250, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [11/50], Step [6/469], Loss: 1.5935, batch time: 0.42, accuracy:  42.19%\n",
      "Epoch [11/50], Step [7/469], Loss: 1.6804, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [8/469], Loss: 1.6639, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [9/469], Loss: 1.6746, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [10/469], Loss: 1.6172, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [11/50], Step [11/469], Loss: 1.4849, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [11/50], Step [12/469], Loss: 1.8210, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [13/469], Loss: 1.6796, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [11/50], Step [14/469], Loss: 1.8201, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [11/50], Step [15/469], Loss: 1.7014, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [16/469], Loss: 1.5784, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [17/469], Loss: 1.6984, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [18/469], Loss: 1.6582, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [11/50], Step [19/469], Loss: 1.6193, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [20/469], Loss: 1.6814, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [21/469], Loss: 1.7538, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [11/50], Step [22/469], Loss: 1.6518, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [23/469], Loss: 1.8084, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [11/50], Step [24/469], Loss: 1.5094, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [25/469], Loss: 1.7374, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [11/50], Step [26/469], Loss: 1.6397, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [27/469], Loss: 1.5766, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [28/469], Loss: 1.6801, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [29/469], Loss: 1.7481, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [11/50], Step [30/469], Loss: 1.6168, batch time: 0.46, accuracy:  48.44%\n",
      "Epoch [11/50], Step [31/469], Loss: 1.9588, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [32/469], Loss: 1.6383, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [33/469], Loss: 1.7778, batch time: 0.40, accuracy:  32.03%\n",
      "Epoch [11/50], Step [34/469], Loss: 1.6486, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [35/469], Loss: 1.5976, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [36/469], Loss: 1.6692, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [37/469], Loss: 1.7281, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [38/469], Loss: 1.6639, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [39/469], Loss: 1.7033, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [40/469], Loss: 1.6999, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [41/469], Loss: 1.6485, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [42/469], Loss: 1.6660, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [11/50], Step [43/469], Loss: 1.7980, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [44/469], Loss: 1.6247, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [45/469], Loss: 1.6915, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [46/469], Loss: 1.5673, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [47/469], Loss: 1.6713, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [11/50], Step [48/469], Loss: 1.6698, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [49/469], Loss: 1.7328, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [50/469], Loss: 1.7001, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [51/469], Loss: 1.6211, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [52/469], Loss: 1.5531, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [53/469], Loss: 1.8523, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [11/50], Step [54/469], Loss: 1.6069, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [55/469], Loss: 1.4649, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [56/469], Loss: 1.6626, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [57/469], Loss: 1.5777, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [58/469], Loss: 1.5402, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [59/469], Loss: 1.6150, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [60/469], Loss: 1.5165, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [61/469], Loss: 1.6762, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [62/469], Loss: 1.6212, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [63/469], Loss: 1.6167, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [11/50], Step [64/469], Loss: 1.6715, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [65/469], Loss: 1.6225, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [66/469], Loss: 1.7961, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [67/469], Loss: 1.5370, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [68/469], Loss: 1.7707, batch time: 0.46, accuracy:  43.75%\n",
      "Epoch [11/50], Step [69/469], Loss: 1.7401, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [70/469], Loss: 1.5698, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [71/469], Loss: 1.6918, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [72/469], Loss: 1.7340, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [11/50], Step [73/469], Loss: 1.7212, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [74/469], Loss: 1.6513, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [75/469], Loss: 1.5415, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [76/469], Loss: 1.5830, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [77/469], Loss: 1.5603, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [78/469], Loss: 1.6170, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [79/469], Loss: 1.5280, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [80/469], Loss: 1.6165, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [11/50], Step [81/469], Loss: 1.7952, batch time: 0.42, accuracy:  35.16%\n",
      "Epoch [11/50], Step [82/469], Loss: 1.8473, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [11/50], Step [83/469], Loss: 1.5309, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [84/469], Loss: 1.5779, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [85/469], Loss: 1.5879, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [86/469], Loss: 1.5721, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [87/469], Loss: 1.7217, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [88/469], Loss: 1.6125, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [89/469], Loss: 1.8051, batch time: 0.40, accuracy:  34.38%\n",
      "Epoch [11/50], Step [90/469], Loss: 1.6480, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [11/50], Step [91/469], Loss: 1.5065, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [92/469], Loss: 1.5574, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [11/50], Step [93/469], Loss: 1.5804, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [94/469], Loss: 1.6129, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [95/469], Loss: 1.6699, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [96/469], Loss: 1.7669, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [97/469], Loss: 1.6620, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [98/469], Loss: 1.7441, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [11/50], Step [99/469], Loss: 1.6522, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [100/469], Loss: 1.6832, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [101/469], Loss: 1.6675, batch time: 0.47, accuracy:  45.31%\n",
      "Epoch [11/50], Step [102/469], Loss: 1.5993, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [103/469], Loss: 1.6344, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [104/469], Loss: 1.6044, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [105/469], Loss: 1.7025, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [11/50], Step [106/469], Loss: 1.5175, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [11/50], Step [107/469], Loss: 1.6511, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [108/469], Loss: 1.6645, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [109/469], Loss: 1.5930, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [110/469], Loss: 1.5878, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [111/469], Loss: 1.6402, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [112/469], Loss: 1.7225, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [11/50], Step [113/469], Loss: 1.6298, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [114/469], Loss: 1.6055, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [115/469], Loss: 1.7797, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [116/469], Loss: 1.7060, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [117/469], Loss: 1.9032, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [11/50], Step [118/469], Loss: 1.5892, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [119/469], Loss: 1.6738, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [120/469], Loss: 1.6253, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [121/469], Loss: 1.6332, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [122/469], Loss: 1.7558, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [11/50], Step [123/469], Loss: 1.6673, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [11/50], Step [124/469], Loss: 1.5241, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [125/469], Loss: 1.8348, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [126/469], Loss: 1.6818, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [11/50], Step [127/469], Loss: 1.5830, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [128/469], Loss: 1.6556, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [129/469], Loss: 1.5576, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [130/469], Loss: 1.8102, batch time: 0.40, accuracy:  36.72%\n",
      "Epoch [11/50], Step [131/469], Loss: 1.7141, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [132/469], Loss: 1.7440, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [133/469], Loss: 1.5958, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [134/469], Loss: 1.6010, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [135/469], Loss: 1.4861, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [136/469], Loss: 1.6820, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [137/469], Loss: 1.5037, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [138/469], Loss: 1.5644, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [139/469], Loss: 1.6797, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [140/469], Loss: 1.4546, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [141/469], Loss: 1.6726, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [142/469], Loss: 1.6120, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [143/469], Loss: 1.6561, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [144/469], Loss: 1.6780, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [145/469], Loss: 1.5544, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [146/469], Loss: 1.6603, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [147/469], Loss: 1.5768, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [148/469], Loss: 1.7101, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [149/469], Loss: 1.5805, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [150/469], Loss: 1.6945, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [151/469], Loss: 1.7565, batch time: 0.40, accuracy:  35.16%\n",
      "Epoch [11/50], Step [152/469], Loss: 1.5659, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [153/469], Loss: 1.6662, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [154/469], Loss: 1.5950, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [155/469], Loss: 1.5177, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [156/469], Loss: 1.6397, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [157/469], Loss: 1.6645, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [158/469], Loss: 1.5915, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [159/469], Loss: 1.5498, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [160/469], Loss: 1.5453, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [161/469], Loss: 1.5408, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [162/469], Loss: 1.7570, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [11/50], Step [163/469], Loss: 1.6329, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [164/469], Loss: 1.5435, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [165/469], Loss: 1.4776, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [166/469], Loss: 1.6475, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [11/50], Step [167/469], Loss: 1.7319, batch time: 0.41, accuracy:  35.16%\n",
      "Epoch [11/50], Step [168/469], Loss: 1.6537, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [169/469], Loss: 1.5833, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [170/469], Loss: 1.7437, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [11/50], Step [171/469], Loss: 1.5975, batch time: 0.42, accuracy:  42.19%\n",
      "Epoch [11/50], Step [172/469], Loss: 1.6456, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [173/469], Loss: 1.7488, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [174/469], Loss: 1.5848, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [175/469], Loss: 1.4817, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [176/469], Loss: 1.6635, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [177/469], Loss: 1.5038, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [178/469], Loss: 1.4473, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [179/469], Loss: 1.6193, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [180/469], Loss: 1.3772, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [11/50], Step [181/469], Loss: 1.5742, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [182/469], Loss: 1.6034, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [183/469], Loss: 1.5206, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [184/469], Loss: 1.6305, batch time: 0.41, accuracy:  38.28%\n",
      "Epoch [11/50], Step [185/469], Loss: 1.6766, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [186/469], Loss: 1.6390, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [187/469], Loss: 1.5741, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [188/469], Loss: 1.5368, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [189/469], Loss: 1.8713, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [11/50], Step [190/469], Loss: 1.7629, batch time: 0.41, accuracy:  37.50%\n",
      "Epoch [11/50], Step [191/469], Loss: 1.6856, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [192/469], Loss: 1.5271, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [193/469], Loss: 1.4890, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [194/469], Loss: 1.5351, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [195/469], Loss: 1.6271, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [196/469], Loss: 1.5489, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [197/469], Loss: 1.5201, batch time: 0.44, accuracy:  54.69%\n",
      "Epoch [11/50], Step [198/469], Loss: 1.5585, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [199/469], Loss: 1.6281, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [200/469], Loss: 1.6153, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [201/469], Loss: 1.5569, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [202/469], Loss: 1.5447, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [203/469], Loss: 1.4072, batch time: 0.47, accuracy:  53.91%\n",
      "Epoch [11/50], Step [204/469], Loss: 1.5530, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [205/469], Loss: 1.6246, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [206/469], Loss: 1.6152, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [207/469], Loss: 1.7419, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [11/50], Step [208/469], Loss: 1.6255, batch time: 0.41, accuracy:  35.94%\n",
      "Epoch [11/50], Step [209/469], Loss: 1.5149, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [11/50], Step [210/469], Loss: 1.5315, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [211/469], Loss: 1.4341, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [212/469], Loss: 1.5622, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [213/469], Loss: 1.6022, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [214/469], Loss: 1.5481, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [215/469], Loss: 1.4446, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [11/50], Step [216/469], Loss: 1.4120, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [217/469], Loss: 1.5115, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [11/50], Step [218/469], Loss: 1.4782, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [11/50], Step [219/469], Loss: 1.6121, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [220/469], Loss: 1.6911, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [221/469], Loss: 1.6859, batch time: 0.41, accuracy:  34.38%\n",
      "Epoch [11/50], Step [222/469], Loss: 1.6421, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [223/469], Loss: 1.5049, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [224/469], Loss: 1.7436, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [225/469], Loss: 1.5742, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [226/469], Loss: 1.5964, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [11/50], Step [227/469], Loss: 1.6201, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [228/469], Loss: 1.6994, batch time: 0.42, accuracy:  32.03%\n",
      "Epoch [11/50], Step [229/469], Loss: 1.4897, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [11/50], Step [230/469], Loss: 1.5452, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [11/50], Step [231/469], Loss: 1.3371, batch time: 0.42, accuracy:  53.12%\n",
      "Epoch [11/50], Step [232/469], Loss: 1.7171, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [233/469], Loss: 1.6076, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [234/469], Loss: 1.7554, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [235/469], Loss: 1.4760, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [236/469], Loss: 1.5483, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [237/469], Loss: 1.4504, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [238/469], Loss: 1.6690, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [239/469], Loss: 1.5454, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [240/469], Loss: 1.5924, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [241/469], Loss: 1.5295, batch time: 0.47, accuracy:  39.06%\n",
      "Epoch [11/50], Step [242/469], Loss: 1.3904, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [243/469], Loss: 1.5794, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [244/469], Loss: 1.6101, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [245/469], Loss: 1.5310, batch time: 0.46, accuracy:  49.22%\n",
      "Epoch [11/50], Step [246/469], Loss: 1.7396, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [247/469], Loss: 1.5657, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [248/469], Loss: 1.5927, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [249/469], Loss: 1.5728, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [11/50], Step [250/469], Loss: 1.4922, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [251/469], Loss: 1.5800, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [252/469], Loss: 1.5884, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [11/50], Step [253/469], Loss: 1.5482, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [11/50], Step [254/469], Loss: 1.4291, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [255/469], Loss: 1.5195, batch time: 0.42, accuracy:  42.97%\n",
      "Epoch [11/50], Step [256/469], Loss: 1.5996, batch time: 0.42, accuracy:  49.22%\n",
      "Epoch [11/50], Step [257/469], Loss: 1.5493, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [258/469], Loss: 1.5878, batch time: 0.42, accuracy:  38.28%\n",
      "Epoch [11/50], Step [259/469], Loss: 1.3889, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [260/469], Loss: 1.5181, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [261/469], Loss: 1.5143, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [262/469], Loss: 1.5000, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [263/469], Loss: 1.5180, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [264/469], Loss: 1.5918, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [265/469], Loss: 1.4113, batch time: 0.44, accuracy:  57.81%\n",
      "Epoch [11/50], Step [266/469], Loss: 1.5047, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [267/469], Loss: 1.6645, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [268/469], Loss: 1.5486, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [269/469], Loss: 1.4165, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [270/469], Loss: 1.6261, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [271/469], Loss: 1.5999, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [272/469], Loss: 1.5943, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [11/50], Step [273/469], Loss: 1.6589, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [274/469], Loss: 1.5842, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [275/469], Loss: 1.5111, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [11/50], Step [276/469], Loss: 1.6320, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [277/469], Loss: 1.4685, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [11/50], Step [278/469], Loss: 1.4433, batch time: 0.47, accuracy:  53.12%\n",
      "Epoch [11/50], Step [279/469], Loss: 1.4952, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [280/469], Loss: 1.5210, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [281/469], Loss: 1.5699, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [282/469], Loss: 1.4917, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [283/469], Loss: 1.5255, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [284/469], Loss: 1.4556, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [285/469], Loss: 1.5170, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [286/469], Loss: 1.7059, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [287/469], Loss: 1.4936, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [288/469], Loss: 1.4697, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [289/469], Loss: 1.6308, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [290/469], Loss: 1.5782, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [291/469], Loss: 1.6207, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [292/469], Loss: 1.5705, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [293/469], Loss: 1.5297, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [11/50], Step [294/469], Loss: 1.6940, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [295/469], Loss: 1.6836, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [296/469], Loss: 1.5740, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [297/469], Loss: 1.5175, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [11/50], Step [298/469], Loss: 1.5929, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [299/469], Loss: 1.5616, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [300/469], Loss: 1.5428, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [301/469], Loss: 1.5119, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [302/469], Loss: 1.4942, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [303/469], Loss: 1.4421, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [11/50], Step [304/469], Loss: 1.4086, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [11/50], Step [305/469], Loss: 1.4560, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [306/469], Loss: 1.5130, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [307/469], Loss: 1.5751, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [308/469], Loss: 1.5778, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [309/469], Loss: 1.4284, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [310/469], Loss: 1.5767, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [11/50], Step [311/469], Loss: 1.6023, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [312/469], Loss: 1.7379, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [11/50], Step [313/469], Loss: 1.8607, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [314/469], Loss: 1.6208, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [315/469], Loss: 1.5349, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [316/469], Loss: 1.4802, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [317/469], Loss: 1.5524, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [11/50], Step [318/469], Loss: 1.5592, batch time: 0.41, accuracy:  40.62%\n",
      "Epoch [11/50], Step [319/469], Loss: 1.6232, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [320/469], Loss: 1.6666, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [11/50], Step [321/469], Loss: 1.7183, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [322/469], Loss: 1.5557, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [323/469], Loss: 1.3979, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [324/469], Loss: 1.3258, batch time: 0.46, accuracy:  47.66%\n",
      "Epoch [11/50], Step [325/469], Loss: 1.6071, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [326/469], Loss: 1.5114, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [327/469], Loss: 1.4620, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [328/469], Loss: 1.6007, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [329/469], Loss: 1.4870, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [330/469], Loss: 1.3534, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [11/50], Step [331/469], Loss: 1.5431, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [332/469], Loss: 1.4436, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [333/469], Loss: 1.4142, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [334/469], Loss: 1.4684, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [335/469], Loss: 1.4797, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [11/50], Step [336/469], Loss: 1.6196, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [11/50], Step [337/469], Loss: 1.5388, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [338/469], Loss: 1.5370, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [339/469], Loss: 1.5571, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [340/469], Loss: 1.6925, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [341/469], Loss: 1.4886, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [342/469], Loss: 1.4611, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [11/50], Step [343/469], Loss: 1.4986, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [344/469], Loss: 1.5004, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [345/469], Loss: 1.5765, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [346/469], Loss: 1.5090, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [347/469], Loss: 1.4653, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [348/469], Loss: 1.4864, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [349/469], Loss: 1.4877, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [350/469], Loss: 1.5032, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [11/50], Step [351/469], Loss: 1.4474, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [11/50], Step [352/469], Loss: 1.4087, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [353/469], Loss: 1.5671, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [354/469], Loss: 1.5099, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [11/50], Step [355/469], Loss: 1.4763, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [356/469], Loss: 1.3275, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [11/50], Step [357/469], Loss: 1.5615, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [358/469], Loss: 1.4912, batch time: 0.42, accuracy:  54.69%\n",
      "Epoch [11/50], Step [359/469], Loss: 1.5442, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [360/469], Loss: 1.6626, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [361/469], Loss: 1.4693, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [362/469], Loss: 1.5643, batch time: 0.47, accuracy:  43.75%\n",
      "Epoch [11/50], Step [363/469], Loss: 1.4005, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [11/50], Step [364/469], Loss: 1.4687, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [365/469], Loss: 1.6130, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [366/469], Loss: 1.5361, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [367/469], Loss: 1.5179, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [368/469], Loss: 1.4502, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [369/469], Loss: 1.3900, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [11/50], Step [370/469], Loss: 1.4460, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [371/469], Loss: 1.4124, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [11/50], Step [372/469], Loss: 1.5485, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [373/469], Loss: 1.5184, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [374/469], Loss: 1.4587, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [375/469], Loss: 1.5226, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [11/50], Step [376/469], Loss: 1.6259, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [11/50], Step [377/469], Loss: 1.4802, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [378/469], Loss: 1.5413, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [379/469], Loss: 1.4541, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [380/469], Loss: 1.3613, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [11/50], Step [381/469], Loss: 1.5171, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [382/469], Loss: 1.5279, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [383/469], Loss: 1.5119, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [11/50], Step [384/469], Loss: 1.5742, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [385/469], Loss: 1.5639, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [386/469], Loss: 1.6003, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [387/469], Loss: 1.3496, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [11/50], Step [388/469], Loss: 1.6938, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [389/469], Loss: 1.3310, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [11/50], Step [390/469], Loss: 1.3638, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [11/50], Step [391/469], Loss: 1.5919, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [392/469], Loss: 1.3460, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [11/50], Step [393/469], Loss: 1.3884, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [11/50], Step [394/469], Loss: 1.5930, batch time: 0.42, accuracy:  42.97%\n",
      "Epoch [11/50], Step [395/469], Loss: 1.3678, batch time: 0.47, accuracy:  56.25%\n",
      "Epoch [11/50], Step [396/469], Loss: 1.5107, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [397/469], Loss: 1.3468, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [11/50], Step [398/469], Loss: 1.4163, batch time: 0.42, accuracy:  45.31%\n",
      "Epoch [11/50], Step [399/469], Loss: 1.6196, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [11/50], Step [400/469], Loss: 1.6230, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [401/469], Loss: 1.5495, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [402/469], Loss: 1.3130, batch time: 0.44, accuracy:  60.94%\n",
      "Epoch [11/50], Step [403/469], Loss: 1.4840, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [11/50], Step [404/469], Loss: 1.4646, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [405/469], Loss: 1.3882, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [406/469], Loss: 1.4912, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [407/469], Loss: 1.4557, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [408/469], Loss: 1.3093, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [11/50], Step [409/469], Loss: 1.4381, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [11/50], Step [410/469], Loss: 1.4605, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [411/469], Loss: 1.7123, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [11/50], Step [412/469], Loss: 1.7142, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [413/469], Loss: 1.6296, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [414/469], Loss: 1.4996, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [11/50], Step [415/469], Loss: 1.5710, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [11/50], Step [416/469], Loss: 1.6050, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [417/469], Loss: 1.5513, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [418/469], Loss: 1.4505, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [11/50], Step [419/469], Loss: 1.5031, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [420/469], Loss: 1.5531, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [421/469], Loss: 1.5249, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [422/469], Loss: 1.3647, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [11/50], Step [423/469], Loss: 1.4335, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [424/469], Loss: 1.5158, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [425/469], Loss: 1.4480, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [11/50], Step [426/469], Loss: 1.4181, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [11/50], Step [427/469], Loss: 1.3895, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [11/50], Step [428/469], Loss: 1.4599, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [429/469], Loss: 1.4955, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [430/469], Loss: 1.3376, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [11/50], Step [431/469], Loss: 1.6181, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [11/50], Step [432/469], Loss: 1.4163, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [11/50], Step [433/469], Loss: 1.4205, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [11/50], Step [434/469], Loss: 1.3315, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [11/50], Step [435/469], Loss: 1.4084, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [11/50], Step [436/469], Loss: 1.5043, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [11/50], Step [437/469], Loss: 1.7722, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [11/50], Step [438/469], Loss: 1.4888, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [11/50], Step [439/469], Loss: 1.6693, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [440/469], Loss: 1.3334, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [11/50], Step [441/469], Loss: 1.5178, batch time: 0.46, accuracy:  42.97%\n",
      "Epoch [11/50], Step [442/469], Loss: 1.3845, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [11/50], Step [443/469], Loss: 1.6098, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [444/469], Loss: 1.4072, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [11/50], Step [445/469], Loss: 1.5064, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [11/50], Step [446/469], Loss: 1.3874, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [11/50], Step [447/469], Loss: 1.7231, batch time: 0.40, accuracy:  38.28%\n",
      "Epoch [11/50], Step [448/469], Loss: 1.5089, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [449/469], Loss: 1.4611, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [11/50], Step [450/469], Loss: 1.4541, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [451/469], Loss: 1.4881, batch time: 0.40, accuracy:  39.06%\n",
      "Epoch [11/50], Step [452/469], Loss: 1.5807, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [453/469], Loss: 1.4392, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [11/50], Step [454/469], Loss: 1.6232, batch time: 0.40, accuracy:  37.50%\n",
      "Epoch [11/50], Step [455/469], Loss: 1.3891, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [11/50], Step [456/469], Loss: 1.5151, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [11/50], Step [457/469], Loss: 1.4497, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [11/50], Step [458/469], Loss: 1.3699, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [11/50], Step [459/469], Loss: 1.5801, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [11/50], Step [460/469], Loss: 1.4951, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [11/50], Step [461/469], Loss: 1.6306, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [11/50], Step [462/469], Loss: 1.3211, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [11/50], Step [463/469], Loss: 1.4295, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [11/50], Step [464/469], Loss: 1.3889, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [11/50], Step [465/469], Loss: 1.3184, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [11/50], Step [466/469], Loss: 1.4294, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [11/50], Step [467/469], Loss: 1.6702, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [11/50], Step [468/469], Loss: 1.6462, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [11/50], Step [469/469], Loss: 1.4377, batch time: 0.42, accuracy:  44.79%\n",
      "Epoch [12/50], Step [1/469], Loss: 1.5013, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [12/50], Step [2/469], Loss: 1.4188, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [3/469], Loss: 1.6197, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [12/50], Step [4/469], Loss: 1.4368, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [5/469], Loss: 1.5731, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [12/50], Step [6/469], Loss: 1.5504, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [12/50], Step [7/469], Loss: 1.4301, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [8/469], Loss: 1.5167, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [9/469], Loss: 1.4669, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [10/469], Loss: 1.4054, batch time: 0.46, accuracy:  51.56%\n",
      "Epoch [12/50], Step [11/469], Loss: 1.4004, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [12/50], Step [12/469], Loss: 1.5561, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [12/50], Step [13/469], Loss: 1.3872, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [14/469], Loss: 1.3979, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [15/469], Loss: 1.5296, batch time: 0.42, accuracy:  52.34%\n",
      "Epoch [12/50], Step [16/469], Loss: 1.6016, batch time: 0.41, accuracy:  36.72%\n",
      "Epoch [12/50], Step [17/469], Loss: 1.5932, batch time: 0.40, accuracy:  40.62%\n",
      "Epoch [12/50], Step [18/469], Loss: 1.5123, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [12/50], Step [19/469], Loss: 1.6127, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [20/469], Loss: 1.5409, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [21/469], Loss: 1.4956, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [22/469], Loss: 1.6847, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [23/469], Loss: 1.4516, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [24/469], Loss: 1.4225, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [25/469], Loss: 1.8001, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [12/50], Step [26/469], Loss: 1.4989, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [12/50], Step [27/469], Loss: 1.4430, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [12/50], Step [28/469], Loss: 1.3420, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [29/469], Loss: 1.3334, batch time: 0.42, accuracy:  50.00%\n",
      "Epoch [12/50], Step [30/469], Loss: 1.5896, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [12/50], Step [31/469], Loss: 1.4262, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [12/50], Step [32/469], Loss: 1.5524, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [33/469], Loss: 1.6314, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [34/469], Loss: 1.4460, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [12/50], Step [35/469], Loss: 1.5385, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [12/50], Step [36/469], Loss: 1.4339, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [37/469], Loss: 1.4930, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [38/469], Loss: 1.4897, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [39/469], Loss: 1.3496, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [40/469], Loss: 1.2901, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [41/469], Loss: 1.5038, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [42/469], Loss: 1.5151, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [43/469], Loss: 1.3974, batch time: 0.46, accuracy:  56.25%\n",
      "Epoch [12/50], Step [44/469], Loss: 1.5606, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [12/50], Step [45/469], Loss: 1.5729, batch time: 0.41, accuracy:  39.06%\n",
      "Epoch [12/50], Step [46/469], Loss: 1.6838, batch time: 0.40, accuracy:  35.94%\n",
      "Epoch [12/50], Step [47/469], Loss: 1.5851, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [12/50], Step [48/469], Loss: 1.3840, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [49/469], Loss: 1.4144, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [12/50], Step [50/469], Loss: 1.4911, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [51/469], Loss: 1.4294, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [52/469], Loss: 1.4340, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [53/469], Loss: 1.5884, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [54/469], Loss: 1.4928, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [12/50], Step [55/469], Loss: 1.4794, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [56/469], Loss: 1.4640, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [57/469], Loss: 1.4270, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [58/469], Loss: 1.3869, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [59/469], Loss: 1.5181, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [60/469], Loss: 1.4231, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [61/469], Loss: 1.3721, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [62/469], Loss: 1.4083, batch time: 0.42, accuracy:  51.56%\n",
      "Epoch [12/50], Step [63/469], Loss: 1.5163, batch time: 0.42, accuracy:  45.31%\n",
      "Epoch [12/50], Step [64/469], Loss: 1.4220, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [65/469], Loss: 1.4571, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [66/469], Loss: 1.3800, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [12/50], Step [67/469], Loss: 1.3663, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [68/469], Loss: 1.5908, batch time: 0.40, accuracy:  39.84%\n",
      "Epoch [12/50], Step [69/469], Loss: 1.5842, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [12/50], Step [70/469], Loss: 1.4249, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [71/469], Loss: 1.4510, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [72/469], Loss: 1.4395, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [73/469], Loss: 1.5392, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [74/469], Loss: 1.4237, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [75/469], Loss: 1.4382, batch time: 0.42, accuracy:  49.22%\n",
      "Epoch [12/50], Step [76/469], Loss: 1.6003, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [77/469], Loss: 1.5255, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [78/469], Loss: 1.6316, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [12/50], Step [79/469], Loss: 1.4290, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [80/469], Loss: 1.4488, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [81/469], Loss: 1.4172, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [82/469], Loss: 1.5559, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [83/469], Loss: 1.5223, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [12/50], Step [84/469], Loss: 1.5188, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [85/469], Loss: 1.4560, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [12/50], Step [86/469], Loss: 1.3352, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [87/469], Loss: 1.4562, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [88/469], Loss: 1.4848, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [89/469], Loss: 1.2754, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [90/469], Loss: 1.3950, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [91/469], Loss: 1.5828, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [12/50], Step [92/469], Loss: 1.4935, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [93/469], Loss: 1.3972, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [94/469], Loss: 1.5048, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [95/469], Loss: 1.4023, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [96/469], Loss: 1.3935, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [97/469], Loss: 1.5109, batch time: 0.40, accuracy:  42.19%\n",
      "Epoch [12/50], Step [98/469], Loss: 1.3701, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [99/469], Loss: 1.4030, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [100/469], Loss: 1.4530, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [101/469], Loss: 1.6167, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [102/469], Loss: 1.3875, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [103/469], Loss: 1.5602, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [12/50], Step [104/469], Loss: 1.3515, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [105/469], Loss: 1.5853, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [12/50], Step [106/469], Loss: 1.4049, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [107/469], Loss: 1.4833, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [108/469], Loss: 1.6782, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [12/50], Step [109/469], Loss: 1.3694, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [110/469], Loss: 1.5479, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [12/50], Step [111/469], Loss: 1.5953, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [12/50], Step [112/469], Loss: 1.4088, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [113/469], Loss: 1.2319, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [114/469], Loss: 1.4361, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [115/469], Loss: 1.6167, batch time: 0.41, accuracy:  42.19%\n",
      "Epoch [12/50], Step [116/469], Loss: 1.3834, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [117/469], Loss: 1.4159, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [118/469], Loss: 1.3582, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [119/469], Loss: 1.6091, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [120/469], Loss: 1.4939, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [12/50], Step [121/469], Loss: 1.4353, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [122/469], Loss: 1.4668, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [123/469], Loss: 1.3723, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [124/469], Loss: 1.6321, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [125/469], Loss: 1.4060, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [126/469], Loss: 1.4830, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [127/469], Loss: 1.4460, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [128/469], Loss: 1.5555, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [129/469], Loss: 1.5882, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [130/469], Loss: 1.4676, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [12/50], Step [131/469], Loss: 1.2041, batch time: 0.42, accuracy:  53.12%\n",
      "Epoch [12/50], Step [132/469], Loss: 1.3308, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [133/469], Loss: 1.5410, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [134/469], Loss: 1.4169, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [135/469], Loss: 1.3810, batch time: 0.42, accuracy:  49.22%\n",
      "Epoch [12/50], Step [136/469], Loss: 1.3670, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [137/469], Loss: 1.5066, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [12/50], Step [138/469], Loss: 1.3163, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [139/469], Loss: 1.4744, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [140/469], Loss: 1.4677, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [141/469], Loss: 1.3099, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [142/469], Loss: 1.5636, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [143/469], Loss: 1.5327, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [144/469], Loss: 1.4953, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [145/469], Loss: 1.5540, batch time: 0.42, accuracy:  45.31%\n",
      "Epoch [12/50], Step [146/469], Loss: 1.2527, batch time: 0.42, accuracy:  54.69%\n",
      "Epoch [12/50], Step [147/469], Loss: 1.3102, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [148/469], Loss: 1.3494, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [149/469], Loss: 1.5098, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [150/469], Loss: 1.4602, batch time: 0.42, accuracy:  50.00%\n",
      "Epoch [12/50], Step [151/469], Loss: 1.4173, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [152/469], Loss: 1.3589, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [153/469], Loss: 1.3787, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [12/50], Step [154/469], Loss: 1.4783, batch time: 0.40, accuracy:  44.53%\n",
      "Epoch [12/50], Step [155/469], Loss: 1.4342, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [156/469], Loss: 1.4077, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [157/469], Loss: 1.3936, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [158/469], Loss: 1.2722, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [159/469], Loss: 1.4474, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [12/50], Step [160/469], Loss: 1.3534, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [161/469], Loss: 1.3470, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [162/469], Loss: 1.4134, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [12/50], Step [163/469], Loss: 1.4079, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [164/469], Loss: 1.4952, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [12/50], Step [165/469], Loss: 1.3590, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [12/50], Step [166/469], Loss: 1.4018, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [167/469], Loss: 1.4026, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [168/469], Loss: 1.4742, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [169/469], Loss: 1.4415, batch time: 0.46, accuracy:  57.03%\n",
      "Epoch [12/50], Step [170/469], Loss: 1.3584, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [171/469], Loss: 1.3181, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [172/469], Loss: 1.6330, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [12/50], Step [173/469], Loss: 1.3049, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [174/469], Loss: 1.4841, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [12/50], Step [175/469], Loss: 1.3355, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [176/469], Loss: 1.3208, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [177/469], Loss: 1.4895, batch time: 0.42, accuracy:  46.88%\n",
      "Epoch [12/50], Step [178/469], Loss: 1.4149, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [179/469], Loss: 1.3916, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [180/469], Loss: 1.3214, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [181/469], Loss: 1.3477, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [182/469], Loss: 1.4699, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [183/469], Loss: 1.2394, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [12/50], Step [184/469], Loss: 1.4609, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [12/50], Step [185/469], Loss: 1.3428, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [186/469], Loss: 1.4299, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [187/469], Loss: 1.4964, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [188/469], Loss: 1.3000, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [189/469], Loss: 1.5341, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [12/50], Step [190/469], Loss: 1.3914, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [191/469], Loss: 1.3240, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [192/469], Loss: 1.3046, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [193/469], Loss: 1.3079, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [194/469], Loss: 1.3996, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [195/469], Loss: 1.5319, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [196/469], Loss: 1.4708, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [197/469], Loss: 1.3384, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [198/469], Loss: 1.4526, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [12/50], Step [199/469], Loss: 1.3966, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [200/469], Loss: 1.4401, batch time: 0.42, accuracy:  48.44%\n",
      "Epoch [12/50], Step [201/469], Loss: 1.2165, batch time: 0.44, accuracy:  61.72%\n",
      "Epoch [12/50], Step [202/469], Loss: 1.5590, batch time: 0.40, accuracy:  41.41%\n",
      "Epoch [12/50], Step [203/469], Loss: 1.5339, batch time: 0.42, accuracy:  48.44%\n",
      "Epoch [12/50], Step [204/469], Loss: 1.3307, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [205/469], Loss: 1.5608, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [206/469], Loss: 1.4894, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [207/469], Loss: 1.3844, batch time: 0.42, accuracy:  52.34%\n",
      "Epoch [12/50], Step [208/469], Loss: 1.2463, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [209/469], Loss: 1.6125, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [12/50], Step [210/469], Loss: 1.3406, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [211/469], Loss: 1.4182, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [212/469], Loss: 1.3792, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [213/469], Loss: 1.3604, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [214/469], Loss: 1.5201, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [12/50], Step [215/469], Loss: 1.4744, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [216/469], Loss: 1.2945, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [217/469], Loss: 1.3709, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [218/469], Loss: 1.3333, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [219/469], Loss: 1.2536, batch time: 0.46, accuracy:  58.59%\n",
      "Epoch [12/50], Step [220/469], Loss: 1.2782, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [12/50], Step [221/469], Loss: 1.4089, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [222/469], Loss: 1.4461, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [223/469], Loss: 1.5705, batch time: 0.40, accuracy:  42.97%\n",
      "Epoch [12/50], Step [224/469], Loss: 1.3174, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [12/50], Step [225/469], Loss: 1.2903, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [226/469], Loss: 1.4211, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [12/50], Step [227/469], Loss: 1.4224, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [228/469], Loss: 1.4390, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [229/469], Loss: 1.4414, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [230/469], Loss: 1.2981, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [231/469], Loss: 1.4815, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [12/50], Step [232/469], Loss: 1.3246, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [233/469], Loss: 1.4673, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [234/469], Loss: 1.3470, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [235/469], Loss: 1.4738, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [236/469], Loss: 1.2601, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [237/469], Loss: 1.2458, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [238/469], Loss: 1.5511, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [239/469], Loss: 1.4467, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [240/469], Loss: 1.3178, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [241/469], Loss: 1.2736, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [242/469], Loss: 1.3638, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [243/469], Loss: 1.3328, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [244/469], Loss: 1.4441, batch time: 0.41, accuracy:  45.31%\n",
      "Epoch [12/50], Step [245/469], Loss: 1.4549, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [246/469], Loss: 1.3436, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [247/469], Loss: 1.4668, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [248/469], Loss: 1.5107, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [249/469], Loss: 1.3581, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [250/469], Loss: 1.5925, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [251/469], Loss: 1.5638, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [252/469], Loss: 1.3055, batch time: 0.47, accuracy:  53.91%\n",
      "Epoch [12/50], Step [253/469], Loss: 1.4366, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [254/469], Loss: 1.3696, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [255/469], Loss: 1.3245, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [256/469], Loss: 1.6493, batch time: 0.41, accuracy:  44.53%\n",
      "Epoch [12/50], Step [257/469], Loss: 1.6547, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [12/50], Step [258/469], Loss: 1.3730, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [259/469], Loss: 1.3500, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [12/50], Step [260/469], Loss: 1.4553, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [12/50], Step [261/469], Loss: 1.4271, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [262/469], Loss: 1.4864, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [263/469], Loss: 1.3597, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [264/469], Loss: 1.3240, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [265/469], Loss: 1.3905, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [266/469], Loss: 1.4479, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [267/469], Loss: 1.5755, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [268/469], Loss: 1.4057, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [269/469], Loss: 1.3478, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [270/469], Loss: 1.2681, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [12/50], Step [271/469], Loss: 1.4193, batch time: 0.42, accuracy:  48.44%\n",
      "Epoch [12/50], Step [272/469], Loss: 1.5635, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [273/469], Loss: 1.5490, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [274/469], Loss: 1.4959, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [275/469], Loss: 1.3683, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [276/469], Loss: 1.4334, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [277/469], Loss: 1.3946, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [278/469], Loss: 1.4416, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [279/469], Loss: 1.3267, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [280/469], Loss: 1.4519, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [281/469], Loss: 1.3358, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [12/50], Step [282/469], Loss: 1.3550, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [283/469], Loss: 1.3062, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [12/50], Step [284/469], Loss: 1.3742, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [285/469], Loss: 1.4216, batch time: 0.42, accuracy:  50.78%\n",
      "Epoch [12/50], Step [286/469], Loss: 1.2453, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [12/50], Step [287/469], Loss: 1.4336, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [288/469], Loss: 1.3644, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [289/469], Loss: 1.4203, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [290/469], Loss: 1.4493, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [291/469], Loss: 1.2977, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [12/50], Step [292/469], Loss: 1.3200, batch time: 0.42, accuracy:  52.34%\n",
      "Epoch [12/50], Step [293/469], Loss: 1.4797, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [294/469], Loss: 1.2291, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [295/469], Loss: 1.4444, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [296/469], Loss: 1.4776, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [297/469], Loss: 1.3188, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [298/469], Loss: 1.3910, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [299/469], Loss: 1.2671, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [12/50], Step [300/469], Loss: 1.3219, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [301/469], Loss: 1.4216, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [302/469], Loss: 1.5354, batch time: 0.41, accuracy:  41.41%\n",
      "Epoch [12/50], Step [303/469], Loss: 1.4823, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [304/469], Loss: 1.2732, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [305/469], Loss: 1.4225, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [306/469], Loss: 1.4774, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [307/469], Loss: 1.3915, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [308/469], Loss: 1.2482, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [309/469], Loss: 1.2231, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [310/469], Loss: 1.3310, batch time: 0.42, accuracy:  51.56%\n",
      "Epoch [12/50], Step [311/469], Loss: 1.1374, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [312/469], Loss: 1.3402, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [313/469], Loss: 1.3217, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [314/469], Loss: 1.3181, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [12/50], Step [315/469], Loss: 1.4554, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [316/469], Loss: 1.3061, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [317/469], Loss: 1.3730, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [318/469], Loss: 1.3032, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [319/469], Loss: 1.2956, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [320/469], Loss: 1.3216, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [12/50], Step [321/469], Loss: 1.3420, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [12/50], Step [322/469], Loss: 1.3970, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [323/469], Loss: 1.3200, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [12/50], Step [324/469], Loss: 1.3663, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [325/469], Loss: 1.3283, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [326/469], Loss: 1.3481, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [12/50], Step [327/469], Loss: 1.5389, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [328/469], Loss: 1.2732, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [329/469], Loss: 1.3361, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [12/50], Step [330/469], Loss: 1.1774, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [12/50], Step [331/469], Loss: 1.2315, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [332/469], Loss: 1.2364, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [12/50], Step [333/469], Loss: 1.3991, batch time: 0.40, accuracy:  50.00%\n",
      "Epoch [12/50], Step [334/469], Loss: 1.2700, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [12/50], Step [335/469], Loss: 1.3292, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [336/469], Loss: 1.3009, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [12/50], Step [337/469], Loss: 1.3856, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [338/469], Loss: 1.4221, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [339/469], Loss: 1.3417, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [340/469], Loss: 1.4077, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [341/469], Loss: 1.3575, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [12/50], Step [342/469], Loss: 1.2505, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [343/469], Loss: 1.5102, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [12/50], Step [344/469], Loss: 1.4257, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [345/469], Loss: 1.2191, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [346/469], Loss: 1.2873, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [347/469], Loss: 1.4294, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [12/50], Step [348/469], Loss: 1.3973, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [349/469], Loss: 1.4700, batch time: 0.43, accuracy:  46.09%\n",
      "Epoch [12/50], Step [350/469], Loss: 1.3479, batch time: 0.40, accuracy:  45.31%\n",
      "Epoch [12/50], Step [351/469], Loss: 1.4753, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [12/50], Step [352/469], Loss: 1.4286, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [353/469], Loss: 1.3732, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [354/469], Loss: 1.3032, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [12/50], Step [355/469], Loss: 1.4261, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [12/50], Step [356/469], Loss: 1.3223, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [357/469], Loss: 1.4794, batch time: 0.40, accuracy:  48.44%\n",
      "Epoch [12/50], Step [358/469], Loss: 1.3350, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [359/469], Loss: 1.3449, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [12/50], Step [360/469], Loss: 1.4063, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [361/469], Loss: 1.5585, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [362/469], Loss: 1.3114, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [363/469], Loss: 1.3722, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [364/469], Loss: 1.3550, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [365/469], Loss: 1.5996, batch time: 0.40, accuracy:  46.09%\n",
      "Epoch [12/50], Step [366/469], Loss: 1.3267, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [367/469], Loss: 1.3107, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [12/50], Step [368/469], Loss: 1.2822, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [12/50], Step [369/469], Loss: 1.3719, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [370/469], Loss: 1.2914, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [371/469], Loss: 1.3495, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [372/469], Loss: 1.3255, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [373/469], Loss: 1.0146, batch time: 0.50, accuracy:  65.62%\n",
      "Epoch [12/50], Step [374/469], Loss: 1.3061, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [375/469], Loss: 1.3145, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [376/469], Loss: 1.6241, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [12/50], Step [377/469], Loss: 1.3986, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [378/469], Loss: 1.3585, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [379/469], Loss: 1.2674, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [12/50], Step [380/469], Loss: 1.2823, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [12/50], Step [381/469], Loss: 1.3267, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [382/469], Loss: 1.3367, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [12/50], Step [383/469], Loss: 1.4046, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [384/469], Loss: 1.2627, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [385/469], Loss: 1.3204, batch time: 0.42, accuracy:  56.25%\n",
      "Epoch [12/50], Step [386/469], Loss: 1.2693, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [387/469], Loss: 1.4091, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [388/469], Loss: 1.3711, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [389/469], Loss: 1.2946, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [390/469], Loss: 1.2854, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [391/469], Loss: 1.3537, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [392/469], Loss: 1.4127, batch time: 0.41, accuracy:  39.84%\n",
      "Epoch [12/50], Step [393/469], Loss: 1.3437, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [12/50], Step [394/469], Loss: 1.2990, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [12/50], Step [395/469], Loss: 1.3798, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [396/469], Loss: 1.3623, batch time: 0.42, accuracy:  52.34%\n",
      "Epoch [12/50], Step [397/469], Loss: 1.3900, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [398/469], Loss: 1.2730, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [12/50], Step [399/469], Loss: 1.3210, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [12/50], Step [400/469], Loss: 1.3068, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [401/469], Loss: 1.3288, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [402/469], Loss: 1.3653, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [12/50], Step [403/469], Loss: 1.2380, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [12/50], Step [404/469], Loss: 1.3290, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [405/469], Loss: 1.2654, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [12/50], Step [406/469], Loss: 1.2935, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [407/469], Loss: 1.6030, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [408/469], Loss: 1.4597, batch time: 0.41, accuracy:  46.88%\n",
      "Epoch [12/50], Step [409/469], Loss: 1.3263, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [410/469], Loss: 1.5010, batch time: 0.46, accuracy:  50.00%\n",
      "Epoch [12/50], Step [411/469], Loss: 1.2698, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [12/50], Step [412/469], Loss: 1.3318, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [413/469], Loss: 1.3252, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [414/469], Loss: 1.5046, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [12/50], Step [415/469], Loss: 1.2423, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [416/469], Loss: 1.3023, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [12/50], Step [417/469], Loss: 1.3264, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [418/469], Loss: 1.3200, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [419/469], Loss: 1.2991, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [12/50], Step [420/469], Loss: 1.2990, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [12/50], Step [421/469], Loss: 1.3297, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [12/50], Step [422/469], Loss: 1.3461, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [12/50], Step [423/469], Loss: 1.2315, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [12/50], Step [424/469], Loss: 1.2425, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [12/50], Step [425/469], Loss: 1.2840, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [12/50], Step [426/469], Loss: 1.3605, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [427/469], Loss: 1.3083, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [12/50], Step [428/469], Loss: 1.2386, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [12/50], Step [429/469], Loss: 1.1991, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [12/50], Step [430/469], Loss: 1.2578, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [12/50], Step [431/469], Loss: 1.1550, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [12/50], Step [432/469], Loss: 1.2649, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [433/469], Loss: 1.2480, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [434/469], Loss: 1.4553, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [12/50], Step [435/469], Loss: 1.3694, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [436/469], Loss: 1.2737, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [437/469], Loss: 1.4226, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [438/469], Loss: 1.1074, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [12/50], Step [439/469], Loss: 1.3739, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [440/469], Loss: 1.4961, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [12/50], Step [441/469], Loss: 1.5895, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [442/469], Loss: 1.3971, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [12/50], Step [443/469], Loss: 1.3992, batch time: 0.46, accuracy:  55.47%\n",
      "Epoch [12/50], Step [444/469], Loss: 1.2193, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [12/50], Step [445/469], Loss: 1.3211, batch time: 0.42, accuracy:  57.03%\n",
      "Epoch [12/50], Step [446/469], Loss: 1.0624, batch time: 0.44, accuracy:  66.41%\n",
      "Epoch [12/50], Step [447/469], Loss: 1.3231, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [12/50], Step [448/469], Loss: 1.4018, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [12/50], Step [449/469], Loss: 1.2777, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [12/50], Step [450/469], Loss: 1.2441, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [451/469], Loss: 1.1513, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [452/469], Loss: 1.2576, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [453/469], Loss: 1.2764, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [12/50], Step [454/469], Loss: 1.4004, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [12/50], Step [455/469], Loss: 1.2107, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [12/50], Step [456/469], Loss: 1.4108, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [12/50], Step [457/469], Loss: 1.4225, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [458/469], Loss: 1.4317, batch time: 0.40, accuracy:  43.75%\n",
      "Epoch [12/50], Step [459/469], Loss: 1.2678, batch time: 0.42, accuracy:  50.00%\n",
      "Epoch [12/50], Step [460/469], Loss: 1.3104, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [461/469], Loss: 1.2453, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [12/50], Step [462/469], Loss: 1.4404, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [12/50], Step [463/469], Loss: 1.2402, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [12/50], Step [464/469], Loss: 1.4441, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [12/50], Step [465/469], Loss: 1.3715, batch time: 0.42, accuracy:  52.34%\n",
      "Epoch [12/50], Step [466/469], Loss: 1.1330, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [12/50], Step [467/469], Loss: 1.4354, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [12/50], Step [468/469], Loss: 1.3948, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [12/50], Step [469/469], Loss: 1.1435, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [13/50], Step [1/469], Loss: 1.2475, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [2/469], Loss: 1.5024, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [3/469], Loss: 1.4451, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [13/50], Step [4/469], Loss: 1.3197, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [13/50], Step [5/469], Loss: 1.4772, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [13/50], Step [6/469], Loss: 1.3217, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [7/469], Loss: 1.0982, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [8/469], Loss: 1.4189, batch time: 0.41, accuracy:  43.75%\n",
      "Epoch [13/50], Step [9/469], Loss: 1.3389, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [13/50], Step [10/469], Loss: 1.0501, batch time: 0.43, accuracy:  70.31%\n",
      "Epoch [13/50], Step [11/469], Loss: 1.3267, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [13/50], Step [12/469], Loss: 1.4990, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [13/469], Loss: 1.2135, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [14/469], Loss: 1.5093, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [13/50], Step [15/469], Loss: 1.2423, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [16/469], Loss: 1.3814, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [17/469], Loss: 1.3021, batch time: 0.46, accuracy:  55.47%\n",
      "Epoch [13/50], Step [18/469], Loss: 1.3730, batch time: 0.42, accuracy:  56.25%\n",
      "Epoch [13/50], Step [19/469], Loss: 1.2447, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [20/469], Loss: 1.3423, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [21/469], Loss: 1.3575, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [13/50], Step [22/469], Loss: 1.3011, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [23/469], Loss: 1.2678, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [13/50], Step [24/469], Loss: 1.2737, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [25/469], Loss: 1.3659, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [13/50], Step [26/469], Loss: 1.4517, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [13/50], Step [27/469], Loss: 1.4279, batch time: 0.40, accuracy:  49.22%\n",
      "Epoch [13/50], Step [28/469], Loss: 1.3268, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [29/469], Loss: 1.4352, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [13/50], Step [30/469], Loss: 1.4931, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [13/50], Step [31/469], Loss: 1.3222, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [32/469], Loss: 1.2513, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [33/469], Loss: 1.2431, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [34/469], Loss: 1.2109, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [35/469], Loss: 1.3324, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [13/50], Step [36/469], Loss: 1.2237, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [37/469], Loss: 1.2908, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [13/50], Step [38/469], Loss: 1.3271, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [13/50], Step [39/469], Loss: 1.5960, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [40/469], Loss: 1.3432, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [41/469], Loss: 1.3152, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [42/469], Loss: 1.2336, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [43/469], Loss: 1.2083, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [44/469], Loss: 1.3533, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [45/469], Loss: 1.3225, batch time: 0.41, accuracy:  48.44%\n",
      "Epoch [13/50], Step [46/469], Loss: 1.2933, batch time: 0.42, accuracy:  55.47%\n",
      "Epoch [13/50], Step [47/469], Loss: 1.1941, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [48/469], Loss: 1.2645, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [49/469], Loss: 1.2724, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [13/50], Step [50/469], Loss: 1.3760, batch time: 0.42, accuracy:  57.03%\n",
      "Epoch [13/50], Step [51/469], Loss: 1.2706, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [13/50], Step [52/469], Loss: 1.2243, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [53/469], Loss: 1.4287, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [54/469], Loss: 1.4893, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [13/50], Step [55/469], Loss: 1.3116, batch time: 0.47, accuracy:  50.00%\n",
      "Epoch [13/50], Step [56/469], Loss: 1.2300, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [13/50], Step [57/469], Loss: 1.6708, batch time: 0.41, accuracy:  42.97%\n",
      "Epoch [13/50], Step [58/469], Loss: 1.4873, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [13/50], Step [59/469], Loss: 1.2128, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [60/469], Loss: 1.4099, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [61/469], Loss: 1.2801, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [62/469], Loss: 1.4009, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [13/50], Step [63/469], Loss: 1.2201, batch time: 0.42, accuracy:  59.38%\n",
      "Epoch [13/50], Step [64/469], Loss: 1.3158, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [65/469], Loss: 1.3575, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [66/469], Loss: 1.3283, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [67/469], Loss: 1.4483, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [68/469], Loss: 1.3106, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [69/469], Loss: 1.2973, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [13/50], Step [70/469], Loss: 1.1510, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [71/469], Loss: 1.2377, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [13/50], Step [72/469], Loss: 1.2391, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [73/469], Loss: 1.2009, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [74/469], Loss: 1.2518, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [13/50], Step [75/469], Loss: 1.0950, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [76/469], Loss: 1.1849, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [13/50], Step [77/469], Loss: 1.2975, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [78/469], Loss: 1.4540, batch time: 0.41, accuracy:  47.66%\n",
      "Epoch [13/50], Step [79/469], Loss: 1.3703, batch time: 0.41, accuracy:  49.22%\n",
      "Epoch [13/50], Step [80/469], Loss: 1.3475, batch time: 0.40, accuracy:  47.66%\n",
      "Epoch [13/50], Step [81/469], Loss: 1.3598, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [13/50], Step [82/469], Loss: 1.3571, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [13/50], Step [83/469], Loss: 1.2016, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [84/469], Loss: 1.2645, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [85/469], Loss: 1.3073, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [86/469], Loss: 1.3363, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [87/469], Loss: 1.3842, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [13/50], Step [88/469], Loss: 1.2331, batch time: 0.47, accuracy:  55.47%\n",
      "Epoch [13/50], Step [89/469], Loss: 1.2921, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [13/50], Step [90/469], Loss: 1.3593, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [13/50], Step [91/469], Loss: 1.3904, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [13/50], Step [92/469], Loss: 1.4056, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [13/50], Step [93/469], Loss: 1.2619, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [94/469], Loss: 1.2054, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [95/469], Loss: 1.2429, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [13/50], Step [96/469], Loss: 1.2521, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [97/469], Loss: 1.1912, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [98/469], Loss: 1.3595, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [99/469], Loss: 1.3445, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [100/469], Loss: 1.1078, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [13/50], Step [101/469], Loss: 1.5481, batch time: 0.41, accuracy:  50.78%\n",
      "Epoch [13/50], Step [102/469], Loss: 1.2361, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [103/469], Loss: 1.4272, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [104/469], Loss: 1.0120, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [13/50], Step [105/469], Loss: 1.4424, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [106/469], Loss: 1.3806, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [13/50], Step [107/469], Loss: 1.0866, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [13/50], Step [108/469], Loss: 1.3716, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [109/469], Loss: 1.2538, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [110/469], Loss: 1.3251, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [111/469], Loss: 1.3681, batch time: 0.42, accuracy:  52.34%\n",
      "Epoch [13/50], Step [112/469], Loss: 1.1818, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [113/469], Loss: 1.0999, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [13/50], Step [114/469], Loss: 1.2793, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [115/469], Loss: 1.2777, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [116/469], Loss: 1.4823, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [13/50], Step [117/469], Loss: 1.3000, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [118/469], Loss: 1.3666, batch time: 0.41, accuracy:  50.00%\n",
      "Epoch [13/50], Step [119/469], Loss: 1.0721, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [13/50], Step [120/469], Loss: 1.2702, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [121/469], Loss: 1.2277, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [122/469], Loss: 1.3197, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [13/50], Step [123/469], Loss: 1.1706, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [124/469], Loss: 1.2349, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [13/50], Step [125/469], Loss: 1.2819, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [126/469], Loss: 1.1533, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [127/469], Loss: 1.2651, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [128/469], Loss: 1.2419, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [129/469], Loss: 1.2111, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [130/469], Loss: 1.2563, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [131/469], Loss: 1.1410, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [132/469], Loss: 1.3437, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [133/469], Loss: 1.1688, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [134/469], Loss: 1.1541, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [135/469], Loss: 1.2917, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [13/50], Step [136/469], Loss: 1.4722, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [137/469], Loss: 1.2003, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [138/469], Loss: 1.3717, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [139/469], Loss: 1.1568, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [13/50], Step [140/469], Loss: 1.5131, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [141/469], Loss: 1.0627, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [13/50], Step [142/469], Loss: 1.3256, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [143/469], Loss: 1.1754, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [144/469], Loss: 1.3638, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [145/469], Loss: 1.2084, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [146/469], Loss: 1.3468, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [13/50], Step [147/469], Loss: 1.2608, batch time: 0.41, accuracy:  54.69%\n",
      "Epoch [13/50], Step [148/469], Loss: 1.4223, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [149/469], Loss: 1.3035, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [150/469], Loss: 1.2796, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [151/469], Loss: 1.1256, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [13/50], Step [152/469], Loss: 1.3298, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [153/469], Loss: 1.2496, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [154/469], Loss: 1.3173, batch time: 0.42, accuracy:  53.91%\n",
      "Epoch [13/50], Step [155/469], Loss: 1.2800, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [156/469], Loss: 1.2250, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [157/469], Loss: 1.3378, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [158/469], Loss: 1.2617, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [159/469], Loss: 1.2424, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [160/469], Loss: 1.2059, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [161/469], Loss: 1.2331, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [162/469], Loss: 1.2869, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [163/469], Loss: 1.2735, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [164/469], Loss: 1.2126, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [13/50], Step [165/469], Loss: 1.2585, batch time: 0.45, accuracy:  60.94%\n",
      "Epoch [13/50], Step [166/469], Loss: 1.2390, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [167/469], Loss: 1.3391, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [168/469], Loss: 1.3863, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [169/469], Loss: 1.4497, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [170/469], Loss: 1.3385, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [171/469], Loss: 1.1598, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [172/469], Loss: 1.1812, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [173/469], Loss: 1.2688, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [174/469], Loss: 1.2373, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [175/469], Loss: 1.2466, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [13/50], Step [176/469], Loss: 1.1312, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [13/50], Step [177/469], Loss: 1.3808, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [178/469], Loss: 1.3679, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [179/469], Loss: 1.2158, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [180/469], Loss: 1.3078, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [181/469], Loss: 1.1362, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [182/469], Loss: 1.3740, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [183/469], Loss: 1.2007, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [184/469], Loss: 1.2789, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [185/469], Loss: 1.3554, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [186/469], Loss: 1.2384, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [187/469], Loss: 1.2899, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [188/469], Loss: 1.3298, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [13/50], Step [189/469], Loss: 1.2209, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [13/50], Step [190/469], Loss: 1.2996, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [13/50], Step [191/469], Loss: 1.2183, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [192/469], Loss: 1.3022, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [193/469], Loss: 1.1679, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [13/50], Step [194/469], Loss: 1.3674, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [195/469], Loss: 1.3695, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [196/469], Loss: 1.4822, batch time: 0.40, accuracy:  46.88%\n",
      "Epoch [13/50], Step [197/469], Loss: 1.1889, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [198/469], Loss: 1.3550, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [13/50], Step [199/469], Loss: 1.0670, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [200/469], Loss: 1.1503, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [201/469], Loss: 1.2847, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [202/469], Loss: 1.1721, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [13/50], Step [203/469], Loss: 1.3909, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [204/469], Loss: 1.3954, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [205/469], Loss: 1.2687, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [206/469], Loss: 1.3308, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [207/469], Loss: 1.2712, batch time: 0.41, accuracy:  53.12%\n",
      "Epoch [13/50], Step [208/469], Loss: 1.3214, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [209/469], Loss: 1.1532, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [210/469], Loss: 1.1339, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [211/469], Loss: 1.2409, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [212/469], Loss: 1.4681, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [13/50], Step [213/469], Loss: 1.2521, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [13/50], Step [214/469], Loss: 1.2010, batch time: 0.47, accuracy:  60.94%\n",
      "Epoch [13/50], Step [215/469], Loss: 1.1823, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [216/469], Loss: 1.2576, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [13/50], Step [217/469], Loss: 1.2703, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [218/469], Loss: 1.3452, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [219/469], Loss: 1.2872, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [220/469], Loss: 1.3496, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [13/50], Step [221/469], Loss: 1.2750, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [222/469], Loss: 1.1621, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [223/469], Loss: 1.2987, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [224/469], Loss: 1.2390, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [225/469], Loss: 1.2908, batch time: 0.42, accuracy:  59.38%\n",
      "Epoch [13/50], Step [226/469], Loss: 1.3126, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [227/469], Loss: 1.2273, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [228/469], Loss: 1.2698, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [13/50], Step [229/469], Loss: 1.1498, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [230/469], Loss: 1.2252, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [231/469], Loss: 1.1712, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [13/50], Step [232/469], Loss: 1.3568, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [233/469], Loss: 1.2557, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [234/469], Loss: 1.4291, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [235/469], Loss: 1.3565, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [236/469], Loss: 1.1687, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [237/469], Loss: 1.2654, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [238/469], Loss: 1.2286, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [239/469], Loss: 1.0122, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [13/50], Step [240/469], Loss: 1.1889, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [241/469], Loss: 1.1377, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [242/469], Loss: 1.3157, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [243/469], Loss: 1.2574, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [244/469], Loss: 1.4358, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [245/469], Loss: 1.1640, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [246/469], Loss: 0.9812, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [13/50], Step [247/469], Loss: 1.1735, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [248/469], Loss: 1.0912, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [13/50], Step [249/469], Loss: 1.2240, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [13/50], Step [250/469], Loss: 1.2007, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [251/469], Loss: 1.1413, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [252/469], Loss: 1.3057, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [253/469], Loss: 1.2601, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [254/469], Loss: 1.0972, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [13/50], Step [255/469], Loss: 1.1862, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [13/50], Step [256/469], Loss: 1.1783, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [13/50], Step [257/469], Loss: 1.1879, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [258/469], Loss: 1.4652, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [259/469], Loss: 1.3000, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [13/50], Step [260/469], Loss: 1.3713, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [261/469], Loss: 1.1599, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [262/469], Loss: 1.1546, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [263/469], Loss: 1.3934, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [264/469], Loss: 1.2265, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [265/469], Loss: 1.1859, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [266/469], Loss: 1.3450, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [267/469], Loss: 1.3507, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [268/469], Loss: 1.1953, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [13/50], Step [269/469], Loss: 1.2019, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [270/469], Loss: 1.0900, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [13/50], Step [271/469], Loss: 1.1003, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [13/50], Step [272/469], Loss: 1.0263, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [13/50], Step [273/469], Loss: 1.2268, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [274/469], Loss: 1.1750, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [13/50], Step [275/469], Loss: 1.0863, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [13/50], Step [276/469], Loss: 1.1762, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [277/469], Loss: 1.2680, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [278/469], Loss: 1.4607, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [279/469], Loss: 1.2333, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [280/469], Loss: 1.2218, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [281/469], Loss: 1.1216, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [282/469], Loss: 1.3436, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [13/50], Step [283/469], Loss: 1.4085, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [284/469], Loss: 1.1620, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [13/50], Step [285/469], Loss: 1.2214, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [286/469], Loss: 1.2352, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [287/469], Loss: 1.2064, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [13/50], Step [288/469], Loss: 1.3300, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [289/469], Loss: 1.4611, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [290/469], Loss: 1.1249, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [13/50], Step [291/469], Loss: 1.2497, batch time: 0.40, accuracy:  52.34%\n",
      "Epoch [13/50], Step [292/469], Loss: 1.2867, batch time: 0.46, accuracy:  59.38%\n",
      "Epoch [13/50], Step [293/469], Loss: 0.9994, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [13/50], Step [294/469], Loss: 1.1512, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [295/469], Loss: 1.1691, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [13/50], Step [296/469], Loss: 1.3413, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [13/50], Step [297/469], Loss: 1.1145, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [298/469], Loss: 1.1926, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [299/469], Loss: 1.1407, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [300/469], Loss: 1.2223, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [301/469], Loss: 1.2448, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [302/469], Loss: 1.0808, batch time: 0.43, accuracy:  66.41%\n",
      "Epoch [13/50], Step [303/469], Loss: 1.1556, batch time: 0.45, accuracy:  63.28%\n",
      "Epoch [13/50], Step [304/469], Loss: 1.3597, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [13/50], Step [305/469], Loss: 1.0969, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [13/50], Step [306/469], Loss: 1.1537, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [307/469], Loss: 1.0694, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [13/50], Step [308/469], Loss: 1.2163, batch time: 0.43, accuracy:  57.03%\n",
      "Epoch [13/50], Step [309/469], Loss: 1.1893, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [13/50], Step [310/469], Loss: 1.3550, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [13/50], Step [311/469], Loss: 1.0327, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [13/50], Step [312/469], Loss: 1.2619, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [13/50], Step [313/469], Loss: 1.1658, batch time: 0.43, accuracy:  60.94%\n",
      "Epoch [13/50], Step [314/469], Loss: 1.2631, batch time: 0.41, accuracy:  46.09%\n",
      "Epoch [13/50], Step [315/469], Loss: 1.0780, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [316/469], Loss: 1.1625, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [317/469], Loss: 1.1701, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [318/469], Loss: 1.2356, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [319/469], Loss: 1.1259, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [13/50], Step [320/469], Loss: 1.2732, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [13/50], Step [321/469], Loss: 1.3414, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [322/469], Loss: 1.3097, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [13/50], Step [323/469], Loss: 1.4405, batch time: 0.42, accuracy:  54.69%\n",
      "Epoch [13/50], Step [324/469], Loss: 1.1922, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [325/469], Loss: 1.1915, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [326/469], Loss: 1.0970, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [13/50], Step [327/469], Loss: 1.1472, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [13/50], Step [328/469], Loss: 1.2813, batch time: 0.43, accuracy:  53.12%\n",
      "Epoch [13/50], Step [329/469], Loss: 1.1950, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [13/50], Step [330/469], Loss: 1.2562, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [13/50], Step [331/469], Loss: 0.9068, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [13/50], Step [332/469], Loss: 1.0724, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [13/50], Step [333/469], Loss: 1.2651, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [13/50], Step [334/469], Loss: 1.1285, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [13/50], Step [335/469], Loss: 1.2466, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [336/469], Loss: 1.2472, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [337/469], Loss: 1.2355, batch time: 0.43, accuracy:  60.16%\n",
      "Epoch [13/50], Step [338/469], Loss: 1.0718, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [13/50], Step [339/469], Loss: 1.2496, batch time: 0.46, accuracy:  59.38%\n",
      "Epoch [13/50], Step [340/469], Loss: 1.2908, batch time: 0.42, accuracy:  56.25%\n",
      "Epoch [13/50], Step [341/469], Loss: 1.2567, batch time: 0.42, accuracy:  53.12%\n",
      "Epoch [13/50], Step [342/469], Loss: 1.3193, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [343/469], Loss: 1.0329, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [13/50], Step [344/469], Loss: 1.0952, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [13/50], Step [345/469], Loss: 1.2462, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [346/469], Loss: 1.4541, batch time: 0.41, accuracy:  51.56%\n",
      "Epoch [13/50], Step [347/469], Loss: 1.1193, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [13/50], Step [348/469], Loss: 1.1991, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [13/50], Step [349/469], Loss: 1.3164, batch time: 0.40, accuracy:  51.56%\n",
      "Epoch [13/50], Step [350/469], Loss: 1.1390, batch time: 0.42, accuracy:  56.25%\n",
      "Epoch [13/50], Step [351/469], Loss: 1.3233, batch time: 0.42, accuracy:  52.34%\n",
      "Epoch [13/50], Step [352/469], Loss: 1.0518, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [13/50], Step [353/469], Loss: 1.2603, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [13/50], Step [354/469], Loss: 1.2150, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [13/50], Step [355/469], Loss: 1.0810, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [13/50], Step [356/469], Loss: 1.1169, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [13/50], Step [357/469], Loss: 1.1231, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [358/469], Loss: 1.0906, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [13/50], Step [359/469], Loss: 1.3528, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [360/469], Loss: 1.1438, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [13/50], Step [361/469], Loss: 1.1093, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [13/50], Step [362/469], Loss: 1.1145, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [363/469], Loss: 1.1020, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [13/50], Step [364/469], Loss: 1.1592, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [365/469], Loss: 0.9950, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [13/50], Step [366/469], Loss: 1.1636, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [367/469], Loss: 1.1267, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [13/50], Step [368/469], Loss: 1.1651, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [369/469], Loss: 1.1944, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [13/50], Step [370/469], Loss: 1.1472, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [13/50], Step [371/469], Loss: 1.0552, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [13/50], Step [372/469], Loss: 1.1618, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [13/50], Step [373/469], Loss: 1.2690, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [374/469], Loss: 1.2211, batch time: 0.40, accuracy:  55.47%\n",
      "Epoch [13/50], Step [375/469], Loss: 1.2341, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [376/469], Loss: 1.1089, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [377/469], Loss: 1.0369, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [13/50], Step [378/469], Loss: 1.0621, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [13/50], Step [379/469], Loss: 1.0731, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [380/469], Loss: 1.0904, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [13/50], Step [381/469], Loss: 1.1236, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [382/469], Loss: 1.2244, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [13/50], Step [383/469], Loss: 1.3571, batch time: 0.40, accuracy:  50.78%\n",
      "Epoch [13/50], Step [384/469], Loss: 1.2323, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [13/50], Step [385/469], Loss: 1.0851, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [13/50], Step [386/469], Loss: 1.2079, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [13/50], Step [387/469], Loss: 1.3026, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [388/469], Loss: 1.3615, batch time: 0.41, accuracy:  57.03%\n",
      "Epoch [13/50], Step [389/469], Loss: 1.2405, batch time: 0.41, accuracy:  52.34%\n",
      "Epoch [13/50], Step [390/469], Loss: 1.2410, batch time: 0.43, accuracy:  60.16%\n",
      "Epoch [13/50], Step [391/469], Loss: 1.1021, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [392/469], Loss: 1.0782, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [13/50], Step [393/469], Loss: 1.2524, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [394/469], Loss: 1.0489, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [13/50], Step [395/469], Loss: 1.2385, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [396/469], Loss: 1.2358, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [397/469], Loss: 0.9893, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [13/50], Step [398/469], Loss: 1.2484, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [399/469], Loss: 1.2839, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [400/469], Loss: 1.2470, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [13/50], Step [401/469], Loss: 1.2675, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [402/469], Loss: 1.0198, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [13/50], Step [403/469], Loss: 1.1259, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [13/50], Step [404/469], Loss: 1.2574, batch time: 0.43, accuracy:  53.91%\n",
      "Epoch [13/50], Step [405/469], Loss: 1.3422, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [13/50], Step [406/469], Loss: 1.2479, batch time: 0.42, accuracy:  55.47%\n",
      "Epoch [13/50], Step [407/469], Loss: 1.1625, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [408/469], Loss: 1.2583, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [13/50], Step [409/469], Loss: 1.1556, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [410/469], Loss: 1.1029, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [13/50], Step [411/469], Loss: 0.9828, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [13/50], Step [412/469], Loss: 1.2389, batch time: 0.42, accuracy:  59.38%\n",
      "Epoch [13/50], Step [413/469], Loss: 1.1724, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [13/50], Step [414/469], Loss: 1.1955, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [13/50], Step [415/469], Loss: 1.1632, batch time: 0.42, accuracy:  55.47%\n",
      "Epoch [13/50], Step [416/469], Loss: 1.3820, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [13/50], Step [417/469], Loss: 1.1503, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [13/50], Step [418/469], Loss: 1.2198, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [13/50], Step [419/469], Loss: 1.3897, batch time: 0.42, accuracy:  53.12%\n",
      "Epoch [13/50], Step [420/469], Loss: 1.0818, batch time: 0.43, accuracy:  68.75%\n",
      "Epoch [13/50], Step [421/469], Loss: 1.4624, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [13/50], Step [422/469], Loss: 1.1552, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [13/50], Step [423/469], Loss: 1.1513, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [13/50], Step [424/469], Loss: 1.2024, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [13/50], Step [425/469], Loss: 1.3110, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [13/50], Step [426/469], Loss: 1.1821, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [427/469], Loss: 1.1072, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [428/469], Loss: 1.4084, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [429/469], Loss: 1.1509, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [13/50], Step [430/469], Loss: 1.0314, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [13/50], Step [431/469], Loss: 1.3834, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [432/469], Loss: 1.2940, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [13/50], Step [433/469], Loss: 1.2568, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [13/50], Step [434/469], Loss: 1.1754, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [13/50], Step [435/469], Loss: 1.0819, batch time: 0.40, accuracy:  54.69%\n",
      "Epoch [13/50], Step [436/469], Loss: 1.1781, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [13/50], Step [437/469], Loss: 1.1854, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [13/50], Step [438/469], Loss: 1.0445, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [439/469], Loss: 1.0195, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [13/50], Step [440/469], Loss: 1.1776, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [441/469], Loss: 1.0663, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [13/50], Step [442/469], Loss: 1.2829, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [13/50], Step [443/469], Loss: 1.2151, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [444/469], Loss: 1.2951, batch time: 0.41, accuracy:  53.91%\n",
      "Epoch [13/50], Step [445/469], Loss: 1.2428, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [13/50], Step [446/469], Loss: 1.4313, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [447/469], Loss: 1.1857, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [13/50], Step [448/469], Loss: 1.1536, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [13/50], Step [449/469], Loss: 1.2361, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [13/50], Step [450/469], Loss: 1.1697, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [13/50], Step [451/469], Loss: 1.3711, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [13/50], Step [452/469], Loss: 1.3019, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [13/50], Step [453/469], Loss: 0.9934, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [13/50], Step [454/469], Loss: 1.2899, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [13/50], Step [455/469], Loss: 1.1663, batch time: 0.42, accuracy:  57.03%\n",
      "Epoch [13/50], Step [456/469], Loss: 1.3217, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [13/50], Step [457/469], Loss: 1.2949, batch time: 0.43, accuracy:  61.72%\n",
      "Epoch [13/50], Step [458/469], Loss: 1.3907, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [13/50], Step [459/469], Loss: 1.1223, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [460/469], Loss: 1.3156, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [461/469], Loss: 1.0684, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [13/50], Step [462/469], Loss: 1.0382, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [13/50], Step [463/469], Loss: 1.0604, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [13/50], Step [464/469], Loss: 1.2253, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [13/50], Step [465/469], Loss: 1.0726, batch time: 0.48, accuracy:  63.28%\n",
      "Epoch [13/50], Step [466/469], Loss: 1.1493, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [13/50], Step [467/469], Loss: 1.0574, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [13/50], Step [468/469], Loss: 1.1910, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [13/50], Step [469/469], Loss: 1.2198, batch time: 0.41, accuracy:  63.54%\n",
      "Epoch [14/50], Step [1/469], Loss: 1.1876, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [14/50], Step [2/469], Loss: 1.1462, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [14/50], Step [3/469], Loss: 1.1891, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [4/469], Loss: 0.9953, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [14/50], Step [5/469], Loss: 1.2504, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [6/469], Loss: 1.1362, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [14/50], Step [7/469], Loss: 1.3043, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [8/469], Loss: 1.1335, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [14/50], Step [9/469], Loss: 1.1719, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [14/50], Step [10/469], Loss: 1.1889, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [11/469], Loss: 1.2690, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [12/469], Loss: 0.9964, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [14/50], Step [13/469], Loss: 0.9704, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [14/469], Loss: 1.4383, batch time: 0.42, accuracy:  55.47%\n",
      "Epoch [14/50], Step [15/469], Loss: 1.0240, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [16/469], Loss: 1.1943, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [14/50], Step [17/469], Loss: 1.2554, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [14/50], Step [18/469], Loss: 1.2315, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [14/50], Step [19/469], Loss: 1.1088, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [14/50], Step [20/469], Loss: 1.3483, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [14/50], Step [21/469], Loss: 1.1278, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [22/469], Loss: 1.3724, batch time: 0.40, accuracy:  56.25%\n",
      "Epoch [14/50], Step [23/469], Loss: 1.2530, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [14/50], Step [24/469], Loss: 0.9578, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [14/50], Step [25/469], Loss: 1.1651, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [26/469], Loss: 1.1496, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [14/50], Step [27/469], Loss: 1.0366, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [14/50], Step [28/469], Loss: 1.1764, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [29/469], Loss: 1.1926, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [14/50], Step [30/469], Loss: 1.0541, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [31/469], Loss: 1.2264, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [14/50], Step [32/469], Loss: 1.1633, batch time: 0.40, accuracy:  59.38%\n",
      "Epoch [14/50], Step [33/469], Loss: 1.1309, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [14/50], Step [34/469], Loss: 1.1434, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [14/50], Step [35/469], Loss: 0.9140, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [14/50], Step [36/469], Loss: 1.2452, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [37/469], Loss: 1.0461, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [14/50], Step [38/469], Loss: 1.3466, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [39/469], Loss: 1.1250, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [14/50], Step [40/469], Loss: 1.0166, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [41/469], Loss: 1.2241, batch time: 0.43, accuracy:  59.38%\n",
      "Epoch [14/50], Step [42/469], Loss: 1.2048, batch time: 0.42, accuracy:  57.03%\n",
      "Epoch [14/50], Step [43/469], Loss: 1.2040, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [44/469], Loss: 1.1061, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [14/50], Step [45/469], Loss: 1.0371, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [46/469], Loss: 1.2908, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [47/469], Loss: 1.2269, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [14/50], Step [48/469], Loss: 1.3083, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [14/50], Step [49/469], Loss: 1.2397, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [14/50], Step [50/469], Loss: 1.1095, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [51/469], Loss: 1.1671, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [14/50], Step [52/469], Loss: 1.1919, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [14/50], Step [53/469], Loss: 1.1306, batch time: 0.43, accuracy:  60.16%\n",
      "Epoch [14/50], Step [54/469], Loss: 1.0254, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [14/50], Step [55/469], Loss: 1.0254, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [14/50], Step [56/469], Loss: 1.0478, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [57/469], Loss: 1.0274, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [58/469], Loss: 1.1484, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [14/50], Step [59/469], Loss: 1.0535, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [60/469], Loss: 1.2852, batch time: 0.42, accuracy:  56.25%\n",
      "Epoch [14/50], Step [61/469], Loss: 1.0448, batch time: 0.43, accuracy:  66.41%\n",
      "Epoch [14/50], Step [62/469], Loss: 0.9721, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [14/50], Step [63/469], Loss: 1.0462, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [14/50], Step [64/469], Loss: 1.0242, batch time: 0.43, accuracy:  69.53%\n",
      "Epoch [14/50], Step [65/469], Loss: 1.2789, batch time: 0.43, accuracy:  58.59%\n",
      "Epoch [14/50], Step [66/469], Loss: 1.2388, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [67/469], Loss: 1.0247, batch time: 0.43, accuracy:  67.19%\n",
      "Epoch [14/50], Step [68/469], Loss: 1.0604, batch time: 0.42, accuracy:  59.38%\n",
      "Epoch [14/50], Step [69/469], Loss: 0.9915, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [14/50], Step [70/469], Loss: 1.1628, batch time: 0.42, accuracy:  57.81%\n",
      "Epoch [14/50], Step [71/469], Loss: 1.2196, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [14/50], Step [72/469], Loss: 1.2681, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [73/469], Loss: 1.1474, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [14/50], Step [74/469], Loss: 1.0495, batch time: 0.49, accuracy:  58.59%\n",
      "Epoch [14/50], Step [75/469], Loss: 1.1342, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [14/50], Step [76/469], Loss: 1.2040, batch time: 0.43, accuracy:  61.72%\n",
      "Epoch [14/50], Step [77/469], Loss: 1.0829, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [78/469], Loss: 1.2711, batch time: 0.43, accuracy:  57.81%\n",
      "Epoch [14/50], Step [79/469], Loss: 1.1015, batch time: 0.43, accuracy:  69.53%\n",
      "Epoch [14/50], Step [80/469], Loss: 1.1069, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [14/50], Step [81/469], Loss: 1.0990, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [82/469], Loss: 1.0430, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [83/469], Loss: 1.1221, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [84/469], Loss: 0.9589, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [14/50], Step [85/469], Loss: 1.0722, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [14/50], Step [86/469], Loss: 1.0735, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [14/50], Step [87/469], Loss: 1.0494, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [88/469], Loss: 1.3762, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [14/50], Step [89/469], Loss: 1.1709, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [14/50], Step [90/469], Loss: 1.1208, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [14/50], Step [91/469], Loss: 1.1983, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [92/469], Loss: 0.9822, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [93/469], Loss: 0.8992, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [14/50], Step [94/469], Loss: 1.1186, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [95/469], Loss: 1.0981, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [96/469], Loss: 1.0567, batch time: 0.43, accuracy:  68.75%\n",
      "Epoch [14/50], Step [97/469], Loss: 1.3572, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [14/50], Step [98/469], Loss: 1.1000, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [14/50], Step [99/469], Loss: 1.0724, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [14/50], Step [100/469], Loss: 1.1080, batch time: 0.43, accuracy:  69.53%\n",
      "Epoch [14/50], Step [101/469], Loss: 1.2245, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [14/50], Step [102/469], Loss: 1.0211, batch time: 0.43, accuracy:  71.88%\n",
      "Epoch [14/50], Step [103/469], Loss: 1.0917, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [14/50], Step [104/469], Loss: 1.0565, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [14/50], Step [105/469], Loss: 1.0292, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [106/469], Loss: 0.9888, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [14/50], Step [107/469], Loss: 1.3678, batch time: 0.40, accuracy:  60.16%\n",
      "Epoch [14/50], Step [108/469], Loss: 1.1071, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [109/469], Loss: 1.1873, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [14/50], Step [110/469], Loss: 1.2205, batch time: 0.41, accuracy:  57.81%\n",
      "Epoch [14/50], Step [111/469], Loss: 1.0582, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [14/50], Step [112/469], Loss: 1.0694, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [113/469], Loss: 1.1878, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [14/50], Step [114/469], Loss: 1.4094, batch time: 0.40, accuracy:  53.91%\n",
      "Epoch [14/50], Step [115/469], Loss: 1.0985, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [116/469], Loss: 1.2535, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [14/50], Step [117/469], Loss: 0.9938, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [118/469], Loss: 1.0263, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [119/469], Loss: 1.2554, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [120/469], Loss: 1.1238, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [121/469], Loss: 1.2372, batch time: 0.43, accuracy:  60.16%\n",
      "Epoch [14/50], Step [122/469], Loss: 1.4297, batch time: 0.43, accuracy:  61.72%\n",
      "Epoch [14/50], Step [123/469], Loss: 1.1754, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [124/469], Loss: 1.2257, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [14/50], Step [125/469], Loss: 1.3102, batch time: 0.43, accuracy:  57.81%\n",
      "Epoch [14/50], Step [126/469], Loss: 1.1382, batch time: 0.43, accuracy:  64.84%\n",
      "Epoch [14/50], Step [127/469], Loss: 1.0476, batch time: 0.43, accuracy:  65.62%\n",
      "Epoch [14/50], Step [128/469], Loss: 1.1266, batch time: 0.43, accuracy:  67.97%\n",
      "Epoch [14/50], Step [129/469], Loss: 1.0241, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [14/50], Step [130/469], Loss: 1.0685, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [14/50], Step [131/469], Loss: 1.0235, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [14/50], Step [132/469], Loss: 1.0668, batch time: 0.46, accuracy:  59.38%\n",
      "Epoch [14/50], Step [133/469], Loss: 1.0133, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [134/469], Loss: 1.2275, batch time: 0.43, accuracy:  64.06%\n",
      "Epoch [14/50], Step [135/469], Loss: 0.9758, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [14/50], Step [136/469], Loss: 1.1423, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [14/50], Step [137/469], Loss: 1.1204, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [14/50], Step [138/469], Loss: 0.9199, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [14/50], Step [139/469], Loss: 1.2070, batch time: 0.42, accuracy:  57.03%\n",
      "Epoch [14/50], Step [140/469], Loss: 1.1010, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [14/50], Step [141/469], Loss: 1.1899, batch time: 0.44, accuracy:  58.59%\n",
      "Epoch [14/50], Step [142/469], Loss: 1.0126, batch time: 0.43, accuracy:  67.19%\n",
      "Epoch [14/50], Step [143/469], Loss: 0.9748, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [14/50], Step [144/469], Loss: 1.0770, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [14/50], Step [145/469], Loss: 1.2133, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [146/469], Loss: 0.9482, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [14/50], Step [147/469], Loss: 1.2093, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [148/469], Loss: 0.9641, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [149/469], Loss: 1.1631, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [14/50], Step [150/469], Loss: 1.0925, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [14/50], Step [151/469], Loss: 1.4046, batch time: 0.40, accuracy:  53.12%\n",
      "Epoch [14/50], Step [152/469], Loss: 1.0908, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [153/469], Loss: 1.3532, batch time: 0.45, accuracy:  57.81%\n",
      "Epoch [14/50], Step [154/469], Loss: 1.0878, batch time: 0.44, accuracy:  65.62%\n",
      "Epoch [14/50], Step [155/469], Loss: 1.0096, batch time: 0.44, accuracy:  68.75%\n",
      "Epoch [14/50], Step [156/469], Loss: 1.0624, batch time: 0.43, accuracy:  65.62%\n",
      "Epoch [14/50], Step [157/469], Loss: 1.0394, batch time: 0.43, accuracy:  67.19%\n",
      "Epoch [14/50], Step [158/469], Loss: 1.0089, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [14/50], Step [159/469], Loss: 1.3136, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [160/469], Loss: 1.1177, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [14/50], Step [161/469], Loss: 1.0171, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [162/469], Loss: 1.0015, batch time: 0.43, accuracy:  63.28%\n",
      "Epoch [14/50], Step [163/469], Loss: 1.2076, batch time: 0.43, accuracy:  65.62%\n",
      "Epoch [14/50], Step [164/469], Loss: 1.3356, batch time: 0.43, accuracy:  57.03%\n",
      "Epoch [14/50], Step [165/469], Loss: 1.1503, batch time: 0.43, accuracy:  66.41%\n",
      "Epoch [14/50], Step [166/469], Loss: 1.1660, batch time: 0.44, accuracy:  65.62%\n",
      "Epoch [14/50], Step [167/469], Loss: 1.1725, batch time: 0.43, accuracy:  63.28%\n",
      "Epoch [14/50], Step [168/469], Loss: 1.1204, batch time: 0.43, accuracy:  64.06%\n",
      "Epoch [14/50], Step [169/469], Loss: 1.1187, batch time: 0.43, accuracy:  65.62%\n",
      "Epoch [14/50], Step [170/469], Loss: 1.0284, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [171/469], Loss: 1.1272, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [172/469], Loss: 1.1865, batch time: 0.43, accuracy:  66.41%\n",
      "Epoch [14/50], Step [173/469], Loss: 1.1538, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [174/469], Loss: 1.2503, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [14/50], Step [175/469], Loss: 1.0523, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [176/469], Loss: 1.1651, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [14/50], Step [177/469], Loss: 1.1734, batch time: 0.43, accuracy:  57.81%\n",
      "Epoch [14/50], Step [178/469], Loss: 1.2396, batch time: 0.48, accuracy:  62.50%\n",
      "Epoch [14/50], Step [179/469], Loss: 1.1975, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [180/469], Loss: 1.1611, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [181/469], Loss: 1.2867, batch time: 0.41, accuracy:  56.25%\n",
      "Epoch [14/50], Step [182/469], Loss: 1.0177, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [14/50], Step [183/469], Loss: 0.9360, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [14/50], Step [184/469], Loss: 1.2194, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [185/469], Loss: 0.9451, batch time: 0.43, accuracy:  64.84%\n",
      "Epoch [14/50], Step [186/469], Loss: 1.0128, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [187/469], Loss: 1.1928, batch time: 0.43, accuracy:  62.50%\n",
      "Epoch [14/50], Step [188/469], Loss: 1.0542, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [189/469], Loss: 1.0981, batch time: 0.43, accuracy:  65.62%\n",
      "Epoch [14/50], Step [190/469], Loss: 0.9275, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [191/469], Loss: 1.0379, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [192/469], Loss: 1.1717, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [14/50], Step [193/469], Loss: 0.9497, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [14/50], Step [194/469], Loss: 1.2356, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [195/469], Loss: 1.0696, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [196/469], Loss: 1.0696, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [197/469], Loss: 1.0567, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [198/469], Loss: 0.9740, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [14/50], Step [199/469], Loss: 0.9687, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [200/469], Loss: 1.1742, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [14/50], Step [201/469], Loss: 1.2964, batch time: 0.41, accuracy:  55.47%\n",
      "Epoch [14/50], Step [202/469], Loss: 1.1558, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [14/50], Step [203/469], Loss: 1.0705, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [14/50], Step [204/469], Loss: 0.9532, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [14/50], Step [205/469], Loss: 1.0389, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [206/469], Loss: 1.0213, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [14/50], Step [207/469], Loss: 1.2773, batch time: 0.42, accuracy:  59.38%\n",
      "Epoch [14/50], Step [208/469], Loss: 0.9477, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [14/50], Step [209/469], Loss: 1.1770, batch time: 0.43, accuracy:  60.94%\n",
      "Epoch [14/50], Step [210/469], Loss: 1.0793, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [14/50], Step [211/469], Loss: 1.1334, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [14/50], Step [212/469], Loss: 1.1281, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [14/50], Step [213/469], Loss: 1.0845, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [214/469], Loss: 1.0372, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [215/469], Loss: 1.1828, batch time: 0.42, accuracy:  59.38%\n",
      "Epoch [14/50], Step [216/469], Loss: 1.0532, batch time: 0.47, accuracy:  71.09%\n",
      "Epoch [14/50], Step [217/469], Loss: 0.9967, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [218/469], Loss: 1.0782, batch time: 0.43, accuracy:  65.62%\n",
      "Epoch [14/50], Step [219/469], Loss: 0.9834, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [220/469], Loss: 1.0686, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [221/469], Loss: 1.1919, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [222/469], Loss: 1.1153, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [223/469], Loss: 1.0114, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [14/50], Step [224/469], Loss: 1.1657, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [14/50], Step [225/469], Loss: 1.0939, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [14/50], Step [226/469], Loss: 0.9811, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [14/50], Step [227/469], Loss: 0.9300, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [14/50], Step [228/469], Loss: 1.0572, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [14/50], Step [229/469], Loss: 1.0059, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [14/50], Step [230/469], Loss: 1.0901, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [14/50], Step [231/469], Loss: 1.2602, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [232/469], Loss: 1.3040, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [233/469], Loss: 1.0267, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [234/469], Loss: 1.1479, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [235/469], Loss: 1.1730, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [236/469], Loss: 1.0915, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [14/50], Step [237/469], Loss: 1.2201, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [14/50], Step [238/469], Loss: 1.0437, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [239/469], Loss: 1.0623, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [240/469], Loss: 1.1281, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [241/469], Loss: 1.1819, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [14/50], Step [242/469], Loss: 1.0944, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [14/50], Step [243/469], Loss: 1.0783, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [244/469], Loss: 0.9663, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [245/469], Loss: 1.1141, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [14/50], Step [246/469], Loss: 1.0966, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [247/469], Loss: 1.1834, batch time: 0.42, accuracy:  59.38%\n",
      "Epoch [14/50], Step [248/469], Loss: 1.0727, batch time: 0.44, accuracy:  66.41%\n",
      "Epoch [14/50], Step [249/469], Loss: 0.9701, batch time: 0.48, accuracy:  67.97%\n",
      "Epoch [14/50], Step [250/469], Loss: 1.0223, batch time: 0.43, accuracy:  67.19%\n",
      "Epoch [14/50], Step [251/469], Loss: 1.2664, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [14/50], Step [252/469], Loss: 1.0729, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [253/469], Loss: 1.0592, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [14/50], Step [254/469], Loss: 1.0736, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [14/50], Step [255/469], Loss: 1.0797, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [14/50], Step [256/469], Loss: 1.0566, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [14/50], Step [257/469], Loss: 1.0318, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [14/50], Step [258/469], Loss: 1.1672, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [14/50], Step [259/469], Loss: 1.1315, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [260/469], Loss: 1.0854, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [261/469], Loss: 1.0130, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [262/469], Loss: 0.9817, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [263/469], Loss: 1.2025, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [14/50], Step [264/469], Loss: 1.1906, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [265/469], Loss: 1.0811, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [266/469], Loss: 1.1262, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [267/469], Loss: 1.1468, batch time: 0.40, accuracy:  57.81%\n",
      "Epoch [14/50], Step [268/469], Loss: 0.9872, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [269/469], Loss: 0.9867, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [270/469], Loss: 1.0881, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [271/469], Loss: 0.9280, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [14/50], Step [272/469], Loss: 0.9763, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [14/50], Step [273/469], Loss: 1.0240, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [274/469], Loss: 1.0887, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [275/469], Loss: 1.0869, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [276/469], Loss: 1.0779, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [14/50], Step [277/469], Loss: 1.3061, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [14/50], Step [278/469], Loss: 1.1636, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [279/469], Loss: 0.9165, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [280/469], Loss: 1.0019, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [281/469], Loss: 0.7741, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [14/50], Step [282/469], Loss: 1.1005, batch time: 0.43, accuracy:  68.75%\n",
      "Epoch [14/50], Step [283/469], Loss: 1.1071, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [284/469], Loss: 1.2981, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [285/469], Loss: 0.9069, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [286/469], Loss: 1.1348, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [287/469], Loss: 0.9878, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [288/469], Loss: 1.0325, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [14/50], Step [289/469], Loss: 1.2163, batch time: 0.41, accuracy:  60.16%\n",
      "Epoch [14/50], Step [290/469], Loss: 1.0672, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [14/50], Step [291/469], Loss: 0.9068, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [14/50], Step [292/469], Loss: 1.1092, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [293/469], Loss: 1.0922, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [14/50], Step [294/469], Loss: 1.0218, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [14/50], Step [295/469], Loss: 1.3032, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [14/50], Step [296/469], Loss: 0.8657, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [14/50], Step [297/469], Loss: 1.1546, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [14/50], Step [298/469], Loss: 1.1746, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [299/469], Loss: 1.1718, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [14/50], Step [300/469], Loss: 1.0890, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [14/50], Step [301/469], Loss: 1.2413, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [302/469], Loss: 0.9989, batch time: 0.43, accuracy:  71.88%\n",
      "Epoch [14/50], Step [303/469], Loss: 1.0817, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [14/50], Step [304/469], Loss: 1.1624, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [14/50], Step [305/469], Loss: 0.9717, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [14/50], Step [306/469], Loss: 1.2026, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [14/50], Step [307/469], Loss: 1.0223, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [14/50], Step [308/469], Loss: 1.0678, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [14/50], Step [309/469], Loss: 0.9813, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [310/469], Loss: 1.2005, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [311/469], Loss: 1.2465, batch time: 0.47, accuracy:  58.59%\n",
      "Epoch [14/50], Step [312/469], Loss: 1.0171, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [313/469], Loss: 1.0877, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [314/469], Loss: 1.0248, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [14/50], Step [315/469], Loss: 0.9618, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [316/469], Loss: 0.9914, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [14/50], Step [317/469], Loss: 0.8477, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [14/50], Step [318/469], Loss: 1.1217, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [319/469], Loss: 1.0924, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [320/469], Loss: 1.0667, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [321/469], Loss: 1.0437, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [322/469], Loss: 1.3251, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [14/50], Step [323/469], Loss: 0.9615, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [14/50], Step [324/469], Loss: 1.0990, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [14/50], Step [325/469], Loss: 0.9462, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [14/50], Step [326/469], Loss: 1.0033, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [14/50], Step [327/469], Loss: 1.0926, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [328/469], Loss: 1.0505, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [329/469], Loss: 1.1649, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [14/50], Step [330/469], Loss: 0.9428, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [331/469], Loss: 1.1647, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [332/469], Loss: 0.9891, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [14/50], Step [333/469], Loss: 1.0133, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [334/469], Loss: 1.0938, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [14/50], Step [335/469], Loss: 1.0507, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [336/469], Loss: 0.9932, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [14/50], Step [337/469], Loss: 1.2636, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [14/50], Step [338/469], Loss: 1.0456, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [339/469], Loss: 0.8676, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [14/50], Step [340/469], Loss: 0.8632, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [14/50], Step [341/469], Loss: 0.9579, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [14/50], Step [342/469], Loss: 1.2255, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [14/50], Step [343/469], Loss: 1.0552, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [344/469], Loss: 1.0336, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [345/469], Loss: 1.0204, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [346/469], Loss: 1.0265, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [347/469], Loss: 0.9505, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [348/469], Loss: 0.8510, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [14/50], Step [349/469], Loss: 0.9657, batch time: 0.47, accuracy:  65.62%\n",
      "Epoch [14/50], Step [350/469], Loss: 0.9483, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [14/50], Step [351/469], Loss: 0.9910, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [14/50], Step [352/469], Loss: 1.0055, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [14/50], Step [353/469], Loss: 1.0948, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [354/469], Loss: 1.0189, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [14/50], Step [355/469], Loss: 1.0486, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [14/50], Step [356/469], Loss: 1.1633, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [14/50], Step [357/469], Loss: 1.1615, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [358/469], Loss: 0.9646, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [14/50], Step [359/469], Loss: 0.9391, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [14/50], Step [360/469], Loss: 1.2749, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [361/469], Loss: 1.1419, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [14/50], Step [362/469], Loss: 1.0576, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [14/50], Step [363/469], Loss: 1.1588, batch time: 0.42, accuracy:  58.59%\n",
      "Epoch [14/50], Step [364/469], Loss: 1.1211, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [365/469], Loss: 1.1789, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [14/50], Step [366/469], Loss: 0.8206, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [14/50], Step [367/469], Loss: 1.0673, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [368/469], Loss: 1.0068, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [14/50], Step [369/469], Loss: 1.0108, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [370/469], Loss: 0.8363, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [14/50], Step [371/469], Loss: 0.9205, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [14/50], Step [372/469], Loss: 1.0350, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [14/50], Step [373/469], Loss: 0.8569, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [374/469], Loss: 1.1200, batch time: 0.42, accuracy:  60.94%\n",
      "Epoch [14/50], Step [375/469], Loss: 1.0209, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [376/469], Loss: 0.8964, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [14/50], Step [377/469], Loss: 0.9659, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [14/50], Step [378/469], Loss: 1.0814, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [14/50], Step [379/469], Loss: 1.0359, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [14/50], Step [380/469], Loss: 1.0377, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [14/50], Step [381/469], Loss: 1.0818, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [382/469], Loss: 0.9784, batch time: 0.48, accuracy:  71.09%\n",
      "Epoch [14/50], Step [383/469], Loss: 0.9894, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [14/50], Step [384/469], Loss: 0.9658, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [14/50], Step [385/469], Loss: 1.0804, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [14/50], Step [386/469], Loss: 0.9629, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [14/50], Step [387/469], Loss: 0.8701, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [14/50], Step [388/469], Loss: 1.1520, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [389/469], Loss: 1.0708, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [14/50], Step [390/469], Loss: 0.8588, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [14/50], Step [391/469], Loss: 1.0125, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [392/469], Loss: 1.0112, batch time: 0.42, accuracy:  64.06%\n",
      "Epoch [14/50], Step [393/469], Loss: 0.8494, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [14/50], Step [394/469], Loss: 1.0175, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [395/469], Loss: 1.0335, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [396/469], Loss: 1.2288, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [397/469], Loss: 1.1076, batch time: 0.40, accuracy:  60.94%\n",
      "Epoch [14/50], Step [398/469], Loss: 1.0498, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [14/50], Step [399/469], Loss: 1.0038, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [14/50], Step [400/469], Loss: 1.0508, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [401/469], Loss: 0.8874, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [14/50], Step [402/469], Loss: 1.1480, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [14/50], Step [403/469], Loss: 1.2285, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [404/469], Loss: 1.1067, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [14/50], Step [405/469], Loss: 1.1184, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [14/50], Step [406/469], Loss: 0.9695, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [14/50], Step [407/469], Loss: 0.9302, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [14/50], Step [408/469], Loss: 1.0959, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [14/50], Step [409/469], Loss: 1.0740, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [14/50], Step [410/469], Loss: 0.8471, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [14/50], Step [411/469], Loss: 1.0773, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [412/469], Loss: 0.9696, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [413/469], Loss: 1.0025, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [14/50], Step [414/469], Loss: 0.9808, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [14/50], Step [415/469], Loss: 1.1887, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [416/469], Loss: 0.9840, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [417/469], Loss: 1.2545, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [14/50], Step [418/469], Loss: 1.0914, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [419/469], Loss: 1.1894, batch time: 0.40, accuracy:  63.28%\n",
      "Epoch [14/50], Step [420/469], Loss: 1.1199, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [421/469], Loss: 1.1558, batch time: 0.41, accuracy:  59.38%\n",
      "Epoch [14/50], Step [422/469], Loss: 0.9440, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [423/469], Loss: 1.1303, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [424/469], Loss: 0.9352, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [14/50], Step [425/469], Loss: 1.0457, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [14/50], Step [426/469], Loss: 1.1007, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [427/469], Loss: 1.1827, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [428/469], Loss: 1.0966, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [429/469], Loss: 0.9612, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [430/469], Loss: 0.9944, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [431/469], Loss: 0.8750, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [14/50], Step [432/469], Loss: 1.2171, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [14/50], Step [433/469], Loss: 0.9573, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [14/50], Step [434/469], Loss: 1.2826, batch time: 0.42, accuracy:  53.91%\n",
      "Epoch [14/50], Step [435/469], Loss: 1.0121, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [14/50], Step [436/469], Loss: 0.9343, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [14/50], Step [437/469], Loss: 1.1431, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [438/469], Loss: 1.1297, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [439/469], Loss: 0.9809, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [14/50], Step [440/469], Loss: 0.9093, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [14/50], Step [441/469], Loss: 1.0122, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [14/50], Step [442/469], Loss: 1.0624, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [443/469], Loss: 0.8213, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [14/50], Step [444/469], Loss: 0.9090, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [14/50], Step [445/469], Loss: 1.0333, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [446/469], Loss: 1.0573, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [447/469], Loss: 0.9853, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [448/469], Loss: 1.0306, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [14/50], Step [449/469], Loss: 1.2475, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [14/50], Step [450/469], Loss: 0.9830, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [14/50], Step [451/469], Loss: 0.9795, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [14/50], Step [452/469], Loss: 0.9138, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [14/50], Step [453/469], Loss: 0.9602, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [14/50], Step [454/469], Loss: 1.2845, batch time: 0.40, accuracy:  61.72%\n",
      "Epoch [14/50], Step [455/469], Loss: 0.9346, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [14/50], Step [456/469], Loss: 0.9801, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [14/50], Step [457/469], Loss: 1.1145, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [458/469], Loss: 0.8580, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [14/50], Step [459/469], Loss: 1.0009, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [14/50], Step [460/469], Loss: 1.1866, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [461/469], Loss: 1.0568, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [14/50], Step [462/469], Loss: 1.0281, batch time: 0.46, accuracy:  63.28%\n",
      "Epoch [14/50], Step [463/469], Loss: 1.1376, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [14/50], Step [464/469], Loss: 0.8471, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [14/50], Step [465/469], Loss: 1.1316, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [14/50], Step [466/469], Loss: 1.0154, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [14/50], Step [467/469], Loss: 0.9635, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [14/50], Step [468/469], Loss: 0.9682, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [14/50], Step [469/469], Loss: 1.0160, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [15/50], Step [1/469], Loss: 0.8868, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [2/469], Loss: 0.9420, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [3/469], Loss: 0.9436, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [4/469], Loss: 1.0215, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [15/50], Step [5/469], Loss: 1.0394, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [6/469], Loss: 0.9926, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [7/469], Loss: 1.0181, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [15/50], Step [8/469], Loss: 1.0832, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [15/50], Step [9/469], Loss: 1.4627, batch time: 0.40, accuracy:  57.03%\n",
      "Epoch [15/50], Step [10/469], Loss: 0.9939, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [11/469], Loss: 1.1234, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [12/469], Loss: 1.2013, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [15/50], Step [13/469], Loss: 0.9993, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [14/469], Loss: 1.0144, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [15/469], Loss: 1.0660, batch time: 0.42, accuracy:  61.72%\n",
      "Epoch [15/50], Step [16/469], Loss: 1.0360, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [15/50], Step [17/469], Loss: 1.1289, batch time: 0.42, accuracy:  62.50%\n",
      "Epoch [15/50], Step [18/469], Loss: 1.1585, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [15/50], Step [19/469], Loss: 0.9028, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [15/50], Step [20/469], Loss: 1.1163, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [15/50], Step [21/469], Loss: 1.1664, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [15/50], Step [22/469], Loss: 1.1432, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [15/50], Step [23/469], Loss: 1.0461, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [15/50], Step [24/469], Loss: 0.9553, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [25/469], Loss: 0.9366, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [26/469], Loss: 1.2611, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [15/50], Step [27/469], Loss: 0.8500, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [15/50], Step [28/469], Loss: 1.1431, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [15/50], Step [29/469], Loss: 0.9882, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [30/469], Loss: 1.1273, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [15/50], Step [31/469], Loss: 1.0119, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [32/469], Loss: 1.0952, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [33/469], Loss: 1.3428, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [15/50], Step [34/469], Loss: 1.0235, batch time: 0.46, accuracy:  67.19%\n",
      "Epoch [15/50], Step [35/469], Loss: 1.0635, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [15/50], Step [36/469], Loss: 0.9998, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [37/469], Loss: 0.9759, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [38/469], Loss: 1.0324, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [39/469], Loss: 0.9663, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [15/50], Step [40/469], Loss: 0.9788, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [15/50], Step [41/469], Loss: 1.1579, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [42/469], Loss: 0.8863, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [43/469], Loss: 0.9569, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [44/469], Loss: 1.0711, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [15/50], Step [45/469], Loss: 0.8268, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [15/50], Step [46/469], Loss: 0.9319, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [47/469], Loss: 0.9872, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [48/469], Loss: 1.1788, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [15/50], Step [49/469], Loss: 0.9976, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [50/469], Loss: 0.8966, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [51/469], Loss: 0.9975, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [52/469], Loss: 0.8711, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [15/50], Step [53/469], Loss: 0.9916, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [54/469], Loss: 0.9296, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [55/469], Loss: 1.0561, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [56/469], Loss: 1.0711, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [57/469], Loss: 1.0749, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [58/469], Loss: 0.8976, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [15/50], Step [59/469], Loss: 0.8607, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [15/50], Step [60/469], Loss: 0.9598, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [61/469], Loss: 0.9909, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [62/469], Loss: 0.8817, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [63/469], Loss: 1.0428, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [64/469], Loss: 0.9366, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [65/469], Loss: 1.0628, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [66/469], Loss: 1.0713, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [15/50], Step [67/469], Loss: 0.9626, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [68/469], Loss: 0.9281, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [15/50], Step [69/469], Loss: 1.1711, batch time: 0.42, accuracy:  63.28%\n",
      "Epoch [15/50], Step [70/469], Loss: 1.0751, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [71/469], Loss: 1.1987, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [15/50], Step [72/469], Loss: 1.0763, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [15/50], Step [73/469], Loss: 0.9517, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [74/469], Loss: 0.9208, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [75/469], Loss: 0.9357, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [76/469], Loss: 0.9918, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [77/469], Loss: 1.0812, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [78/469], Loss: 1.0105, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [15/50], Step [79/469], Loss: 0.8004, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [80/469], Loss: 1.0555, batch time: 0.42, accuracy:  60.16%\n",
      "Epoch [15/50], Step [81/469], Loss: 0.8829, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [15/50], Step [82/469], Loss: 0.9793, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [83/469], Loss: 0.9142, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [84/469], Loss: 0.8763, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [85/469], Loss: 0.8961, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [15/50], Step [86/469], Loss: 1.0391, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [15/50], Step [87/469], Loss: 1.1067, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [88/469], Loss: 0.7328, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [15/50], Step [89/469], Loss: 1.1582, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [90/469], Loss: 0.9920, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [15/50], Step [91/469], Loss: 1.0826, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [92/469], Loss: 1.1845, batch time: 0.48, accuracy:  64.06%\n",
      "Epoch [15/50], Step [93/469], Loss: 1.1119, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [15/50], Step [94/469], Loss: 0.9644, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [95/469], Loss: 1.0171, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [96/469], Loss: 1.0730, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [15/50], Step [97/469], Loss: 1.0542, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [98/469], Loss: 0.9278, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [99/469], Loss: 0.9857, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [100/469], Loss: 0.8828, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [15/50], Step [101/469], Loss: 0.9362, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [102/469], Loss: 1.0849, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [103/469], Loss: 0.8425, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [104/469], Loss: 1.1133, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [105/469], Loss: 0.8584, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [106/469], Loss: 0.8839, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [107/469], Loss: 1.0365, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [108/469], Loss: 0.8044, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [15/50], Step [109/469], Loss: 0.9879, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [110/469], Loss: 1.0007, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [15/50], Step [111/469], Loss: 0.8893, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [15/50], Step [112/469], Loss: 0.8926, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [113/469], Loss: 0.9065, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [15/50], Step [114/469], Loss: 0.9060, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [115/469], Loss: 1.0545, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [15/50], Step [116/469], Loss: 1.1755, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [117/469], Loss: 1.0689, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [15/50], Step [118/469], Loss: 0.9884, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [119/469], Loss: 1.1239, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [15/50], Step [120/469], Loss: 0.8867, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [121/469], Loss: 0.9721, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [122/469], Loss: 0.9464, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [15/50], Step [123/469], Loss: 0.9846, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [15/50], Step [124/469], Loss: 0.9610, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [125/469], Loss: 0.8129, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [126/469], Loss: 0.9308, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [127/469], Loss: 1.1097, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [15/50], Step [128/469], Loss: 1.0012, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [129/469], Loss: 1.0840, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [15/50], Step [130/469], Loss: 1.0532, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [131/469], Loss: 1.0625, batch time: 0.40, accuracy:  64.06%\n",
      "Epoch [15/50], Step [132/469], Loss: 1.0498, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [15/50], Step [133/469], Loss: 0.8849, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [134/469], Loss: 1.1237, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [15/50], Step [135/469], Loss: 0.9406, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [136/469], Loss: 0.7571, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [15/50], Step [137/469], Loss: 1.0063, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [15/50], Step [138/469], Loss: 1.0796, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [15/50], Step [139/469], Loss: 1.1035, batch time: 0.47, accuracy:  68.75%\n",
      "Epoch [15/50], Step [140/469], Loss: 0.7917, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [15/50], Step [141/469], Loss: 0.8719, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [142/469], Loss: 0.7707, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [143/469], Loss: 0.8784, batch time: 0.40, accuracy:  66.41%\n",
      "Epoch [15/50], Step [144/469], Loss: 1.0089, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [15/50], Step [145/469], Loss: 1.1363, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [146/469], Loss: 1.1176, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [147/469], Loss: 0.7896, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [15/50], Step [148/469], Loss: 0.8822, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [149/469], Loss: 1.2624, batch time: 0.41, accuracy:  58.59%\n",
      "Epoch [15/50], Step [150/469], Loss: 1.1997, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [15/50], Step [151/469], Loss: 1.1252, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [15/50], Step [152/469], Loss: 0.8042, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [153/469], Loss: 0.8252, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [15/50], Step [154/469], Loss: 0.9652, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [155/469], Loss: 1.0404, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [156/469], Loss: 1.0600, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [157/469], Loss: 0.8361, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [158/469], Loss: 0.9133, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [159/469], Loss: 0.8316, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [160/469], Loss: 1.0299, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [161/469], Loss: 0.9422, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [162/469], Loss: 0.9187, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [163/469], Loss: 0.8349, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [164/469], Loss: 1.0426, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [165/469], Loss: 1.0745, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [166/469], Loss: 0.9613, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [167/469], Loss: 0.8461, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [168/469], Loss: 1.1081, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [169/469], Loss: 0.9356, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [15/50], Step [170/469], Loss: 0.9260, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [171/469], Loss: 1.0967, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [172/469], Loss: 0.9057, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [15/50], Step [173/469], Loss: 1.0972, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [15/50], Step [174/469], Loss: 0.9198, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [175/469], Loss: 0.8871, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [176/469], Loss: 0.9472, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [15/50], Step [177/469], Loss: 1.0368, batch time: 0.40, accuracy:  58.59%\n",
      "Epoch [15/50], Step [178/469], Loss: 1.0109, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [179/469], Loss: 0.8189, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [180/469], Loss: 0.9008, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [181/469], Loss: 1.0099, batch time: 0.41, accuracy:  63.28%\n",
      "Epoch [15/50], Step [182/469], Loss: 0.9842, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [15/50], Step [183/469], Loss: 0.9671, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [15/50], Step [184/469], Loss: 0.9764, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [15/50], Step [185/469], Loss: 0.9423, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [186/469], Loss: 0.9759, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [15/50], Step [187/469], Loss: 0.8874, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [188/469], Loss: 1.0903, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [15/50], Step [189/469], Loss: 0.8945, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [190/469], Loss: 0.8516, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [191/469], Loss: 1.0359, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [192/469], Loss: 1.0683, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [193/469], Loss: 0.9743, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [194/469], Loss: 0.8894, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [195/469], Loss: 0.8051, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [15/50], Step [196/469], Loss: 0.8385, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [197/469], Loss: 1.0093, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [198/469], Loss: 0.7820, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [199/469], Loss: 1.0422, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [200/469], Loss: 0.8692, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [15/50], Step [201/469], Loss: 0.9019, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [202/469], Loss: 1.1430, batch time: 0.41, accuracy:  60.94%\n",
      "Epoch [15/50], Step [203/469], Loss: 0.8699, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [204/469], Loss: 0.9583, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [15/50], Step [205/469], Loss: 1.1109, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [15/50], Step [206/469], Loss: 0.8216, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [207/469], Loss: 0.8541, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [208/469], Loss: 0.7335, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [15/50], Step [209/469], Loss: 0.9572, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [15/50], Step [210/469], Loss: 0.9478, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [15/50], Step [211/469], Loss: 0.9053, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [212/469], Loss: 0.9376, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [15/50], Step [213/469], Loss: 0.8781, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [214/469], Loss: 0.9171, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [215/469], Loss: 0.8133, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [216/469], Loss: 0.9177, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [217/469], Loss: 0.7770, batch time: 0.48, accuracy:  73.44%\n",
      "Epoch [15/50], Step [218/469], Loss: 0.9539, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [219/469], Loss: 1.0058, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [15/50], Step [220/469], Loss: 1.0979, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [15/50], Step [221/469], Loss: 0.8587, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [222/469], Loss: 1.0441, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [223/469], Loss: 0.9226, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [224/469], Loss: 0.9228, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [225/469], Loss: 0.8674, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [226/469], Loss: 1.1931, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [15/50], Step [227/469], Loss: 0.8205, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [15/50], Step [228/469], Loss: 0.7241, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [15/50], Step [229/469], Loss: 1.0070, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [15/50], Step [230/469], Loss: 0.8761, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [231/469], Loss: 0.8706, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [15/50], Step [232/469], Loss: 0.7912, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [233/469], Loss: 0.8009, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [15/50], Step [234/469], Loss: 0.8585, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [235/469], Loss: 0.9836, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [236/469], Loss: 0.8550, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [237/469], Loss: 0.9262, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [238/469], Loss: 0.8772, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [239/469], Loss: 0.9028, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [240/469], Loss: 0.7933, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [15/50], Step [241/469], Loss: 0.8107, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [242/469], Loss: 1.0305, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [243/469], Loss: 0.8139, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [15/50], Step [244/469], Loss: 0.8529, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [245/469], Loss: 0.7767, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [246/469], Loss: 1.0812, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [247/469], Loss: 0.9651, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [15/50], Step [248/469], Loss: 0.9192, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [249/469], Loss: 0.8129, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [250/469], Loss: 1.0736, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [251/469], Loss: 0.8459, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [252/469], Loss: 0.7636, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [15/50], Step [253/469], Loss: 0.9059, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [254/469], Loss: 0.8260, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [255/469], Loss: 0.8243, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [256/469], Loss: 1.0623, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [257/469], Loss: 0.7946, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [258/469], Loss: 0.8914, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [259/469], Loss: 0.8362, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [15/50], Step [260/469], Loss: 0.9462, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [261/469], Loss: 0.8170, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [15/50], Step [262/469], Loss: 1.1198, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [15/50], Step [263/469], Loss: 0.8265, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [264/469], Loss: 1.0295, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [265/469], Loss: 0.8022, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [266/469], Loss: 0.9816, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [267/469], Loss: 0.8559, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [268/469], Loss: 0.8813, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [15/50], Step [269/469], Loss: 0.7969, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [15/50], Step [270/469], Loss: 1.0365, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [15/50], Step [271/469], Loss: 0.9456, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [15/50], Step [272/469], Loss: 1.2526, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [273/469], Loss: 0.8063, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [15/50], Step [274/469], Loss: 0.9926, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [275/469], Loss: 1.1568, batch time: 0.47, accuracy:  64.84%\n",
      "Epoch [15/50], Step [276/469], Loss: 1.0460, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [277/469], Loss: 0.8766, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [278/469], Loss: 0.8208, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [15/50], Step [279/469], Loss: 0.9806, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [15/50], Step [280/469], Loss: 1.0874, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [281/469], Loss: 0.7529, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [15/50], Step [282/469], Loss: 0.8406, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [283/469], Loss: 1.0742, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [284/469], Loss: 0.7762, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [15/50], Step [285/469], Loss: 1.0919, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [286/469], Loss: 0.7719, batch time: 0.42, accuracy:  79.69%\n",
      "Epoch [15/50], Step [287/469], Loss: 1.2271, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [288/469], Loss: 0.8204, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [289/469], Loss: 1.0467, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [290/469], Loss: 1.0315, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [291/469], Loss: 1.0805, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [15/50], Step [292/469], Loss: 0.8289, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [15/50], Step [293/469], Loss: 1.0111, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [294/469], Loss: 0.7544, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [15/50], Step [295/469], Loss: 0.8023, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [15/50], Step [296/469], Loss: 0.7970, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [297/469], Loss: 0.7927, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [15/50], Step [298/469], Loss: 1.0189, batch time: 0.41, accuracy:  64.84%\n",
      "Epoch [15/50], Step [299/469], Loss: 0.9627, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [15/50], Step [300/469], Loss: 0.8313, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [15/50], Step [301/469], Loss: 0.9580, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [302/469], Loss: 0.8481, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [15/50], Step [303/469], Loss: 0.9480, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [304/469], Loss: 0.9914, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [15/50], Step [305/469], Loss: 1.1115, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [306/469], Loss: 1.0271, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [307/469], Loss: 1.1780, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [15/50], Step [308/469], Loss: 0.9490, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [309/469], Loss: 0.7755, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [15/50], Step [310/469], Loss: 0.8178, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [15/50], Step [311/469], Loss: 1.0232, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [312/469], Loss: 0.8896, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [313/469], Loss: 1.0162, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [15/50], Step [314/469], Loss: 0.8491, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [315/469], Loss: 1.1628, batch time: 0.43, accuracy:  67.97%\n",
      "Epoch [15/50], Step [316/469], Loss: 0.8701, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [317/469], Loss: 0.8976, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [318/469], Loss: 0.8799, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [319/469], Loss: 0.9029, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [320/469], Loss: 0.9315, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [321/469], Loss: 0.7666, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [322/469], Loss: 0.9987, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [323/469], Loss: 0.8113, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [324/469], Loss: 0.9916, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [325/469], Loss: 0.8751, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [15/50], Step [326/469], Loss: 0.9198, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [327/469], Loss: 0.8181, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [328/469], Loss: 1.2526, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [329/469], Loss: 0.8610, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [15/50], Step [330/469], Loss: 0.9573, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [15/50], Step [331/469], Loss: 0.8594, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [15/50], Step [332/469], Loss: 0.9488, batch time: 0.43, accuracy:  64.84%\n",
      "Epoch [15/50], Step [333/469], Loss: 0.8106, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [334/469], Loss: 0.8226, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [15/50], Step [335/469], Loss: 0.8844, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [15/50], Step [336/469], Loss: 0.9633, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [337/469], Loss: 0.8206, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [338/469], Loss: 0.8799, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [15/50], Step [339/469], Loss: 0.8776, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [340/469], Loss: 0.9072, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [15/50], Step [341/469], Loss: 0.8109, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [342/469], Loss: 0.9185, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [343/469], Loss: 0.9464, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [344/469], Loss: 0.9002, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [15/50], Step [345/469], Loss: 0.9731, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [346/469], Loss: 0.9216, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [347/469], Loss: 0.7727, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [15/50], Step [348/469], Loss: 0.7883, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [349/469], Loss: 1.0923, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [350/469], Loss: 0.8369, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [351/469], Loss: 1.0909, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [352/469], Loss: 1.1120, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [15/50], Step [353/469], Loss: 0.8487, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [354/469], Loss: 0.8365, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [355/469], Loss: 0.8601, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [356/469], Loss: 0.7742, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [357/469], Loss: 0.9316, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [358/469], Loss: 0.9094, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [359/469], Loss: 0.8627, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [360/469], Loss: 0.8366, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [15/50], Step [361/469], Loss: 0.9110, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [362/469], Loss: 0.7470, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [15/50], Step [363/469], Loss: 0.9852, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [15/50], Step [364/469], Loss: 0.9140, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [365/469], Loss: 0.9330, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [366/469], Loss: 1.1527, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [367/469], Loss: 0.9608, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [15/50], Step [368/469], Loss: 0.8713, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [15/50], Step [369/469], Loss: 0.9488, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [370/469], Loss: 0.7972, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [15/50], Step [371/469], Loss: 0.7410, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [15/50], Step [372/469], Loss: 0.8198, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [373/469], Loss: 0.8769, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [374/469], Loss: 1.0907, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [375/469], Loss: 0.6747, batch time: 0.42, accuracy:  79.69%\n",
      "Epoch [15/50], Step [376/469], Loss: 0.8729, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [15/50], Step [377/469], Loss: 0.8960, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [378/469], Loss: 0.8852, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [379/469], Loss: 1.0658, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [15/50], Step [380/469], Loss: 0.8644, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [15/50], Step [381/469], Loss: 0.7985, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [382/469], Loss: 0.8650, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [383/469], Loss: 0.8416, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [384/469], Loss: 0.8031, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [15/50], Step [385/469], Loss: 1.0215, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [386/469], Loss: 0.7141, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [15/50], Step [387/469], Loss: 0.8825, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [15/50], Step [388/469], Loss: 0.9566, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [389/469], Loss: 0.8964, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [15/50], Step [390/469], Loss: 1.1210, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [391/469], Loss: 0.7957, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [15/50], Step [392/469], Loss: 0.7502, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [393/469], Loss: 0.9120, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [15/50], Step [394/469], Loss: 0.8260, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [395/469], Loss: 0.7837, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [396/469], Loss: 0.8143, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [15/50], Step [397/469], Loss: 1.0125, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [398/469], Loss: 0.7410, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [15/50], Step [399/469], Loss: 0.9864, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [15/50], Step [400/469], Loss: 0.9216, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [401/469], Loss: 1.1354, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [15/50], Step [402/469], Loss: 0.9045, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [15/50], Step [403/469], Loss: 0.7903, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [15/50], Step [404/469], Loss: 0.7938, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [405/469], Loss: 0.7656, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [15/50], Step [406/469], Loss: 0.9201, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [407/469], Loss: 0.9769, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [408/469], Loss: 0.7292, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [15/50], Step [409/469], Loss: 0.9306, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [410/469], Loss: 0.9609, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [15/50], Step [411/469], Loss: 0.7463, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [15/50], Step [412/469], Loss: 0.9075, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [413/469], Loss: 0.7386, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [15/50], Step [414/469], Loss: 0.7443, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [15/50], Step [415/469], Loss: 0.8557, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [15/50], Step [416/469], Loss: 0.9259, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [15/50], Step [417/469], Loss: 0.9153, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [418/469], Loss: 0.8169, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [15/50], Step [419/469], Loss: 0.9650, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [15/50], Step [420/469], Loss: 0.8126, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [421/469], Loss: 0.8789, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [422/469], Loss: 0.9131, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [423/469], Loss: 0.7982, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [15/50], Step [424/469], Loss: 0.7928, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [15/50], Step [425/469], Loss: 0.9111, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [15/50], Step [426/469], Loss: 1.1228, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [427/469], Loss: 0.8087, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [428/469], Loss: 0.9052, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [429/469], Loss: 0.8032, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [15/50], Step [430/469], Loss: 0.9179, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [15/50], Step [431/469], Loss: 0.8542, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [15/50], Step [432/469], Loss: 1.1317, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [15/50], Step [433/469], Loss: 1.0451, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [434/469], Loss: 0.8382, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [15/50], Step [435/469], Loss: 0.7299, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [15/50], Step [436/469], Loss: 0.9523, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [15/50], Step [437/469], Loss: 0.9134, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [15/50], Step [438/469], Loss: 1.0230, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [439/469], Loss: 0.9575, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [15/50], Step [440/469], Loss: 0.8339, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [15/50], Step [441/469], Loss: 0.7169, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [15/50], Step [442/469], Loss: 1.0777, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [15/50], Step [443/469], Loss: 0.9527, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [15/50], Step [444/469], Loss: 0.8949, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [15/50], Step [445/469], Loss: 1.0048, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [15/50], Step [446/469], Loss: 0.9886, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [447/469], Loss: 1.0149, batch time: 0.41, accuracy:  64.06%\n",
      "Epoch [15/50], Step [448/469], Loss: 0.8017, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [15/50], Step [449/469], Loss: 1.0983, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [15/50], Step [450/469], Loss: 0.9250, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [15/50], Step [451/469], Loss: 0.8344, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [15/50], Step [452/469], Loss: 0.8480, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [15/50], Step [453/469], Loss: 0.9821, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [15/50], Step [454/469], Loss: 0.9259, batch time: 0.47, accuracy:  71.09%\n",
      "Epoch [15/50], Step [455/469], Loss: 0.8373, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [15/50], Step [456/469], Loss: 0.8760, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [15/50], Step [457/469], Loss: 0.9337, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [15/50], Step [458/469], Loss: 1.0138, batch time: 0.40, accuracy:  64.84%\n",
      "Epoch [15/50], Step [459/469], Loss: 0.8392, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [15/50], Step [460/469], Loss: 0.7348, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [15/50], Step [461/469], Loss: 0.9195, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [15/50], Step [462/469], Loss: 0.7831, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [463/469], Loss: 0.7925, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [15/50], Step [464/469], Loss: 0.9821, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [15/50], Step [465/469], Loss: 0.9250, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [15/50], Step [466/469], Loss: 1.0650, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [15/50], Step [467/469], Loss: 0.7915, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [15/50], Step [468/469], Loss: 0.8502, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [15/50], Step [469/469], Loss: 1.0727, batch time: 0.44, accuracy:  70.83%\n",
      "Epoch [16/50], Step [1/469], Loss: 0.9068, batch time: 0.43, accuracy:  72.66%\n",
      "Epoch [16/50], Step [2/469], Loss: 0.9161, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [16/50], Step [3/469], Loss: 0.9060, batch time: 0.40, accuracy:  67.97%\n",
      "Epoch [16/50], Step [4/469], Loss: 0.9039, batch time: 0.48, accuracy:  67.19%\n",
      "Epoch [16/50], Step [5/469], Loss: 0.7385, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [16/50], Step [6/469], Loss: 0.7963, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [16/50], Step [7/469], Loss: 1.0891, batch time: 0.44, accuracy:  64.84%\n",
      "Epoch [16/50], Step [8/469], Loss: 0.9519, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [16/50], Step [9/469], Loss: 0.9452, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [16/50], Step [10/469], Loss: 0.8010, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [11/469], Loss: 0.7604, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [16/50], Step [12/469], Loss: 0.8460, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [16/50], Step [13/469], Loss: 0.7490, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [14/469], Loss: 0.9538, batch time: 0.43, accuracy:  70.31%\n",
      "Epoch [16/50], Step [15/469], Loss: 0.8698, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [16/469], Loss: 0.8479, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [16/50], Step [17/469], Loss: 1.0311, batch time: 0.44, accuracy:  73.44%\n",
      "Epoch [16/50], Step [18/469], Loss: 0.9582, batch time: 0.43, accuracy:  71.09%\n",
      "Epoch [16/50], Step [19/469], Loss: 0.8615, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [20/469], Loss: 0.8392, batch time: 0.48, accuracy:  73.44%\n",
      "Epoch [16/50], Step [21/469], Loss: 0.7495, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [16/50], Step [22/469], Loss: 0.9670, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [16/50], Step [23/469], Loss: 0.7554, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [24/469], Loss: 0.8148, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [16/50], Step [25/469], Loss: 0.6904, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [26/469], Loss: 0.8568, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [27/469], Loss: 0.9958, batch time: 0.43, accuracy:  71.09%\n",
      "Epoch [16/50], Step [28/469], Loss: 0.9435, batch time: 0.43, accuracy:  71.09%\n",
      "Epoch [16/50], Step [29/469], Loss: 0.9830, batch time: 0.43, accuracy:  71.88%\n",
      "Epoch [16/50], Step [30/469], Loss: 0.9049, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [16/50], Step [31/469], Loss: 0.7906, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [32/469], Loss: 0.8599, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [16/50], Step [33/469], Loss: 1.0244, batch time: 0.40, accuracy:  67.19%\n",
      "Epoch [16/50], Step [34/469], Loss: 0.9181, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [35/469], Loss: 0.8313, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [16/50], Step [36/469], Loss: 0.6473, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [16/50], Step [37/469], Loss: 0.6734, batch time: 0.40, accuracy:  81.25%\n",
      "Epoch [16/50], Step [38/469], Loss: 0.9474, batch time: 0.49, accuracy:  77.34%\n",
      "Epoch [16/50], Step [39/469], Loss: 0.6433, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [16/50], Step [40/469], Loss: 0.7605, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [41/469], Loss: 1.0623, batch time: 0.43, accuracy:  69.53%\n",
      "Epoch [16/50], Step [42/469], Loss: 0.7424, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [16/50], Step [43/469], Loss: 0.8157, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [44/469], Loss: 0.9060, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [16/50], Step [45/469], Loss: 0.8576, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [16/50], Step [46/469], Loss: 0.9068, batch time: 0.43, accuracy:  74.22%\n",
      "Epoch [16/50], Step [47/469], Loss: 1.0361, batch time: 0.45, accuracy:  71.88%\n",
      "Epoch [16/50], Step [48/469], Loss: 0.7099, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [16/50], Step [49/469], Loss: 0.8335, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [16/50], Step [50/469], Loss: 0.7893, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [16/50], Step [51/469], Loss: 0.9005, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [52/469], Loss: 1.0111, batch time: 0.43, accuracy:  68.75%\n",
      "Epoch [16/50], Step [53/469], Loss: 0.7074, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [16/50], Step [54/469], Loss: 0.8689, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [55/469], Loss: 0.8197, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [16/50], Step [56/469], Loss: 0.9387, batch time: 0.48, accuracy:  73.44%\n",
      "Epoch [16/50], Step [57/469], Loss: 0.8486, batch time: 0.50, accuracy:  72.66%\n",
      "Epoch [16/50], Step [58/469], Loss: 0.8024, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [16/50], Step [59/469], Loss: 0.8560, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [16/50], Step [60/469], Loss: 1.0756, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [61/469], Loss: 0.8227, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [16/50], Step [62/469], Loss: 0.9945, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [16/50], Step [63/469], Loss: 0.6947, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [16/50], Step [64/469], Loss: 0.7928, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [16/50], Step [65/469], Loss: 0.7729, batch time: 0.44, accuracy:  72.66%\n",
      "Epoch [16/50], Step [66/469], Loss: 1.0104, batch time: 0.45, accuracy:  70.31%\n",
      "Epoch [16/50], Step [67/469], Loss: 0.7237, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [16/50], Step [68/469], Loss: 0.7282, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [16/50], Step [69/469], Loss: 0.8186, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [70/469], Loss: 0.6850, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [71/469], Loss: 0.6315, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [16/50], Step [72/469], Loss: 0.7608, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [73/469], Loss: 0.7144, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [74/469], Loss: 0.6669, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [75/469], Loss: 0.8337, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [16/50], Step [76/469], Loss: 0.8344, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [77/469], Loss: 0.6749, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [78/469], Loss: 0.8564, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [16/50], Step [79/469], Loss: 0.7965, batch time: 0.47, accuracy:  69.53%\n",
      "Epoch [16/50], Step [80/469], Loss: 1.0126, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [81/469], Loss: 0.7855, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [16/50], Step [82/469], Loss: 0.6746, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [16/50], Step [83/469], Loss: 0.8885, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [16/50], Step [84/469], Loss: 1.1189, batch time: 0.41, accuracy:  61.72%\n",
      "Epoch [16/50], Step [85/469], Loss: 0.7144, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [16/50], Step [86/469], Loss: 0.9143, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [16/50], Step [87/469], Loss: 1.0282, batch time: 0.54, accuracy:  70.31%\n",
      "Epoch [16/50], Step [88/469], Loss: 0.8246, batch time: 0.51, accuracy:  75.00%\n",
      "Epoch [16/50], Step [89/469], Loss: 0.6682, batch time: 0.59, accuracy:  81.25%\n",
      "Epoch [16/50], Step [90/469], Loss: 0.5775, batch time: 0.41, accuracy:  82.81%\n",
      "Epoch [16/50], Step [91/469], Loss: 0.7054, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [92/469], Loss: 0.8386, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [16/50], Step [93/469], Loss: 0.7978, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [16/50], Step [94/469], Loss: 0.6646, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [16/50], Step [95/469], Loss: 1.0097, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [96/469], Loss: 0.9148, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [16/50], Step [97/469], Loss: 1.0427, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [98/469], Loss: 0.9265, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [16/50], Step [99/469], Loss: 0.7587, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [100/469], Loss: 0.8385, batch time: 0.42, accuracy:  80.47%\n",
      "Epoch [16/50], Step [101/469], Loss: 0.9254, batch time: 0.45, accuracy:  71.09%\n",
      "Epoch [16/50], Step [102/469], Loss: 0.8130, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [16/50], Step [103/469], Loss: 0.8307, batch time: 0.45, accuracy:  74.22%\n",
      "Epoch [16/50], Step [104/469], Loss: 0.8635, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [105/469], Loss: 0.9086, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [16/50], Step [106/469], Loss: 0.8990, batch time: 0.48, accuracy:  75.78%\n",
      "Epoch [16/50], Step [107/469], Loss: 0.7207, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [108/469], Loss: 0.9464, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [16/50], Step [109/469], Loss: 0.7669, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [16/50], Step [110/469], Loss: 0.9103, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [16/50], Step [111/469], Loss: 0.8419, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [112/469], Loss: 1.0588, batch time: 0.42, accuracy:  65.62%\n",
      "Epoch [16/50], Step [113/469], Loss: 0.8299, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [114/469], Loss: 0.7209, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [16/50], Step [115/469], Loss: 0.6593, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [116/469], Loss: 0.6648, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [16/50], Step [117/469], Loss: 1.0521, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [118/469], Loss: 0.8528, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [119/469], Loss: 0.8158, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [120/469], Loss: 0.8564, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [121/469], Loss: 0.8090, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [122/469], Loss: 0.7632, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [123/469], Loss: 0.9105, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [124/469], Loss: 0.8196, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [125/469], Loss: 0.8503, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [16/50], Step [126/469], Loss: 0.7715, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [16/50], Step [127/469], Loss: 0.8596, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [16/50], Step [128/469], Loss: 0.7869, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [129/469], Loss: 0.8521, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [130/469], Loss: 1.1363, batch time: 0.43, accuracy:  69.53%\n",
      "Epoch [16/50], Step [131/469], Loss: 0.8840, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [132/469], Loss: 0.8574, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [16/50], Step [133/469], Loss: 0.9515, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [134/469], Loss: 0.8123, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [135/469], Loss: 0.7771, batch time: 0.42, accuracy:  80.47%\n",
      "Epoch [16/50], Step [136/469], Loss: 0.7998, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [137/469], Loss: 0.8601, batch time: 0.43, accuracy:  72.66%\n",
      "Epoch [16/50], Step [138/469], Loss: 1.2937, batch time: 0.40, accuracy:  62.50%\n",
      "Epoch [16/50], Step [139/469], Loss: 0.7494, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [16/50], Step [140/469], Loss: 0.8895, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [16/50], Step [141/469], Loss: 0.7211, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [16/50], Step [142/469], Loss: 0.7261, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [143/469], Loss: 0.6296, batch time: 0.40, accuracy:  81.25%\n",
      "Epoch [16/50], Step [144/469], Loss: 1.0841, batch time: 0.46, accuracy:  74.22%\n",
      "Epoch [16/50], Step [145/469], Loss: 0.9566, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [16/50], Step [146/469], Loss: 0.6898, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [16/50], Step [147/469], Loss: 0.8238, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [16/50], Step [148/469], Loss: 0.7496, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [149/469], Loss: 0.8874, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [150/469], Loss: 0.7447, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [151/469], Loss: 0.8782, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [152/469], Loss: 0.7795, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [16/50], Step [153/469], Loss: 0.7286, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [154/469], Loss: 0.7432, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [16/50], Step [155/469], Loss: 0.8125, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [16/50], Step [156/469], Loss: 0.7236, batch time: 0.42, accuracy:  82.03%\n",
      "Epoch [16/50], Step [157/469], Loss: 1.0034, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [16/50], Step [158/469], Loss: 1.0132, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [16/50], Step [159/469], Loss: 0.9361, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [160/469], Loss: 0.8420, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [161/469], Loss: 0.6701, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [162/469], Loss: 0.6991, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [16/50], Step [163/469], Loss: 0.8472, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [16/50], Step [164/469], Loss: 0.8496, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [16/50], Step [165/469], Loss: 0.9265, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [166/469], Loss: 0.8270, batch time: 0.45, accuracy:  72.66%\n",
      "Epoch [16/50], Step [167/469], Loss: 0.7198, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [16/50], Step [168/469], Loss: 0.8357, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [169/469], Loss: 0.9762, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [170/469], Loss: 0.9095, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [16/50], Step [171/469], Loss: 0.7800, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [16/50], Step [172/469], Loss: 0.8531, batch time: 0.43, accuracy:  72.66%\n",
      "Epoch [16/50], Step [173/469], Loss: 0.8883, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [174/469], Loss: 0.6812, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [16/50], Step [175/469], Loss: 0.6397, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [176/469], Loss: 0.8282, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [177/469], Loss: 0.7901, batch time: 0.46, accuracy:  72.66%\n",
      "Epoch [16/50], Step [178/469], Loss: 0.8964, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [179/469], Loss: 0.8071, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [16/50], Step [180/469], Loss: 0.9900, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [16/50], Step [181/469], Loss: 1.0012, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [16/50], Step [182/469], Loss: 0.9610, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [183/469], Loss: 0.7267, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [16/50], Step [184/469], Loss: 0.9120, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [16/50], Step [185/469], Loss: 0.7091, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [186/469], Loss: 0.6180, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [16/50], Step [187/469], Loss: 0.7355, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [188/469], Loss: 0.8006, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [189/469], Loss: 0.7558, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [190/469], Loss: 0.7040, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [191/469], Loss: 0.8409, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [192/469], Loss: 0.8148, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [193/469], Loss: 0.7368, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [194/469], Loss: 0.7166, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [195/469], Loss: 0.7819, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [196/469], Loss: 0.8307, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [197/469], Loss: 0.6600, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [16/50], Step [198/469], Loss: 0.7948, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [16/50], Step [199/469], Loss: 0.8235, batch time: 0.43, accuracy:  71.88%\n",
      "Epoch [16/50], Step [200/469], Loss: 0.8977, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [201/469], Loss: 0.9331, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [16/50], Step [202/469], Loss: 0.8262, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [203/469], Loss: 0.7461, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [16/50], Step [204/469], Loss: 0.7823, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [205/469], Loss: 0.8837, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [206/469], Loss: 0.6874, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [16/50], Step [207/469], Loss: 0.8139, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [208/469], Loss: 0.8307, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [209/469], Loss: 0.8239, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [16/50], Step [210/469], Loss: 0.7519, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [211/469], Loss: 0.8169, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [212/469], Loss: 0.9410, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [16/50], Step [213/469], Loss: 0.7978, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [16/50], Step [214/469], Loss: 0.9174, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [215/469], Loss: 1.0259, batch time: 0.41, accuracy:  67.19%\n",
      "Epoch [16/50], Step [216/469], Loss: 0.8729, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [217/469], Loss: 0.7877, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [218/469], Loss: 0.7380, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [16/50], Step [219/469], Loss: 0.8408, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [16/50], Step [220/469], Loss: 0.6471, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [221/469], Loss: 0.7573, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [16/50], Step [222/469], Loss: 0.8382, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [223/469], Loss: 1.0230, batch time: 0.41, accuracy:  66.41%\n",
      "Epoch [16/50], Step [224/469], Loss: 0.9301, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [225/469], Loss: 0.8248, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [226/469], Loss: 0.7507, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [227/469], Loss: 0.7283, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [228/469], Loss: 0.7169, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [229/469], Loss: 0.9097, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [230/469], Loss: 0.8030, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [231/469], Loss: 0.7323, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [16/50], Step [232/469], Loss: 0.7851, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [233/469], Loss: 0.6677, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [234/469], Loss: 0.8557, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [16/50], Step [235/469], Loss: 0.8184, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [236/469], Loss: 0.6363, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [237/469], Loss: 0.8324, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [16/50], Step [238/469], Loss: 0.6543, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [239/469], Loss: 0.6679, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [240/469], Loss: 1.0739, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [241/469], Loss: 0.9349, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [16/50], Step [242/469], Loss: 0.8259, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [243/469], Loss: 0.7541, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [244/469], Loss: 0.8283, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [245/469], Loss: 0.7842, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [246/469], Loss: 0.8831, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [247/469], Loss: 1.1035, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [248/469], Loss: 1.1724, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [249/469], Loss: 0.8269, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [16/50], Step [250/469], Loss: 0.6620, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [251/469], Loss: 0.9165, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [252/469], Loss: 1.0588, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [253/469], Loss: 0.7013, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [16/50], Step [254/469], Loss: 0.7856, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [16/50], Step [255/469], Loss: 0.8368, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [256/469], Loss: 0.9951, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [16/50], Step [257/469], Loss: 0.8698, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [258/469], Loss: 0.7909, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [16/50], Step [259/469], Loss: 0.8344, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [260/469], Loss: 0.7682, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [261/469], Loss: 0.6820, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [262/469], Loss: 0.8278, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [263/469], Loss: 0.8577, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [264/469], Loss: 0.7393, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [265/469], Loss: 0.9626, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [266/469], Loss: 1.1007, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [267/469], Loss: 0.7688, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [268/469], Loss: 1.0438, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [269/469], Loss: 0.8071, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [270/469], Loss: 0.6760, batch time: 0.42, accuracy:  82.03%\n",
      "Epoch [16/50], Step [271/469], Loss: 1.0162, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [272/469], Loss: 0.6168, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [16/50], Step [273/469], Loss: 0.6896, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [274/469], Loss: 0.8192, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [275/469], Loss: 0.8589, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [276/469], Loss: 0.9607, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [16/50], Step [277/469], Loss: 1.1155, batch time: 0.42, accuracy:  64.84%\n",
      "Epoch [16/50], Step [278/469], Loss: 0.6702, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [279/469], Loss: 0.7517, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [16/50], Step [280/469], Loss: 0.7598, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [281/469], Loss: 0.8041, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [282/469], Loss: 0.9984, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [16/50], Step [283/469], Loss: 0.7867, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [284/469], Loss: 0.7908, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [285/469], Loss: 0.8050, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [286/469], Loss: 0.8764, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [287/469], Loss: 0.8245, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [288/469], Loss: 0.7091, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [289/469], Loss: 0.7638, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [16/50], Step [290/469], Loss: 0.8119, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [16/50], Step [291/469], Loss: 0.9134, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [16/50], Step [292/469], Loss: 0.8499, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [16/50], Step [293/469], Loss: 0.9349, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [16/50], Step [294/469], Loss: 0.8776, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [295/469], Loss: 0.7211, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [16/50], Step [296/469], Loss: 0.9002, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [297/469], Loss: 0.7205, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [298/469], Loss: 0.8275, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [299/469], Loss: 0.7400, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [300/469], Loss: 0.9856, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [301/469], Loss: 0.8046, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [302/469], Loss: 0.7721, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [303/469], Loss: 0.8674, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [16/50], Step [304/469], Loss: 0.9654, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [16/50], Step [305/469], Loss: 0.9180, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [306/469], Loss: 0.9236, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [307/469], Loss: 0.8354, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [308/469], Loss: 0.7526, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [309/469], Loss: 0.7061, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [310/469], Loss: 0.7587, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [311/469], Loss: 1.0523, batch time: 0.42, accuracy:  66.41%\n",
      "Epoch [16/50], Step [312/469], Loss: 0.8878, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [313/469], Loss: 0.7743, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [314/469], Loss: 0.6844, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [315/469], Loss: 0.8278, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [16/50], Step [316/469], Loss: 0.8963, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [317/469], Loss: 0.8767, batch time: 0.47, accuracy:  71.88%\n",
      "Epoch [16/50], Step [318/469], Loss: 0.8933, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [319/469], Loss: 0.7323, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [320/469], Loss: 0.8807, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [321/469], Loss: 0.8620, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [16/50], Step [322/469], Loss: 0.7157, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [323/469], Loss: 0.7604, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [324/469], Loss: 0.9708, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [325/469], Loss: 0.6703, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [16/50], Step [326/469], Loss: 0.7892, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [327/469], Loss: 0.7914, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [328/469], Loss: 0.6746, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [329/469], Loss: 0.6428, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [330/469], Loss: 0.9096, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [331/469], Loss: 0.6175, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [332/469], Loss: 0.6964, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [333/469], Loss: 0.5635, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [16/50], Step [334/469], Loss: 0.7536, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [335/469], Loss: 0.6723, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [336/469], Loss: 0.8992, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [16/50], Step [337/469], Loss: 0.5870, batch time: 0.40, accuracy:  82.03%\n",
      "Epoch [16/50], Step [338/469], Loss: 0.8766, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [16/50], Step [339/469], Loss: 0.8955, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [340/469], Loss: 0.7524, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [16/50], Step [341/469], Loss: 0.9185, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [342/469], Loss: 0.6661, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [16/50], Step [343/469], Loss: 0.9558, batch time: 0.44, accuracy:  70.31%\n",
      "Epoch [16/50], Step [344/469], Loss: 0.8676, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [345/469], Loss: 0.7587, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [16/50], Step [346/469], Loss: 0.8095, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [347/469], Loss: 0.7250, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [16/50], Step [348/469], Loss: 0.8319, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [16/50], Step [349/469], Loss: 0.8711, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [16/50], Step [350/469], Loss: 0.8379, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [16/50], Step [351/469], Loss: 0.6114, batch time: 0.40, accuracy:  82.81%\n",
      "Epoch [16/50], Step [352/469], Loss: 0.7641, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [353/469], Loss: 0.7124, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [354/469], Loss: 0.7921, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [355/469], Loss: 0.8799, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [356/469], Loss: 0.9548, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [16/50], Step [357/469], Loss: 0.7644, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [358/469], Loss: 0.9074, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [16/50], Step [359/469], Loss: 0.7075, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [16/50], Step [360/469], Loss: 0.7018, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [16/50], Step [361/469], Loss: 0.5232, batch time: 0.42, accuracy:  82.03%\n",
      "Epoch [16/50], Step [362/469], Loss: 0.7771, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [363/469], Loss: 0.6882, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [364/469], Loss: 0.6283, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [16/50], Step [365/469], Loss: 0.6485, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [366/469], Loss: 0.6973, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [367/469], Loss: 0.7114, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [368/469], Loss: 0.8949, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [16/50], Step [369/469], Loss: 0.7923, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [370/469], Loss: 0.8485, batch time: 0.40, accuracy:  68.75%\n",
      "Epoch [16/50], Step [371/469], Loss: 0.7685, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [16/50], Step [372/469], Loss: 0.6616, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [16/50], Step [373/469], Loss: 0.7539, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [374/469], Loss: 0.8202, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [16/50], Step [375/469], Loss: 0.7068, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [376/469], Loss: 0.7953, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [377/469], Loss: 0.8949, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [16/50], Step [378/469], Loss: 0.8529, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [16/50], Step [379/469], Loss: 0.9951, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [16/50], Step [380/469], Loss: 1.0688, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [16/50], Step [381/469], Loss: 1.2042, batch time: 0.41, accuracy:  62.50%\n",
      "Epoch [16/50], Step [382/469], Loss: 0.7757, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [383/469], Loss: 0.8058, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [384/469], Loss: 0.8589, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [385/469], Loss: 0.8712, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [386/469], Loss: 0.9189, batch time: 0.43, accuracy:  74.22%\n",
      "Epoch [16/50], Step [387/469], Loss: 0.7475, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [388/469], Loss: 0.7685, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [389/469], Loss: 0.9011, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [16/50], Step [390/469], Loss: 0.8506, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [391/469], Loss: 0.7602, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [392/469], Loss: 0.7054, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [16/50], Step [393/469], Loss: 0.6316, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [394/469], Loss: 0.7865, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [16/50], Step [395/469], Loss: 0.7626, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [396/469], Loss: 0.6960, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [397/469], Loss: 0.7252, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [16/50], Step [398/469], Loss: 0.8605, batch time: 0.46, accuracy:  73.44%\n",
      "Epoch [16/50], Step [399/469], Loss: 0.8778, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [400/469], Loss: 0.8537, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [401/469], Loss: 0.9276, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [16/50], Step [402/469], Loss: 0.8639, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [16/50], Step [403/469], Loss: 0.7217, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [16/50], Step [404/469], Loss: 0.7513, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [405/469], Loss: 0.8687, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [406/469], Loss: 0.8473, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [407/469], Loss: 0.8677, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [16/50], Step [408/469], Loss: 0.8533, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [409/469], Loss: 0.7805, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [410/469], Loss: 0.7268, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [16/50], Step [411/469], Loss: 0.6018, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [16/50], Step [412/469], Loss: 0.8709, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [413/469], Loss: 0.9031, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [414/469], Loss: 0.8631, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [16/50], Step [415/469], Loss: 0.8123, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [416/469], Loss: 0.9500, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [417/469], Loss: 0.7370, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [418/469], Loss: 0.8248, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [419/469], Loss: 0.8210, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [16/50], Step [420/469], Loss: 0.7504, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [421/469], Loss: 0.6975, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [422/469], Loss: 0.7335, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [423/469], Loss: 0.9577, batch time: 0.41, accuracy:  67.97%\n",
      "Epoch [16/50], Step [424/469], Loss: 1.0449, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [16/50], Step [425/469], Loss: 0.7530, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [426/469], Loss: 0.7343, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [16/50], Step [427/469], Loss: 0.7121, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [428/469], Loss: 0.7145, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [16/50], Step [429/469], Loss: 0.8951, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [430/469], Loss: 0.8848, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [431/469], Loss: 0.7450, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [16/50], Step [432/469], Loss: 0.7786, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [433/469], Loss: 0.7953, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [434/469], Loss: 0.8114, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [435/469], Loss: 0.8094, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [16/50], Step [436/469], Loss: 1.0925, batch time: 0.47, accuracy:  75.78%\n",
      "Epoch [16/50], Step [437/469], Loss: 0.8614, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [438/469], Loss: 0.8355, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [16/50], Step [439/469], Loss: 0.6657, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [440/469], Loss: 0.8359, batch time: 0.40, accuracy:  65.62%\n",
      "Epoch [16/50], Step [441/469], Loss: 0.8747, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [16/50], Step [442/469], Loss: 0.6988, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [16/50], Step [443/469], Loss: 0.8148, batch time: 0.41, accuracy:  69.53%\n",
      "Epoch [16/50], Step [444/469], Loss: 0.9191, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [16/50], Step [445/469], Loss: 0.8121, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [446/469], Loss: 0.6937, batch time: 0.42, accuracy:  82.81%\n",
      "Epoch [16/50], Step [447/469], Loss: 0.8216, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [16/50], Step [448/469], Loss: 0.6404, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [16/50], Step [449/469], Loss: 0.8519, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [16/50], Step [450/469], Loss: 0.7941, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [16/50], Step [451/469], Loss: 0.4617, batch time: 0.41, accuracy:  85.94%\n",
      "Epoch [16/50], Step [452/469], Loss: 0.7818, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [453/469], Loss: 0.5965, batch time: 0.42, accuracy:  84.38%\n",
      "Epoch [16/50], Step [454/469], Loss: 0.7379, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [16/50], Step [455/469], Loss: 0.8547, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [456/469], Loss: 0.7336, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [16/50], Step [457/469], Loss: 0.7988, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [16/50], Step [458/469], Loss: 0.8775, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [16/50], Step [459/469], Loss: 0.8312, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [460/469], Loss: 0.7556, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [16/50], Step [461/469], Loss: 0.6650, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [462/469], Loss: 0.6017, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [16/50], Step [463/469], Loss: 0.7594, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [16/50], Step [464/469], Loss: 0.7370, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [16/50], Step [465/469], Loss: 0.8993, batch time: 0.40, accuracy:  71.88%\n",
      "Epoch [16/50], Step [466/469], Loss: 0.9681, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [16/50], Step [467/469], Loss: 0.7467, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [16/50], Step [468/469], Loss: 0.9509, batch time: 0.42, accuracy:  69.53%\n",
      "Epoch [16/50], Step [469/469], Loss: 0.8044, batch time: 0.47, accuracy:  73.96%\n",
      "Epoch [17/50], Step [1/469], Loss: 1.2003, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [17/50], Step [2/469], Loss: 0.9439, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [17/50], Step [3/469], Loss: 0.6677, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [17/50], Step [4/469], Loss: 0.7628, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [17/50], Step [5/469], Loss: 0.8180, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [6/469], Loss: 1.0173, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [17/50], Step [7/469], Loss: 0.8473, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [17/50], Step [8/469], Loss: 0.8296, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [17/50], Step [9/469], Loss: 0.7124, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [17/50], Step [10/469], Loss: 0.8276, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [17/50], Step [11/469], Loss: 0.7803, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [12/469], Loss: 0.7193, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [17/50], Step [13/469], Loss: 0.8454, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [17/50], Step [14/469], Loss: 0.7433, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [15/469], Loss: 0.8846, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [17/50], Step [16/469], Loss: 0.8108, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [17/469], Loss: 0.7986, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [17/50], Step [18/469], Loss: 0.6771, batch time: 0.40, accuracy:  81.25%\n",
      "Epoch [17/50], Step [19/469], Loss: 0.6862, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [17/50], Step [20/469], Loss: 0.7801, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [17/50], Step [21/469], Loss: 0.7024, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [17/50], Step [22/469], Loss: 0.7303, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [23/469], Loss: 0.9455, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [17/50], Step [24/469], Loss: 0.7209, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [25/469], Loss: 0.7760, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [17/50], Step [26/469], Loss: 0.7010, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [17/50], Step [27/469], Loss: 0.6911, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [28/469], Loss: 0.9692, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [17/50], Step [29/469], Loss: 0.7746, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [17/50], Step [30/469], Loss: 0.6249, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [17/50], Step [31/469], Loss: 0.6928, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [32/469], Loss: 0.5443, batch time: 0.40, accuracy:  83.59%\n",
      "Epoch [17/50], Step [33/469], Loss: 0.7653, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [34/469], Loss: 0.7115, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [35/469], Loss: 0.8399, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [36/469], Loss: 1.0667, batch time: 0.42, accuracy:  67.19%\n",
      "Epoch [17/50], Step [37/469], Loss: 0.8106, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [38/469], Loss: 0.7952, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [39/469], Loss: 0.8036, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [17/50], Step [40/469], Loss: 0.8094, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [17/50], Step [41/469], Loss: 0.8985, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [17/50], Step [42/469], Loss: 0.7974, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [17/50], Step [43/469], Loss: 0.6978, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [44/469], Loss: 0.5781, batch time: 0.42, accuracy:  82.81%\n",
      "Epoch [17/50], Step [45/469], Loss: 0.9176, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [17/50], Step [46/469], Loss: 0.9327, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [47/469], Loss: 0.6918, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [17/50], Step [48/469], Loss: 0.7010, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [49/469], Loss: 0.7714, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [50/469], Loss: 0.7832, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [51/469], Loss: 0.6646, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [17/50], Step [52/469], Loss: 1.0814, batch time: 0.42, accuracy:  68.75%\n",
      "Epoch [17/50], Step [53/469], Loss: 0.5658, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [54/469], Loss: 0.6719, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [55/469], Loss: 0.7954, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [56/469], Loss: 1.0749, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [17/50], Step [57/469], Loss: 0.7678, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [58/469], Loss: 0.6612, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [59/469], Loss: 0.7806, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [60/469], Loss: 0.7750, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [61/469], Loss: 1.0360, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [62/469], Loss: 0.6002, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [17/50], Step [63/469], Loss: 0.7180, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [64/469], Loss: 0.7634, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [17/50], Step [65/469], Loss: 0.8520, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [17/50], Step [66/469], Loss: 0.6890, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [67/469], Loss: 0.7589, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [68/469], Loss: 0.7393, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [17/50], Step [69/469], Loss: 0.7525, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [70/469], Loss: 0.6793, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [71/469], Loss: 0.8171, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [72/469], Loss: 0.4955, batch time: 0.41, accuracy:  84.38%\n",
      "Epoch [17/50], Step [73/469], Loss: 0.6647, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [74/469], Loss: 0.8294, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [17/50], Step [75/469], Loss: 0.7957, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [76/469], Loss: 0.9224, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [17/50], Step [77/469], Loss: 0.7856, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [78/469], Loss: 0.7773, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [79/469], Loss: 0.9637, batch time: 0.42, accuracy:  71.88%\n",
      "Epoch [17/50], Step [80/469], Loss: 0.7438, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [81/469], Loss: 1.1327, batch time: 0.41, accuracy:  68.75%\n",
      "Epoch [17/50], Step [82/469], Loss: 0.9430, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [17/50], Step [83/469], Loss: 0.8515, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [84/469], Loss: 0.6932, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [85/469], Loss: 0.7405, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [17/50], Step [86/469], Loss: 0.6320, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [87/469], Loss: 0.6222, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [88/469], Loss: 0.6884, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [89/469], Loss: 0.7791, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [90/469], Loss: 0.8605, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [17/50], Step [91/469], Loss: 0.7201, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [17/50], Step [92/469], Loss: 0.7207, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [93/469], Loss: 0.7796, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [94/469], Loss: 0.7271, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [17/50], Step [95/469], Loss: 0.7736, batch time: 0.40, accuracy:  69.53%\n",
      "Epoch [17/50], Step [96/469], Loss: 0.7411, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [17/50], Step [97/469], Loss: 0.7416, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [17/50], Step [98/469], Loss: 0.6357, batch time: 0.42, accuracy:  79.69%\n",
      "Epoch [17/50], Step [99/469], Loss: 0.5783, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [100/469], Loss: 0.6627, batch time: 0.42, accuracy:  84.38%\n",
      "Epoch [17/50], Step [101/469], Loss: 0.7298, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [102/469], Loss: 0.7546, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [17/50], Step [103/469], Loss: 0.8293, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [104/469], Loss: 0.7100, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [105/469], Loss: 0.8101, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [106/469], Loss: 1.0270, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [107/469], Loss: 0.6399, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [108/469], Loss: 0.6670, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [17/50], Step [109/469], Loss: 0.7273, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [17/50], Step [110/469], Loss: 0.6650, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [111/469], Loss: 0.9865, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [17/50], Step [112/469], Loss: 0.7807, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [113/469], Loss: 0.8458, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [114/469], Loss: 0.7614, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [115/469], Loss: 0.7012, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [116/469], Loss: 0.7727, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [117/469], Loss: 0.6358, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [118/469], Loss: 0.6272, batch time: 0.42, accuracy:  82.03%\n",
      "Epoch [17/50], Step [119/469], Loss: 0.8710, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [120/469], Loss: 0.6853, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [121/469], Loss: 0.6909, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [122/469], Loss: 0.6371, batch time: 0.42, accuracy:  80.47%\n",
      "Epoch [17/50], Step [123/469], Loss: 0.8436, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [124/469], Loss: 0.7357, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [125/469], Loss: 0.7288, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [126/469], Loss: 0.5906, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [17/50], Step [127/469], Loss: 0.6897, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [128/469], Loss: 0.6090, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [129/469], Loss: 0.6867, batch time: 0.41, accuracy:  82.81%\n",
      "Epoch [17/50], Step [130/469], Loss: 0.7926, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [131/469], Loss: 0.7534, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [132/469], Loss: 0.8090, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [17/50], Step [133/469], Loss: 0.8097, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [134/469], Loss: 0.6788, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [17/50], Step [135/469], Loss: 0.7471, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [17/50], Step [136/469], Loss: 0.6359, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [17/50], Step [137/469], Loss: 0.7032, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [138/469], Loss: 0.7607, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [139/469], Loss: 0.7900, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [140/469], Loss: 0.6836, batch time: 0.40, accuracy:  81.25%\n",
      "Epoch [17/50], Step [141/469], Loss: 0.6403, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [142/469], Loss: 0.7528, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [17/50], Step [143/469], Loss: 1.0258, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [17/50], Step [144/469], Loss: 0.7683, batch time: 0.41, accuracy:  82.81%\n",
      "Epoch [17/50], Step [145/469], Loss: 0.8230, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [146/469], Loss: 0.7723, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [147/469], Loss: 0.6030, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [17/50], Step [148/469], Loss: 0.7573, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [17/50], Step [149/469], Loss: 0.7493, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [150/469], Loss: 0.8186, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [17/50], Step [151/469], Loss: 0.7704, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [152/469], Loss: 0.7875, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [153/469], Loss: 0.8357, batch time: 0.42, accuracy:  75.78%\n",
      "Epoch [17/50], Step [154/469], Loss: 0.8217, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [155/469], Loss: 0.7739, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [156/469], Loss: 0.8485, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [17/50], Step [157/469], Loss: 0.7523, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [158/469], Loss: 0.6816, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [17/50], Step [159/469], Loss: 0.8166, batch time: 0.41, accuracy:  72.66%\n",
      "Epoch [17/50], Step [160/469], Loss: 0.7408, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [161/469], Loss: 0.6988, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [162/469], Loss: 0.6628, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [163/469], Loss: 0.6490, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [164/469], Loss: 0.7675, batch time: 0.41, accuracy:  82.81%\n",
      "Epoch [17/50], Step [165/469], Loss: 0.8017, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [166/469], Loss: 0.8198, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [167/469], Loss: 0.7489, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [168/469], Loss: 0.7661, batch time: 0.42, accuracy:  70.31%\n",
      "Epoch [17/50], Step [169/469], Loss: 0.9027, batch time: 0.41, accuracy:  65.62%\n",
      "Epoch [17/50], Step [170/469], Loss: 0.7876, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [171/469], Loss: 0.8801, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [172/469], Loss: 0.6290, batch time: 0.41, accuracy:  85.16%\n",
      "Epoch [17/50], Step [173/469], Loss: 0.6728, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [174/469], Loss: 0.8374, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [175/469], Loss: 0.7817, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [176/469], Loss: 0.7194, batch time: 0.42, accuracy:  79.69%\n",
      "Epoch [17/50], Step [177/469], Loss: 0.8345, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [178/469], Loss: 0.7782, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [179/469], Loss: 0.8299, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [17/50], Step [180/469], Loss: 0.5551, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [17/50], Step [181/469], Loss: 0.6676, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [17/50], Step [182/469], Loss: 0.6179, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [183/469], Loss: 0.6704, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [17/50], Step [184/469], Loss: 0.7977, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [185/469], Loss: 0.9204, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [17/50], Step [186/469], Loss: 0.6458, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [187/469], Loss: 0.7911, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [17/50], Step [188/469], Loss: 0.5631, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [189/469], Loss: 0.6082, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [190/469], Loss: 0.7345, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [191/469], Loss: 0.7916, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [192/469], Loss: 0.6848, batch time: 0.40, accuracy:  78.12%\n",
      "Epoch [17/50], Step [193/469], Loss: 0.6028, batch time: 0.40, accuracy:  81.25%\n",
      "Epoch [17/50], Step [194/469], Loss: 0.7568, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [195/469], Loss: 0.8636, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [196/469], Loss: 0.8872, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [17/50], Step [197/469], Loss: 1.0017, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [17/50], Step [198/469], Loss: 0.6814, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [199/469], Loss: 0.7418, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [17/50], Step [200/469], Loss: 0.6273, batch time: 0.40, accuracy:  83.59%\n",
      "Epoch [17/50], Step [201/469], Loss: 0.7821, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [202/469], Loss: 0.8141, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [17/50], Step [203/469], Loss: 0.6013, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [17/50], Step [204/469], Loss: 0.8025, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [205/469], Loss: 0.5605, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [17/50], Step [206/469], Loss: 0.7750, batch time: 0.47, accuracy:  75.00%\n",
      "Epoch [17/50], Step [207/469], Loss: 0.6487, batch time: 0.40, accuracy:  85.94%\n",
      "Epoch [17/50], Step [208/469], Loss: 0.9313, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [17/50], Step [209/469], Loss: 0.6978, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [17/50], Step [210/469], Loss: 0.6700, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [211/469], Loss: 0.7600, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [212/469], Loss: 0.7061, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [17/50], Step [213/469], Loss: 0.7499, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [214/469], Loss: 0.6641, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [215/469], Loss: 0.6840, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [216/469], Loss: 0.7193, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [17/50], Step [217/469], Loss: 0.6589, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [218/469], Loss: 0.7216, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [17/50], Step [219/469], Loss: 0.5513, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [220/469], Loss: 0.7926, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [17/50], Step [221/469], Loss: 0.7417, batch time: 0.40, accuracy:  72.66%\n",
      "Epoch [17/50], Step [222/469], Loss: 0.7364, batch time: 0.40, accuracy:  81.25%\n",
      "Epoch [17/50], Step [223/469], Loss: 0.8701, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [224/469], Loss: 0.7411, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [17/50], Step [225/469], Loss: 0.9097, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [17/50], Step [226/469], Loss: 0.8745, batch time: 0.42, accuracy:  73.44%\n",
      "Epoch [17/50], Step [227/469], Loss: 0.7741, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [228/469], Loss: 0.6779, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [229/469], Loss: 0.7376, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [17/50], Step [230/469], Loss: 0.8338, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [231/469], Loss: 0.7357, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [17/50], Step [232/469], Loss: 0.6408, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [17/50], Step [233/469], Loss: 0.8589, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [234/469], Loss: 0.8920, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [235/469], Loss: 0.6557, batch time: 0.40, accuracy:  75.00%\n",
      "Epoch [17/50], Step [236/469], Loss: 0.6616, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [17/50], Step [237/469], Loss: 0.6268, batch time: 0.41, accuracy:  78.91%\n",
      "Epoch [17/50], Step [238/469], Loss: 0.7054, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [17/50], Step [239/469], Loss: 0.5971, batch time: 0.40, accuracy:  84.38%\n",
      "Epoch [17/50], Step [240/469], Loss: 0.7480, batch time: 0.40, accuracy:  73.44%\n",
      "Epoch [17/50], Step [241/469], Loss: 0.5254, batch time: 0.41, accuracy:  85.94%\n",
      "Epoch [17/50], Step [242/469], Loss: 0.7304, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [243/469], Loss: 0.5923, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [17/50], Step [244/469], Loss: 0.7844, batch time: 0.40, accuracy:  71.09%\n",
      "Epoch [17/50], Step [245/469], Loss: 0.8842, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [246/469], Loss: 0.5985, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [17/50], Step [247/469], Loss: 0.7616, batch time: 0.40, accuracy:  77.34%\n",
      "Epoch [17/50], Step [248/469], Loss: 0.9065, batch time: 0.40, accuracy:  76.56%\n",
      "Epoch [17/50], Step [249/469], Loss: 0.7679, batch time: 0.40, accuracy:  75.78%\n",
      "Epoch [17/50], Step [250/469], Loss: 0.5961, batch time: 0.42, accuracy:  82.03%\n",
      "Epoch [17/50], Step [251/469], Loss: 0.7757, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [17/50], Step [252/469], Loss: 0.7606, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [253/469], Loss: 0.9225, batch time: 0.41, accuracy:  70.31%\n",
      "Epoch [17/50], Step [254/469], Loss: 1.0108, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [255/469], Loss: 0.9660, batch time: 0.42, accuracy:  74.22%\n",
      "Epoch [17/50], Step [256/469], Loss: 0.6424, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [257/469], Loss: 0.7324, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [17/50], Step [258/469], Loss: 0.9819, batch time: 0.42, accuracy:  71.09%\n",
      "Epoch [17/50], Step [259/469], Loss: 0.7746, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [260/469], Loss: 0.8105, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [261/469], Loss: 0.6927, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [262/469], Loss: 0.6784, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [263/469], Loss: 0.7271, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [264/469], Loss: 0.7401, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [17/50], Step [265/469], Loss: 0.7119, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [266/469], Loss: 0.9659, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [267/469], Loss: 0.7855, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [268/469], Loss: 0.6377, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [269/469], Loss: 0.5685, batch time: 0.42, accuracy:  80.47%\n",
      "Epoch [17/50], Step [270/469], Loss: 0.6432, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [271/469], Loss: 0.6909, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [272/469], Loss: 0.8701, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [273/469], Loss: 0.7925, batch time: 0.40, accuracy:  82.03%\n",
      "Epoch [17/50], Step [274/469], Loss: 0.7402, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [275/469], Loss: 0.7703, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [276/469], Loss: 0.7431, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [277/469], Loss: 0.7037, batch time: 0.40, accuracy:  79.69%\n",
      "Epoch [17/50], Step [278/469], Loss: 0.6301, batch time: 0.40, accuracy:  80.47%\n",
      "Epoch [17/50], Step [279/469], Loss: 0.8181, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [280/469], Loss: 0.9278, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [281/469], Loss: 0.8534, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [282/469], Loss: 0.7982, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [283/469], Loss: 0.7306, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [284/469], Loss: 0.7208, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [285/469], Loss: 0.7024, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [286/469], Loss: 0.6784, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [287/469], Loss: 0.8022, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [288/469], Loss: 0.6441, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [17/50], Step [289/469], Loss: 0.5942, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [290/469], Loss: 0.6199, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [291/469], Loss: 0.6749, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [17/50], Step [292/469], Loss: 0.7321, batch time: 0.42, accuracy:  75.00%\n",
      "Epoch [17/50], Step [293/469], Loss: 0.7379, batch time: 0.42, accuracy:  76.56%\n",
      "Epoch [17/50], Step [294/469], Loss: 0.8335, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [17/50], Step [295/469], Loss: 0.6823, batch time: 0.42, accuracy:  79.69%\n",
      "Epoch [17/50], Step [296/469], Loss: 0.7520, batch time: 0.42, accuracy:  78.91%\n",
      "Epoch [17/50], Step [297/469], Loss: 0.7078, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [17/50], Step [298/469], Loss: 0.7279, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [299/469], Loss: 0.6688, batch time: 0.40, accuracy:  78.91%\n",
      "Epoch [17/50], Step [300/469], Loss: 0.8733, batch time: 0.41, accuracy:  71.88%\n",
      "Epoch [17/50], Step [301/469], Loss: 0.7416, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [302/469], Loss: 0.6903, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [303/469], Loss: 0.6930, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [17/50], Step [304/469], Loss: 0.5593, batch time: 0.60, accuracy:  87.50%\n",
      "Epoch [17/50], Step [305/469], Loss: 0.6580, batch time: 0.42, accuracy:  80.47%\n",
      "Epoch [17/50], Step [306/469], Loss: 0.7479, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [307/469], Loss: 0.7807, batch time: 0.41, accuracy:  83.59%\n",
      "Epoch [17/50], Step [308/469], Loss: 0.6919, batch time: 0.41, accuracy:  75.78%\n",
      "Epoch [17/50], Step [309/469], Loss: 0.7305, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [310/469], Loss: 0.6455, batch time: 0.41, accuracy:  79.69%\n",
      "Epoch [17/50], Step [311/469], Loss: 0.8159, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [312/469], Loss: 0.6588, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [313/469], Loss: 0.8405, batch time: 0.41, accuracy:  73.44%\n",
      "Epoch [17/50], Step [314/469], Loss: 1.0131, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [17/50], Step [315/469], Loss: 0.8506, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [316/469], Loss: 0.7433, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [317/469], Loss: 0.8387, batch time: 0.48, accuracy:  72.66%\n",
      "Epoch [17/50], Step [318/469], Loss: 0.7720, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [319/469], Loss: 0.5867, batch time: 0.41, accuracy:  81.25%\n",
      "Epoch [17/50], Step [320/469], Loss: 0.7884, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [17/50], Step [321/469], Loss: 0.6232, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [322/469], Loss: 0.7352, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [323/469], Loss: 0.7782, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [324/469], Loss: 0.7733, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [325/469], Loss: 0.7012, batch time: 0.40, accuracy:  81.25%\n",
      "Epoch [17/50], Step [326/469], Loss: 0.7358, batch time: 0.41, accuracy:  78.12%\n",
      "Epoch [17/50], Step [327/469], Loss: 0.7442, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [328/469], Loss: 0.6995, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [329/469], Loss: 0.7512, batch time: 0.41, accuracy:  71.09%\n",
      "Epoch [17/50], Step [330/469], Loss: 0.6824, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [17/50], Step [331/469], Loss: 0.6513, batch time: 0.42, accuracy:  81.25%\n",
      "Epoch [17/50], Step [332/469], Loss: 0.8054, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [17/50], Step [333/469], Loss: 0.6502, batch time: 0.41, accuracy:  82.03%\n",
      "Epoch [17/50], Step [334/469], Loss: 0.7376, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [17/50], Step [335/469], Loss: 0.7838, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [336/469], Loss: 0.6363, batch time: 0.41, accuracy:  82.81%\n",
      "Epoch [17/50], Step [337/469], Loss: 0.7147, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [17/50], Step [338/469], Loss: 0.7816, batch time: 0.42, accuracy:  77.34%\n",
      "Epoch [17/50], Step [339/469], Loss: 0.8024, batch time: 0.41, accuracy:  74.22%\n",
      "Epoch [17/50], Step [340/469], Loss: 0.8766, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [341/469], Loss: 0.6991, batch time: 0.41, accuracy:  80.47%\n",
      "Epoch [17/50], Step [342/469], Loss: 0.6962, batch time: 0.41, accuracy:  76.56%\n",
      "Epoch [17/50], Step [343/469], Loss: 0.8553, batch time: 0.42, accuracy:  72.66%\n",
      "Epoch [17/50], Step [344/469], Loss: 1.0013, batch time: 0.42, accuracy:  67.97%\n",
      "Epoch [17/50], Step [345/469], Loss: 0.6392, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [17/50], Step [346/469], Loss: 0.7435, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [17/50], Step [347/469], Loss: 0.6453, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [17/50], Step [348/469], Loss: 0.7081, batch time: 0.41, accuracy:  77.34%\n",
      "Epoch [17/50], Step [349/469], Loss: 0.7621, batch time: 0.40, accuracy:  70.31%\n",
      "Epoch [17/50], Step [350/469], Loss: 0.7326, batch time: 0.40, accuracy:  74.22%\n",
      "Epoch [17/50], Step [351/469], Loss: 0.8186, batch time: 0.41, accuracy:  75.00%\n",
      "Epoch [17/50], Step [352/469], Loss: 0.6164, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [17/50], Step [353/469], Loss: 0.7267, batch time: 0.56, accuracy:  77.34%\n",
      "Epoch [17/50], Step [354/469], Loss: 0.6320, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [17/50], Step [355/469], Loss: 0.7147, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [17/50], Step [356/469], Loss: 0.9141, batch time: 0.50, accuracy:  69.53%\n",
      "Epoch [17/50], Step [357/469], Loss: 0.6124, batch time: 0.59, accuracy:  78.91%\n",
      "Epoch [17/50], Step [358/469], Loss: 0.8024, batch time: 0.52, accuracy:  76.56%\n",
      "Epoch [17/50], Step [359/469], Loss: 0.7074, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [17/50], Step [360/469], Loss: 0.7473, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [17/50], Step [361/469], Loss: 0.6916, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [17/50], Step [362/469], Loss: 0.7129, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [17/50], Step [363/469], Loss: 0.6616, batch time: 0.62, accuracy:  79.69%\n",
      "Epoch [17/50], Step [364/469], Loss: 0.6123, batch time: 0.60, accuracy:  82.03%\n",
      "Epoch [17/50], Step [365/469], Loss: 0.7444, batch time: 0.66, accuracy:  78.91%\n",
      "Epoch [17/50], Step [366/469], Loss: 0.8322, batch time: 0.48, accuracy:  75.78%\n",
      "Epoch [17/50], Step [367/469], Loss: 0.6284, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [17/50], Step [368/469], Loss: 0.7627, batch time: 0.58, accuracy:  80.47%\n",
      "Epoch [17/50], Step [369/469], Loss: 0.7918, batch time: 0.62, accuracy:  78.91%\n",
      "Epoch [17/50], Step [370/469], Loss: 0.6038, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [17/50], Step [371/469], Loss: 0.5237, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [17/50], Step [372/469], Loss: 0.8321, batch time: 0.44, accuracy:  71.09%\n",
      "Epoch [17/50], Step [373/469], Loss: 0.8328, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [17/50], Step [374/469], Loss: 0.6784, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [17/50], Step [375/469], Loss: 0.6982, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [17/50], Step [376/469], Loss: 0.5999, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [17/50], Step [377/469], Loss: 0.7847, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [17/50], Step [378/469], Loss: 0.7459, batch time: 0.47, accuracy:  75.78%\n",
      "Epoch [17/50], Step [379/469], Loss: 0.8509, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [17/50], Step [380/469], Loss: 0.6114, batch time: 0.56, accuracy:  78.91%\n",
      "Epoch [17/50], Step [381/469], Loss: 0.7705, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [17/50], Step [382/469], Loss: 0.6407, batch time: 0.56, accuracy:  81.25%\n",
      "Epoch [17/50], Step [383/469], Loss: 0.6078, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [17/50], Step [384/469], Loss: 0.7861, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [17/50], Step [385/469], Loss: 0.6871, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [17/50], Step [386/469], Loss: 0.9223, batch time: 0.49, accuracy:  72.66%\n",
      "Epoch [17/50], Step [387/469], Loss: 0.9905, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [17/50], Step [388/469], Loss: 0.6908, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [17/50], Step [389/469], Loss: 0.6240, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [17/50], Step [390/469], Loss: 0.5295, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [17/50], Step [391/469], Loss: 0.5631, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [17/50], Step [392/469], Loss: 0.5401, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [17/50], Step [393/469], Loss: 0.6888, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [17/50], Step [394/469], Loss: 0.7618, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [17/50], Step [395/469], Loss: 0.7074, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [17/50], Step [396/469], Loss: 0.6899, batch time: 0.46, accuracy:  76.56%\n",
      "Epoch [17/50], Step [397/469], Loss: 0.8122, batch time: 0.52, accuracy:  78.12%\n",
      "Epoch [17/50], Step [398/469], Loss: 0.6281, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [17/50], Step [399/469], Loss: 0.7262, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [17/50], Step [400/469], Loss: 0.6263, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [17/50], Step [401/469], Loss: 0.7129, batch time: 0.52, accuracy:  76.56%\n",
      "Epoch [17/50], Step [402/469], Loss: 0.5207, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [17/50], Step [403/469], Loss: 0.6544, batch time: 0.56, accuracy:  77.34%\n",
      "Epoch [17/50], Step [404/469], Loss: 0.7648, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [17/50], Step [405/469], Loss: 0.6279, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [17/50], Step [406/469], Loss: 0.5294, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [17/50], Step [407/469], Loss: 0.4546, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [17/50], Step [408/469], Loss: 0.5998, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [17/50], Step [409/469], Loss: 0.8786, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [17/50], Step [410/469], Loss: 0.5833, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [17/50], Step [411/469], Loss: 0.7459, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [17/50], Step [412/469], Loss: 0.7908, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [17/50], Step [413/469], Loss: 0.6631, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [17/50], Step [414/469], Loss: 0.7239, batch time: 0.46, accuracy:  73.44%\n",
      "Epoch [17/50], Step [415/469], Loss: 0.6871, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [17/50], Step [416/469], Loss: 0.6304, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [17/50], Step [417/469], Loss: 0.7395, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [17/50], Step [418/469], Loss: 0.6471, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [17/50], Step [419/469], Loss: 0.6995, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [17/50], Step [420/469], Loss: 0.6629, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [17/50], Step [421/469], Loss: 0.6573, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [17/50], Step [422/469], Loss: 0.7048, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [17/50], Step [423/469], Loss: 0.8092, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [17/50], Step [424/469], Loss: 0.6918, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [17/50], Step [425/469], Loss: 0.7250, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [17/50], Step [426/469], Loss: 0.7118, batch time: 0.56, accuracy:  78.12%\n",
      "Epoch [17/50], Step [427/469], Loss: 0.8034, batch time: 0.58, accuracy:  76.56%\n",
      "Epoch [17/50], Step [428/469], Loss: 0.6867, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [17/50], Step [429/469], Loss: 0.7209, batch time: 0.57, accuracy:  80.47%\n",
      "Epoch [17/50], Step [430/469], Loss: 0.8056, batch time: 0.47, accuracy:  74.22%\n",
      "Epoch [17/50], Step [431/469], Loss: 0.7002, batch time: 0.46, accuracy:  73.44%\n",
      "Epoch [17/50], Step [432/469], Loss: 0.3976, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [17/50], Step [433/469], Loss: 0.7056, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [17/50], Step [434/469], Loss: 0.8391, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [17/50], Step [435/469], Loss: 0.6137, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [17/50], Step [436/469], Loss: 0.9122, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [17/50], Step [437/469], Loss: 0.7138, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [17/50], Step [438/469], Loss: 0.6258, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [17/50], Step [439/469], Loss: 0.6948, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [17/50], Step [440/469], Loss: 0.7459, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [17/50], Step [441/469], Loss: 0.8548, batch time: 0.50, accuracy:  75.00%\n",
      "Epoch [17/50], Step [442/469], Loss: 0.6490, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [17/50], Step [443/469], Loss: 0.7057, batch time: 0.50, accuracy:  75.78%\n",
      "Epoch [17/50], Step [444/469], Loss: 0.6779, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [17/50], Step [445/469], Loss: 0.7391, batch time: 0.50, accuracy:  71.09%\n",
      "Epoch [17/50], Step [446/469], Loss: 0.6540, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [17/50], Step [447/469], Loss: 0.6776, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [17/50], Step [448/469], Loss: 0.5081, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [17/50], Step [449/469], Loss: 0.6713, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [17/50], Step [450/469], Loss: 0.6364, batch time: 0.51, accuracy:  79.69%\n",
      "Epoch [17/50], Step [451/469], Loss: 0.5447, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [17/50], Step [452/469], Loss: 0.7368, batch time: 0.43, accuracy:  72.66%\n",
      "Epoch [17/50], Step [453/469], Loss: 0.5670, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [17/50], Step [454/469], Loss: 0.8259, batch time: 0.44, accuracy:  70.31%\n",
      "Epoch [17/50], Step [455/469], Loss: 0.7700, batch time: 0.51, accuracy:  76.56%\n",
      "Epoch [17/50], Step [456/469], Loss: 0.6640, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [17/50], Step [457/469], Loss: 0.8011, batch time: 0.46, accuracy:  71.88%\n",
      "Epoch [17/50], Step [458/469], Loss: 0.5691, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [17/50], Step [459/469], Loss: 0.6522, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [17/50], Step [460/469], Loss: 0.8747, batch time: 0.45, accuracy:  74.22%\n",
      "Epoch [17/50], Step [461/469], Loss: 0.6360, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [17/50], Step [462/469], Loss: 0.9868, batch time: 0.50, accuracy:  71.09%\n",
      "Epoch [17/50], Step [463/469], Loss: 0.5935, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [17/50], Step [464/469], Loss: 0.6823, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [17/50], Step [465/469], Loss: 0.5661, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [17/50], Step [466/469], Loss: 0.5536, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [17/50], Step [467/469], Loss: 0.6268, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [17/50], Step [468/469], Loss: 0.8153, batch time: 0.52, accuracy:  73.44%\n",
      "Epoch [17/50], Step [469/469], Loss: 0.5543, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [18/50], Step [1/469], Loss: 0.8011, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [18/50], Step [2/469], Loss: 0.7569, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [3/469], Loss: 0.6689, batch time: 0.47, accuracy:  75.78%\n",
      "Epoch [18/50], Step [4/469], Loss: 0.6639, batch time: 0.46, accuracy:  71.88%\n",
      "Epoch [18/50], Step [5/469], Loss: 0.4728, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [18/50], Step [6/469], Loss: 0.5693, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [18/50], Step [7/469], Loss: 0.6816, batch time: 0.49, accuracy:  75.00%\n",
      "Epoch [18/50], Step [8/469], Loss: 0.5717, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [18/50], Step [9/469], Loss: 0.7114, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [18/50], Step [10/469], Loss: 0.5756, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [11/469], Loss: 0.9046, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [12/469], Loss: 0.9372, batch time: 0.45, accuracy:  74.22%\n",
      "Epoch [18/50], Step [13/469], Loss: 0.5448, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [14/469], Loss: 0.6565, batch time: 0.52, accuracy:  77.34%\n",
      "Epoch [18/50], Step [15/469], Loss: 0.6914, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [18/50], Step [16/469], Loss: 0.7548, batch time: 0.48, accuracy:  75.00%\n",
      "Epoch [18/50], Step [17/469], Loss: 0.7947, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [18/469], Loss: 0.8252, batch time: 0.44, accuracy:  73.44%\n",
      "Epoch [18/50], Step [19/469], Loss: 0.5721, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [20/469], Loss: 0.4938, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [18/50], Step [21/469], Loss: 0.6247, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [18/50], Step [22/469], Loss: 0.6076, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [23/469], Loss: 0.9447, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [24/469], Loss: 0.6948, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [18/50], Step [25/469], Loss: 0.6650, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [18/50], Step [26/469], Loss: 0.7452, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [27/469], Loss: 0.6997, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [18/50], Step [28/469], Loss: 0.8191, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [29/469], Loss: 0.7032, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [18/50], Step [30/469], Loss: 0.6547, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [31/469], Loss: 0.7068, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [32/469], Loss: 0.6203, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [18/50], Step [33/469], Loss: 0.6359, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [18/50], Step [34/469], Loss: 0.7983, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [18/50], Step [35/469], Loss: 0.8293, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [18/50], Step [36/469], Loss: 0.7833, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [18/50], Step [37/469], Loss: 0.4304, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [18/50], Step [38/469], Loss: 0.6813, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [18/50], Step [39/469], Loss: 0.5701, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [18/50], Step [40/469], Loss: 0.7450, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [18/50], Step [41/469], Loss: 0.6446, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [42/469], Loss: 0.6616, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [18/50], Step [43/469], Loss: 0.7117, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [18/50], Step [44/469], Loss: 0.7174, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [45/469], Loss: 0.6400, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [18/50], Step [46/469], Loss: 0.6616, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [47/469], Loss: 0.6295, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [48/469], Loss: 0.7132, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [49/469], Loss: 0.6055, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [18/50], Step [50/469], Loss: 0.7609, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [18/50], Step [51/469], Loss: 0.6331, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [52/469], Loss: 0.6394, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [18/50], Step [53/469], Loss: 0.7645, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [54/469], Loss: 0.6302, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [55/469], Loss: 0.8406, batch time: 0.50, accuracy:  72.66%\n",
      "Epoch [18/50], Step [56/469], Loss: 0.4756, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [18/50], Step [57/469], Loss: 0.7974, batch time: 0.44, accuracy:  73.44%\n",
      "Epoch [18/50], Step [58/469], Loss: 0.6005, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [59/469], Loss: 0.6491, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [60/469], Loss: 0.6986, batch time: 0.55, accuracy:  80.47%\n",
      "Epoch [18/50], Step [61/469], Loss: 0.7249, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [18/50], Step [62/469], Loss: 0.7630, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [18/50], Step [63/469], Loss: 0.8105, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [18/50], Step [64/469], Loss: 0.6665, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [65/469], Loss: 0.5627, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [18/50], Step [66/469], Loss: 0.6748, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [18/50], Step [67/469], Loss: 0.7983, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [68/469], Loss: 0.7694, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [69/469], Loss: 0.8088, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [18/50], Step [70/469], Loss: 0.8259, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [71/469], Loss: 0.7270, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [18/50], Step [72/469], Loss: 0.6129, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [18/50], Step [73/469], Loss: 0.7047, batch time: 0.51, accuracy:  78.91%\n",
      "Epoch [18/50], Step [74/469], Loss: 0.6847, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [18/50], Step [75/469], Loss: 0.6168, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [18/50], Step [76/469], Loss: 0.7768, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [18/50], Step [77/469], Loss: 0.5228, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [18/50], Step [78/469], Loss: 0.7386, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [18/50], Step [79/469], Loss: 0.5916, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [80/469], Loss: 0.5972, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [81/469], Loss: 0.7455, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [82/469], Loss: 0.6613, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [83/469], Loss: 0.6546, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [84/469], Loss: 0.7088, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [85/469], Loss: 0.6743, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [86/469], Loss: 0.6065, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [87/469], Loss: 0.6743, batch time: 0.52, accuracy:  77.34%\n",
      "Epoch [18/50], Step [88/469], Loss: 0.9234, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [18/50], Step [89/469], Loss: 0.6453, batch time: 0.47, accuracy:  73.44%\n",
      "Epoch [18/50], Step [90/469], Loss: 0.5148, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [18/50], Step [91/469], Loss: 0.7595, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [18/50], Step [92/469], Loss: 0.8245, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [93/469], Loss: 0.7075, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [18/50], Step [94/469], Loss: 0.7867, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [95/469], Loss: 0.6519, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [96/469], Loss: 0.7942, batch time: 0.44, accuracy:  73.44%\n",
      "Epoch [18/50], Step [97/469], Loss: 0.8047, batch time: 0.44, accuracy:  72.66%\n",
      "Epoch [18/50], Step [98/469], Loss: 0.6260, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [18/50], Step [99/469], Loss: 0.7743, batch time: 0.49, accuracy:  77.34%\n",
      "Epoch [18/50], Step [100/469], Loss: 0.7262, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [18/50], Step [101/469], Loss: 0.6539, batch time: 0.48, accuracy:  73.44%\n",
      "Epoch [18/50], Step [102/469], Loss: 0.5729, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [103/469], Loss: 0.6687, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [104/469], Loss: 0.7605, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [18/50], Step [105/469], Loss: 0.7614, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [18/50], Step [106/469], Loss: 0.4929, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [18/50], Step [107/469], Loss: 0.8243, batch time: 0.44, accuracy:  73.44%\n",
      "Epoch [18/50], Step [108/469], Loss: 0.6136, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [18/50], Step [109/469], Loss: 0.7376, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [18/50], Step [110/469], Loss: 0.8593, batch time: 0.45, accuracy:  74.22%\n",
      "Epoch [18/50], Step [111/469], Loss: 0.7736, batch time: 0.43, accuracy:  74.22%\n",
      "Epoch [18/50], Step [112/469], Loss: 0.5695, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [18/50], Step [113/469], Loss: 0.6782, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [18/50], Step [114/469], Loss: 0.8854, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [115/469], Loss: 0.5586, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [18/50], Step [116/469], Loss: 0.5349, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [18/50], Step [117/469], Loss: 0.5804, batch time: 0.48, accuracy:  76.56%\n",
      "Epoch [18/50], Step [118/469], Loss: 0.5799, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [119/469], Loss: 0.8452, batch time: 0.47, accuracy:  77.34%\n",
      "Epoch [18/50], Step [120/469], Loss: 0.6963, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [121/469], Loss: 0.7878, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [18/50], Step [122/469], Loss: 0.5757, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [18/50], Step [123/469], Loss: 0.7332, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [18/50], Step [124/469], Loss: 0.7156, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [18/50], Step [125/469], Loss: 0.6878, batch time: 0.46, accuracy:  75.78%\n",
      "Epoch [18/50], Step [126/469], Loss: 0.7999, batch time: 0.46, accuracy:  76.56%\n",
      "Epoch [18/50], Step [127/469], Loss: 0.5389, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [128/469], Loss: 0.7709, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [18/50], Step [129/469], Loss: 0.6597, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [130/469], Loss: 0.7456, batch time: 0.46, accuracy:  76.56%\n",
      "Epoch [18/50], Step [131/469], Loss: 0.8949, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [132/469], Loss: 0.6222, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [18/50], Step [133/469], Loss: 0.6283, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [18/50], Step [134/469], Loss: 0.5329, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [135/469], Loss: 0.6595, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [18/50], Step [136/469], Loss: 0.7549, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [18/50], Step [137/469], Loss: 0.6931, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [18/50], Step [138/469], Loss: 0.8252, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [18/50], Step [139/469], Loss: 0.6846, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [18/50], Step [140/469], Loss: 0.6468, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [18/50], Step [141/469], Loss: 0.8565, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [18/50], Step [142/469], Loss: 0.5998, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [18/50], Step [143/469], Loss: 0.5349, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [18/50], Step [144/469], Loss: 0.6820, batch time: 0.49, accuracy:  78.12%\n",
      "Epoch [18/50], Step [145/469], Loss: 0.5660, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [18/50], Step [146/469], Loss: 0.5510, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [18/50], Step [147/469], Loss: 0.7426, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [18/50], Step [148/469], Loss: 0.6415, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [18/50], Step [149/469], Loss: 0.7476, batch time: 0.51, accuracy:  78.12%\n",
      "Epoch [18/50], Step [150/469], Loss: 0.6733, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [18/50], Step [151/469], Loss: 0.8421, batch time: 0.47, accuracy:  76.56%\n",
      "Epoch [18/50], Step [152/469], Loss: 0.7720, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [18/50], Step [153/469], Loss: 0.5770, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [18/50], Step [154/469], Loss: 0.5836, batch time: 0.81, accuracy:  83.59%\n",
      "Epoch [18/50], Step [155/469], Loss: 0.8170, batch time: 0.43, accuracy:  74.22%\n",
      "Epoch [18/50], Step [156/469], Loss: 0.9460, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [18/50], Step [157/469], Loss: 0.7213, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [18/50], Step [158/469], Loss: 0.6874, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [159/469], Loss: 0.7754, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [18/50], Step [160/469], Loss: 0.7360, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [18/50], Step [161/469], Loss: 0.8532, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [162/469], Loss: 0.6721, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [163/469], Loss: 0.6552, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [164/469], Loss: 0.6645, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [165/469], Loss: 0.5930, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [18/50], Step [166/469], Loss: 0.7148, batch time: 0.46, accuracy:  76.56%\n",
      "Epoch [18/50], Step [167/469], Loss: 0.6519, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [18/50], Step [168/469], Loss: 0.5804, batch time: 0.52, accuracy:  78.12%\n",
      "Epoch [18/50], Step [169/469], Loss: 0.7781, batch time: 0.49, accuracy:  78.12%\n",
      "Epoch [18/50], Step [170/469], Loss: 0.8072, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [18/50], Step [171/469], Loss: 0.7686, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [18/50], Step [172/469], Loss: 0.8572, batch time: 0.49, accuracy:  71.88%\n",
      "Epoch [18/50], Step [173/469], Loss: 0.5377, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [18/50], Step [174/469], Loss: 0.9737, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [18/50], Step [175/469], Loss: 0.7039, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [18/50], Step [176/469], Loss: 0.8313, batch time: 0.54, accuracy:  73.44%\n",
      "Epoch [18/50], Step [177/469], Loss: 0.6765, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [18/50], Step [178/469], Loss: 0.5977, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [18/50], Step [179/469], Loss: 0.5409, batch time: 0.56, accuracy:  82.81%\n",
      "Epoch [18/50], Step [180/469], Loss: 0.6340, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [181/469], Loss: 0.5577, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [182/469], Loss: 0.6382, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [18/50], Step [183/469], Loss: 0.5980, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [18/50], Step [184/469], Loss: 0.7434, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [185/469], Loss: 0.5210, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [18/50], Step [186/469], Loss: 0.7960, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [187/469], Loss: 0.5658, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [188/469], Loss: 0.6346, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [18/50], Step [189/469], Loss: 0.6546, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [190/469], Loss: 0.6855, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [191/469], Loss: 0.8126, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [18/50], Step [192/469], Loss: 0.5891, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [193/469], Loss: 0.5679, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [194/469], Loss: 0.6777, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [18/50], Step [195/469], Loss: 0.6775, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [196/469], Loss: 0.6237, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [197/469], Loss: 0.7324, batch time: 0.51, accuracy:  78.91%\n",
      "Epoch [18/50], Step [198/469], Loss: 0.4259, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [18/50], Step [199/469], Loss: 0.7119, batch time: 0.48, accuracy:  76.56%\n",
      "Epoch [18/50], Step [200/469], Loss: 0.7271, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [201/469], Loss: 0.5507, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [18/50], Step [202/469], Loss: 0.5794, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [18/50], Step [203/469], Loss: 0.6960, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [204/469], Loss: 0.6376, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [18/50], Step [205/469], Loss: 0.6086, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [206/469], Loss: 0.7519, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [207/469], Loss: 0.7372, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [18/50], Step [208/469], Loss: 0.6748, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [18/50], Step [209/469], Loss: 0.7035, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [18/50], Step [210/469], Loss: 0.5585, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [18/50], Step [211/469], Loss: 0.5420, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [212/469], Loss: 0.6860, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [213/469], Loss: 0.5898, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [214/469], Loss: 0.6326, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [215/469], Loss: 0.6877, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [216/469], Loss: 0.7671, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [18/50], Step [217/469], Loss: 0.6238, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [18/50], Step [218/469], Loss: 0.4942, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [18/50], Step [219/469], Loss: 0.6504, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [18/50], Step [220/469], Loss: 0.6398, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [221/469], Loss: 0.6412, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [18/50], Step [222/469], Loss: 0.6585, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [18/50], Step [223/469], Loss: 0.6521, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [18/50], Step [224/469], Loss: 0.7339, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [18/50], Step [225/469], Loss: 0.5451, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [18/50], Step [226/469], Loss: 0.6788, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [18/50], Step [227/469], Loss: 0.6724, batch time: 0.44, accuracy:  72.66%\n",
      "Epoch [18/50], Step [228/469], Loss: 0.6070, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [18/50], Step [229/469], Loss: 0.5083, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [18/50], Step [230/469], Loss: 0.7738, batch time: 0.53, accuracy:  79.69%\n",
      "Epoch [18/50], Step [231/469], Loss: 0.8342, batch time: 0.52, accuracy:  76.56%\n",
      "Epoch [18/50], Step [232/469], Loss: 0.6013, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [18/50], Step [233/469], Loss: 0.7704, batch time: 1.03, accuracy:  81.25%\n",
      "Epoch [18/50], Step [234/469], Loss: 0.6083, batch time: 0.64, accuracy:  80.47%\n",
      "Epoch [18/50], Step [235/469], Loss: 0.6006, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [18/50], Step [236/469], Loss: 0.5669, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [237/469], Loss: 0.6604, batch time: 0.50, accuracy:  76.56%\n",
      "Epoch [18/50], Step [238/469], Loss: 0.5102, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [18/50], Step [239/469], Loss: 0.6123, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [240/469], Loss: 0.5555, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [18/50], Step [241/469], Loss: 0.7513, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [242/469], Loss: 0.8741, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [243/469], Loss: 0.7067, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [18/50], Step [244/469], Loss: 0.7803, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [18/50], Step [245/469], Loss: 0.7353, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [18/50], Step [246/469], Loss: 0.9229, batch time: 0.47, accuracy:  72.66%\n",
      "Epoch [18/50], Step [247/469], Loss: 0.6314, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [248/469], Loss: 0.6440, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [249/469], Loss: 0.6741, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [18/50], Step [250/469], Loss: 0.6059, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [18/50], Step [251/469], Loss: 0.6152, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [18/50], Step [252/469], Loss: 0.5796, batch time: 0.54, accuracy:  80.47%\n",
      "Epoch [18/50], Step [253/469], Loss: 0.7352, batch time: 0.46, accuracy:  75.00%\n",
      "Epoch [18/50], Step [254/469], Loss: 0.5969, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [18/50], Step [255/469], Loss: 0.8680, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [18/50], Step [256/469], Loss: 0.6022, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [18/50], Step [257/469], Loss: 0.8048, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [18/50], Step [258/469], Loss: 0.5582, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [18/50], Step [259/469], Loss: 0.6859, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [260/469], Loss: 0.6127, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [18/50], Step [261/469], Loss: 0.6910, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [262/469], Loss: 0.4942, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [18/50], Step [263/469], Loss: 0.5010, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [18/50], Step [264/469], Loss: 0.6051, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [18/50], Step [265/469], Loss: 0.6359, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [18/50], Step [266/469], Loss: 0.5128, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [18/50], Step [267/469], Loss: 0.8327, batch time: 0.49, accuracy:  75.00%\n",
      "Epoch [18/50], Step [268/469], Loss: 0.6872, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [18/50], Step [269/469], Loss: 0.5223, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [18/50], Step [270/469], Loss: 0.6316, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [18/50], Step [271/469], Loss: 0.6608, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [18/50], Step [272/469], Loss: 0.7262, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [273/469], Loss: 0.6720, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [274/469], Loss: 0.6638, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [18/50], Step [275/469], Loss: 0.6977, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [18/50], Step [276/469], Loss: 0.7991, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [277/469], Loss: 0.7074, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [18/50], Step [278/469], Loss: 0.6212, batch time: 0.51, accuracy:  78.91%\n",
      "Epoch [18/50], Step [279/469], Loss: 0.7725, batch time: 0.55, accuracy:  73.44%\n",
      "Epoch [18/50], Step [280/469], Loss: 0.7535, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [18/50], Step [281/469], Loss: 0.5617, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [18/50], Step [282/469], Loss: 0.8136, batch time: 0.48, accuracy:  68.75%\n",
      "Epoch [18/50], Step [283/469], Loss: 0.5788, batch time: 0.60, accuracy:  80.47%\n",
      "Epoch [18/50], Step [284/469], Loss: 0.7571, batch time: 0.87, accuracy:  75.78%\n",
      "Epoch [18/50], Step [285/469], Loss: 0.7490, batch time: 0.43, accuracy:  71.88%\n",
      "Epoch [18/50], Step [286/469], Loss: 0.7657, batch time: 0.44, accuracy:  70.31%\n",
      "Epoch [18/50], Step [287/469], Loss: 0.7339, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [288/469], Loss: 0.5814, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [18/50], Step [289/469], Loss: 0.6943, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [18/50], Step [290/469], Loss: 0.6371, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [18/50], Step [291/469], Loss: 0.7387, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [292/469], Loss: 0.6925, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [18/50], Step [293/469], Loss: 0.7160, batch time: 0.44, accuracy:  74.22%\n",
      "Epoch [18/50], Step [294/469], Loss: 0.6873, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [295/469], Loss: 0.7471, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [18/50], Step [296/469], Loss: 0.6006, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [18/50], Step [297/469], Loss: 0.8291, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [18/50], Step [298/469], Loss: 0.6989, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [18/50], Step [299/469], Loss: 0.7911, batch time: 0.49, accuracy:  76.56%\n",
      "Epoch [18/50], Step [300/469], Loss: 0.8312, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [18/50], Step [301/469], Loss: 0.5471, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [18/50], Step [302/469], Loss: 0.5878, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [18/50], Step [303/469], Loss: 0.7538, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [18/50], Step [304/469], Loss: 0.6603, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [18/50], Step [305/469], Loss: 0.7741, batch time: 0.45, accuracy:  74.22%\n",
      "Epoch [18/50], Step [306/469], Loss: 0.7429, batch time: 0.44, accuracy:  73.44%\n",
      "Epoch [18/50], Step [307/469], Loss: 0.5862, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [308/469], Loss: 0.6499, batch time: 0.48, accuracy:  75.78%\n",
      "Epoch [18/50], Step [309/469], Loss: 0.9083, batch time: 0.50, accuracy:  71.09%\n",
      "Epoch [18/50], Step [310/469], Loss: 0.4924, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [18/50], Step [311/469], Loss: 0.6856, batch time: 0.50, accuracy:  75.78%\n",
      "Epoch [18/50], Step [312/469], Loss: 0.8420, batch time: 0.43, accuracy:  72.66%\n",
      "Epoch [18/50], Step [313/469], Loss: 0.7420, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [314/469], Loss: 0.6201, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [18/50], Step [315/469], Loss: 0.7308, batch time: 0.52, accuracy:  72.66%\n",
      "Epoch [18/50], Step [316/469], Loss: 0.6166, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [18/50], Step [317/469], Loss: 0.6470, batch time: 0.52, accuracy:  78.91%\n",
      "Epoch [18/50], Step [318/469], Loss: 0.6452, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [18/50], Step [319/469], Loss: 0.7190, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [18/50], Step [320/469], Loss: 0.8537, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [18/50], Step [321/469], Loss: 0.8259, batch time: 0.59, accuracy:  74.22%\n",
      "Epoch [18/50], Step [322/469], Loss: 0.7100, batch time: 0.51, accuracy:  79.69%\n",
      "Epoch [18/50], Step [323/469], Loss: 0.6558, batch time: 0.51, accuracy:  78.12%\n",
      "Epoch [18/50], Step [324/469], Loss: 0.5452, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [18/50], Step [325/469], Loss: 0.7083, batch time: 0.47, accuracy:  75.78%\n",
      "Epoch [18/50], Step [326/469], Loss: 0.9384, batch time: 0.50, accuracy:  71.88%\n",
      "Epoch [18/50], Step [327/469], Loss: 0.7067, batch time: 0.54, accuracy:  80.47%\n",
      "Epoch [18/50], Step [328/469], Loss: 0.8629, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [18/50], Step [329/469], Loss: 0.5770, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [18/50], Step [330/469], Loss: 0.7021, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [331/469], Loss: 0.6574, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [18/50], Step [332/469], Loss: 0.6176, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [333/469], Loss: 0.7082, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [18/50], Step [334/469], Loss: 0.6953, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [18/50], Step [335/469], Loss: 0.6754, batch time: 0.53, accuracy:  77.34%\n",
      "Epoch [18/50], Step [336/469], Loss: 0.5003, batch time: 0.82, accuracy:  83.59%\n",
      "Epoch [18/50], Step [337/469], Loss: 0.7811, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [18/50], Step [338/469], Loss: 0.6934, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [18/50], Step [339/469], Loss: 0.5713, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [340/469], Loss: 0.6134, batch time: 0.47, accuracy:  75.78%\n",
      "Epoch [18/50], Step [341/469], Loss: 0.5856, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [18/50], Step [342/469], Loss: 0.6340, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [18/50], Step [343/469], Loss: 0.7785, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [18/50], Step [344/469], Loss: 0.6852, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [18/50], Step [345/469], Loss: 0.7768, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [18/50], Step [346/469], Loss: 0.7331, batch time: 0.49, accuracy:  77.34%\n",
      "Epoch [18/50], Step [347/469], Loss: 0.6053, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [18/50], Step [348/469], Loss: 0.6395, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [349/469], Loss: 0.7691, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [350/469], Loss: 0.5934, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [18/50], Step [351/469], Loss: 0.6921, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [352/469], Loss: 0.6836, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [353/469], Loss: 0.6583, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [354/469], Loss: 0.6460, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [18/50], Step [355/469], Loss: 0.6335, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [356/469], Loss: 0.5964, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [357/469], Loss: 0.6858, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [358/469], Loss: 0.6224, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [18/50], Step [359/469], Loss: 0.6001, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [18/50], Step [360/469], Loss: 0.8655, batch time: 0.46, accuracy:  71.09%\n",
      "Epoch [18/50], Step [361/469], Loss: 0.7262, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [362/469], Loss: 0.5201, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [18/50], Step [363/469], Loss: 0.5962, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [18/50], Step [364/469], Loss: 0.7276, batch time: 0.43, accuracy:  71.09%\n",
      "Epoch [18/50], Step [365/469], Loss: 0.6014, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [18/50], Step [366/469], Loss: 0.6832, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [18/50], Step [367/469], Loss: 0.5753, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [18/50], Step [368/469], Loss: 0.6176, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [18/50], Step [369/469], Loss: 0.6156, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [18/50], Step [370/469], Loss: 0.5917, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [371/469], Loss: 0.5813, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [18/50], Step [372/469], Loss: 0.5848, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [18/50], Step [373/469], Loss: 0.5192, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [18/50], Step [374/469], Loss: 0.5364, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [18/50], Step [375/469], Loss: 0.5426, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [18/50], Step [376/469], Loss: 0.6451, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [18/50], Step [377/469], Loss: 0.5620, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [18/50], Step [378/469], Loss: 0.6601, batch time: 0.72, accuracy:  78.12%\n",
      "Epoch [18/50], Step [379/469], Loss: 0.5441, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [18/50], Step [380/469], Loss: 0.8642, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [381/469], Loss: 0.8260, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [18/50], Step [382/469], Loss: 0.9423, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [18/50], Step [383/469], Loss: 0.5331, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [18/50], Step [384/469], Loss: 0.5425, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [18/50], Step [385/469], Loss: 0.5835, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [18/50], Step [386/469], Loss: 0.5649, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [18/50], Step [387/469], Loss: 0.5749, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [18/50], Step [388/469], Loss: 0.5910, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [18/50], Step [389/469], Loss: 0.7173, batch time: 0.50, accuracy:  79.69%\n",
      "Epoch [18/50], Step [390/469], Loss: 0.6551, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [18/50], Step [391/469], Loss: 0.5733, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [18/50], Step [392/469], Loss: 0.7134, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [18/50], Step [393/469], Loss: 0.5845, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [18/50], Step [394/469], Loss: 0.4974, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [18/50], Step [395/469], Loss: 0.6653, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [18/50], Step [396/469], Loss: 0.7947, batch time: 0.50, accuracy:  77.34%\n",
      "Epoch [18/50], Step [397/469], Loss: 0.6095, batch time: 0.59, accuracy:  81.25%\n",
      "Epoch [18/50], Step [398/469], Loss: 0.6739, batch time: 0.57, accuracy:  81.25%\n",
      "Epoch [18/50], Step [399/469], Loss: 0.6519, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [18/50], Step [400/469], Loss: 0.7394, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [18/50], Step [401/469], Loss: 0.6703, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [18/50], Step [402/469], Loss: 0.7850, batch time: 0.49, accuracy:  76.56%\n",
      "Epoch [18/50], Step [403/469], Loss: 0.7144, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [18/50], Step [404/469], Loss: 0.4651, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [18/50], Step [405/469], Loss: 0.5781, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [18/50], Step [406/469], Loss: 0.7414, batch time: 0.52, accuracy:  78.12%\n",
      "Epoch [18/50], Step [407/469], Loss: 0.6148, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [18/50], Step [408/469], Loss: 0.7464, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [18/50], Step [409/469], Loss: 0.5879, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [18/50], Step [410/469], Loss: 0.5827, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [411/469], Loss: 0.7040, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [18/50], Step [412/469], Loss: 0.8048, batch time: 0.51, accuracy:  79.69%\n",
      "Epoch [18/50], Step [413/469], Loss: 0.6240, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [414/469], Loss: 0.6450, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [415/469], Loss: 0.6157, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [18/50], Step [416/469], Loss: 0.7508, batch time: 0.47, accuracy:  77.34%\n",
      "Epoch [18/50], Step [417/469], Loss: 0.7265, batch time: 0.53, accuracy:  78.12%\n",
      "Epoch [18/50], Step [418/469], Loss: 0.7873, batch time: 0.55, accuracy:  75.78%\n",
      "Epoch [18/50], Step [419/469], Loss: 0.7059, batch time: 0.95, accuracy:  84.38%\n",
      "Epoch [18/50], Step [420/469], Loss: 0.5810, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [18/50], Step [421/469], Loss: 0.5572, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [18/50], Step [422/469], Loss: 0.5440, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [18/50], Step [423/469], Loss: 0.6907, batch time: 0.49, accuracy:  76.56%\n",
      "Epoch [18/50], Step [424/469], Loss: 0.5393, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [18/50], Step [425/469], Loss: 0.6706, batch time: 0.46, accuracy:  76.56%\n",
      "Epoch [18/50], Step [426/469], Loss: 0.8221, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [18/50], Step [427/469], Loss: 0.4863, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [18/50], Step [428/469], Loss: 0.7141, batch time: 0.47, accuracy:  77.34%\n",
      "Epoch [18/50], Step [429/469], Loss: 0.6664, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [18/50], Step [430/469], Loss: 0.7108, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [18/50], Step [431/469], Loss: 0.5958, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [18/50], Step [432/469], Loss: 0.6697, batch time: 0.53, accuracy:  76.56%\n",
      "Epoch [18/50], Step [433/469], Loss: 0.6706, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [18/50], Step [434/469], Loss: 0.6486, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [18/50], Step [435/469], Loss: 0.4908, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [18/50], Step [436/469], Loss: 0.5317, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [18/50], Step [437/469], Loss: 0.5996, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [18/50], Step [438/469], Loss: 0.6788, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [18/50], Step [439/469], Loss: 0.8821, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [18/50], Step [440/469], Loss: 0.7131, batch time: 0.55, accuracy:  80.47%\n",
      "Epoch [18/50], Step [441/469], Loss: 0.6025, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [18/50], Step [442/469], Loss: 0.8106, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [18/50], Step [443/469], Loss: 0.5260, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [18/50], Step [444/469], Loss: 0.6808, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [18/50], Step [445/469], Loss: 0.7054, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [18/50], Step [446/469], Loss: 0.6801, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [18/50], Step [447/469], Loss: 0.7364, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [18/50], Step [448/469], Loss: 0.5744, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [18/50], Step [449/469], Loss: 0.5829, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [18/50], Step [450/469], Loss: 0.5760, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [18/50], Step [451/469], Loss: 0.6781, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [18/50], Step [452/469], Loss: 0.5545, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [18/50], Step [453/469], Loss: 0.5925, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [18/50], Step [454/469], Loss: 0.6078, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [18/50], Step [455/469], Loss: 0.5672, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [18/50], Step [456/469], Loss: 0.6715, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [457/469], Loss: 0.6297, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [18/50], Step [458/469], Loss: 0.5654, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [18/50], Step [459/469], Loss: 0.6700, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [18/50], Step [460/469], Loss: 0.5866, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [18/50], Step [461/469], Loss: 0.5895, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [18/50], Step [462/469], Loss: 0.6797, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [18/50], Step [463/469], Loss: 0.7509, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [18/50], Step [464/469], Loss: 0.5514, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [18/50], Step [465/469], Loss: 0.5065, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [18/50], Step [466/469], Loss: 0.6678, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [18/50], Step [467/469], Loss: 0.5735, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [18/50], Step [468/469], Loss: 0.5780, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [18/50], Step [469/469], Loss: 0.6810, batch time: 0.56, accuracy:  80.21%\n",
      "Epoch [19/50], Step [1/469], Loss: 0.6907, batch time: 0.64, accuracy:  78.12%\n",
      "Epoch [19/50], Step [2/469], Loss: 0.5941, batch time: 0.63, accuracy:  85.94%\n",
      "Epoch [19/50], Step [3/469], Loss: 0.6071, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [19/50], Step [4/469], Loss: 0.6800, batch time: 0.45, accuracy:  73.44%\n",
      "Epoch [19/50], Step [5/469], Loss: 0.6511, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [19/50], Step [6/469], Loss: 0.7207, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [19/50], Step [7/469], Loss: 0.4470, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [19/50], Step [8/469], Loss: 0.6243, batch time: 0.61, accuracy:  79.69%\n",
      "Epoch [19/50], Step [9/469], Loss: 0.7074, batch time: 0.47, accuracy:  75.78%\n",
      "Epoch [19/50], Step [10/469], Loss: 0.5329, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [19/50], Step [11/469], Loss: 0.5971, batch time: 0.56, accuracy:  80.47%\n",
      "Epoch [19/50], Step [12/469], Loss: 0.7451, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [19/50], Step [13/469], Loss: 0.7774, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [19/50], Step [14/469], Loss: 0.5429, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [19/50], Step [15/469], Loss: 0.7189, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [19/50], Step [16/469], Loss: 0.4065, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [19/50], Step [17/469], Loss: 0.5709, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [19/50], Step [18/469], Loss: 0.4627, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [19/50], Step [19/469], Loss: 0.5920, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [19/50], Step [20/469], Loss: 0.5944, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [19/50], Step [21/469], Loss: 0.6399, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [22/469], Loss: 0.6210, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [19/50], Step [23/469], Loss: 0.7487, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [19/50], Step [24/469], Loss: 0.7140, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [19/50], Step [25/469], Loss: 0.5812, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [26/469], Loss: 0.6277, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [27/469], Loss: 0.7512, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [19/50], Step [28/469], Loss: 0.5683, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [19/50], Step [29/469], Loss: 0.6141, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [30/469], Loss: 0.7249, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [19/50], Step [31/469], Loss: 0.7636, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [19/50], Step [32/469], Loss: 0.6079, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [19/50], Step [33/469], Loss: 0.5607, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [19/50], Step [34/469], Loss: 0.8062, batch time: 0.50, accuracy:  75.00%\n",
      "Epoch [19/50], Step [35/469], Loss: 1.0530, batch time: 0.50, accuracy:  77.34%\n",
      "Epoch [19/50], Step [36/469], Loss: 0.6689, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [19/50], Step [37/469], Loss: 0.4182, batch time: 0.79, accuracy:  89.84%\n",
      "Epoch [19/50], Step [38/469], Loss: 0.6691, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [19/50], Step [39/469], Loss: 0.6745, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [19/50], Step [40/469], Loss: 0.6174, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [19/50], Step [41/469], Loss: 0.6991, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [19/50], Step [42/469], Loss: 0.5573, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [19/50], Step [43/469], Loss: 0.6683, batch time: 0.51, accuracy:  79.69%\n",
      "Epoch [19/50], Step [44/469], Loss: 0.6714, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [19/50], Step [45/469], Loss: 0.7431, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [19/50], Step [46/469], Loss: 0.6730, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [19/50], Step [47/469], Loss: 0.7127, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [19/50], Step [48/469], Loss: 0.7281, batch time: 0.51, accuracy:  75.78%\n",
      "Epoch [19/50], Step [49/469], Loss: 0.5903, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [19/50], Step [50/469], Loss: 0.5329, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [19/50], Step [51/469], Loss: 0.7265, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [19/50], Step [52/469], Loss: 0.3543, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [19/50], Step [53/469], Loss: 0.5668, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [19/50], Step [54/469], Loss: 0.8555, batch time: 0.46, accuracy:  71.09%\n",
      "Epoch [19/50], Step [55/469], Loss: 0.6043, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [56/469], Loss: 0.4601, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [19/50], Step [57/469], Loss: 0.6024, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [19/50], Step [58/469], Loss: 0.5584, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [59/469], Loss: 0.7540, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [19/50], Step [60/469], Loss: 0.5649, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [19/50], Step [61/469], Loss: 0.4967, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [19/50], Step [62/469], Loss: 0.4465, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [19/50], Step [63/469], Loss: 0.5643, batch time: 0.56, accuracy:  81.25%\n",
      "Epoch [19/50], Step [64/469], Loss: 0.5706, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [19/50], Step [65/469], Loss: 0.6149, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [19/50], Step [66/469], Loss: 0.5451, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [19/50], Step [67/469], Loss: 0.5260, batch time: 1.14, accuracy:  82.81%\n",
      "Epoch [19/50], Step [68/469], Loss: 0.5796, batch time: 0.51, accuracy:  78.12%\n",
      "Epoch [19/50], Step [69/469], Loss: 0.6610, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [70/469], Loss: 0.6770, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [19/50], Step [71/469], Loss: 0.5034, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [72/469], Loss: 0.5682, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [19/50], Step [73/469], Loss: 0.5179, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [19/50], Step [74/469], Loss: 0.5215, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [19/50], Step [75/469], Loss: 0.6786, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [19/50], Step [76/469], Loss: 0.3448, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [19/50], Step [77/469], Loss: 0.6727, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [78/469], Loss: 0.7228, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [79/469], Loss: 0.4799, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [19/50], Step [80/469], Loss: 0.6134, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [19/50], Step [81/469], Loss: 0.5827, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [19/50], Step [82/469], Loss: 0.6656, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [19/50], Step [83/469], Loss: 0.8849, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [19/50], Step [84/469], Loss: 0.4169, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [19/50], Step [85/469], Loss: 0.5497, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [19/50], Step [86/469], Loss: 0.5668, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [19/50], Step [87/469], Loss: 0.6458, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [88/469], Loss: 0.5622, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [89/469], Loss: 0.5040, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [19/50], Step [90/469], Loss: 0.8555, batch time: 0.44, accuracy:  73.44%\n",
      "Epoch [19/50], Step [91/469], Loss: 0.7228, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [92/469], Loss: 0.7487, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [19/50], Step [93/469], Loss: 0.7775, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [94/469], Loss: 0.6618, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [19/50], Step [95/469], Loss: 0.7645, batch time: 0.52, accuracy:  76.56%\n",
      "Epoch [19/50], Step [96/469], Loss: 0.6337, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [97/469], Loss: 0.6421, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [19/50], Step [98/469], Loss: 0.7132, batch time: 0.47, accuracy:  76.56%\n",
      "Epoch [19/50], Step [99/469], Loss: 0.5001, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [19/50], Step [100/469], Loss: 0.6248, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [19/50], Step [101/469], Loss: 0.8621, batch time: 0.53, accuracy:  75.00%\n",
      "Epoch [19/50], Step [102/469], Loss: 0.6437, batch time: 0.79, accuracy:  82.03%\n",
      "Epoch [19/50], Step [103/469], Loss: 0.6063, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [104/469], Loss: 0.6687, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [19/50], Step [105/469], Loss: 0.4708, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [106/469], Loss: 0.5449, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [19/50], Step [107/469], Loss: 0.7460, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [19/50], Step [108/469], Loss: 0.6044, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [109/469], Loss: 0.6303, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [19/50], Step [110/469], Loss: 0.3964, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [19/50], Step [111/469], Loss: 0.5707, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [19/50], Step [112/469], Loss: 0.6937, batch time: 0.49, accuracy:  77.34%\n",
      "Epoch [19/50], Step [113/469], Loss: 0.6821, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [19/50], Step [114/469], Loss: 0.7056, batch time: 0.44, accuracy:  74.22%\n",
      "Epoch [19/50], Step [115/469], Loss: 0.7098, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [19/50], Step [116/469], Loss: 0.5870, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [19/50], Step [117/469], Loss: 0.5887, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [19/50], Step [118/469], Loss: 0.5218, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [19/50], Step [119/469], Loss: 0.6524, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [19/50], Step [120/469], Loss: 0.6843, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [19/50], Step [121/469], Loss: 0.6956, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [19/50], Step [122/469], Loss: 0.5925, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [19/50], Step [123/469], Loss: 0.5600, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [19/50], Step [124/469], Loss: 0.7161, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [19/50], Step [125/469], Loss: 0.7340, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [19/50], Step [126/469], Loss: 0.6482, batch time: 0.54, accuracy:  77.34%\n",
      "Epoch [19/50], Step [127/469], Loss: 0.5498, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [128/469], Loss: 0.5816, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [19/50], Step [129/469], Loss: 0.7073, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [130/469], Loss: 0.5520, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [131/469], Loss: 0.5972, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [19/50], Step [132/469], Loss: 0.6595, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [133/469], Loss: 0.5554, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [19/50], Step [134/469], Loss: 0.7969, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [19/50], Step [135/469], Loss: 0.6461, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [19/50], Step [136/469], Loss: 0.5688, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [19/50], Step [137/469], Loss: 0.5773, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [19/50], Step [138/469], Loss: 0.5291, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [19/50], Step [139/469], Loss: 0.6066, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [19/50], Step [140/469], Loss: 0.6558, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [19/50], Step [141/469], Loss: 0.6307, batch time: 0.57, accuracy:  81.25%\n",
      "Epoch [19/50], Step [142/469], Loss: 0.6777, batch time: 0.47, accuracy:  76.56%\n",
      "Epoch [19/50], Step [143/469], Loss: 0.5171, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [144/469], Loss: 0.8391, batch time: 0.48, accuracy:  70.31%\n",
      "Epoch [19/50], Step [145/469], Loss: 0.5317, batch time: 1.15, accuracy:  78.91%\n",
      "Epoch [19/50], Step [146/469], Loss: 0.5693, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [19/50], Step [147/469], Loss: 0.7784, batch time: 0.49, accuracy:  75.00%\n",
      "Epoch [19/50], Step [148/469], Loss: 0.5110, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [19/50], Step [149/469], Loss: 0.6835, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [150/469], Loss: 0.6724, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [19/50], Step [151/469], Loss: 0.5498, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [19/50], Step [152/469], Loss: 0.5123, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [19/50], Step [153/469], Loss: 0.4799, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [19/50], Step [154/469], Loss: 0.8947, batch time: 0.47, accuracy:  68.75%\n",
      "Epoch [19/50], Step [155/469], Loss: 0.7150, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [19/50], Step [156/469], Loss: 0.7258, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [157/469], Loss: 0.7230, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [19/50], Step [158/469], Loss: 0.5768, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [19/50], Step [159/469], Loss: 0.6044, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [19/50], Step [160/469], Loss: 0.6328, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [19/50], Step [161/469], Loss: 0.7751, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [162/469], Loss: 0.5071, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [19/50], Step [163/469], Loss: 0.8000, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [164/469], Loss: 0.7192, batch time: 0.53, accuracy:  78.12%\n",
      "Epoch [19/50], Step [165/469], Loss: 0.6237, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [19/50], Step [166/469], Loss: 0.5660, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [19/50], Step [167/469], Loss: 0.7165, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [19/50], Step [168/469], Loss: 0.7041, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [19/50], Step [169/469], Loss: 0.8351, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [170/469], Loss: 0.5348, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [171/469], Loss: 0.4270, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [19/50], Step [172/469], Loss: 0.7188, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [19/50], Step [173/469], Loss: 0.8737, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [19/50], Step [174/469], Loss: 0.6258, batch time: 0.52, accuracy:  78.91%\n",
      "Epoch [19/50], Step [175/469], Loss: 0.6613, batch time: 0.94, accuracy:  81.25%\n",
      "Epoch [19/50], Step [176/469], Loss: 0.6257, batch time: 0.47, accuracy:  77.34%\n",
      "Epoch [19/50], Step [177/469], Loss: 0.6315, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [178/469], Loss: 0.7964, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [179/469], Loss: 0.5270, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [19/50], Step [180/469], Loss: 0.7520, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [19/50], Step [181/469], Loss: 0.5199, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [19/50], Step [182/469], Loss: 0.4670, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [19/50], Step [183/469], Loss: 0.4746, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [19/50], Step [184/469], Loss: 0.6763, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [19/50], Step [185/469], Loss: 0.7985, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [19/50], Step [186/469], Loss: 0.6726, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [19/50], Step [187/469], Loss: 0.6202, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [188/469], Loss: 0.5676, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [19/50], Step [189/469], Loss: 0.5308, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [190/469], Loss: 0.7461, batch time: 0.47, accuracy:  76.56%\n",
      "Epoch [19/50], Step [191/469], Loss: 0.6554, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [192/469], Loss: 0.4031, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [19/50], Step [193/469], Loss: 0.4912, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [19/50], Step [194/469], Loss: 0.7254, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [19/50], Step [195/469], Loss: 0.7739, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [196/469], Loss: 0.6455, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [197/469], Loss: 0.4999, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [19/50], Step [198/469], Loss: 0.5226, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [199/469], Loss: 0.6028, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [19/50], Step [200/469], Loss: 0.7528, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [19/50], Step [201/469], Loss: 0.7803, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [19/50], Step [202/469], Loss: 0.5163, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [203/469], Loss: 0.5737, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [204/469], Loss: 0.6999, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [205/469], Loss: 0.9010, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [19/50], Step [206/469], Loss: 0.6393, batch time: 0.61, accuracy:  78.12%\n",
      "Epoch [19/50], Step [207/469], Loss: 0.4982, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [208/469], Loss: 0.5688, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [209/469], Loss: 0.5921, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [210/469], Loss: 0.6850, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [19/50], Step [211/469], Loss: 0.6010, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [19/50], Step [212/469], Loss: 0.7701, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [19/50], Step [213/469], Loss: 0.6063, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [214/469], Loss: 0.9232, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [19/50], Step [215/469], Loss: 0.8497, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [19/50], Step [216/469], Loss: 0.4694, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [19/50], Step [217/469], Loss: 0.6066, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [19/50], Step [218/469], Loss: 0.4420, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [19/50], Step [219/469], Loss: 0.6576, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [19/50], Step [220/469], Loss: 0.5203, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [19/50], Step [221/469], Loss: 0.6508, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [19/50], Step [222/469], Loss: 0.7244, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [19/50], Step [223/469], Loss: 0.6627, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [19/50], Step [224/469], Loss: 0.5043, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [19/50], Step [225/469], Loss: 0.6573, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [19/50], Step [226/469], Loss: 0.6197, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [19/50], Step [227/469], Loss: 0.7354, batch time: 0.50, accuracy:  75.78%\n",
      "Epoch [19/50], Step [228/469], Loss: 0.7589, batch time: 0.51, accuracy:  74.22%\n",
      "Epoch [19/50], Step [229/469], Loss: 0.6264, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [19/50], Step [230/469], Loss: 0.5289, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [19/50], Step [231/469], Loss: 0.6261, batch time: 0.54, accuracy:  80.47%\n",
      "Epoch [19/50], Step [232/469], Loss: 0.6455, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [19/50], Step [233/469], Loss: 0.5867, batch time: 0.43, accuracy:  76.56%\n",
      "Epoch [19/50], Step [234/469], Loss: 0.7754, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [19/50], Step [235/469], Loss: 0.6104, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [236/469], Loss: 0.6336, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [19/50], Step [237/469], Loss: 0.6031, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [238/469], Loss: 0.5223, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [239/469], Loss: 0.7539, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [19/50], Step [240/469], Loss: 0.4671, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [19/50], Step [241/469], Loss: 0.5737, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [19/50], Step [242/469], Loss: 0.5187, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [19/50], Step [243/469], Loss: 0.6478, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [19/50], Step [244/469], Loss: 0.5763, batch time: 0.50, accuracy:  79.69%\n",
      "Epoch [19/50], Step [245/469], Loss: 0.5961, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [19/50], Step [246/469], Loss: 0.6787, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [19/50], Step [247/469], Loss: 0.4476, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [19/50], Step [248/469], Loss: 0.7632, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [19/50], Step [249/469], Loss: 0.6757, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [19/50], Step [250/469], Loss: 0.6754, batch time: 0.43, accuracy:  72.66%\n",
      "Epoch [19/50], Step [251/469], Loss: 0.5534, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [252/469], Loss: 0.5764, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [253/469], Loss: 0.5348, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [19/50], Step [254/469], Loss: 0.7358, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [19/50], Step [255/469], Loss: 0.4334, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [19/50], Step [256/469], Loss: 0.6768, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [19/50], Step [257/469], Loss: 0.7047, batch time: 0.49, accuracy:  76.56%\n",
      "Epoch [19/50], Step [258/469], Loss: 0.6760, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [19/50], Step [259/469], Loss: 0.5489, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [260/469], Loss: 0.6710, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [19/50], Step [261/469], Loss: 0.5373, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [19/50], Step [262/469], Loss: 0.5768, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [19/50], Step [263/469], Loss: 0.5651, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [264/469], Loss: 0.4594, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [19/50], Step [265/469], Loss: 0.5247, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [19/50], Step [266/469], Loss: 0.5854, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [19/50], Step [267/469], Loss: 0.6681, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [19/50], Step [268/469], Loss: 0.5543, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [19/50], Step [269/469], Loss: 0.6443, batch time: 0.52, accuracy:  78.12%\n",
      "Epoch [19/50], Step [270/469], Loss: 0.7788, batch time: 0.47, accuracy:  69.53%\n",
      "Epoch [19/50], Step [271/469], Loss: 0.5681, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [19/50], Step [272/469], Loss: 0.7576, batch time: 0.53, accuracy:  79.69%\n",
      "Epoch [19/50], Step [273/469], Loss: 0.6671, batch time: 0.55, accuracy:  79.69%\n",
      "Epoch [19/50], Step [274/469], Loss: 0.5148, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [19/50], Step [275/469], Loss: 0.6159, batch time: 0.94, accuracy:  83.59%\n",
      "Epoch [19/50], Step [276/469], Loss: 0.7673, batch time: 0.52, accuracy:  77.34%\n",
      "Epoch [19/50], Step [277/469], Loss: 0.6814, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [278/469], Loss: 0.6818, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [19/50], Step [279/469], Loss: 0.5530, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [19/50], Step [280/469], Loss: 0.9134, batch time: 0.44, accuracy:  71.88%\n",
      "Epoch [19/50], Step [281/469], Loss: 0.7374, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [19/50], Step [282/469], Loss: 0.5818, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [283/469], Loss: 0.5828, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [284/469], Loss: 0.7499, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [19/50], Step [285/469], Loss: 0.6279, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [19/50], Step [286/469], Loss: 0.5955, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [287/469], Loss: 0.7414, batch time: 0.50, accuracy:  75.00%\n",
      "Epoch [19/50], Step [288/469], Loss: 0.5338, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [19/50], Step [289/469], Loss: 0.7587, batch time: 0.53, accuracy:  80.47%\n",
      "Epoch [19/50], Step [290/469], Loss: 0.5091, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [19/50], Step [291/469], Loss: 0.6657, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [19/50], Step [292/469], Loss: 0.5762, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [19/50], Step [293/469], Loss: 0.6983, batch time: 0.50, accuracy:  77.34%\n",
      "Epoch [19/50], Step [294/469], Loss: 0.6703, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [19/50], Step [295/469], Loss: 0.5802, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [19/50], Step [296/469], Loss: 0.5880, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [19/50], Step [297/469], Loss: 0.6943, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [19/50], Step [298/469], Loss: 0.4778, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [19/50], Step [299/469], Loss: 0.6062, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [19/50], Step [300/469], Loss: 0.6170, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [19/50], Step [301/469], Loss: 0.6219, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [19/50], Step [302/469], Loss: 0.7310, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [303/469], Loss: 0.4813, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [19/50], Step [304/469], Loss: 0.5653, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [19/50], Step [305/469], Loss: 0.7092, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [306/469], Loss: 0.3989, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [19/50], Step [307/469], Loss: 0.5173, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [19/50], Step [308/469], Loss: 0.7479, batch time: 1.02, accuracy:  79.69%\n",
      "Epoch [19/50], Step [309/469], Loss: 0.8140, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [19/50], Step [310/469], Loss: 0.5566, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [19/50], Step [311/469], Loss: 0.4507, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [19/50], Step [312/469], Loss: 0.6699, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [313/469], Loss: 0.6125, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [19/50], Step [314/469], Loss: 0.5445, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [315/469], Loss: 0.5408, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [19/50], Step [316/469], Loss: 0.7587, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [19/50], Step [317/469], Loss: 0.4215, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [19/50], Step [318/469], Loss: 0.5395, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [19/50], Step [319/469], Loss: 0.6639, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [19/50], Step [320/469], Loss: 0.6340, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [321/469], Loss: 0.5291, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [322/469], Loss: 0.5465, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [323/469], Loss: 0.4615, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [19/50], Step [324/469], Loss: 0.6164, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [19/50], Step [325/469], Loss: 0.4061, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [19/50], Step [326/469], Loss: 0.5548, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [327/469], Loss: 0.7266, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [19/50], Step [328/469], Loss: 0.5891, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [19/50], Step [329/469], Loss: 0.5483, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [19/50], Step [330/469], Loss: 0.6478, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [19/50], Step [331/469], Loss: 0.7292, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [19/50], Step [332/469], Loss: 0.4308, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [19/50], Step [333/469], Loss: 0.6676, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [334/469], Loss: 0.4045, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [19/50], Step [335/469], Loss: 0.6609, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [19/50], Step [336/469], Loss: 0.4061, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [19/50], Step [337/469], Loss: 0.5431, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [19/50], Step [338/469], Loss: 0.7218, batch time: 0.49, accuracy:  75.78%\n",
      "Epoch [19/50], Step [339/469], Loss: 0.4488, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [19/50], Step [340/469], Loss: 0.6764, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [19/50], Step [341/469], Loss: 0.6943, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [19/50], Step [342/469], Loss: 0.5645, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [19/50], Step [343/469], Loss: 0.5627, batch time: 0.58, accuracy:  82.03%\n",
      "Epoch [19/50], Step [344/469], Loss: 0.7297, batch time: 1.21, accuracy:  77.34%\n",
      "Epoch [19/50], Step [345/469], Loss: 0.6183, batch time: 0.49, accuracy:  77.34%\n",
      "Epoch [19/50], Step [346/469], Loss: 0.6596, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [19/50], Step [347/469], Loss: 0.5785, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [348/469], Loss: 0.4960, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [349/469], Loss: 0.7499, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [19/50], Step [350/469], Loss: 0.6365, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [19/50], Step [351/469], Loss: 0.8897, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [19/50], Step [352/469], Loss: 0.5833, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [353/469], Loss: 0.5368, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [19/50], Step [354/469], Loss: 0.5756, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [19/50], Step [355/469], Loss: 0.6554, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [19/50], Step [356/469], Loss: 0.7020, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [19/50], Step [357/469], Loss: 0.4981, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [19/50], Step [358/469], Loss: 0.4795, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [19/50], Step [359/469], Loss: 0.7565, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [19/50], Step [360/469], Loss: 0.6646, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [19/50], Step [361/469], Loss: 0.7112, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [19/50], Step [362/469], Loss: 0.7123, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [19/50], Step [363/469], Loss: 0.5859, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [19/50], Step [364/469], Loss: 0.5940, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [19/50], Step [365/469], Loss: 0.4461, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [19/50], Step [366/469], Loss: 0.8182, batch time: 0.49, accuracy:  74.22%\n",
      "Epoch [19/50], Step [367/469], Loss: 0.4541, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [19/50], Step [368/469], Loss: 0.8057, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [369/469], Loss: 0.6603, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [19/50], Step [370/469], Loss: 0.5382, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [19/50], Step [371/469], Loss: 0.8584, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [19/50], Step [372/469], Loss: 0.5689, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [19/50], Step [373/469], Loss: 0.6010, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [19/50], Step [374/469], Loss: 0.6479, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [19/50], Step [375/469], Loss: 0.6393, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [19/50], Step [376/469], Loss: 0.5178, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [19/50], Step [377/469], Loss: 0.5724, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [19/50], Step [378/469], Loss: 0.6851, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [19/50], Step [379/469], Loss: 0.7405, batch time: 0.55, accuracy:  78.91%\n",
      "Epoch [19/50], Step [380/469], Loss: 0.6104, batch time: 0.89, accuracy:  79.69%\n",
      "Epoch [19/50], Step [381/469], Loss: 0.6585, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [382/469], Loss: 0.6904, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [19/50], Step [383/469], Loss: 0.6537, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [19/50], Step [384/469], Loss: 0.4724, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [19/50], Step [385/469], Loss: 0.6430, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [19/50], Step [386/469], Loss: 0.5558, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [387/469], Loss: 0.5938, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [19/50], Step [388/469], Loss: 0.6479, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [389/469], Loss: 0.6925, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [19/50], Step [390/469], Loss: 0.6372, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [19/50], Step [391/469], Loss: 0.5917, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [392/469], Loss: 0.6881, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [19/50], Step [393/469], Loss: 0.5781, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [394/469], Loss: 0.5458, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [19/50], Step [395/469], Loss: 0.5249, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [19/50], Step [396/469], Loss: 0.4786, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [19/50], Step [397/469], Loss: 0.6056, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [19/50], Step [398/469], Loss: 0.7281, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [19/50], Step [399/469], Loss: 0.6112, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [19/50], Step [400/469], Loss: 0.7191, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [19/50], Step [401/469], Loss: 0.4319, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [19/50], Step [402/469], Loss: 0.6871, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [19/50], Step [403/469], Loss: 0.5724, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [404/469], Loss: 0.6101, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [405/469], Loss: 0.5509, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [19/50], Step [406/469], Loss: 0.5593, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [19/50], Step [407/469], Loss: 0.7239, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [408/469], Loss: 0.6122, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [19/50], Step [409/469], Loss: 0.7640, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [410/469], Loss: 0.5685, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [19/50], Step [411/469], Loss: 0.4673, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [19/50], Step [412/469], Loss: 0.5503, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [19/50], Step [413/469], Loss: 0.7369, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [19/50], Step [414/469], Loss: 0.6232, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [19/50], Step [415/469], Loss: 0.5893, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [416/469], Loss: 0.6722, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [19/50], Step [417/469], Loss: 0.5960, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [19/50], Step [418/469], Loss: 0.4069, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [19/50], Step [419/469], Loss: 0.4965, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [19/50], Step [420/469], Loss: 0.5419, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [19/50], Step [421/469], Loss: 0.5580, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [19/50], Step [422/469], Loss: 0.6378, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [423/469], Loss: 0.4049, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [19/50], Step [424/469], Loss: 0.6699, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [19/50], Step [425/469], Loss: 0.5287, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [19/50], Step [426/469], Loss: 0.6558, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [427/469], Loss: 0.5885, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [428/469], Loss: 0.5589, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [19/50], Step [429/469], Loss: 0.5709, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [19/50], Step [430/469], Loss: 0.6612, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [19/50], Step [431/469], Loss: 0.5987, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [19/50], Step [432/469], Loss: 0.5519, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [19/50], Step [433/469], Loss: 0.7011, batch time: 0.51, accuracy:  78.12%\n",
      "Epoch [19/50], Step [434/469], Loss: 0.6543, batch time: 0.52, accuracy:  78.12%\n",
      "Epoch [19/50], Step [435/469], Loss: 0.5489, batch time: 0.61, accuracy:  82.03%\n",
      "Epoch [19/50], Step [436/469], Loss: 0.6780, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [19/50], Step [437/469], Loss: 0.5451, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [19/50], Step [438/469], Loss: 0.5697, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [19/50], Step [439/469], Loss: 0.5994, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [19/50], Step [440/469], Loss: 0.5240, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [19/50], Step [441/469], Loss: 0.5662, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [19/50], Step [442/469], Loss: 0.5267, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [19/50], Step [443/469], Loss: 0.7332, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [19/50], Step [444/469], Loss: 0.4905, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [19/50], Step [445/469], Loss: 0.6818, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [19/50], Step [446/469], Loss: 0.5077, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [19/50], Step [447/469], Loss: 0.4333, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [19/50], Step [448/469], Loss: 0.7198, batch time: 0.54, accuracy:  78.12%\n",
      "Epoch [19/50], Step [449/469], Loss: 0.6005, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [19/50], Step [450/469], Loss: 0.4792, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [19/50], Step [451/469], Loss: 0.6039, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [19/50], Step [452/469], Loss: 0.8230, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [19/50], Step [453/469], Loss: 0.6129, batch time: 0.56, accuracy:  80.47%\n",
      "Epoch [19/50], Step [454/469], Loss: 0.7627, batch time: 0.50, accuracy:  75.78%\n",
      "Epoch [19/50], Step [455/469], Loss: 0.6666, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [19/50], Step [456/469], Loss: 0.4476, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [19/50], Step [457/469], Loss: 0.7499, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [19/50], Step [458/469], Loss: 0.5325, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [19/50], Step [459/469], Loss: 0.8143, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [19/50], Step [460/469], Loss: 0.5050, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [19/50], Step [461/469], Loss: 0.5936, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [19/50], Step [462/469], Loss: 0.6902, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [19/50], Step [463/469], Loss: 0.5734, batch time: 0.57, accuracy:  78.12%\n",
      "Epoch [19/50], Step [464/469], Loss: 0.6911, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [19/50], Step [465/469], Loss: 0.8375, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [19/50], Step [466/469], Loss: 0.5768, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [19/50], Step [467/469], Loss: 0.6029, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [19/50], Step [468/469], Loss: 0.5412, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [19/50], Step [469/469], Loss: 0.7061, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [20/50], Step [1/469], Loss: 0.5212, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [20/50], Step [2/469], Loss: 0.6886, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [20/50], Step [3/469], Loss: 0.6123, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [4/469], Loss: 0.6279, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [5/469], Loss: 0.6881, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [20/50], Step [6/469], Loss: 0.5537, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [7/469], Loss: 0.6820, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [20/50], Step [8/469], Loss: 0.7117, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [20/50], Step [9/469], Loss: 0.5213, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [20/50], Step [10/469], Loss: 0.8823, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [20/50], Step [11/469], Loss: 0.5824, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [20/50], Step [12/469], Loss: 0.6800, batch time: 0.51, accuracy:  78.12%\n",
      "Epoch [20/50], Step [13/469], Loss: 0.5003, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [14/469], Loss: 0.5986, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [20/50], Step [15/469], Loss: 0.5538, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [20/50], Step [16/469], Loss: 0.5503, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [20/50], Step [17/469], Loss: 0.7424, batch time: 0.49, accuracy:  78.12%\n",
      "Epoch [20/50], Step [18/469], Loss: 0.7517, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [20/50], Step [19/469], Loss: 0.6088, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [20/50], Step [20/469], Loss: 0.5134, batch time: 0.59, accuracy:  81.25%\n",
      "Epoch [20/50], Step [21/469], Loss: 0.6751, batch time: 0.55, accuracy:  78.12%\n",
      "Epoch [20/50], Step [22/469], Loss: 0.6008, batch time: 0.65, accuracy:  82.81%\n",
      "Epoch [20/50], Step [23/469], Loss: 0.5974, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [20/50], Step [24/469], Loss: 0.5675, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [20/50], Step [25/469], Loss: 0.4532, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [20/50], Step [26/469], Loss: 0.6923, batch time: 0.50, accuracy:  77.34%\n",
      "Epoch [20/50], Step [27/469], Loss: 0.6512, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [20/50], Step [28/469], Loss: 0.5662, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [29/469], Loss: 0.6464, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [30/469], Loss: 0.5906, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [20/50], Step [31/469], Loss: 0.5798, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [20/50], Step [32/469], Loss: 0.7437, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [33/469], Loss: 0.5567, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [20/50], Step [34/469], Loss: 0.6207, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [35/469], Loss: 0.4858, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [20/50], Step [36/469], Loss: 0.5904, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [20/50], Step [37/469], Loss: 0.7625, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [20/50], Step [38/469], Loss: 0.5921, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [20/50], Step [39/469], Loss: 0.4402, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [20/50], Step [40/469], Loss: 0.5916, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [20/50], Step [41/469], Loss: 0.5412, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [20/50], Step [42/469], Loss: 0.5967, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [20/50], Step [43/469], Loss: 0.5447, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [44/469], Loss: 0.7634, batch time: 0.45, accuracy:  74.22%\n",
      "Epoch [20/50], Step [45/469], Loss: 0.5750, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [20/50], Step [46/469], Loss: 0.6824, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [20/50], Step [47/469], Loss: 0.7756, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [20/50], Step [48/469], Loss: 0.5411, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [49/469], Loss: 0.4253, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [20/50], Step [50/469], Loss: 0.6291, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [51/469], Loss: 0.4991, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [20/50], Step [52/469], Loss: 0.5890, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [20/50], Step [53/469], Loss: 0.5823, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [20/50], Step [54/469], Loss: 0.7097, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [55/469], Loss: 0.6387, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [20/50], Step [56/469], Loss: 0.5711, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [20/50], Step [57/469], Loss: 0.6489, batch time: 0.89, accuracy:  80.47%\n",
      "Epoch [20/50], Step [58/469], Loss: 0.4821, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [20/50], Step [59/469], Loss: 0.8161, batch time: 0.50, accuracy:  72.66%\n",
      "Epoch [20/50], Step [60/469], Loss: 0.6586, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [20/50], Step [61/469], Loss: 0.5144, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [20/50], Step [62/469], Loss: 0.4275, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [20/50], Step [63/469], Loss: 0.7618, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [20/50], Step [64/469], Loss: 0.7954, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [65/469], Loss: 0.5751, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [66/469], Loss: 0.4797, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [67/469], Loss: 0.5922, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [20/50], Step [68/469], Loss: 0.6860, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [20/50], Step [69/469], Loss: 0.7500, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [20/50], Step [70/469], Loss: 0.5316, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [71/469], Loss: 0.7059, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [72/469], Loss: 0.4581, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [20/50], Step [73/469], Loss: 0.5850, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [20/50], Step [74/469], Loss: 0.5058, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [75/469], Loss: 0.5973, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [20/50], Step [76/469], Loss: 0.7110, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [20/50], Step [77/469], Loss: 0.5613, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [78/469], Loss: 0.5049, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [79/469], Loss: 0.5065, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [80/469], Loss: 0.7114, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [81/469], Loss: 0.5068, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [20/50], Step [82/469], Loss: 0.5053, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [83/469], Loss: 0.6498, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [84/469], Loss: 0.5112, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [85/469], Loss: 0.5189, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [20/50], Step [86/469], Loss: 0.5264, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [20/50], Step [87/469], Loss: 0.6567, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [20/50], Step [88/469], Loss: 0.6998, batch time: 0.53, accuracy:  80.47%\n",
      "Epoch [20/50], Step [89/469], Loss: 0.5174, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [20/50], Step [90/469], Loss: 0.7199, batch time: 0.68, accuracy:  83.59%\n",
      "Epoch [20/50], Step [91/469], Loss: 0.5770, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [20/50], Step [92/469], Loss: 0.5964, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [93/469], Loss: 0.6451, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [94/469], Loss: 0.6292, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [20/50], Step [95/469], Loss: 0.4908, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [20/50], Step [96/469], Loss: 0.5400, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [20/50], Step [97/469], Loss: 0.5304, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [20/50], Step [98/469], Loss: 0.5045, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [20/50], Step [99/469], Loss: 0.6351, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [20/50], Step [100/469], Loss: 0.6308, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [20/50], Step [101/469], Loss: 0.6377, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [20/50], Step [102/469], Loss: 0.5705, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [103/469], Loss: 0.5254, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [20/50], Step [104/469], Loss: 0.5987, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [20/50], Step [105/469], Loss: 0.6162, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [20/50], Step [106/469], Loss: 0.6754, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [20/50], Step [107/469], Loss: 0.5079, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [20/50], Step [108/469], Loss: 0.5338, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [20/50], Step [109/469], Loss: 0.4643, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [20/50], Step [110/469], Loss: 0.5195, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [111/469], Loss: 0.5978, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [112/469], Loss: 0.3905, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [20/50], Step [113/469], Loss: 0.7486, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [20/50], Step [114/469], Loss: 0.7003, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [20/50], Step [115/469], Loss: 0.4710, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [20/50], Step [116/469], Loss: 0.5803, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [117/469], Loss: 0.4990, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [118/469], Loss: 0.7448, batch time: 0.48, accuracy:  71.88%\n",
      "Epoch [20/50], Step [119/469], Loss: 0.4087, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [20/50], Step [120/469], Loss: 0.7131, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [20/50], Step [121/469], Loss: 0.6605, batch time: 0.51, accuracy:  79.69%\n",
      "Epoch [20/50], Step [122/469], Loss: 0.5383, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [123/469], Loss: 0.4257, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [20/50], Step [124/469], Loss: 0.6889, batch time: 0.46, accuracy:  75.00%\n",
      "Epoch [20/50], Step [125/469], Loss: 0.7427, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [20/50], Step [126/469], Loss: 0.3885, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [20/50], Step [127/469], Loss: 0.5791, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [20/50], Step [128/469], Loss: 0.4625, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [20/50], Step [129/469], Loss: 0.5314, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [130/469], Loss: 0.4751, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [20/50], Step [131/469], Loss: 0.7658, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [132/469], Loss: 0.5977, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [133/469], Loss: 0.5735, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [20/50], Step [134/469], Loss: 0.8150, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [20/50], Step [135/469], Loss: 0.5040, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [136/469], Loss: 0.5875, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [137/469], Loss: 0.5936, batch time: 0.54, accuracy:  79.69%\n",
      "Epoch [20/50], Step [138/469], Loss: 0.4175, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [20/50], Step [139/469], Loss: 0.6211, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [20/50], Step [140/469], Loss: 0.7024, batch time: 0.57, accuracy:  76.56%\n",
      "Epoch [20/50], Step [141/469], Loss: 0.6151, batch time: 0.69, accuracy:  85.16%\n",
      "Epoch [20/50], Step [142/469], Loss: 0.4102, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [20/50], Step [143/469], Loss: 0.6422, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [20/50], Step [144/469], Loss: 0.6798, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [20/50], Step [145/469], Loss: 0.4988, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [20/50], Step [146/469], Loss: 0.5683, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [20/50], Step [147/469], Loss: 0.6459, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [20/50], Step [148/469], Loss: 0.4407, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [20/50], Step [149/469], Loss: 0.6863, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [20/50], Step [150/469], Loss: 0.5591, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [151/469], Loss: 0.6365, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [20/50], Step [152/469], Loss: 0.4953, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [20/50], Step [153/469], Loss: 0.4761, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [20/50], Step [154/469], Loss: 0.5763, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [20/50], Step [155/469], Loss: 0.6252, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [156/469], Loss: 0.4670, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [157/469], Loss: 0.5377, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [158/469], Loss: 0.6820, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [159/469], Loss: 0.5095, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [160/469], Loss: 0.4914, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [20/50], Step [161/469], Loss: 0.6996, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [20/50], Step [162/469], Loss: 0.5826, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [20/50], Step [163/469], Loss: 0.6148, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [20/50], Step [164/469], Loss: 0.7734, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [20/50], Step [165/469], Loss: 0.8994, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [20/50], Step [166/469], Loss: 0.4633, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [20/50], Step [167/469], Loss: 0.5366, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [20/50], Step [168/469], Loss: 0.7103, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [20/50], Step [169/469], Loss: 0.6209, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [20/50], Step [170/469], Loss: 0.6516, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [20/50], Step [171/469], Loss: 0.6282, batch time: 0.60, accuracy:  81.25%\n",
      "Epoch [20/50], Step [172/469], Loss: 0.6389, batch time: 0.55, accuracy:  78.12%\n",
      "Epoch [20/50], Step [173/469], Loss: 0.4224, batch time: 0.91, accuracy:  85.94%\n",
      "Epoch [20/50], Step [174/469], Loss: 0.5964, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [20/50], Step [175/469], Loss: 0.6915, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [176/469], Loss: 0.4464, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [177/469], Loss: 0.6787, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [178/469], Loss: 0.6561, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [179/469], Loss: 0.6910, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [20/50], Step [180/469], Loss: 0.3515, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [20/50], Step [181/469], Loss: 0.4153, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [20/50], Step [182/469], Loss: 0.6232, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [20/50], Step [183/469], Loss: 0.6372, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [184/469], Loss: 0.7850, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [20/50], Step [185/469], Loss: 0.5798, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [20/50], Step [186/469], Loss: 0.5187, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [20/50], Step [187/469], Loss: 0.6055, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [188/469], Loss: 0.6027, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [20/50], Step [189/469], Loss: 0.3893, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [20/50], Step [190/469], Loss: 0.6282, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [20/50], Step [191/469], Loss: 0.4772, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [192/469], Loss: 0.5700, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [193/469], Loss: 0.6326, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [20/50], Step [194/469], Loss: 0.6234, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [195/469], Loss: 0.4893, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [20/50], Step [196/469], Loss: 0.5526, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [20/50], Step [197/469], Loss: 0.6536, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [20/50], Step [198/469], Loss: 0.5733, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [20/50], Step [199/469], Loss: 0.8199, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [20/50], Step [200/469], Loss: 0.8345, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [20/50], Step [201/469], Loss: 0.6642, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [20/50], Step [202/469], Loss: 0.4349, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [20/50], Step [203/469], Loss: 0.4646, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [20/50], Step [204/469], Loss: 0.6448, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [20/50], Step [205/469], Loss: 0.3942, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [20/50], Step [206/469], Loss: 0.8127, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [20/50], Step [207/469], Loss: 0.5727, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [20/50], Step [208/469], Loss: 0.5160, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [20/50], Step [209/469], Loss: 0.5590, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [20/50], Step [210/469], Loss: 0.3904, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [20/50], Step [211/469], Loss: 0.4815, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [20/50], Step [212/469], Loss: 0.4975, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [20/50], Step [213/469], Loss: 0.5404, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [20/50], Step [214/469], Loss: 0.5356, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [215/469], Loss: 0.4536, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [20/50], Step [216/469], Loss: 0.5167, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [217/469], Loss: 0.5811, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [218/469], Loss: 0.4206, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [20/50], Step [219/469], Loss: 0.5425, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [220/469], Loss: 0.7202, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [20/50], Step [221/469], Loss: 0.5752, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [222/469], Loss: 0.5477, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [20/50], Step [223/469], Loss: 0.5613, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [20/50], Step [224/469], Loss: 0.6310, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [20/50], Step [225/469], Loss: 0.4381, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [20/50], Step [226/469], Loss: 0.6700, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [20/50], Step [227/469], Loss: 0.4911, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [20/50], Step [228/469], Loss: 0.5005, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [229/469], Loss: 0.5744, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [230/469], Loss: 0.6428, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [20/50], Step [231/469], Loss: 0.6138, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [232/469], Loss: 0.5110, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [233/469], Loss: 0.5110, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [20/50], Step [234/469], Loss: 0.6484, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [20/50], Step [235/469], Loss: 0.6603, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [20/50], Step [236/469], Loss: 0.6024, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [20/50], Step [237/469], Loss: 0.6803, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [20/50], Step [238/469], Loss: 0.5250, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [20/50], Step [239/469], Loss: 0.4780, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [20/50], Step [240/469], Loss: 0.6197, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [241/469], Loss: 0.7567, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [242/469], Loss: 0.6276, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [243/469], Loss: 0.7429, batch time: 0.53, accuracy:  75.78%\n",
      "Epoch [20/50], Step [244/469], Loss: 0.6273, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [20/50], Step [245/469], Loss: 0.4696, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [20/50], Step [246/469], Loss: 0.6112, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [20/50], Step [247/469], Loss: 0.5905, batch time: 0.83, accuracy:  81.25%\n",
      "Epoch [20/50], Step [248/469], Loss: 0.4872, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [20/50], Step [249/469], Loss: 0.6127, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [20/50], Step [250/469], Loss: 0.8736, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [20/50], Step [251/469], Loss: 0.4978, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [20/50], Step [252/469], Loss: 0.4400, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [20/50], Step [253/469], Loss: 0.5074, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [20/50], Step [254/469], Loss: 0.5234, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [20/50], Step [255/469], Loss: 0.4491, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [20/50], Step [256/469], Loss: 0.8474, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [20/50], Step [257/469], Loss: 0.5636, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [20/50], Step [258/469], Loss: 0.4715, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [20/50], Step [259/469], Loss: 0.5457, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [20/50], Step [260/469], Loss: 0.5032, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [20/50], Step [261/469], Loss: 0.5075, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [20/50], Step [262/469], Loss: 0.5251, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [20/50], Step [263/469], Loss: 0.4431, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [20/50], Step [264/469], Loss: 0.6006, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [265/469], Loss: 0.6606, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [266/469], Loss: 0.7225, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [20/50], Step [267/469], Loss: 0.4306, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [20/50], Step [268/469], Loss: 0.5086, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [20/50], Step [269/469], Loss: 0.4587, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [270/469], Loss: 0.5841, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [271/469], Loss: 0.4984, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [20/50], Step [272/469], Loss: 0.5243, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [20/50], Step [273/469], Loss: 0.5453, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [20/50], Step [274/469], Loss: 0.4931, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [20/50], Step [275/469], Loss: 0.6620, batch time: 0.78, accuracy:  83.59%\n",
      "Epoch [20/50], Step [276/469], Loss: 0.6254, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [20/50], Step [277/469], Loss: 0.6943, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [278/469], Loss: 0.4982, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [279/469], Loss: 0.6330, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [20/50], Step [280/469], Loss: 0.6743, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [281/469], Loss: 0.6484, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [282/469], Loss: 0.3661, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [20/50], Step [283/469], Loss: 0.7744, batch time: 0.43, accuracy:  73.44%\n",
      "Epoch [20/50], Step [284/469], Loss: 0.4882, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [285/469], Loss: 0.4560, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [286/469], Loss: 0.7938, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [20/50], Step [287/469], Loss: 0.5013, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [20/50], Step [288/469], Loss: 0.7452, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [289/469], Loss: 0.5497, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [290/469], Loss: 0.6558, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [20/50], Step [291/469], Loss: 0.7158, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [292/469], Loss: 0.5689, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [20/50], Step [293/469], Loss: 0.6190, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [294/469], Loss: 0.7298, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [295/469], Loss: 0.5954, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [296/469], Loss: 0.4877, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [20/50], Step [297/469], Loss: 0.7621, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [298/469], Loss: 0.6058, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [20/50], Step [299/469], Loss: 0.5490, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [300/469], Loss: 0.7389, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [301/469], Loss: 0.4608, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [20/50], Step [302/469], Loss: 0.5174, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [20/50], Step [303/469], Loss: 0.4693, batch time: 0.96, accuracy:  81.25%\n",
      "Epoch [20/50], Step [304/469], Loss: 0.6798, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [20/50], Step [305/469], Loss: 0.5345, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [20/50], Step [306/469], Loss: 0.5491, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [20/50], Step [307/469], Loss: 0.5153, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [20/50], Step [308/469], Loss: 0.5533, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [20/50], Step [309/469], Loss: 0.8985, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [20/50], Step [310/469], Loss: 0.6023, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [20/50], Step [311/469], Loss: 0.4815, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [312/469], Loss: 0.5681, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [313/469], Loss: 0.5520, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [20/50], Step [314/469], Loss: 0.6955, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [20/50], Step [315/469], Loss: 0.7855, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [20/50], Step [316/469], Loss: 0.6108, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [317/469], Loss: 0.4911, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [20/50], Step [318/469], Loss: 0.5856, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [319/469], Loss: 0.4987, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [20/50], Step [320/469], Loss: 0.6558, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [20/50], Step [321/469], Loss: 0.5474, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [322/469], Loss: 0.6529, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [20/50], Step [323/469], Loss: 0.5705, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [324/469], Loss: 0.6874, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [20/50], Step [325/469], Loss: 0.4866, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [20/50], Step [326/469], Loss: 0.5340, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [327/469], Loss: 0.5747, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [328/469], Loss: 0.7234, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [20/50], Step [329/469], Loss: 0.6385, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [330/469], Loss: 0.4981, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [331/469], Loss: 0.5681, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [20/50], Step [332/469], Loss: 0.8439, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [20/50], Step [333/469], Loss: 0.6270, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [20/50], Step [334/469], Loss: 0.6832, batch time: 0.84, accuracy:  81.25%\n",
      "Epoch [20/50], Step [335/469], Loss: 0.7229, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [336/469], Loss: 0.8056, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [20/50], Step [337/469], Loss: 0.5943, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [20/50], Step [338/469], Loss: 0.4776, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [20/50], Step [339/469], Loss: 0.5234, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [20/50], Step [340/469], Loss: 0.4507, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [341/469], Loss: 0.4827, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [20/50], Step [342/469], Loss: 0.3828, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [20/50], Step [343/469], Loss: 0.7801, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [20/50], Step [344/469], Loss: 0.6835, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [345/469], Loss: 0.6971, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [20/50], Step [346/469], Loss: 0.5833, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [347/469], Loss: 0.5232, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [20/50], Step [348/469], Loss: 0.6808, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [20/50], Step [349/469], Loss: 0.4846, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [20/50], Step [350/469], Loss: 0.6103, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [351/469], Loss: 0.5632, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [352/469], Loss: 0.4724, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [20/50], Step [353/469], Loss: 0.5882, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [20/50], Step [354/469], Loss: 0.6578, batch time: 0.47, accuracy:  76.56%\n",
      "Epoch [20/50], Step [355/469], Loss: 0.5756, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [356/469], Loss: 0.6451, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [357/469], Loss: 0.4542, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [20/50], Step [358/469], Loss: 0.4767, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [20/50], Step [359/469], Loss: 0.6002, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [20/50], Step [360/469], Loss: 0.5397, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [20/50], Step [361/469], Loss: 0.4630, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [362/469], Loss: 0.5341, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [20/50], Step [363/469], Loss: 0.6601, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [20/50], Step [364/469], Loss: 0.6424, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [20/50], Step [365/469], Loss: 0.5380, batch time: 0.87, accuracy:  83.59%\n",
      "Epoch [20/50], Step [366/469], Loss: 0.4321, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [20/50], Step [367/469], Loss: 0.4736, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [368/469], Loss: 0.4015, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [20/50], Step [369/469], Loss: 0.5743, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [370/469], Loss: 0.4681, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [20/50], Step [371/469], Loss: 0.6764, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [20/50], Step [372/469], Loss: 0.4863, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [20/50], Step [373/469], Loss: 0.5999, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [20/50], Step [374/469], Loss: 0.5287, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [375/469], Loss: 0.7250, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [20/50], Step [376/469], Loss: 0.4758, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [20/50], Step [377/469], Loss: 0.4943, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [20/50], Step [378/469], Loss: 0.5802, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [20/50], Step [379/469], Loss: 0.4875, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [20/50], Step [380/469], Loss: 0.5842, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [20/50], Step [381/469], Loss: 0.4565, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [20/50], Step [382/469], Loss: 0.5120, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [20/50], Step [383/469], Loss: 0.5266, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [20/50], Step [384/469], Loss: 0.6405, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [20/50], Step [385/469], Loss: 0.4178, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [20/50], Step [386/469], Loss: 0.4975, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [20/50], Step [387/469], Loss: 0.3244, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [20/50], Step [388/469], Loss: 0.5082, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [389/469], Loss: 0.3708, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [20/50], Step [390/469], Loss: 0.6265, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [391/469], Loss: 0.5265, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [392/469], Loss: 0.5485, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [393/469], Loss: 0.6485, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [20/50], Step [394/469], Loss: 0.4942, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [20/50], Step [395/469], Loss: 0.4385, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [396/469], Loss: 0.4853, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [397/469], Loss: 0.4183, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [20/50], Step [398/469], Loss: 0.5172, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [20/50], Step [399/469], Loss: 0.5124, batch time: 0.77, accuracy:  88.28%\n",
      "Epoch [20/50], Step [400/469], Loss: 0.5799, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [401/469], Loss: 0.7855, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [402/469], Loss: 0.5043, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [403/469], Loss: 0.6153, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [20/50], Step [404/469], Loss: 0.5836, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [20/50], Step [405/469], Loss: 0.5280, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [20/50], Step [406/469], Loss: 0.3947, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [20/50], Step [407/469], Loss: 0.4963, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [20/50], Step [408/469], Loss: 0.5817, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [409/469], Loss: 0.7321, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [20/50], Step [410/469], Loss: 0.5038, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [20/50], Step [411/469], Loss: 0.4469, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [412/469], Loss: 0.3547, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [20/50], Step [413/469], Loss: 0.5809, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [20/50], Step [414/469], Loss: 0.5792, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [415/469], Loss: 0.5316, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [416/469], Loss: 0.6240, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [20/50], Step [417/469], Loss: 0.5292, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [20/50], Step [418/469], Loss: 0.8147, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [419/469], Loss: 0.5734, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [420/469], Loss: 0.4621, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [421/469], Loss: 0.5870, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [422/469], Loss: 0.6473, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [20/50], Step [423/469], Loss: 0.6063, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [20/50], Step [424/469], Loss: 0.3731, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [20/50], Step [425/469], Loss: 0.4070, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [20/50], Step [426/469], Loss: 0.5632, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [20/50], Step [427/469], Loss: 0.4848, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [20/50], Step [428/469], Loss: 0.3891, batch time: 0.77, accuracy:  88.28%\n",
      "Epoch [20/50], Step [429/469], Loss: 0.4608, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [20/50], Step [430/469], Loss: 0.6009, batch time: 0.43, accuracy:  75.00%\n",
      "Epoch [20/50], Step [431/469], Loss: 0.5080, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [20/50], Step [432/469], Loss: 0.5038, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [20/50], Step [433/469], Loss: 0.6175, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [20/50], Step [434/469], Loss: 0.4910, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [20/50], Step [435/469], Loss: 0.5429, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [20/50], Step [436/469], Loss: 0.4952, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [20/50], Step [437/469], Loss: 0.5199, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [20/50], Step [438/469], Loss: 0.4889, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [20/50], Step [439/469], Loss: 0.3276, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [20/50], Step [440/469], Loss: 0.5125, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [20/50], Step [441/469], Loss: 0.4261, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [20/50], Step [442/469], Loss: 0.6600, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [20/50], Step [443/469], Loss: 0.5173, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [20/50], Step [444/469], Loss: 0.7273, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [20/50], Step [445/469], Loss: 0.4497, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [20/50], Step [446/469], Loss: 0.4974, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [20/50], Step [447/469], Loss: 0.6170, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [20/50], Step [448/469], Loss: 0.7062, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [20/50], Step [449/469], Loss: 0.6004, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [20/50], Step [450/469], Loss: 0.6428, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [20/50], Step [451/469], Loss: 0.4039, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [20/50], Step [452/469], Loss: 0.5160, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [20/50], Step [453/469], Loss: 0.6924, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [20/50], Step [454/469], Loss: 0.6086, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [20/50], Step [455/469], Loss: 0.6008, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [20/50], Step [456/469], Loss: 0.5487, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [20/50], Step [457/469], Loss: 0.5579, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [20/50], Step [458/469], Loss: 0.5399, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [20/50], Step [459/469], Loss: 0.4395, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [20/50], Step [460/469], Loss: 0.6782, batch time: 0.55, accuracy:  78.12%\n",
      "Epoch [20/50], Step [461/469], Loss: 0.5297, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [20/50], Step [462/469], Loss: 0.5617, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [20/50], Step [463/469], Loss: 0.6035, batch time: 0.55, accuracy:  77.34%\n",
      "Epoch [20/50], Step [464/469], Loss: 0.5000, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [20/50], Step [465/469], Loss: 0.8233, batch time: 0.43, accuracy:  75.78%\n",
      "Epoch [20/50], Step [466/469], Loss: 0.4829, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [20/50], Step [467/469], Loss: 0.4916, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [20/50], Step [468/469], Loss: 0.4375, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [20/50], Step [469/469], Loss: 0.4954, batch time: 0.43, accuracy:  82.29%\n",
      "Epoch [21/50], Step [1/469], Loss: 0.5645, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [21/50], Step [2/469], Loss: 0.5750, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [21/50], Step [3/469], Loss: 0.4722, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [21/50], Step [4/469], Loss: 0.4992, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [5/469], Loss: 0.5711, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [21/50], Step [6/469], Loss: 0.5222, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [21/50], Step [7/469], Loss: 0.4201, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [21/50], Step [8/469], Loss: 0.6107, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [21/50], Step [9/469], Loss: 0.7913, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [21/50], Step [10/469], Loss: 0.6021, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [11/469], Loss: 0.8502, batch time: 0.43, accuracy:  78.12%\n",
      "Epoch [21/50], Step [12/469], Loss: 0.5044, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [21/50], Step [13/469], Loss: 0.4694, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [21/50], Step [14/469], Loss: 0.5281, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [21/50], Step [15/469], Loss: 0.4455, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [21/50], Step [16/469], Loss: 0.4635, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [21/50], Step [17/469], Loss: 0.7047, batch time: 0.51, accuracy:  74.22%\n",
      "Epoch [21/50], Step [18/469], Loss: 0.5889, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [21/50], Step [19/469], Loss: 0.5713, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [21/50], Step [20/469], Loss: 0.6070, batch time: 0.47, accuracy:  77.34%\n",
      "Epoch [21/50], Step [21/469], Loss: 0.5600, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [21/50], Step [22/469], Loss: 0.6353, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [21/50], Step [23/469], Loss: 0.5540, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [24/469], Loss: 0.5026, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [21/50], Step [25/469], Loss: 0.6429, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [21/50], Step [26/469], Loss: 0.5209, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [27/469], Loss: 0.5814, batch time: 0.53, accuracy:  79.69%\n",
      "Epoch [21/50], Step [28/469], Loss: 0.5659, batch time: 0.80, accuracy:  82.03%\n",
      "Epoch [21/50], Step [29/469], Loss: 0.4065, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [21/50], Step [30/469], Loss: 0.4475, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [21/50], Step [31/469], Loss: 0.5788, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [21/50], Step [32/469], Loss: 0.4120, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [21/50], Step [33/469], Loss: 0.5774, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [34/469], Loss: 0.6408, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [21/50], Step [35/469], Loss: 0.4064, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [36/469], Loss: 0.5440, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [21/50], Step [37/469], Loss: 0.4729, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [21/50], Step [38/469], Loss: 0.5559, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [21/50], Step [39/469], Loss: 0.4644, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [40/469], Loss: 0.6129, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [21/50], Step [41/469], Loss: 0.5583, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [21/50], Step [42/469], Loss: 0.5511, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [21/50], Step [43/469], Loss: 0.7033, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [21/50], Step [44/469], Loss: 0.7466, batch time: 0.51, accuracy:  78.12%\n",
      "Epoch [21/50], Step [45/469], Loss: 0.7784, batch time: 0.51, accuracy:  75.00%\n",
      "Epoch [21/50], Step [46/469], Loss: 0.5295, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [47/469], Loss: 0.6017, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [21/50], Step [48/469], Loss: 0.6842, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [21/50], Step [49/469], Loss: 0.4864, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [21/50], Step [50/469], Loss: 0.5963, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [21/50], Step [51/469], Loss: 0.4574, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [21/50], Step [52/469], Loss: 0.6575, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [21/50], Step [53/469], Loss: 0.7757, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [21/50], Step [54/469], Loss: 0.5069, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [21/50], Step [55/469], Loss: 0.6517, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [21/50], Step [56/469], Loss: 0.6427, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [21/50], Step [57/469], Loss: 0.6282, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [21/50], Step [58/469], Loss: 0.4266, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [21/50], Step [59/469], Loss: 0.6510, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [21/50], Step [60/469], Loss: 0.5766, batch time: 0.86, accuracy:  82.03%\n",
      "Epoch [21/50], Step [61/469], Loss: 0.5363, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [21/50], Step [62/469], Loss: 0.6869, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [21/50], Step [63/469], Loss: 0.4818, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [21/50], Step [64/469], Loss: 0.6534, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [21/50], Step [65/469], Loss: 0.5744, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [21/50], Step [66/469], Loss: 0.4785, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [21/50], Step [67/469], Loss: 0.5103, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [21/50], Step [68/469], Loss: 0.6227, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [21/50], Step [69/469], Loss: 0.6163, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [21/50], Step [70/469], Loss: 0.4835, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [21/50], Step [71/469], Loss: 0.5092, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [21/50], Step [72/469], Loss: 0.5287, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [21/50], Step [73/469], Loss: 0.6959, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [21/50], Step [74/469], Loss: 0.4436, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [21/50], Step [75/469], Loss: 0.4546, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [76/469], Loss: 0.4704, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [77/469], Loss: 0.4687, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [78/469], Loss: 0.4689, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [21/50], Step [79/469], Loss: 0.5789, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [80/469], Loss: 0.5058, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [21/50], Step [81/469], Loss: 0.4516, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [21/50], Step [82/469], Loss: 0.5805, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [21/50], Step [83/469], Loss: 0.4812, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [84/469], Loss: 0.4836, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [21/50], Step [85/469], Loss: 0.7508, batch time: 0.51, accuracy:  77.34%\n",
      "Epoch [21/50], Step [86/469], Loss: 0.6778, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [21/50], Step [87/469], Loss: 0.5260, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [21/50], Step [88/469], Loss: 0.3704, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [21/50], Step [89/469], Loss: 0.3594, batch time: 1.00, accuracy:  88.28%\n",
      "Epoch [21/50], Step [90/469], Loss: 0.7517, batch time: 0.45, accuracy:  75.00%\n",
      "Epoch [21/50], Step [91/469], Loss: 0.8105, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [21/50], Step [92/469], Loss: 0.5414, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [21/50], Step [93/469], Loss: 0.3651, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [21/50], Step [94/469], Loss: 0.6086, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [21/50], Step [95/469], Loss: 0.3818, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [21/50], Step [96/469], Loss: 0.5684, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [21/50], Step [97/469], Loss: 0.4352, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [98/469], Loss: 0.5793, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [21/50], Step [99/469], Loss: 0.6221, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [21/50], Step [100/469], Loss: 0.6435, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [101/469], Loss: 0.5812, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [21/50], Step [102/469], Loss: 0.5025, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [103/469], Loss: 0.4918, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [104/469], Loss: 0.4379, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [105/469], Loss: 0.6261, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [21/50], Step [106/469], Loss: 0.6340, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [21/50], Step [107/469], Loss: 0.4593, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [21/50], Step [108/469], Loss: 0.5304, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [21/50], Step [109/469], Loss: 0.5718, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [110/469], Loss: 0.4530, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [111/469], Loss: 0.6271, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [21/50], Step [112/469], Loss: 0.5126, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [21/50], Step [113/469], Loss: 0.5517, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [114/469], Loss: 0.5176, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [115/469], Loss: 0.4262, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [21/50], Step [116/469], Loss: 0.7119, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [21/50], Step [117/469], Loss: 0.7611, batch time: 0.54, accuracy:  77.34%\n",
      "Epoch [21/50], Step [118/469], Loss: 0.6493, batch time: 0.49, accuracy:  73.44%\n",
      "Epoch [21/50], Step [119/469], Loss: 0.3715, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [21/50], Step [120/469], Loss: 0.5457, batch time: 0.76, accuracy:  81.25%\n",
      "Epoch [21/50], Step [121/469], Loss: 0.4605, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [122/469], Loss: 0.5446, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [123/469], Loss: 0.7008, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [21/50], Step [124/469], Loss: 0.5385, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [125/469], Loss: 0.6372, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [21/50], Step [126/469], Loss: 0.8750, batch time: 0.48, accuracy:  76.56%\n",
      "Epoch [21/50], Step [127/469], Loss: 0.5347, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [21/50], Step [128/469], Loss: 0.4980, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [21/50], Step [129/469], Loss: 0.6243, batch time: 0.55, accuracy:  78.91%\n",
      "Epoch [21/50], Step [130/469], Loss: 0.5762, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [21/50], Step [131/469], Loss: 0.5872, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [21/50], Step [132/469], Loss: 0.4733, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [21/50], Step [133/469], Loss: 0.5971, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [21/50], Step [134/469], Loss: 0.6231, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [21/50], Step [135/469], Loss: 0.4898, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [21/50], Step [136/469], Loss: 0.4668, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [21/50], Step [137/469], Loss: 0.5481, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [21/50], Step [138/469], Loss: 0.5492, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [139/469], Loss: 0.6527, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [21/50], Step [140/469], Loss: 0.5497, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [21/50], Step [141/469], Loss: 0.5261, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [142/469], Loss: 0.6650, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [21/50], Step [143/469], Loss: 0.6235, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [144/469], Loss: 0.6242, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [21/50], Step [145/469], Loss: 0.5516, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [21/50], Step [146/469], Loss: 0.6595, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [21/50], Step [147/469], Loss: 0.5704, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [148/469], Loss: 0.6985, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [21/50], Step [149/469], Loss: 0.5327, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [150/469], Loss: 0.4046, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [21/50], Step [151/469], Loss: 0.6150, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [21/50], Step [152/469], Loss: 0.5469, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [21/50], Step [153/469], Loss: 0.4078, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [21/50], Step [154/469], Loss: 0.6138, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [21/50], Step [155/469], Loss: 0.5760, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [21/50], Step [156/469], Loss: 0.5630, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [21/50], Step [157/469], Loss: 0.5570, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [21/50], Step [158/469], Loss: 0.5243, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [21/50], Step [159/469], Loss: 0.5388, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [21/50], Step [160/469], Loss: 0.3637, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [21/50], Step [161/469], Loss: 0.5605, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [21/50], Step [162/469], Loss: 0.4222, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [163/469], Loss: 0.4482, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [21/50], Step [164/469], Loss: 0.4824, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [21/50], Step [165/469], Loss: 0.5933, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [21/50], Step [166/469], Loss: 0.4707, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [21/50], Step [167/469], Loss: 0.5114, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [168/469], Loss: 0.5993, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [21/50], Step [169/469], Loss: 0.6027, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [21/50], Step [170/469], Loss: 0.5283, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [21/50], Step [171/469], Loss: 0.4882, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [21/50], Step [172/469], Loss: 0.5860, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [21/50], Step [173/469], Loss: 0.6949, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [21/50], Step [174/469], Loss: 0.6823, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [21/50], Step [175/469], Loss: 0.4110, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [21/50], Step [176/469], Loss: 0.7005, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [21/50], Step [177/469], Loss: 0.4910, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [21/50], Step [178/469], Loss: 0.5352, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [21/50], Step [179/469], Loss: 0.5932, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [21/50], Step [180/469], Loss: 0.4369, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [21/50], Step [181/469], Loss: 0.5580, batch time: 0.61, accuracy:  82.81%\n",
      "Epoch [21/50], Step [182/469], Loss: 0.5503, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [21/50], Step [183/469], Loss: 0.3519, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [21/50], Step [184/469], Loss: 0.5448, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [21/50], Step [185/469], Loss: 0.5400, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [186/469], Loss: 0.5265, batch time: 0.53, accuracy:  80.47%\n",
      "Epoch [21/50], Step [187/469], Loss: 0.5337, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [188/469], Loss: 0.5839, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [21/50], Step [189/469], Loss: 0.6293, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [21/50], Step [190/469], Loss: 0.4438, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [21/50], Step [191/469], Loss: 0.5638, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [192/469], Loss: 0.6472, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [21/50], Step [193/469], Loss: 0.4616, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [194/469], Loss: 0.5011, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [21/50], Step [195/469], Loss: 0.3168, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [21/50], Step [196/469], Loss: 0.4530, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [21/50], Step [197/469], Loss: 0.5364, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [198/469], Loss: 0.5518, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [21/50], Step [199/469], Loss: 0.5233, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [21/50], Step [200/469], Loss: 0.4655, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [201/469], Loss: 0.6058, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [21/50], Step [202/469], Loss: 0.5044, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [21/50], Step [203/469], Loss: 0.5706, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [21/50], Step [204/469], Loss: 0.5279, batch time: 0.56, accuracy:  82.81%\n",
      "Epoch [21/50], Step [205/469], Loss: 0.6098, batch time: 0.57, accuracy:  78.91%\n",
      "Epoch [21/50], Step [206/469], Loss: 0.7647, batch time: 0.65, accuracy:  76.56%\n",
      "Epoch [21/50], Step [207/469], Loss: 0.7789, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [21/50], Step [208/469], Loss: 0.3271, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [21/50], Step [209/469], Loss: 0.6264, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [210/469], Loss: 0.5546, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [21/50], Step [211/469], Loss: 0.7395, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [21/50], Step [212/469], Loss: 0.6645, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [213/469], Loss: 0.4696, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [21/50], Step [214/469], Loss: 0.5021, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [215/469], Loss: 0.5780, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [216/469], Loss: 0.9125, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [21/50], Step [217/469], Loss: 0.5119, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [218/469], Loss: 0.4711, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [219/469], Loss: 0.5339, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [220/469], Loss: 0.5305, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [21/50], Step [221/469], Loss: 0.5807, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [222/469], Loss: 0.5251, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [21/50], Step [223/469], Loss: 0.4411, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [21/50], Step [224/469], Loss: 0.5832, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [21/50], Step [225/469], Loss: 0.5728, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [21/50], Step [226/469], Loss: 0.6703, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [21/50], Step [227/469], Loss: 0.4752, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [228/469], Loss: 0.5509, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [21/50], Step [229/469], Loss: 0.3640, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [230/469], Loss: 0.5735, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [21/50], Step [231/469], Loss: 0.5387, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [232/469], Loss: 0.6918, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [233/469], Loss: 0.5695, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [21/50], Step [234/469], Loss: 0.5791, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [21/50], Step [235/469], Loss: 0.6183, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [21/50], Step [236/469], Loss: 0.7643, batch time: 0.59, accuracy:  78.91%\n",
      "Epoch [21/50], Step [237/469], Loss: 0.4932, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [21/50], Step [238/469], Loss: 0.2790, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [21/50], Step [239/469], Loss: 0.6191, batch time: 0.62, accuracy:  80.47%\n",
      "Epoch [21/50], Step [240/469], Loss: 0.6614, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [21/50], Step [241/469], Loss: 0.4711, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [242/469], Loss: 0.6239, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [21/50], Step [243/469], Loss: 0.6769, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [21/50], Step [244/469], Loss: 0.5496, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [21/50], Step [245/469], Loss: 0.6576, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [21/50], Step [246/469], Loss: 0.5254, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [21/50], Step [247/469], Loss: 0.5388, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [21/50], Step [248/469], Loss: 0.4841, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [249/469], Loss: 0.5759, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [21/50], Step [250/469], Loss: 0.7037, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [21/50], Step [251/469], Loss: 0.4515, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [21/50], Step [252/469], Loss: 0.5582, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [21/50], Step [253/469], Loss: 0.5642, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [21/50], Step [254/469], Loss: 0.6138, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [255/469], Loss: 0.5269, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [256/469], Loss: 0.3335, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [21/50], Step [257/469], Loss: 0.4941, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [258/469], Loss: 0.6180, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [259/469], Loss: 0.5491, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [21/50], Step [260/469], Loss: 0.4960, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [21/50], Step [261/469], Loss: 0.5311, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [21/50], Step [262/469], Loss: 0.5247, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [263/469], Loss: 0.5800, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [21/50], Step [264/469], Loss: 0.6771, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [21/50], Step [265/469], Loss: 0.4764, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [21/50], Step [266/469], Loss: 0.5400, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [21/50], Step [267/469], Loss: 0.5655, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [21/50], Step [268/469], Loss: 0.4488, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [21/50], Step [269/469], Loss: 0.5879, batch time: 0.77, accuracy:  82.03%\n",
      "Epoch [21/50], Step [270/469], Loss: 0.4183, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [21/50], Step [271/469], Loss: 0.4321, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [21/50], Step [272/469], Loss: 0.5782, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [21/50], Step [273/469], Loss: 0.4238, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [274/469], Loss: 0.4812, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [21/50], Step [275/469], Loss: 0.5061, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [276/469], Loss: 0.5355, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [21/50], Step [277/469], Loss: 0.5218, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [278/469], Loss: 0.5485, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [21/50], Step [279/469], Loss: 0.5202, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [21/50], Step [280/469], Loss: 0.5282, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [21/50], Step [281/469], Loss: 0.5152, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [21/50], Step [282/469], Loss: 0.5463, batch time: 0.51, accuracy:  78.91%\n",
      "Epoch [21/50], Step [283/469], Loss: 0.5588, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [21/50], Step [284/469], Loss: 0.4735, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [285/469], Loss: 0.4917, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [21/50], Step [286/469], Loss: 0.6213, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [21/50], Step [287/469], Loss: 0.6157, batch time: 0.59, accuracy:  78.12%\n",
      "Epoch [21/50], Step [288/469], Loss: 0.4453, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [21/50], Step [289/469], Loss: 0.4624, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [21/50], Step [290/469], Loss: 0.3548, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [21/50], Step [291/469], Loss: 0.6033, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [21/50], Step [292/469], Loss: 0.7360, batch time: 0.43, accuracy:  77.34%\n",
      "Epoch [21/50], Step [293/469], Loss: 0.6698, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [21/50], Step [294/469], Loss: 0.4228, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [295/469], Loss: 0.6177, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [21/50], Step [296/469], Loss: 0.5608, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [21/50], Step [297/469], Loss: 0.6005, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [21/50], Step [298/469], Loss: 0.6812, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [21/50], Step [299/469], Loss: 0.4372, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [21/50], Step [300/469], Loss: 0.5247, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [21/50], Step [301/469], Loss: 0.5995, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [21/50], Step [302/469], Loss: 0.7497, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [21/50], Step [303/469], Loss: 0.6402, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [21/50], Step [304/469], Loss: 0.5098, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [21/50], Step [305/469], Loss: 0.4988, batch time: 0.59, accuracy:  80.47%\n",
      "Epoch [21/50], Step [306/469], Loss: 0.5794, batch time: 0.57, accuracy:  83.59%\n",
      "Epoch [21/50], Step [307/469], Loss: 0.4851, batch time: 0.62, accuracy:  80.47%\n",
      "Epoch [21/50], Step [308/469], Loss: 0.4911, batch time: 0.62, accuracy:  82.81%\n",
      "Epoch [21/50], Step [309/469], Loss: 0.4738, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [21/50], Step [310/469], Loss: 0.5027, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [311/469], Loss: 0.6164, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [312/469], Loss: 0.7999, batch time: 0.51, accuracy:  73.44%\n",
      "Epoch [21/50], Step [313/469], Loss: 0.5436, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [314/469], Loss: 0.3753, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [21/50], Step [315/469], Loss: 0.4641, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [21/50], Step [316/469], Loss: 0.5213, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [21/50], Step [317/469], Loss: 0.4007, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [21/50], Step [318/469], Loss: 0.7335, batch time: 0.43, accuracy:  78.91%\n",
      "Epoch [21/50], Step [319/469], Loss: 0.4830, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [21/50], Step [320/469], Loss: 0.5623, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [21/50], Step [321/469], Loss: 0.4420, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [21/50], Step [322/469], Loss: 0.4542, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [323/469], Loss: 0.3635, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [21/50], Step [324/469], Loss: 0.4867, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [21/50], Step [325/469], Loss: 0.4492, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [326/469], Loss: 0.4472, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [21/50], Step [327/469], Loss: 0.4728, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [328/469], Loss: 0.4985, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [21/50], Step [329/469], Loss: 0.5592, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [21/50], Step [330/469], Loss: 0.3972, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [21/50], Step [331/469], Loss: 0.5170, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [332/469], Loss: 0.7570, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [333/469], Loss: 0.6500, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [21/50], Step [334/469], Loss: 0.7261, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [21/50], Step [335/469], Loss: 0.3915, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [21/50], Step [336/469], Loss: 0.7855, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [21/50], Step [337/469], Loss: 0.8540, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [21/50], Step [338/469], Loss: 0.5094, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [339/469], Loss: 0.4053, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [21/50], Step [340/469], Loss: 0.8611, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [21/50], Step [341/469], Loss: 0.5041, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [21/50], Step [342/469], Loss: 0.5762, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [21/50], Step [343/469], Loss: 0.4532, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [21/50], Step [344/469], Loss: 0.4966, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [21/50], Step [345/469], Loss: 0.5551, batch time: 0.63, accuracy:  84.38%\n",
      "Epoch [21/50], Step [346/469], Loss: 0.5918, batch time: 0.44, accuracy:  76.56%\n",
      "Epoch [21/50], Step [347/469], Loss: 0.5110, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [348/469], Loss: 0.4534, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [21/50], Step [349/469], Loss: 0.8548, batch time: 0.43, accuracy:  72.66%\n",
      "Epoch [21/50], Step [350/469], Loss: 0.3996, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [21/50], Step [351/469], Loss: 0.5937, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [21/50], Step [352/469], Loss: 0.5418, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [21/50], Step [353/469], Loss: 0.4773, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [21/50], Step [354/469], Loss: 0.5090, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [21/50], Step [355/469], Loss: 0.5290, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [21/50], Step [356/469], Loss: 0.4160, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [21/50], Step [357/469], Loss: 0.3885, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [358/469], Loss: 0.5205, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [21/50], Step [359/469], Loss: 0.5803, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [21/50], Step [360/469], Loss: 0.5134, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [21/50], Step [361/469], Loss: 0.6796, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [21/50], Step [362/469], Loss: 0.3741, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [21/50], Step [363/469], Loss: 0.4170, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [21/50], Step [364/469], Loss: 0.5030, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [21/50], Step [365/469], Loss: 0.5356, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [21/50], Step [366/469], Loss: 0.6156, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [367/469], Loss: 0.4468, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [21/50], Step [368/469], Loss: 0.5969, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [21/50], Step [369/469], Loss: 0.5633, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [21/50], Step [370/469], Loss: 0.5700, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [21/50], Step [371/469], Loss: 0.4877, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [21/50], Step [372/469], Loss: 0.6636, batch time: 0.46, accuracy:  75.00%\n",
      "Epoch [21/50], Step [373/469], Loss: 0.3666, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [21/50], Step [374/469], Loss: 0.3925, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [21/50], Step [375/469], Loss: 0.6057, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [21/50], Step [376/469], Loss: 0.4972, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [21/50], Step [377/469], Loss: 0.4338, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [21/50], Step [378/469], Loss: 0.6280, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [21/50], Step [379/469], Loss: 0.4847, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [21/50], Step [380/469], Loss: 0.4963, batch time: 0.58, accuracy:  82.81%\n",
      "Epoch [21/50], Step [381/469], Loss: 0.5526, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [21/50], Step [382/469], Loss: 0.6474, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [21/50], Step [383/469], Loss: 0.3541, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [21/50], Step [384/469], Loss: 0.6012, batch time: 0.51, accuracy:  79.69%\n",
      "Epoch [21/50], Step [385/469], Loss: 0.4985, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [21/50], Step [386/469], Loss: 0.5071, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [21/50], Step [387/469], Loss: 0.5515, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [21/50], Step [388/469], Loss: 0.6225, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [21/50], Step [389/469], Loss: 0.6099, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [21/50], Step [390/469], Loss: 0.4875, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [21/50], Step [391/469], Loss: 0.6133, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [21/50], Step [392/469], Loss: 0.5792, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [21/50], Step [393/469], Loss: 0.5192, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [21/50], Step [394/469], Loss: 0.4002, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [21/50], Step [395/469], Loss: 0.3944, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [21/50], Step [396/469], Loss: 0.4489, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [21/50], Step [397/469], Loss: 0.5569, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [21/50], Step [398/469], Loss: 0.4126, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [21/50], Step [399/469], Loss: 0.5962, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [21/50], Step [400/469], Loss: 0.5545, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [21/50], Step [401/469], Loss: 0.7691, batch time: 0.50, accuracy:  79.69%\n",
      "Epoch [21/50], Step [402/469], Loss: 0.5249, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [21/50], Step [403/469], Loss: 0.6066, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [21/50], Step [404/469], Loss: 0.3505, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [21/50], Step [405/469], Loss: 0.5310, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [21/50], Step [406/469], Loss: 0.5088, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [21/50], Step [407/469], Loss: 0.3840, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [21/50], Step [408/469], Loss: 0.6004, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [21/50], Step [409/469], Loss: 0.4625, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [21/50], Step [410/469], Loss: 0.4525, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [21/50], Step [411/469], Loss: 0.5997, batch time: 0.57, accuracy:  78.91%\n",
      "Epoch [21/50], Step [412/469], Loss: 0.6033, batch time: 0.66, accuracy:  83.59%\n",
      "Epoch [21/50], Step [413/469], Loss: 0.5584, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [21/50], Step [414/469], Loss: 0.6945, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [21/50], Step [415/469], Loss: 0.5225, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [21/50], Step [416/469], Loss: 0.4808, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [21/50], Step [417/469], Loss: 0.4879, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [21/50], Step [418/469], Loss: 0.6831, batch time: 0.60, accuracy:  78.91%\n",
      "Epoch [21/50], Step [419/469], Loss: 0.5556, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [21/50], Step [420/469], Loss: 0.6040, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [21/50], Step [421/469], Loss: 0.5542, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [21/50], Step [422/469], Loss: 0.6462, batch time: 0.50, accuracy:  80.47%\n",
      "Epoch [21/50], Step [423/469], Loss: 0.3471, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [21/50], Step [424/469], Loss: 0.6077, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [21/50], Step [425/469], Loss: 0.4595, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [21/50], Step [426/469], Loss: 0.4775, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [21/50], Step [427/469], Loss: 0.5711, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [21/50], Step [428/469], Loss: 0.5827, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [429/469], Loss: 0.5201, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [21/50], Step [430/469], Loss: 0.6821, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [21/50], Step [431/469], Loss: 0.4055, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [21/50], Step [432/469], Loss: 0.3702, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [21/50], Step [433/469], Loss: 0.5717, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [21/50], Step [434/469], Loss: 0.5687, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [21/50], Step [435/469], Loss: 0.6061, batch time: 0.60, accuracy:  83.59%\n",
      "Epoch [21/50], Step [436/469], Loss: 0.3461, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [21/50], Step [437/469], Loss: 0.5323, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [21/50], Step [438/469], Loss: 0.3576, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [21/50], Step [439/469], Loss: 0.4067, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [21/50], Step [440/469], Loss: 0.4999, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [21/50], Step [441/469], Loss: 0.7055, batch time: 0.50, accuracy:  79.69%\n",
      "Epoch [21/50], Step [442/469], Loss: 0.5635, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [21/50], Step [443/469], Loss: 0.4563, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [21/50], Step [444/469], Loss: 0.4950, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [21/50], Step [445/469], Loss: 0.7184, batch time: 0.63, accuracy:  78.91%\n",
      "Epoch [21/50], Step [446/469], Loss: 0.5413, batch time: 0.74, accuracy:  86.72%\n",
      "Epoch [21/50], Step [447/469], Loss: 0.6652, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [21/50], Step [448/469], Loss: 0.6397, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [21/50], Step [449/469], Loss: 0.4757, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [450/469], Loss: 0.4865, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [21/50], Step [451/469], Loss: 0.4577, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [452/469], Loss: 0.6365, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [21/50], Step [453/469], Loss: 0.5079, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [21/50], Step [454/469], Loss: 0.6788, batch time: 0.51, accuracy:  76.56%\n",
      "Epoch [21/50], Step [455/469], Loss: 0.3866, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [21/50], Step [456/469], Loss: 0.5728, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [21/50], Step [457/469], Loss: 0.5318, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [21/50], Step [458/469], Loss: 0.4755, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [21/50], Step [459/469], Loss: 0.8040, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [21/50], Step [460/469], Loss: 0.5802, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [21/50], Step [461/469], Loss: 0.6092, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [21/50], Step [462/469], Loss: 0.3432, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [21/50], Step [463/469], Loss: 0.6208, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [21/50], Step [464/469], Loss: 0.7034, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [21/50], Step [465/469], Loss: 0.6473, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [21/50], Step [466/469], Loss: 0.4543, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [21/50], Step [467/469], Loss: 0.5595, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [21/50], Step [468/469], Loss: 0.6180, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [21/50], Step [469/469], Loss: 0.7065, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [22/50], Step [1/469], Loss: 0.5176, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [22/50], Step [2/469], Loss: 0.5073, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [22/50], Step [3/469], Loss: 0.6471, batch time: 0.92, accuracy:  80.47%\n",
      "Epoch [22/50], Step [4/469], Loss: 0.6570, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [22/50], Step [5/469], Loss: 0.5227, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [22/50], Step [6/469], Loss: 0.5097, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [22/50], Step [7/469], Loss: 0.5464, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [22/50], Step [8/469], Loss: 0.4398, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [22/50], Step [9/469], Loss: 0.4010, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [22/50], Step [10/469], Loss: 0.4666, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [22/50], Step [11/469], Loss: 0.6523, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [22/50], Step [12/469], Loss: 0.6408, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [22/50], Step [13/469], Loss: 0.4340, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [22/50], Step [14/469], Loss: 0.5399, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [22/50], Step [15/469], Loss: 0.5222, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [22/50], Step [16/469], Loss: 0.4426, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [22/50], Step [17/469], Loss: 0.5891, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [22/50], Step [18/469], Loss: 0.4213, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [22/50], Step [19/469], Loss: 0.6469, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [22/50], Step [20/469], Loss: 0.4792, batch time: 0.56, accuracy:  83.59%\n",
      "Epoch [22/50], Step [21/469], Loss: 0.4976, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [22/50], Step [22/469], Loss: 0.6404, batch time: 0.59, accuracy:  81.25%\n",
      "Epoch [22/50], Step [23/469], Loss: 0.5548, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [22/50], Step [24/469], Loss: 0.4887, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [22/50], Step [25/469], Loss: 0.5021, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [22/50], Step [26/469], Loss: 0.4980, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [22/50], Step [27/469], Loss: 0.3806, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [22/50], Step [28/469], Loss: 0.6577, batch time: 0.50, accuracy:  75.78%\n",
      "Epoch [22/50], Step [29/469], Loss: 0.5040, batch time: 0.63, accuracy:  80.47%\n",
      "Epoch [22/50], Step [30/469], Loss: 0.5063, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [22/50], Step [31/469], Loss: 0.3794, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [22/50], Step [32/469], Loss: 0.4332, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [22/50], Step [33/469], Loss: 0.5344, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [22/50], Step [34/469], Loss: 0.4969, batch time: 0.63, accuracy:  83.59%\n",
      "Epoch [22/50], Step [35/469], Loss: 0.5585, batch time: 0.71, accuracy:  88.28%\n",
      "Epoch [22/50], Step [36/469], Loss: 0.4900, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [22/50], Step [37/469], Loss: 0.4635, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [22/50], Step [38/469], Loss: 0.5448, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [22/50], Step [39/469], Loss: 0.4775, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [22/50], Step [40/469], Loss: 0.7376, batch time: 0.45, accuracy:  75.78%\n",
      "Epoch [22/50], Step [41/469], Loss: 0.5222, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [22/50], Step [42/469], Loss: 0.4531, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [22/50], Step [43/469], Loss: 0.5932, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [22/50], Step [44/469], Loss: 0.5464, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [22/50], Step [45/469], Loss: 0.5839, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [22/50], Step [46/469], Loss: 0.5933, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [22/50], Step [47/469], Loss: 0.5903, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [22/50], Step [48/469], Loss: 0.5646, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [22/50], Step [49/469], Loss: 0.3787, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [22/50], Step [50/469], Loss: 0.4305, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [22/50], Step [51/469], Loss: 0.5516, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [22/50], Step [52/469], Loss: 0.5047, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [22/50], Step [53/469], Loss: 0.5450, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [22/50], Step [54/469], Loss: 0.6084, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [22/50], Step [55/469], Loss: 0.5222, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [22/50], Step [56/469], Loss: 0.4465, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [22/50], Step [57/469], Loss: 0.4239, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [58/469], Loss: 0.5159, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [22/50], Step [59/469], Loss: 0.3285, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [22/50], Step [60/469], Loss: 0.6276, batch time: 0.58, accuracy:  80.47%\n",
      "Epoch [22/50], Step [61/469], Loss: 0.4773, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [22/50], Step [62/469], Loss: 0.6022, batch time: 0.88, accuracy:  78.91%\n",
      "Epoch [22/50], Step [63/469], Loss: 0.4606, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [22/50], Step [64/469], Loss: 0.6610, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [22/50], Step [65/469], Loss: 0.5946, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [22/50], Step [66/469], Loss: 0.4507, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [22/50], Step [67/469], Loss: 0.5570, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [22/50], Step [68/469], Loss: 0.7580, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [22/50], Step [69/469], Loss: 0.4672, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [22/50], Step [70/469], Loss: 0.6514, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [22/50], Step [71/469], Loss: 0.6071, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [72/469], Loss: 0.5652, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [22/50], Step [73/469], Loss: 0.3698, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [22/50], Step [74/469], Loss: 0.5250, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [22/50], Step [75/469], Loss: 0.6142, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [22/50], Step [76/469], Loss: 0.6107, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [22/50], Step [77/469], Loss: 0.3731, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [22/50], Step [78/469], Loss: 0.5096, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [22/50], Step [79/469], Loss: 0.4163, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [22/50], Step [80/469], Loss: 0.4680, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [81/469], Loss: 0.5437, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [22/50], Step [82/469], Loss: 0.7732, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [22/50], Step [83/469], Loss: 0.4805, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [22/50], Step [84/469], Loss: 0.4622, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [85/469], Loss: 0.4637, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [22/50], Step [86/469], Loss: 0.4754, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [22/50], Step [87/469], Loss: 0.4539, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [22/50], Step [88/469], Loss: 0.6161, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [22/50], Step [89/469], Loss: 0.5341, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [90/469], Loss: 0.4855, batch time: 0.55, accuracy:  82.03%\n",
      "Epoch [22/50], Step [91/469], Loss: 0.4582, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [22/50], Step [92/469], Loss: 0.6129, batch time: 0.64, accuracy:  86.72%\n",
      "Epoch [22/50], Step [93/469], Loss: 0.6322, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [22/50], Step [94/469], Loss: 0.5483, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [22/50], Step [95/469], Loss: 0.4804, batch time: 0.57, accuracy:  83.59%\n",
      "Epoch [22/50], Step [96/469], Loss: 0.5229, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [22/50], Step [97/469], Loss: 0.6139, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [22/50], Step [98/469], Loss: 0.4128, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [22/50], Step [99/469], Loss: 0.4632, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [22/50], Step [100/469], Loss: 0.6070, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [22/50], Step [101/469], Loss: 0.4067, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [22/50], Step [102/469], Loss: 0.4945, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [103/469], Loss: 0.5076, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [22/50], Step [104/469], Loss: 0.4937, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [22/50], Step [105/469], Loss: 0.4270, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [22/50], Step [106/469], Loss: 0.4901, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [22/50], Step [107/469], Loss: 0.4513, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [22/50], Step [108/469], Loss: 0.4005, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [22/50], Step [109/469], Loss: 0.6590, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [22/50], Step [110/469], Loss: 0.4613, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [22/50], Step [111/469], Loss: 0.5899, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [22/50], Step [112/469], Loss: 0.4990, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [22/50], Step [113/469], Loss: 0.3947, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [22/50], Step [114/469], Loss: 0.4534, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [22/50], Step [115/469], Loss: 0.6132, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [22/50], Step [116/469], Loss: 0.6436, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [22/50], Step [117/469], Loss: 0.4263, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [22/50], Step [118/469], Loss: 0.7027, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [22/50], Step [119/469], Loss: 0.6445, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [22/50], Step [120/469], Loss: 0.3960, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [22/50], Step [121/469], Loss: 0.6162, batch time: 0.58, accuracy:  82.81%\n",
      "Epoch [22/50], Step [122/469], Loss: 0.4058, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [22/50], Step [123/469], Loss: 0.5390, batch time: 0.58, accuracy:  82.03%\n",
      "Epoch [22/50], Step [124/469], Loss: 0.4472, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [22/50], Step [125/469], Loss: 0.4836, batch time: 0.66, accuracy:  85.94%\n",
      "Epoch [22/50], Step [126/469], Loss: 0.5253, batch time: 0.60, accuracy:  84.38%\n",
      "Epoch [22/50], Step [127/469], Loss: 0.5952, batch time: 0.60, accuracy:  85.16%\n",
      "Epoch [22/50], Step [128/469], Loss: 0.3723, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [22/50], Step [129/469], Loss: 0.4542, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [22/50], Step [130/469], Loss: 0.6498, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [22/50], Step [131/469], Loss: 0.6642, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [22/50], Step [132/469], Loss: 0.5485, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [22/50], Step [133/469], Loss: 0.5419, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [22/50], Step [134/469], Loss: 0.5612, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [22/50], Step [135/469], Loss: 0.7993, batch time: 0.58, accuracy:  72.66%\n",
      "Epoch [22/50], Step [136/469], Loss: 0.6910, batch time: 0.53, accuracy:  78.91%\n",
      "Epoch [22/50], Step [137/469], Loss: 0.5776, batch time: 0.55, accuracy:  81.25%\n",
      "Epoch [22/50], Step [138/469], Loss: 0.6550, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [22/50], Step [139/469], Loss: 0.5075, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [22/50], Step [140/469], Loss: 0.5934, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [22/50], Step [141/469], Loss: 0.7032, batch time: 0.46, accuracy:  74.22%\n",
      "Epoch [22/50], Step [142/469], Loss: 0.3959, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [22/50], Step [143/469], Loss: 0.4518, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [22/50], Step [144/469], Loss: 0.4055, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [22/50], Step [145/469], Loss: 0.4890, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [22/50], Step [146/469], Loss: 0.6035, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [22/50], Step [147/469], Loss: 0.4363, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [22/50], Step [148/469], Loss: 0.5871, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [149/469], Loss: 0.7010, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [22/50], Step [150/469], Loss: 0.4163, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [22/50], Step [151/469], Loss: 0.7088, batch time: 0.49, accuracy:  77.34%\n",
      "Epoch [22/50], Step [152/469], Loss: 0.5090, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [22/50], Step [153/469], Loss: 0.4483, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [22/50], Step [154/469], Loss: 0.5279, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [22/50], Step [155/469], Loss: 0.5330, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [22/50], Step [156/469], Loss: 0.6691, batch time: 0.62, accuracy:  76.56%\n",
      "Epoch [22/50], Step [157/469], Loss: 0.6699, batch time: 0.88, accuracy:  75.78%\n",
      "Epoch [22/50], Step [158/469], Loss: 0.4763, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [22/50], Step [159/469], Loss: 0.5647, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [22/50], Step [160/469], Loss: 0.5321, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [22/50], Step [161/469], Loss: 0.7713, batch time: 0.49, accuracy:  78.12%\n",
      "Epoch [22/50], Step [162/469], Loss: 0.4243, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [22/50], Step [163/469], Loss: 0.5475, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [164/469], Loss: 0.5705, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [22/50], Step [165/469], Loss: 0.6500, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [22/50], Step [166/469], Loss: 0.5601, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [22/50], Step [167/469], Loss: 0.4469, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [22/50], Step [168/469], Loss: 0.4265, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [22/50], Step [169/469], Loss: 0.4855, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [170/469], Loss: 0.5934, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [22/50], Step [171/469], Loss: 0.5973, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [22/50], Step [172/469], Loss: 0.5299, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [22/50], Step [173/469], Loss: 0.4763, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [22/50], Step [174/469], Loss: 0.6363, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [22/50], Step [175/469], Loss: 0.5289, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [22/50], Step [176/469], Loss: 0.6918, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [22/50], Step [177/469], Loss: 0.3900, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [22/50], Step [178/469], Loss: 0.4775, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [22/50], Step [179/469], Loss: 0.4749, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [22/50], Step [180/469], Loss: 0.5597, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [22/50], Step [181/469], Loss: 0.5257, batch time: 0.49, accuracy:  77.34%\n",
      "Epoch [22/50], Step [182/469], Loss: 0.4660, batch time: 0.59, accuracy:  84.38%\n",
      "Epoch [22/50], Step [183/469], Loss: 0.4424, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [22/50], Step [184/469], Loss: 0.4222, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [22/50], Step [185/469], Loss: 0.4045, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [22/50], Step [186/469], Loss: 0.5021, batch time: 0.61, accuracy:  84.38%\n",
      "Epoch [22/50], Step [187/469], Loss: 0.4948, batch time: 0.63, accuracy:  85.16%\n",
      "Epoch [22/50], Step [188/469], Loss: 0.6981, batch time: 0.74, accuracy:  84.38%\n",
      "Epoch [22/50], Step [189/469], Loss: 0.4392, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [22/50], Step [190/469], Loss: 0.5167, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [22/50], Step [191/469], Loss: 0.4320, batch time: 0.57, accuracy:  85.16%\n",
      "Epoch [22/50], Step [192/469], Loss: 0.4424, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [22/50], Step [193/469], Loss: 0.4649, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [22/50], Step [194/469], Loss: 0.5970, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [22/50], Step [195/469], Loss: 0.5479, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [22/50], Step [196/469], Loss: 0.4598, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [22/50], Step [197/469], Loss: 0.5271, batch time: 0.56, accuracy:  82.81%\n",
      "Epoch [22/50], Step [198/469], Loss: 0.4524, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [22/50], Step [199/469], Loss: 0.3547, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [22/50], Step [200/469], Loss: 0.4576, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [22/50], Step [201/469], Loss: 0.3686, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [202/469], Loss: 0.6414, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [203/469], Loss: 0.5777, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [22/50], Step [204/469], Loss: 0.5835, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [22/50], Step [205/469], Loss: 0.5813, batch time: 0.53, accuracy:  80.47%\n",
      "Epoch [22/50], Step [206/469], Loss: 0.4257, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [22/50], Step [207/469], Loss: 0.7187, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [22/50], Step [208/469], Loss: 0.5431, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [22/50], Step [209/469], Loss: 0.6115, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [22/50], Step [210/469], Loss: 0.4052, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [22/50], Step [211/469], Loss: 0.3307, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [22/50], Step [212/469], Loss: 0.4867, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [22/50], Step [213/469], Loss: 0.5607, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [22/50], Step [214/469], Loss: 0.5391, batch time: 0.64, accuracy:  82.81%\n",
      "Epoch [22/50], Step [215/469], Loss: 0.5483, batch time: 0.59, accuracy:  82.03%\n",
      "Epoch [22/50], Step [216/469], Loss: 0.6035, batch time: 0.62, accuracy:  82.81%\n",
      "Epoch [22/50], Step [217/469], Loss: 0.5930, batch time: 0.60, accuracy:  84.38%\n",
      "Epoch [22/50], Step [218/469], Loss: 0.4182, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [22/50], Step [219/469], Loss: 0.5188, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [22/50], Step [220/469], Loss: 0.6163, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [221/469], Loss: 0.4986, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [22/50], Step [222/469], Loss: 0.3614, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [22/50], Step [223/469], Loss: 0.5407, batch time: 0.55, accuracy:  82.03%\n",
      "Epoch [22/50], Step [224/469], Loss: 0.4005, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [22/50], Step [225/469], Loss: 0.5763, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [22/50], Step [226/469], Loss: 0.6272, batch time: 0.50, accuracy:  79.69%\n",
      "Epoch [22/50], Step [227/469], Loss: 0.5223, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [22/50], Step [228/469], Loss: 0.4898, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [229/469], Loss: 0.5977, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [22/50], Step [230/469], Loss: 0.4212, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [22/50], Step [231/469], Loss: 0.4505, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [22/50], Step [232/469], Loss: 0.5038, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [22/50], Step [233/469], Loss: 0.2746, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [22/50], Step [234/469], Loss: 0.3677, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [22/50], Step [235/469], Loss: 0.4431, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [22/50], Step [236/469], Loss: 0.4562, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [22/50], Step [237/469], Loss: 0.6015, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [238/469], Loss: 0.4345, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [22/50], Step [239/469], Loss: 0.5100, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [22/50], Step [240/469], Loss: 0.6065, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [22/50], Step [241/469], Loss: 0.5906, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [22/50], Step [242/469], Loss: 0.5468, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [22/50], Step [243/469], Loss: 0.7849, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [22/50], Step [244/469], Loss: 0.3514, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [22/50], Step [245/469], Loss: 0.5448, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [22/50], Step [246/469], Loss: 0.6433, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [22/50], Step [247/469], Loss: 0.5994, batch time: 0.56, accuracy:  81.25%\n",
      "Epoch [22/50], Step [248/469], Loss: 0.4740, batch time: 0.59, accuracy:  84.38%\n",
      "Epoch [22/50], Step [249/469], Loss: 0.4484, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [22/50], Step [250/469], Loss: 0.3498, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [22/50], Step [251/469], Loss: 0.3535, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [22/50], Step [252/469], Loss: 0.3302, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [22/50], Step [253/469], Loss: 0.4245, batch time: 0.60, accuracy:  87.50%\n",
      "Epoch [22/50], Step [254/469], Loss: 0.6883, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [22/50], Step [255/469], Loss: 0.8443, batch time: 0.47, accuracy:  75.78%\n",
      "Epoch [22/50], Step [256/469], Loss: 0.5031, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [22/50], Step [257/469], Loss: 0.5687, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [22/50], Step [258/469], Loss: 0.5518, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [22/50], Step [259/469], Loss: 0.4407, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [22/50], Step [260/469], Loss: 0.6040, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [22/50], Step [261/469], Loss: 0.6843, batch time: 0.47, accuracy:  78.12%\n",
      "Epoch [22/50], Step [262/469], Loss: 0.6964, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [22/50], Step [263/469], Loss: 0.4633, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [22/50], Step [264/469], Loss: 0.5347, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [265/469], Loss: 0.4736, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [22/50], Step [266/469], Loss: 0.4690, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [22/50], Step [267/469], Loss: 0.4642, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [22/50], Step [268/469], Loss: 0.4965, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [22/50], Step [269/469], Loss: 0.5191, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [22/50], Step [270/469], Loss: 0.6515, batch time: 0.59, accuracy:  82.03%\n",
      "Epoch [22/50], Step [271/469], Loss: 0.5017, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [22/50], Step [272/469], Loss: 0.5556, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [22/50], Step [273/469], Loss: 0.5711, batch time: 0.60, accuracy:  85.16%\n",
      "Epoch [22/50], Step [274/469], Loss: 0.3725, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [22/50], Step [275/469], Loss: 0.3935, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [22/50], Step [276/469], Loss: 0.4262, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [22/50], Step [277/469], Loss: 0.4132, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [22/50], Step [278/469], Loss: 0.7181, batch time: 0.50, accuracy:  75.78%\n",
      "Epoch [22/50], Step [279/469], Loss: 0.5233, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [22/50], Step [280/469], Loss: 0.6011, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [22/50], Step [281/469], Loss: 0.5938, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [22/50], Step [282/469], Loss: 0.3933, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [22/50], Step [283/469], Loss: 0.6960, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [22/50], Step [284/469], Loss: 0.4719, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [22/50], Step [285/469], Loss: 0.6001, batch time: 0.58, accuracy:  82.81%\n",
      "Epoch [22/50], Step [286/469], Loss: 0.3776, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [22/50], Step [287/469], Loss: 0.7074, batch time: 0.64, accuracy:  78.12%\n",
      "Epoch [22/50], Step [288/469], Loss: 0.5067, batch time: 0.59, accuracy:  83.59%\n",
      "Epoch [22/50], Step [289/469], Loss: 0.6241, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [22/50], Step [290/469], Loss: 0.4778, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [22/50], Step [291/469], Loss: 0.7520, batch time: 0.52, accuracy:  77.34%\n",
      "Epoch [22/50], Step [292/469], Loss: 0.5048, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [22/50], Step [293/469], Loss: 0.6143, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [22/50], Step [294/469], Loss: 0.6196, batch time: 0.57, accuracy:  78.12%\n",
      "Epoch [22/50], Step [295/469], Loss: 0.5310, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [296/469], Loss: 0.5667, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [22/50], Step [297/469], Loss: 0.5439, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [22/50], Step [298/469], Loss: 0.6680, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [22/50], Step [299/469], Loss: 0.4905, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [22/50], Step [300/469], Loss: 0.6331, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [22/50], Step [301/469], Loss: 0.5489, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [22/50], Step [302/469], Loss: 0.4532, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [22/50], Step [303/469], Loss: 0.6499, batch time: 0.52, accuracy:  77.34%\n",
      "Epoch [22/50], Step [304/469], Loss: 0.4465, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [22/50], Step [305/469], Loss: 0.5995, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [22/50], Step [306/469], Loss: 0.6119, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [22/50], Step [307/469], Loss: 0.5349, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [22/50], Step [308/469], Loss: 0.7561, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [22/50], Step [309/469], Loss: 0.5162, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [22/50], Step [310/469], Loss: 0.3065, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [22/50], Step [311/469], Loss: 0.7708, batch time: 0.55, accuracy:  78.91%\n",
      "Epoch [22/50], Step [312/469], Loss: 0.5737, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [313/469], Loss: 0.4465, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [22/50], Step [314/469], Loss: 0.5162, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [22/50], Step [315/469], Loss: 0.4614, batch time: 0.62, accuracy:  85.16%\n",
      "Epoch [22/50], Step [316/469], Loss: 0.4201, batch time: 0.61, accuracy:  84.38%\n",
      "Epoch [22/50], Step [317/469], Loss: 0.6397, batch time: 0.60, accuracy:  80.47%\n",
      "Epoch [22/50], Step [318/469], Loss: 0.5589, batch time: 0.63, accuracy:  80.47%\n",
      "Epoch [22/50], Step [319/469], Loss: 0.5252, batch time: 0.68, accuracy:  86.72%\n",
      "Epoch [22/50], Step [320/469], Loss: 0.4916, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [22/50], Step [321/469], Loss: 0.5548, batch time: 0.55, accuracy:  78.91%\n",
      "Epoch [22/50], Step [322/469], Loss: 0.6498, batch time: 0.55, accuracy:  77.34%\n",
      "Epoch [22/50], Step [323/469], Loss: 0.5244, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [22/50], Step [324/469], Loss: 0.3708, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [22/50], Step [325/469], Loss: 0.5045, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [22/50], Step [326/469], Loss: 0.5654, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [22/50], Step [327/469], Loss: 0.4198, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [22/50], Step [328/469], Loss: 0.5002, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [22/50], Step [329/469], Loss: 0.5816, batch time: 0.54, accuracy:  79.69%\n",
      "Epoch [22/50], Step [330/469], Loss: 0.4221, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [22/50], Step [331/469], Loss: 0.3518, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [22/50], Step [332/469], Loss: 0.6868, batch time: 0.60, accuracy:  83.59%\n",
      "Epoch [22/50], Step [333/469], Loss: 0.6070, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [22/50], Step [334/469], Loss: 0.5703, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [22/50], Step [335/469], Loss: 0.6115, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [336/469], Loss: 0.5465, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [22/50], Step [337/469], Loss: 0.6078, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [22/50], Step [338/469], Loss: 0.6294, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [22/50], Step [339/469], Loss: 0.5429, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [22/50], Step [340/469], Loss: 0.5143, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [22/50], Step [341/469], Loss: 0.4127, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [22/50], Step [342/469], Loss: 0.6857, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [22/50], Step [343/469], Loss: 0.5492, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [22/50], Step [344/469], Loss: 0.5597, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [22/50], Step [345/469], Loss: 0.3991, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [22/50], Step [346/469], Loss: 0.3367, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [22/50], Step [347/469], Loss: 0.4841, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [22/50], Step [348/469], Loss: 0.5980, batch time: 0.69, accuracy:  81.25%\n",
      "Epoch [22/50], Step [349/469], Loss: 0.5855, batch time: 0.76, accuracy:  82.03%\n",
      "Epoch [22/50], Step [350/469], Loss: 0.5619, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [22/50], Step [351/469], Loss: 0.5282, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [22/50], Step [352/469], Loss: 0.4542, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [22/50], Step [353/469], Loss: 0.6536, batch time: 0.51, accuracy:  77.34%\n",
      "Epoch [22/50], Step [354/469], Loss: 0.4783, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [22/50], Step [355/469], Loss: 0.4461, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [22/50], Step [356/469], Loss: 0.5006, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [22/50], Step [357/469], Loss: 0.4420, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [22/50], Step [358/469], Loss: 0.6489, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [22/50], Step [359/469], Loss: 0.5103, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [22/50], Step [360/469], Loss: 0.5956, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [361/469], Loss: 0.5235, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [22/50], Step [362/469], Loss: 0.4633, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [22/50], Step [363/469], Loss: 0.5943, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [22/50], Step [364/469], Loss: 0.5579, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [22/50], Step [365/469], Loss: 0.4134, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [22/50], Step [366/469], Loss: 0.6294, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [22/50], Step [367/469], Loss: 0.7398, batch time: 0.50, accuracy:  75.78%\n",
      "Epoch [22/50], Step [368/469], Loss: 0.5587, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [22/50], Step [369/469], Loss: 0.4981, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [22/50], Step [370/469], Loss: 0.4006, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [22/50], Step [371/469], Loss: 0.4358, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [22/50], Step [372/469], Loss: 0.4887, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [22/50], Step [373/469], Loss: 0.6335, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [22/50], Step [374/469], Loss: 0.4903, batch time: 0.66, accuracy:  89.84%\n",
      "Epoch [22/50], Step [375/469], Loss: 0.3910, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [22/50], Step [376/469], Loss: 0.5255, batch time: 0.59, accuracy:  83.59%\n",
      "Epoch [22/50], Step [377/469], Loss: 0.4162, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [22/50], Step [378/469], Loss: 0.5673, batch time: 0.60, accuracy:  82.03%\n",
      "Epoch [22/50], Step [379/469], Loss: 0.6877, batch time: 0.59, accuracy:  80.47%\n",
      "Epoch [22/50], Step [380/469], Loss: 0.5182, batch time: 0.60, accuracy:  81.25%\n",
      "Epoch [22/50], Step [381/469], Loss: 0.4301, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [22/50], Step [382/469], Loss: 0.4760, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [22/50], Step [383/469], Loss: 0.4466, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [384/469], Loss: 0.5637, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [22/50], Step [385/469], Loss: 0.4863, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [22/50], Step [386/469], Loss: 0.5990, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [22/50], Step [387/469], Loss: 0.5305, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [22/50], Step [388/469], Loss: 0.7282, batch time: 0.47, accuracy:  77.34%\n",
      "Epoch [22/50], Step [389/469], Loss: 0.4043, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [22/50], Step [390/469], Loss: 0.3176, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [22/50], Step [391/469], Loss: 0.6292, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [22/50], Step [392/469], Loss: 0.4729, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [22/50], Step [393/469], Loss: 0.6951, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [22/50], Step [394/469], Loss: 0.5375, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [22/50], Step [395/469], Loss: 0.5681, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [22/50], Step [396/469], Loss: 0.3791, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [22/50], Step [397/469], Loss: 0.6950, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [22/50], Step [398/469], Loss: 0.3313, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [22/50], Step [399/469], Loss: 0.4415, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [22/50], Step [400/469], Loss: 0.4332, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [22/50], Step [401/469], Loss: 0.5218, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [22/50], Step [402/469], Loss: 0.4851, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [22/50], Step [403/469], Loss: 0.5305, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [22/50], Step [404/469], Loss: 0.4655, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [22/50], Step [405/469], Loss: 0.5241, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [22/50], Step [406/469], Loss: 0.4359, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [22/50], Step [407/469], Loss: 0.4519, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [22/50], Step [408/469], Loss: 0.5369, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [22/50], Step [409/469], Loss: 0.3234, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [22/50], Step [410/469], Loss: 0.6959, batch time: 0.62, accuracy:  75.78%\n",
      "Epoch [22/50], Step [411/469], Loss: 0.4998, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [22/50], Step [412/469], Loss: 0.4773, batch time: 0.63, accuracy:  83.59%\n",
      "Epoch [22/50], Step [413/469], Loss: 0.6585, batch time: 0.61, accuracy:  80.47%\n",
      "Epoch [22/50], Step [414/469], Loss: 0.4003, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [22/50], Step [415/469], Loss: 0.4870, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [416/469], Loss: 0.6188, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [22/50], Step [417/469], Loss: 0.4848, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [22/50], Step [418/469], Loss: 0.3675, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [22/50], Step [419/469], Loss: 0.4068, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [22/50], Step [420/469], Loss: 0.5212, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [22/50], Step [421/469], Loss: 0.3697, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [22/50], Step [422/469], Loss: 0.5205, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [22/50], Step [423/469], Loss: 0.6805, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [22/50], Step [424/469], Loss: 0.4123, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [22/50], Step [425/469], Loss: 0.3751, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [22/50], Step [426/469], Loss: 0.4791, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [22/50], Step [427/469], Loss: 0.3261, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [22/50], Step [428/469], Loss: 0.5100, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [22/50], Step [429/469], Loss: 0.5740, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [22/50], Step [430/469], Loss: 0.5183, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [22/50], Step [431/469], Loss: 0.4927, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [22/50], Step [432/469], Loss: 0.5560, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [22/50], Step [433/469], Loss: 0.6253, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [22/50], Step [434/469], Loss: 0.5754, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [22/50], Step [435/469], Loss: 0.4938, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [22/50], Step [436/469], Loss: 0.5756, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [22/50], Step [437/469], Loss: 0.6010, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [22/50], Step [438/469], Loss: 0.5089, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [22/50], Step [439/469], Loss: 0.4580, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [22/50], Step [440/469], Loss: 0.7352, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [22/50], Step [441/469], Loss: 0.5172, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [22/50], Step [442/469], Loss: 0.4669, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [22/50], Step [443/469], Loss: 0.4970, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [22/50], Step [444/469], Loss: 0.4528, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [22/50], Step [445/469], Loss: 0.4659, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [22/50], Step [446/469], Loss: 0.3386, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [22/50], Step [447/469], Loss: 0.4386, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [22/50], Step [448/469], Loss: 0.5860, batch time: 0.67, accuracy:  82.81%\n",
      "Epoch [22/50], Step [449/469], Loss: 0.4350, batch time: 0.63, accuracy:  86.72%\n",
      "Epoch [22/50], Step [450/469], Loss: 0.4491, batch time: 0.64, accuracy:  87.50%\n",
      "Epoch [22/50], Step [451/469], Loss: 0.5093, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [22/50], Step [452/469], Loss: 0.6610, batch time: 0.56, accuracy:  77.34%\n",
      "Epoch [22/50], Step [453/469], Loss: 0.4941, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [22/50], Step [454/469], Loss: 0.5722, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [22/50], Step [455/469], Loss: 0.6866, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [22/50], Step [456/469], Loss: 0.5401, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [22/50], Step [457/469], Loss: 0.3721, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [22/50], Step [458/469], Loss: 0.4607, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [22/50], Step [459/469], Loss: 0.4955, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [22/50], Step [460/469], Loss: 0.4445, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [22/50], Step [461/469], Loss: 0.4205, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [22/50], Step [462/469], Loss: 0.6315, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [22/50], Step [463/469], Loss: 0.7847, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [22/50], Step [464/469], Loss: 0.5035, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [22/50], Step [465/469], Loss: 0.4914, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [22/50], Step [466/469], Loss: 0.3966, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [22/50], Step [467/469], Loss: 0.5900, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [22/50], Step [468/469], Loss: 0.4462, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [22/50], Step [469/469], Loss: 0.5290, batch time: 0.52, accuracy:  83.33%\n",
      "Epoch [23/50], Step [1/469], Loss: 0.4460, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [23/50], Step [2/469], Loss: 0.4370, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [23/50], Step [3/469], Loss: 0.6109, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [23/50], Step [4/469], Loss: 0.4165, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [23/50], Step [5/469], Loss: 0.4123, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [23/50], Step [6/469], Loss: 0.3839, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [23/50], Step [7/469], Loss: 0.4244, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [23/50], Step [8/469], Loss: 0.5790, batch time: 0.67, accuracy:  80.47%\n",
      "Epoch [23/50], Step [9/469], Loss: 0.4393, batch time: 0.65, accuracy:  86.72%\n",
      "Epoch [23/50], Step [10/469], Loss: 0.4301, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [23/50], Step [11/469], Loss: 0.5938, batch time: 0.70, accuracy:  82.81%\n",
      "Epoch [23/50], Step [12/469], Loss: 0.4630, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [23/50], Step [13/469], Loss: 0.3977, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [23/50], Step [14/469], Loss: 0.4229, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [23/50], Step [15/469], Loss: 0.3427, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [23/50], Step [16/469], Loss: 0.7026, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [23/50], Step [17/469], Loss: 0.2183, batch time: 0.68, accuracy:  95.31%\n",
      "Epoch [23/50], Step [18/469], Loss: 0.4451, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [23/50], Step [19/469], Loss: 0.3476, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [23/50], Step [20/469], Loss: 0.4457, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [23/50], Step [21/469], Loss: 0.4074, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [23/50], Step [22/469], Loss: 0.4788, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [23/50], Step [23/469], Loss: 0.6463, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [23/50], Step [24/469], Loss: 0.6111, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [23/50], Step [25/469], Loss: 0.4436, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [23/50], Step [26/469], Loss: 0.4552, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [23/50], Step [27/469], Loss: 0.3752, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [23/50], Step [28/469], Loss: 0.6223, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [23/50], Step [29/469], Loss: 0.5017, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [23/50], Step [30/469], Loss: 0.4371, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [23/50], Step [31/469], Loss: 0.3782, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [23/50], Step [32/469], Loss: 0.5049, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [23/50], Step [33/469], Loss: 0.5175, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [23/50], Step [34/469], Loss: 0.3631, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [23/50], Step [35/469], Loss: 0.4083, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [23/50], Step [36/469], Loss: 0.3280, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [23/50], Step [37/469], Loss: 0.4037, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [23/50], Step [38/469], Loss: 0.4756, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [23/50], Step [39/469], Loss: 0.6307, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [23/50], Step [40/469], Loss: 0.3414, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [23/50], Step [41/469], Loss: 0.8521, batch time: 0.49, accuracy:  75.00%\n",
      "Epoch [23/50], Step [42/469], Loss: 0.6291, batch time: 0.56, accuracy:  82.03%\n",
      "Epoch [23/50], Step [43/469], Loss: 0.2823, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [23/50], Step [44/469], Loss: 0.5889, batch time: 0.63, accuracy:  83.59%\n",
      "Epoch [23/50], Step [45/469], Loss: 0.6640, batch time: 0.59, accuracy:  82.03%\n",
      "Epoch [23/50], Step [46/469], Loss: 0.3528, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [23/50], Step [47/469], Loss: 0.5395, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [23/50], Step [48/469], Loss: 0.5303, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [23/50], Step [49/469], Loss: 0.5868, batch time: 0.62, accuracy:  80.47%\n",
      "Epoch [23/50], Step [50/469], Loss: 0.8062, batch time: 0.63, accuracy:  78.91%\n",
      "Epoch [23/50], Step [51/469], Loss: 0.4871, batch time: 0.59, accuracy:  82.03%\n",
      "Epoch [23/50], Step [52/469], Loss: 0.5847, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [23/50], Step [53/469], Loss: 0.3968, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [23/50], Step [54/469], Loss: 0.4904, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [23/50], Step [55/469], Loss: 0.4356, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [23/50], Step [56/469], Loss: 0.4048, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [23/50], Step [57/469], Loss: 0.4080, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [23/50], Step [58/469], Loss: 0.5794, batch time: 0.59, accuracy:  80.47%\n",
      "Epoch [23/50], Step [59/469], Loss: 0.4361, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [23/50], Step [60/469], Loss: 0.4620, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [23/50], Step [61/469], Loss: 0.6355, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [23/50], Step [62/469], Loss: 0.3432, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [23/50], Step [63/469], Loss: 0.4078, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [23/50], Step [64/469], Loss: 0.6556, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [23/50], Step [65/469], Loss: 0.3590, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [23/50], Step [66/469], Loss: 0.6137, batch time: 0.49, accuracy:  75.78%\n",
      "Epoch [23/50], Step [67/469], Loss: 0.5106, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [23/50], Step [68/469], Loss: 0.5915, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [23/50], Step [69/469], Loss: 0.5005, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [23/50], Step [70/469], Loss: 0.7279, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [23/50], Step [71/469], Loss: 0.6330, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [23/50], Step [72/469], Loss: 0.5674, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [23/50], Step [73/469], Loss: 0.3992, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [23/50], Step [74/469], Loss: 0.6608, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [23/50], Step [75/469], Loss: 0.4485, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [23/50], Step [76/469], Loss: 0.6060, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [23/50], Step [77/469], Loss: 0.5323, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [23/50], Step [78/469], Loss: 0.8955, batch time: 0.54, accuracy:  80.47%\n",
      "Epoch [23/50], Step [79/469], Loss: 0.4514, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [23/50], Step [80/469], Loss: 0.6376, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [23/50], Step [81/469], Loss: 0.4863, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [23/50], Step [82/469], Loss: 0.5918, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [83/469], Loss: 0.4207, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [23/50], Step [84/469], Loss: 0.6115, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [23/50], Step [85/469], Loss: 0.6559, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [23/50], Step [86/469], Loss: 0.6433, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [23/50], Step [87/469], Loss: 0.5072, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [23/50], Step [88/469], Loss: 0.3756, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [23/50], Step [89/469], Loss: 0.5172, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [23/50], Step [90/469], Loss: 0.6767, batch time: 0.56, accuracy:  78.12%\n",
      "Epoch [23/50], Step [91/469], Loss: 0.5774, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [23/50], Step [92/469], Loss: 0.4261, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [23/50], Step [93/469], Loss: 0.6211, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [23/50], Step [94/469], Loss: 0.6547, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [23/50], Step [95/469], Loss: 0.6561, batch time: 0.48, accuracy:  76.56%\n",
      "Epoch [23/50], Step [96/469], Loss: 0.4770, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [23/50], Step [97/469], Loss: 0.5897, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [23/50], Step [98/469], Loss: 0.5197, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [23/50], Step [99/469], Loss: 0.4482, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [23/50], Step [100/469], Loss: 0.5359, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [23/50], Step [101/469], Loss: 0.3098, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [23/50], Step [102/469], Loss: 0.4441, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [23/50], Step [103/469], Loss: 0.5219, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [23/50], Step [104/469], Loss: 0.5056, batch time: 0.54, accuracy:  78.91%\n",
      "Epoch [23/50], Step [105/469], Loss: 0.6187, batch time: 0.62, accuracy:  78.91%\n",
      "Epoch [23/50], Step [106/469], Loss: 0.3676, batch time: 0.65, accuracy:  89.84%\n",
      "Epoch [23/50], Step [107/469], Loss: 0.4170, batch time: 0.67, accuracy:  89.06%\n",
      "Epoch [23/50], Step [108/469], Loss: 0.4167, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [23/50], Step [109/469], Loss: 0.5340, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [110/469], Loss: 0.4193, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [23/50], Step [111/469], Loss: 0.4748, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [23/50], Step [112/469], Loss: 0.4869, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [23/50], Step [113/469], Loss: 0.6542, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [23/50], Step [114/469], Loss: 0.5093, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [23/50], Step [115/469], Loss: 0.4067, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [23/50], Step [116/469], Loss: 0.6212, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [23/50], Step [117/469], Loss: 0.3760, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [23/50], Step [118/469], Loss: 0.4696, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [23/50], Step [119/469], Loss: 0.4038, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [23/50], Step [120/469], Loss: 0.4571, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [23/50], Step [121/469], Loss: 0.6339, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [23/50], Step [122/469], Loss: 0.5582, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [23/50], Step [123/469], Loss: 0.6874, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [23/50], Step [124/469], Loss: 0.6641, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [23/50], Step [125/469], Loss: 0.4346, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [23/50], Step [126/469], Loss: 0.3330, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [23/50], Step [127/469], Loss: 0.5948, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [23/50], Step [128/469], Loss: 0.3879, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [23/50], Step [129/469], Loss: 0.6291, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [23/50], Step [130/469], Loss: 0.7728, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [23/50], Step [131/469], Loss: 0.5044, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [23/50], Step [132/469], Loss: 0.4892, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [23/50], Step [133/469], Loss: 0.4132, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [23/50], Step [134/469], Loss: 0.5418, batch time: 0.56, accuracy:  83.59%\n",
      "Epoch [23/50], Step [135/469], Loss: 0.6125, batch time: 0.62, accuracy:  82.03%\n",
      "Epoch [23/50], Step [136/469], Loss: 0.5158, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [23/50], Step [137/469], Loss: 0.3829, batch time: 0.66, accuracy:  89.06%\n",
      "Epoch [23/50], Step [138/469], Loss: 0.4446, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [23/50], Step [139/469], Loss: 0.6495, batch time: 0.56, accuracy:  83.59%\n",
      "Epoch [23/50], Step [140/469], Loss: 0.4433, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [23/50], Step [141/469], Loss: 0.4682, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [23/50], Step [142/469], Loss: 0.5354, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [23/50], Step [143/469], Loss: 0.5035, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [23/50], Step [144/469], Loss: 0.3951, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [23/50], Step [145/469], Loss: 0.4961, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [23/50], Step [146/469], Loss: 0.4221, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [23/50], Step [147/469], Loss: 0.3661, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [23/50], Step [148/469], Loss: 0.5284, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [23/50], Step [149/469], Loss: 0.6261, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [23/50], Step [150/469], Loss: 0.4882, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [23/50], Step [151/469], Loss: 0.4094, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [23/50], Step [152/469], Loss: 0.4795, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [23/50], Step [153/469], Loss: 0.4469, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [23/50], Step [154/469], Loss: 0.6037, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [23/50], Step [155/469], Loss: 0.5445, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [23/50], Step [156/469], Loss: 0.5728, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [23/50], Step [157/469], Loss: 0.5242, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [23/50], Step [158/469], Loss: 0.6014, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [23/50], Step [159/469], Loss: 0.6580, batch time: 0.52, accuracy:  78.91%\n",
      "Epoch [23/50], Step [160/469], Loss: 0.3441, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [23/50], Step [161/469], Loss: 0.4520, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [23/50], Step [162/469], Loss: 0.4907, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [23/50], Step [163/469], Loss: 0.5060, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [23/50], Step [164/469], Loss: 0.5162, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [23/50], Step [165/469], Loss: 0.4802, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [23/50], Step [166/469], Loss: 0.4964, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [23/50], Step [167/469], Loss: 0.5043, batch time: 0.60, accuracy:  85.94%\n",
      "Epoch [23/50], Step [168/469], Loss: 0.4247, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [23/50], Step [169/469], Loss: 0.4969, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [23/50], Step [170/469], Loss: 0.5791, batch time: 0.68, accuracy:  80.47%\n",
      "Epoch [23/50], Step [171/469], Loss: 0.5120, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [23/50], Step [172/469], Loss: 0.5464, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [23/50], Step [173/469], Loss: 0.6821, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [23/50], Step [174/469], Loss: 0.5142, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [23/50], Step [175/469], Loss: 0.6291, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [23/50], Step [176/469], Loss: 0.3964, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [23/50], Step [177/469], Loss: 0.5891, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [23/50], Step [178/469], Loss: 0.5197, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [23/50], Step [179/469], Loss: 0.5311, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [23/50], Step [180/469], Loss: 0.6709, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [23/50], Step [181/469], Loss: 0.4417, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [23/50], Step [182/469], Loss: 0.4916, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [23/50], Step [183/469], Loss: 0.4243, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [23/50], Step [184/469], Loss: 0.6641, batch time: 0.55, accuracy:  78.91%\n",
      "Epoch [23/50], Step [185/469], Loss: 0.5257, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [23/50], Step [186/469], Loss: 0.5237, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [23/50], Step [187/469], Loss: 0.6188, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [23/50], Step [188/469], Loss: 0.4655, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [23/50], Step [189/469], Loss: 0.3632, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [23/50], Step [190/469], Loss: 0.4581, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [23/50], Step [191/469], Loss: 0.4570, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [192/469], Loss: 0.4210, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [193/469], Loss: 0.5499, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [23/50], Step [194/469], Loss: 0.6101, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [23/50], Step [195/469], Loss: 0.4047, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [23/50], Step [196/469], Loss: 0.4199, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [23/50], Step [197/469], Loss: 0.6220, batch time: 0.47, accuracy:  78.91%\n",
      "Epoch [23/50], Step [198/469], Loss: 0.7145, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [23/50], Step [199/469], Loss: 0.5642, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [23/50], Step [200/469], Loss: 0.5301, batch time: 0.60, accuracy:  85.16%\n",
      "Epoch [23/50], Step [201/469], Loss: 0.4166, batch time: 0.68, accuracy:  86.72%\n",
      "Epoch [23/50], Step [202/469], Loss: 0.4774, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [23/50], Step [203/469], Loss: 0.6484, batch time: 0.55, accuracy:  79.69%\n",
      "Epoch [23/50], Step [204/469], Loss: 0.5034, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [205/469], Loss: 0.4518, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [23/50], Step [206/469], Loss: 0.6253, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [23/50], Step [207/469], Loss: 0.4877, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [23/50], Step [208/469], Loss: 0.7165, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [23/50], Step [209/469], Loss: 0.3859, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [23/50], Step [210/469], Loss: 0.5199, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [23/50], Step [211/469], Loss: 0.4206, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [23/50], Step [212/469], Loss: 0.6005, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [23/50], Step [213/469], Loss: 0.8173, batch time: 0.45, accuracy:  72.66%\n",
      "Epoch [23/50], Step [214/469], Loss: 0.4709, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [23/50], Step [215/469], Loss: 0.4674, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [23/50], Step [216/469], Loss: 0.6195, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [23/50], Step [217/469], Loss: 0.5132, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [23/50], Step [218/469], Loss: 0.5117, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [23/50], Step [219/469], Loss: 0.4782, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [23/50], Step [220/469], Loss: 0.5691, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [23/50], Step [221/469], Loss: 0.3635, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [23/50], Step [222/469], Loss: 0.5114, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [23/50], Step [223/469], Loss: 0.4582, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [23/50], Step [224/469], Loss: 0.4773, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [23/50], Step [225/469], Loss: 0.5409, batch time: 0.56, accuracy:  80.47%\n",
      "Epoch [23/50], Step [226/469], Loss: 0.5727, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [23/50], Step [227/469], Loss: 0.4943, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [23/50], Step [228/469], Loss: 0.4259, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [23/50], Step [229/469], Loss: 0.6099, batch time: 0.51, accuracy:  78.12%\n",
      "Epoch [23/50], Step [230/469], Loss: 0.5754, batch time: 0.64, accuracy:  82.81%\n",
      "Epoch [23/50], Step [231/469], Loss: 0.5585, batch time: 0.62, accuracy:  82.03%\n",
      "Epoch [23/50], Step [232/469], Loss: 0.3962, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [23/50], Step [233/469], Loss: 0.5418, batch time: 0.56, accuracy:  81.25%\n",
      "Epoch [23/50], Step [234/469], Loss: 0.4447, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [23/50], Step [235/469], Loss: 0.4883, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [23/50], Step [236/469], Loss: 0.2876, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [23/50], Step [237/469], Loss: 0.3515, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [23/50], Step [238/469], Loss: 0.7821, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [23/50], Step [239/469], Loss: 0.5096, batch time: 0.59, accuracy:  83.59%\n",
      "Epoch [23/50], Step [240/469], Loss: 0.5531, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [23/50], Step [241/469], Loss: 0.3486, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [23/50], Step [242/469], Loss: 0.5132, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [23/50], Step [243/469], Loss: 0.4510, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [23/50], Step [244/469], Loss: 0.4682, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [23/50], Step [245/469], Loss: 0.4766, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [23/50], Step [246/469], Loss: 0.6057, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [23/50], Step [247/469], Loss: 0.4719, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [23/50], Step [248/469], Loss: 0.6071, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [23/50], Step [249/469], Loss: 0.4872, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [23/50], Step [250/469], Loss: 0.4900, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [23/50], Step [251/469], Loss: 0.5629, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [23/50], Step [252/469], Loss: 0.3959, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [23/50], Step [253/469], Loss: 0.4954, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [23/50], Step [254/469], Loss: 0.5954, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [23/50], Step [255/469], Loss: 0.4863, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [23/50], Step [256/469], Loss: 0.7128, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [23/50], Step [257/469], Loss: 0.6355, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [23/50], Step [258/469], Loss: 0.7005, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [23/50], Step [259/469], Loss: 0.4845, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [23/50], Step [260/469], Loss: 0.7078, batch time: 0.49, accuracy:  74.22%\n",
      "Epoch [23/50], Step [261/469], Loss: 0.3703, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [23/50], Step [262/469], Loss: 0.6063, batch time: 0.50, accuracy:  79.69%\n",
      "Epoch [23/50], Step [263/469], Loss: 0.4556, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [23/50], Step [264/469], Loss: 0.5062, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [23/50], Step [265/469], Loss: 0.4614, batch time: 0.62, accuracy:  83.59%\n",
      "Epoch [23/50], Step [266/469], Loss: 0.4575, batch time: 0.64, accuracy:  85.94%\n",
      "Epoch [23/50], Step [267/469], Loss: 0.4623, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [23/50], Step [268/469], Loss: 0.4891, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [23/50], Step [269/469], Loss: 0.4823, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [23/50], Step [270/469], Loss: 0.5051, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [23/50], Step [271/469], Loss: 0.4881, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [23/50], Step [272/469], Loss: 0.5985, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [23/50], Step [273/469], Loss: 0.5769, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [23/50], Step [274/469], Loss: 0.3872, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [23/50], Step [275/469], Loss: 0.6058, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [23/50], Step [276/469], Loss: 0.3485, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [23/50], Step [277/469], Loss: 0.5483, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [23/50], Step [278/469], Loss: 0.6320, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [23/50], Step [279/469], Loss: 0.4516, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [23/50], Step [280/469], Loss: 0.4459, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [23/50], Step [281/469], Loss: 0.4463, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [23/50], Step [282/469], Loss: 0.4698, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [23/50], Step [283/469], Loss: 0.5080, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [23/50], Step [284/469], Loss: 0.4933, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [23/50], Step [285/469], Loss: 0.3506, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [23/50], Step [286/469], Loss: 0.5385, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [23/50], Step [287/469], Loss: 0.4902, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [23/50], Step [288/469], Loss: 0.4935, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [23/50], Step [289/469], Loss: 0.6877, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [23/50], Step [290/469], Loss: 0.6362, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [23/50], Step [291/469], Loss: 0.5476, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [23/50], Step [292/469], Loss: 0.5631, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [23/50], Step [293/469], Loss: 0.3113, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [23/50], Step [294/469], Loss: 0.3965, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [23/50], Step [295/469], Loss: 0.3415, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [23/50], Step [296/469], Loss: 0.4204, batch time: 0.64, accuracy:  85.94%\n",
      "Epoch [23/50], Step [297/469], Loss: 0.6617, batch time: 0.61, accuracy:  77.34%\n",
      "Epoch [23/50], Step [298/469], Loss: 0.4382, batch time: 0.66, accuracy:  87.50%\n",
      "Epoch [23/50], Step [299/469], Loss: 0.4721, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [23/50], Step [300/469], Loss: 0.5221, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [23/50], Step [301/469], Loss: 0.4305, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [23/50], Step [302/469], Loss: 0.5862, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [23/50], Step [303/469], Loss: 0.3766, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [23/50], Step [304/469], Loss: 0.5429, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [23/50], Step [305/469], Loss: 0.5408, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [23/50], Step [306/469], Loss: 0.6351, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [23/50], Step [307/469], Loss: 0.6287, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [23/50], Step [308/469], Loss: 0.4080, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [23/50], Step [309/469], Loss: 0.4763, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [310/469], Loss: 0.4373, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [23/50], Step [311/469], Loss: 0.4080, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [23/50], Step [312/469], Loss: 0.5777, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [23/50], Step [313/469], Loss: 0.4114, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [23/50], Step [314/469], Loss: 0.4791, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [23/50], Step [315/469], Loss: 0.4218, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [23/50], Step [316/469], Loss: 0.4587, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [23/50], Step [317/469], Loss: 0.5503, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [23/50], Step [318/469], Loss: 0.5973, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [23/50], Step [319/469], Loss: 0.3979, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [23/50], Step [320/469], Loss: 0.5739, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [23/50], Step [321/469], Loss: 0.4549, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [23/50], Step [322/469], Loss: 0.5243, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [23/50], Step [323/469], Loss: 0.4042, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [23/50], Step [324/469], Loss: 0.5451, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [23/50], Step [325/469], Loss: 0.2963, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [23/50], Step [326/469], Loss: 0.5184, batch time: 0.62, accuracy:  85.94%\n",
      "Epoch [23/50], Step [327/469], Loss: 0.4558, batch time: 0.65, accuracy:  87.50%\n",
      "Epoch [23/50], Step [328/469], Loss: 0.5739, batch time: 0.62, accuracy:  85.16%\n",
      "Epoch [23/50], Step [329/469], Loss: 0.4490, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [23/50], Step [330/469], Loss: 0.4616, batch time: 0.65, accuracy:  87.50%\n",
      "Epoch [23/50], Step [331/469], Loss: 0.5008, batch time: 0.65, accuracy:  81.25%\n",
      "Epoch [23/50], Step [332/469], Loss: 0.4555, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [23/50], Step [333/469], Loss: 0.7730, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [23/50], Step [334/469], Loss: 0.4401, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [335/469], Loss: 0.4612, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [336/469], Loss: 0.5037, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [23/50], Step [337/469], Loss: 0.6617, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [23/50], Step [338/469], Loss: 0.4417, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [23/50], Step [339/469], Loss: 0.4432, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [23/50], Step [340/469], Loss: 0.6208, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [23/50], Step [341/469], Loss: 0.4689, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [23/50], Step [342/469], Loss: 0.4078, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [23/50], Step [343/469], Loss: 0.4484, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [23/50], Step [344/469], Loss: 0.5141, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [23/50], Step [345/469], Loss: 0.5000, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [23/50], Step [346/469], Loss: 0.5134, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [23/50], Step [347/469], Loss: 0.5689, batch time: 0.53, accuracy:  78.12%\n",
      "Epoch [23/50], Step [348/469], Loss: 0.5152, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [23/50], Step [349/469], Loss: 0.6577, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [23/50], Step [350/469], Loss: 0.6007, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [23/50], Step [351/469], Loss: 0.4444, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [23/50], Step [352/469], Loss: 0.5009, batch time: 0.64, accuracy:  84.38%\n",
      "Epoch [23/50], Step [353/469], Loss: 0.4829, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [23/50], Step [354/469], Loss: 0.6002, batch time: 0.55, accuracy:  80.47%\n",
      "Epoch [23/50], Step [355/469], Loss: 0.4826, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [23/50], Step [356/469], Loss: 0.3130, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [23/50], Step [357/469], Loss: 0.3770, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [23/50], Step [358/469], Loss: 0.6059, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [23/50], Step [359/469], Loss: 0.4848, batch time: 0.57, accuracy:  85.16%\n",
      "Epoch [23/50], Step [360/469], Loss: 0.4070, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [23/50], Step [361/469], Loss: 0.4917, batch time: 0.61, accuracy:  84.38%\n",
      "Epoch [23/50], Step [362/469], Loss: 0.4520, batch time: 0.67, accuracy:  87.50%\n",
      "Epoch [23/50], Step [363/469], Loss: 0.6486, batch time: 0.60, accuracy:  82.81%\n",
      "Epoch [23/50], Step [364/469], Loss: 0.4174, batch time: 0.64, accuracy:  87.50%\n",
      "Epoch [23/50], Step [365/469], Loss: 0.4794, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [23/50], Step [366/469], Loss: 0.3717, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [23/50], Step [367/469], Loss: 0.6216, batch time: 0.63, accuracy:  82.03%\n",
      "Epoch [23/50], Step [368/469], Loss: 0.3729, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [23/50], Step [369/469], Loss: 0.3707, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [23/50], Step [370/469], Loss: 0.6408, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [23/50], Step [371/469], Loss: 0.3631, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [23/50], Step [372/469], Loss: 0.5578, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [23/50], Step [373/469], Loss: 0.5017, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [23/50], Step [374/469], Loss: 0.3695, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [23/50], Step [375/469], Loss: 0.6783, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [23/50], Step [376/469], Loss: 0.3974, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [23/50], Step [377/469], Loss: 0.3180, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [23/50], Step [378/469], Loss: 0.3787, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [23/50], Step [379/469], Loss: 0.4306, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [23/50], Step [380/469], Loss: 0.4373, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [23/50], Step [381/469], Loss: 0.5254, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [23/50], Step [382/469], Loss: 0.5612, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [23/50], Step [383/469], Loss: 0.4808, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [23/50], Step [384/469], Loss: 0.6902, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [23/50], Step [385/469], Loss: 0.6902, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [23/50], Step [386/469], Loss: 0.3795, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [23/50], Step [387/469], Loss: 0.6073, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [23/50], Step [388/469], Loss: 0.6091, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [23/50], Step [389/469], Loss: 0.4854, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [23/50], Step [390/469], Loss: 0.5649, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [23/50], Step [391/469], Loss: 0.4006, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [23/50], Step [392/469], Loss: 0.4200, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [23/50], Step [393/469], Loss: 0.5137, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [23/50], Step [394/469], Loss: 0.4427, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [23/50], Step [395/469], Loss: 0.4487, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [23/50], Step [396/469], Loss: 0.4436, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [23/50], Step [397/469], Loss: 0.5427, batch time: 0.61, accuracy:  81.25%\n",
      "Epoch [23/50], Step [398/469], Loss: 0.6593, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [23/50], Step [399/469], Loss: 0.4464, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [23/50], Step [400/469], Loss: 0.4806, batch time: 0.57, accuracy:  85.16%\n",
      "Epoch [23/50], Step [401/469], Loss: 0.5028, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [23/50], Step [402/469], Loss: 0.4305, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [23/50], Step [403/469], Loss: 0.4646, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [23/50], Step [404/469], Loss: 0.4214, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [23/50], Step [405/469], Loss: 0.8146, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [23/50], Step [406/469], Loss: 0.4443, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [23/50], Step [407/469], Loss: 0.4025, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [23/50], Step [408/469], Loss: 0.4352, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [23/50], Step [409/469], Loss: 0.4959, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [23/50], Step [410/469], Loss: 0.3651, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [23/50], Step [411/469], Loss: 0.4461, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [23/50], Step [412/469], Loss: 0.4118, batch time: 0.57, accuracy:  85.16%\n",
      "Epoch [23/50], Step [413/469], Loss: 0.4873, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [23/50], Step [414/469], Loss: 0.3787, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [23/50], Step [415/469], Loss: 0.3092, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [23/50], Step [416/469], Loss: 0.7139, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [23/50], Step [417/469], Loss: 0.3804, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [23/50], Step [418/469], Loss: 0.4587, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [23/50], Step [419/469], Loss: 0.4705, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [23/50], Step [420/469], Loss: 0.4090, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [23/50], Step [421/469], Loss: 0.3540, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [23/50], Step [422/469], Loss: 0.4453, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [23/50], Step [423/469], Loss: 0.4862, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [23/50], Step [424/469], Loss: 0.4774, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [23/50], Step [425/469], Loss: 0.4843, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [23/50], Step [426/469], Loss: 0.4940, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [23/50], Step [427/469], Loss: 0.3832, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [23/50], Step [428/469], Loss: 0.5975, batch time: 0.57, accuracy:  83.59%\n",
      "Epoch [23/50], Step [429/469], Loss: 0.4485, batch time: 0.76, accuracy:  85.94%\n",
      "Epoch [23/50], Step [430/469], Loss: 0.5687, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [23/50], Step [431/469], Loss: 0.4696, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [23/50], Step [432/469], Loss: 0.5007, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [23/50], Step [433/469], Loss: 0.6308, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [23/50], Step [434/469], Loss: 0.5236, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [23/50], Step [435/469], Loss: 0.3819, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [23/50], Step [436/469], Loss: 0.4350, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [23/50], Step [437/469], Loss: 0.5013, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [23/50], Step [438/469], Loss: 0.3770, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [23/50], Step [439/469], Loss: 0.3694, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [23/50], Step [440/469], Loss: 0.4893, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [23/50], Step [441/469], Loss: 0.5782, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [23/50], Step [442/469], Loss: 0.3904, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [23/50], Step [443/469], Loss: 0.4511, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [23/50], Step [444/469], Loss: 0.4227, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [23/50], Step [445/469], Loss: 0.5243, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [23/50], Step [446/469], Loss: 0.7274, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [23/50], Step [447/469], Loss: 0.4529, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [23/50], Step [448/469], Loss: 0.5269, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [23/50], Step [449/469], Loss: 0.4647, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [23/50], Step [450/469], Loss: 0.5029, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [23/50], Step [451/469], Loss: 0.2948, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [23/50], Step [452/469], Loss: 0.6102, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [23/50], Step [453/469], Loss: 0.6021, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [23/50], Step [454/469], Loss: 0.5969, batch time: 0.55, accuracy:  81.25%\n",
      "Epoch [23/50], Step [455/469], Loss: 0.6029, batch time: 0.48, accuracy:  78.12%\n",
      "Epoch [23/50], Step [456/469], Loss: 0.4857, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [23/50], Step [457/469], Loss: 0.4821, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [23/50], Step [458/469], Loss: 0.4214, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [23/50], Step [459/469], Loss: 0.6654, batch time: 0.62, accuracy:  83.59%\n",
      "Epoch [23/50], Step [460/469], Loss: 0.5983, batch time: 0.74, accuracy:  84.38%\n",
      "Epoch [23/50], Step [461/469], Loss: 0.6031, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [23/50], Step [462/469], Loss: 0.5696, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [23/50], Step [463/469], Loss: 0.4137, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [23/50], Step [464/469], Loss: 0.4324, batch time: 0.65, accuracy:  86.72%\n",
      "Epoch [23/50], Step [465/469], Loss: 0.5319, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [23/50], Step [466/469], Loss: 0.4583, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [23/50], Step [467/469], Loss: 0.5592, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [23/50], Step [468/469], Loss: 0.4381, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [23/50], Step [469/469], Loss: 0.5079, batch time: 0.46, accuracy:  80.21%\n",
      "Epoch [24/50], Step [1/469], Loss: 0.5079, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [24/50], Step [2/469], Loss: 0.3727, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [24/50], Step [3/469], Loss: 0.6495, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [24/50], Step [4/469], Loss: 0.5782, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [24/50], Step [5/469], Loss: 0.4269, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [24/50], Step [6/469], Loss: 0.4035, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [24/50], Step [7/469], Loss: 0.4955, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [24/50], Step [8/469], Loss: 0.4771, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [24/50], Step [9/469], Loss: 0.5799, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [24/50], Step [10/469], Loss: 0.4548, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [24/50], Step [11/469], Loss: 0.4229, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [24/50], Step [12/469], Loss: 0.4734, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [24/50], Step [13/469], Loss: 0.5607, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [24/50], Step [14/469], Loss: 0.4068, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [24/50], Step [15/469], Loss: 0.4754, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [24/50], Step [16/469], Loss: 0.3647, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [24/50], Step [17/469], Loss: 0.6440, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [24/50], Step [18/469], Loss: 0.6857, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [24/50], Step [19/469], Loss: 0.4703, batch time: 0.57, accuracy:  83.59%\n",
      "Epoch [24/50], Step [20/469], Loss: 0.3677, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [24/50], Step [21/469], Loss: 0.4927, batch time: 0.64, accuracy:  85.16%\n",
      "Epoch [24/50], Step [22/469], Loss: 0.6526, batch time: 0.60, accuracy:  82.03%\n",
      "Epoch [24/50], Step [23/469], Loss: 0.4957, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [24/50], Step [24/469], Loss: 0.6032, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [24/50], Step [25/469], Loss: 0.4751, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [24/50], Step [26/469], Loss: 0.4344, batch time: 0.56, accuracy:  82.03%\n",
      "Epoch [24/50], Step [27/469], Loss: 0.6074, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [28/469], Loss: 0.4962, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [24/50], Step [29/469], Loss: 0.4707, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [24/50], Step [30/469], Loss: 0.4306, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [24/50], Step [31/469], Loss: 0.3563, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [24/50], Step [32/469], Loss: 0.5069, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [24/50], Step [33/469], Loss: 0.4568, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [24/50], Step [34/469], Loss: 0.3623, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [24/50], Step [35/469], Loss: 0.5879, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [24/50], Step [36/469], Loss: 0.3636, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [24/50], Step [37/469], Loss: 0.5967, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [24/50], Step [38/469], Loss: 0.5187, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [24/50], Step [39/469], Loss: 0.5414, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [24/50], Step [40/469], Loss: 0.5359, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [24/50], Step [41/469], Loss: 0.5932, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [24/50], Step [42/469], Loss: 0.4259, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [24/50], Step [43/469], Loss: 0.4338, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [24/50], Step [44/469], Loss: 0.4626, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [24/50], Step [45/469], Loss: 0.2896, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [24/50], Step [46/469], Loss: 0.3878, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [24/50], Step [47/469], Loss: 0.3938, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [24/50], Step [48/469], Loss: 0.3738, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [24/50], Step [49/469], Loss: 0.4921, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [24/50], Step [50/469], Loss: 0.4343, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [24/50], Step [51/469], Loss: 0.6425, batch time: 0.55, accuracy:  80.47%\n",
      "Epoch [24/50], Step [52/469], Loss: 0.5063, batch time: 0.69, accuracy:  85.16%\n",
      "Epoch [24/50], Step [53/469], Loss: 0.5205, batch time: 0.62, accuracy:  79.69%\n",
      "Epoch [24/50], Step [54/469], Loss: 0.6923, batch time: 0.61, accuracy:  80.47%\n",
      "Epoch [24/50], Step [55/469], Loss: 0.5828, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [24/50], Step [56/469], Loss: 0.4119, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [24/50], Step [57/469], Loss: 0.5648, batch time: 0.60, accuracy:  84.38%\n",
      "Epoch [24/50], Step [58/469], Loss: 0.4652, batch time: 0.66, accuracy:  85.16%\n",
      "Epoch [24/50], Step [59/469], Loss: 0.5904, batch time: 0.61, accuracy:  80.47%\n",
      "Epoch [24/50], Step [60/469], Loss: 0.5355, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [24/50], Step [61/469], Loss: 0.4218, batch time: 0.64, accuracy:  83.59%\n",
      "Epoch [24/50], Step [62/469], Loss: 0.6381, batch time: 0.50, accuracy:  78.12%\n",
      "Epoch [24/50], Step [63/469], Loss: 0.6059, batch time: 0.59, accuracy:  83.59%\n",
      "Epoch [24/50], Step [64/469], Loss: 0.3688, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [24/50], Step [65/469], Loss: 0.4076, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [24/50], Step [66/469], Loss: 0.3940, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [24/50], Step [67/469], Loss: 0.2805, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [24/50], Step [68/469], Loss: 0.5892, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [24/50], Step [69/469], Loss: 0.4747, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [24/50], Step [70/469], Loss: 0.4718, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [24/50], Step [71/469], Loss: 0.8292, batch time: 0.47, accuracy:  76.56%\n",
      "Epoch [24/50], Step [72/469], Loss: 0.5631, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [73/469], Loss: 0.3905, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [24/50], Step [74/469], Loss: 0.5141, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [24/50], Step [75/469], Loss: 0.5544, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [24/50], Step [76/469], Loss: 0.4530, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [24/50], Step [77/469], Loss: 0.3793, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [24/50], Step [78/469], Loss: 0.4970, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [24/50], Step [79/469], Loss: 0.3023, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [24/50], Step [80/469], Loss: 0.5628, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [24/50], Step [81/469], Loss: 0.4705, batch time: 0.60, accuracy:  87.50%\n",
      "Epoch [24/50], Step [82/469], Loss: 0.5353, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [24/50], Step [83/469], Loss: 0.4112, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [24/50], Step [84/469], Loss: 0.4103, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [24/50], Step [85/469], Loss: 0.5053, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [24/50], Step [86/469], Loss: 0.4440, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [24/50], Step [87/469], Loss: 0.4286, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [24/50], Step [88/469], Loss: 0.4722, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [24/50], Step [89/469], Loss: 0.4390, batch time: 0.66, accuracy:  84.38%\n",
      "Epoch [24/50], Step [90/469], Loss: 0.4755, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [24/50], Step [91/469], Loss: 0.5272, batch time: 0.59, accuracy:  82.03%\n",
      "Epoch [24/50], Step [92/469], Loss: 0.5119, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [24/50], Step [93/469], Loss: 0.4893, batch time: 0.64, accuracy:  85.16%\n",
      "Epoch [24/50], Step [94/469], Loss: 0.5134, batch time: 0.64, accuracy:  85.16%\n",
      "Epoch [24/50], Step [95/469], Loss: 0.5010, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [24/50], Step [96/469], Loss: 0.4519, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [24/50], Step [97/469], Loss: 0.5572, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [24/50], Step [98/469], Loss: 0.5618, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [24/50], Step [99/469], Loss: 0.5387, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [24/50], Step [100/469], Loss: 0.5309, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [24/50], Step [101/469], Loss: 0.3527, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [24/50], Step [102/469], Loss: 0.4575, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [24/50], Step [103/469], Loss: 0.4344, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [24/50], Step [104/469], Loss: 0.3932, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [24/50], Step [105/469], Loss: 0.4482, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [24/50], Step [106/469], Loss: 0.5752, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [24/50], Step [107/469], Loss: 0.4906, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [24/50], Step [108/469], Loss: 0.4592, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [24/50], Step [109/469], Loss: 0.4696, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [24/50], Step [110/469], Loss: 0.4088, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [24/50], Step [111/469], Loss: 0.5035, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [24/50], Step [112/469], Loss: 0.5338, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [113/469], Loss: 0.5004, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [24/50], Step [114/469], Loss: 0.6214, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [24/50], Step [115/469], Loss: 0.4283, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [24/50], Step [116/469], Loss: 0.4409, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [24/50], Step [117/469], Loss: 0.5109, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [24/50], Step [118/469], Loss: 0.5893, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [24/50], Step [119/469], Loss: 0.4705, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [24/50], Step [120/469], Loss: 0.5203, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [24/50], Step [121/469], Loss: 0.6348, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [24/50], Step [122/469], Loss: 0.3475, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [24/50], Step [123/469], Loss: 0.4348, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [24/50], Step [124/469], Loss: 0.5183, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [24/50], Step [125/469], Loss: 0.3850, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [24/50], Step [126/469], Loss: 0.5365, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [24/50], Step [127/469], Loss: 0.3621, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [24/50], Step [128/469], Loss: 0.3454, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [24/50], Step [129/469], Loss: 0.4557, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [24/50], Step [130/469], Loss: 0.4106, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [24/50], Step [131/469], Loss: 0.4676, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [24/50], Step [132/469], Loss: 0.4451, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [133/469], Loss: 0.4606, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [24/50], Step [134/469], Loss: 0.4324, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [24/50], Step [135/469], Loss: 0.6101, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [24/50], Step [136/469], Loss: 0.4760, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [24/50], Step [137/469], Loss: 0.4304, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [24/50], Step [138/469], Loss: 0.6240, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [24/50], Step [139/469], Loss: 0.4939, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [140/469], Loss: 0.5097, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [24/50], Step [141/469], Loss: 0.5433, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [24/50], Step [142/469], Loss: 0.5726, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [24/50], Step [143/469], Loss: 0.5210, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [24/50], Step [144/469], Loss: 0.4249, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [24/50], Step [145/469], Loss: 0.6306, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [24/50], Step [146/469], Loss: 0.3567, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [24/50], Step [147/469], Loss: 0.3839, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [24/50], Step [148/469], Loss: 0.5210, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [24/50], Step [149/469], Loss: 0.3769, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [24/50], Step [150/469], Loss: 0.6478, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [24/50], Step [151/469], Loss: 0.5084, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [24/50], Step [152/469], Loss: 0.4562, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [24/50], Step [153/469], Loss: 0.5895, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [24/50], Step [154/469], Loss: 0.4695, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [155/469], Loss: 0.4068, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [24/50], Step [156/469], Loss: 0.4471, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [24/50], Step [157/469], Loss: 0.4469, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [24/50], Step [158/469], Loss: 0.5837, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [24/50], Step [159/469], Loss: 0.4831, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [160/469], Loss: 0.3509, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [24/50], Step [161/469], Loss: 0.4713, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [24/50], Step [162/469], Loss: 0.3511, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [24/50], Step [163/469], Loss: 0.4609, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [24/50], Step [164/469], Loss: 0.4133, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [24/50], Step [165/469], Loss: 0.5350, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [24/50], Step [166/469], Loss: 0.4563, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [24/50], Step [167/469], Loss: 0.6299, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [24/50], Step [168/469], Loss: 0.3404, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [24/50], Step [169/469], Loss: 0.4945, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [170/469], Loss: 0.4237, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [24/50], Step [171/469], Loss: 0.5700, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [24/50], Step [172/469], Loss: 0.3372, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [24/50], Step [173/469], Loss: 0.6520, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [24/50], Step [174/469], Loss: 0.4819, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [24/50], Step [175/469], Loss: 0.4310, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [176/469], Loss: 0.4447, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [24/50], Step [177/469], Loss: 0.4633, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [24/50], Step [178/469], Loss: 0.5331, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [24/50], Step [179/469], Loss: 0.6401, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [24/50], Step [180/469], Loss: 0.4871, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [24/50], Step [181/469], Loss: 0.4410, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [24/50], Step [182/469], Loss: 0.3415, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [24/50], Step [183/469], Loss: 0.3521, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [184/469], Loss: 0.4538, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [24/50], Step [185/469], Loss: 0.3948, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [24/50], Step [186/469], Loss: 0.5556, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [187/469], Loss: 0.4649, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [24/50], Step [188/469], Loss: 0.5868, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [24/50], Step [189/469], Loss: 0.4507, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [24/50], Step [190/469], Loss: 0.3639, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [24/50], Step [191/469], Loss: 0.7605, batch time: 0.47, accuracy:  77.34%\n",
      "Epoch [24/50], Step [192/469], Loss: 0.5261, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [24/50], Step [193/469], Loss: 0.4891, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [24/50], Step [194/469], Loss: 0.6070, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [24/50], Step [195/469], Loss: 0.4492, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [24/50], Step [196/469], Loss: 0.6680, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [24/50], Step [197/469], Loss: 0.4089, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [24/50], Step [198/469], Loss: 0.3315, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [24/50], Step [199/469], Loss: 0.4840, batch time: 0.63, accuracy:  82.81%\n",
      "Epoch [24/50], Step [200/469], Loss: 0.4418, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [24/50], Step [201/469], Loss: 0.3523, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [24/50], Step [202/469], Loss: 0.3895, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [24/50], Step [203/469], Loss: 0.5516, batch time: 0.59, accuracy:  78.12%\n",
      "Epoch [24/50], Step [204/469], Loss: 0.3462, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [24/50], Step [205/469], Loss: 0.4833, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [206/469], Loss: 0.3196, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [24/50], Step [207/469], Loss: 0.5642, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [24/50], Step [208/469], Loss: 0.3395, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [24/50], Step [209/469], Loss: 0.3121, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [24/50], Step [210/469], Loss: 0.5070, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [24/50], Step [211/469], Loss: 0.3492, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [24/50], Step [212/469], Loss: 0.4548, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [24/50], Step [213/469], Loss: 0.3842, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [24/50], Step [214/469], Loss: 0.4481, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [215/469], Loss: 0.5973, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [24/50], Step [216/469], Loss: 0.4209, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [24/50], Step [217/469], Loss: 0.4215, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [24/50], Step [218/469], Loss: 0.5058, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [24/50], Step [219/469], Loss: 0.6057, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [24/50], Step [220/469], Loss: 0.3924, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [24/50], Step [221/469], Loss: 0.5920, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [24/50], Step [222/469], Loss: 0.6961, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [223/469], Loss: 0.5337, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [24/50], Step [224/469], Loss: 0.6012, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [24/50], Step [225/469], Loss: 0.3007, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [24/50], Step [226/469], Loss: 0.4405, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [24/50], Step [227/469], Loss: 0.5368, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [24/50], Step [228/469], Loss: 0.5102, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [24/50], Step [229/469], Loss: 0.5302, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [24/50], Step [230/469], Loss: 0.5620, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [24/50], Step [231/469], Loss: 0.3516, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [24/50], Step [232/469], Loss: 0.4672, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [24/50], Step [233/469], Loss: 0.4271, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [24/50], Step [234/469], Loss: 0.3947, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [24/50], Step [235/469], Loss: 0.5272, batch time: 0.84, accuracy:  82.03%\n",
      "Epoch [24/50], Step [236/469], Loss: 0.5012, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [24/50], Step [237/469], Loss: 0.4542, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [24/50], Step [238/469], Loss: 0.6113, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [24/50], Step [239/469], Loss: 0.3765, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [24/50], Step [240/469], Loss: 0.4268, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [24/50], Step [241/469], Loss: 0.5297, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [242/469], Loss: 0.3435, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [24/50], Step [243/469], Loss: 0.4226, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [24/50], Step [244/469], Loss: 0.4400, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [24/50], Step [245/469], Loss: 0.5201, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [24/50], Step [246/469], Loss: 0.6364, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [24/50], Step [247/469], Loss: 0.4485, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [24/50], Step [248/469], Loss: 0.5615, batch time: 0.52, accuracy:  82.03%\n",
      "Epoch [24/50], Step [249/469], Loss: 0.4356, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [24/50], Step [250/469], Loss: 0.5299, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [24/50], Step [251/469], Loss: 0.7648, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [24/50], Step [252/469], Loss: 0.4181, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [253/469], Loss: 0.5920, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [24/50], Step [254/469], Loss: 0.7885, batch time: 0.44, accuracy:  75.00%\n",
      "Epoch [24/50], Step [255/469], Loss: 0.5241, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [24/50], Step [256/469], Loss: 0.6601, batch time: 0.49, accuracy:  76.56%\n",
      "Epoch [24/50], Step [257/469], Loss: 0.5202, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [24/50], Step [258/469], Loss: 0.5141, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [24/50], Step [259/469], Loss: 0.2413, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [24/50], Step [260/469], Loss: 0.5330, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [24/50], Step [261/469], Loss: 0.4220, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [24/50], Step [262/469], Loss: 0.3470, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [24/50], Step [263/469], Loss: 0.4377, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [24/50], Step [264/469], Loss: 0.4636, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [24/50], Step [265/469], Loss: 0.4856, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [24/50], Step [266/469], Loss: 0.4703, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [24/50], Step [267/469], Loss: 0.3332, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [24/50], Step [268/469], Loss: 0.4950, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [24/50], Step [269/469], Loss: 0.6090, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [24/50], Step [270/469], Loss: 0.2473, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [24/50], Step [271/469], Loss: 0.4692, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [24/50], Step [272/469], Loss: 0.3436, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [24/50], Step [273/469], Loss: 0.3485, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [24/50], Step [274/469], Loss: 0.4863, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [275/469], Loss: 0.4958, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [24/50], Step [276/469], Loss: 0.5537, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [277/469], Loss: 0.3200, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [278/469], Loss: 0.4618, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [24/50], Step [279/469], Loss: 0.4350, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [24/50], Step [280/469], Loss: 0.5699, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [24/50], Step [281/469], Loss: 0.5693, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [24/50], Step [282/469], Loss: 0.3804, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [24/50], Step [283/469], Loss: 0.4508, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [24/50], Step [284/469], Loss: 0.4218, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [24/50], Step [285/469], Loss: 0.5474, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [24/50], Step [286/469], Loss: 0.5472, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [24/50], Step [287/469], Loss: 0.4003, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [24/50], Step [288/469], Loss: 0.4198, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [24/50], Step [289/469], Loss: 0.3777, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [24/50], Step [290/469], Loss: 0.4053, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [24/50], Step [291/469], Loss: 0.4348, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [24/50], Step [292/469], Loss: 0.6113, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [24/50], Step [293/469], Loss: 0.3114, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [24/50], Step [294/469], Loss: 0.5382, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [24/50], Step [295/469], Loss: 0.4925, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [24/50], Step [296/469], Loss: 0.5195, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [24/50], Step [297/469], Loss: 0.4024, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [298/469], Loss: 0.5244, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [24/50], Step [299/469], Loss: 0.5790, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [24/50], Step [300/469], Loss: 0.4784, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [24/50], Step [301/469], Loss: 0.4164, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [24/50], Step [302/469], Loss: 0.5380, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [24/50], Step [303/469], Loss: 0.3358, batch time: 0.76, accuracy:  91.41%\n",
      "Epoch [24/50], Step [304/469], Loss: 0.5903, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [305/469], Loss: 0.4502, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [24/50], Step [306/469], Loss: 0.4152, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [24/50], Step [307/469], Loss: 0.4782, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [24/50], Step [308/469], Loss: 0.5310, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [309/469], Loss: 0.5738, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [310/469], Loss: 0.4327, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [24/50], Step [311/469], Loss: 0.9678, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [24/50], Step [312/469], Loss: 0.4969, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [24/50], Step [313/469], Loss: 0.3768, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [24/50], Step [314/469], Loss: 0.4828, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [24/50], Step [315/469], Loss: 0.4267, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [24/50], Step [316/469], Loss: 0.6023, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [24/50], Step [317/469], Loss: 0.4753, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [24/50], Step [318/469], Loss: 0.5542, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [24/50], Step [319/469], Loss: 0.5496, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [320/469], Loss: 0.6183, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [24/50], Step [321/469], Loss: 0.3327, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [24/50], Step [322/469], Loss: 0.4199, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [24/50], Step [323/469], Loss: 0.5502, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [24/50], Step [324/469], Loss: 0.4973, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [24/50], Step [325/469], Loss: 0.4292, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [24/50], Step [326/469], Loss: 0.3551, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [24/50], Step [327/469], Loss: 0.4382, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [24/50], Step [328/469], Loss: 0.3822, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [24/50], Step [329/469], Loss: 0.5726, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [24/50], Step [330/469], Loss: 0.4820, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [24/50], Step [331/469], Loss: 0.5133, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [24/50], Step [332/469], Loss: 0.5471, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [24/50], Step [333/469], Loss: 0.4950, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [24/50], Step [334/469], Loss: 0.6211, batch time: 0.63, accuracy:  76.56%\n",
      "Epoch [24/50], Step [335/469], Loss: 0.4757, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [24/50], Step [336/469], Loss: 0.5960, batch time: 0.47, accuracy:  80.47%\n",
      "Epoch [24/50], Step [337/469], Loss: 0.2670, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [24/50], Step [338/469], Loss: 0.5327, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [24/50], Step [339/469], Loss: 0.4670, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [340/469], Loss: 0.7360, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [24/50], Step [341/469], Loss: 0.4279, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [342/469], Loss: 0.2710, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [24/50], Step [343/469], Loss: 0.4415, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [24/50], Step [344/469], Loss: 0.5032, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [345/469], Loss: 0.5753, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [24/50], Step [346/469], Loss: 0.6342, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [24/50], Step [347/469], Loss: 0.6618, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [348/469], Loss: 0.6498, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [24/50], Step [349/469], Loss: 0.5260, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [24/50], Step [350/469], Loss: 0.4088, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [24/50], Step [351/469], Loss: 0.4953, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [24/50], Step [352/469], Loss: 0.6515, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [24/50], Step [353/469], Loss: 0.7276, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [24/50], Step [354/469], Loss: 0.4637, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [24/50], Step [355/469], Loss: 0.4102, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [24/50], Step [356/469], Loss: 0.4766, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [24/50], Step [357/469], Loss: 0.4755, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [24/50], Step [358/469], Loss: 0.5133, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [24/50], Step [359/469], Loss: 0.5311, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [24/50], Step [360/469], Loss: 0.5390, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [24/50], Step [361/469], Loss: 0.6004, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [24/50], Step [362/469], Loss: 0.4516, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [24/50], Step [363/469], Loss: 0.5083, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [24/50], Step [364/469], Loss: 0.4753, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [24/50], Step [365/469], Loss: 0.5229, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [24/50], Step [366/469], Loss: 0.3359, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [24/50], Step [367/469], Loss: 0.4242, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [24/50], Step [368/469], Loss: 0.4587, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [24/50], Step [369/469], Loss: 0.6238, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [24/50], Step [370/469], Loss: 0.5859, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [24/50], Step [371/469], Loss: 0.5552, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [24/50], Step [372/469], Loss: 0.4710, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [24/50], Step [373/469], Loss: 0.6117, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [24/50], Step [374/469], Loss: 0.6023, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [24/50], Step [375/469], Loss: 0.5265, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [24/50], Step [376/469], Loss: 0.5571, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [377/469], Loss: 0.3758, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [24/50], Step [378/469], Loss: 0.4616, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [24/50], Step [379/469], Loss: 0.3831, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [24/50], Step [380/469], Loss: 0.6007, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [24/50], Step [381/469], Loss: 0.3667, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [24/50], Step [382/469], Loss: 0.4894, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [24/50], Step [383/469], Loss: 0.5427, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [24/50], Step [384/469], Loss: 0.4290, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [24/50], Step [385/469], Loss: 0.5460, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [24/50], Step [386/469], Loss: 0.3468, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [24/50], Step [387/469], Loss: 0.4747, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [24/50], Step [388/469], Loss: 0.3326, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [24/50], Step [389/469], Loss: 0.4799, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [24/50], Step [390/469], Loss: 0.6286, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [24/50], Step [391/469], Loss: 0.4556, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [24/50], Step [392/469], Loss: 0.4264, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [393/469], Loss: 0.6001, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [24/50], Step [394/469], Loss: 0.5459, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [24/50], Step [395/469], Loss: 0.3434, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [24/50], Step [396/469], Loss: 0.3357, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [24/50], Step [397/469], Loss: 0.6367, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [24/50], Step [398/469], Loss: 0.5455, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [24/50], Step [399/469], Loss: 0.4825, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [24/50], Step [400/469], Loss: 0.5555, batch time: 0.67, accuracy:  85.16%\n",
      "Epoch [24/50], Step [401/469], Loss: 0.5072, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [24/50], Step [402/469], Loss: 0.5570, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [24/50], Step [403/469], Loss: 0.4144, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [404/469], Loss: 0.4306, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [405/469], Loss: 0.5586, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [24/50], Step [406/469], Loss: 0.4898, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [407/469], Loss: 0.4337, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [408/469], Loss: 0.4817, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [409/469], Loss: 0.4004, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [24/50], Step [410/469], Loss: 0.4156, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [411/469], Loss: 0.5607, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [24/50], Step [412/469], Loss: 0.5579, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [24/50], Step [413/469], Loss: 0.5947, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [24/50], Step [414/469], Loss: 0.3515, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [24/50], Step [415/469], Loss: 0.3279, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [24/50], Step [416/469], Loss: 0.5502, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [24/50], Step [417/469], Loss: 0.4316, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [24/50], Step [418/469], Loss: 0.4377, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [419/469], Loss: 0.4562, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [24/50], Step [420/469], Loss: 0.5313, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [24/50], Step [421/469], Loss: 0.3774, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [24/50], Step [422/469], Loss: 0.5337, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [423/469], Loss: 0.3465, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [24/50], Step [424/469], Loss: 0.5525, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [24/50], Step [425/469], Loss: 0.4846, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [24/50], Step [426/469], Loss: 0.4700, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [24/50], Step [427/469], Loss: 0.5875, batch time: 0.48, accuracy:  79.69%\n",
      "Epoch [24/50], Step [428/469], Loss: 0.4727, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [24/50], Step [429/469], Loss: 0.4636, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [24/50], Step [430/469], Loss: 0.6832, batch time: 0.53, accuracy:  78.91%\n",
      "Epoch [24/50], Step [431/469], Loss: 0.6550, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [24/50], Step [432/469], Loss: 0.4136, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [24/50], Step [433/469], Loss: 0.6224, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [24/50], Step [434/469], Loss: 0.4434, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [24/50], Step [435/469], Loss: 0.3532, batch time: 0.64, accuracy:  89.06%\n",
      "Epoch [24/50], Step [436/469], Loss: 0.4873, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [24/50], Step [437/469], Loss: 0.4300, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [438/469], Loss: 0.5399, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [24/50], Step [439/469], Loss: 0.4286, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [24/50], Step [440/469], Loss: 0.5426, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [24/50], Step [441/469], Loss: 0.2298, batch time: 0.43, accuracy:  95.31%\n",
      "Epoch [24/50], Step [442/469], Loss: 0.5603, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [443/469], Loss: 0.6502, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [24/50], Step [444/469], Loss: 0.4126, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [24/50], Step [445/469], Loss: 0.5834, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [24/50], Step [446/469], Loss: 0.6377, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [24/50], Step [447/469], Loss: 0.3886, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [24/50], Step [448/469], Loss: 0.5281, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [24/50], Step [449/469], Loss: 0.5132, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [24/50], Step [450/469], Loss: 0.5270, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [24/50], Step [451/469], Loss: 0.4047, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [24/50], Step [452/469], Loss: 0.5108, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [24/50], Step [453/469], Loss: 0.4794, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [24/50], Step [454/469], Loss: 0.3956, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [24/50], Step [455/469], Loss: 0.5007, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [24/50], Step [456/469], Loss: 0.7405, batch time: 0.51, accuracy:  78.91%\n",
      "Epoch [24/50], Step [457/469], Loss: 0.5064, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [24/50], Step [458/469], Loss: 0.3827, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [24/50], Step [459/469], Loss: 0.4529, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [24/50], Step [460/469], Loss: 0.5755, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [24/50], Step [461/469], Loss: 0.5961, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [24/50], Step [462/469], Loss: 0.4819, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [24/50], Step [463/469], Loss: 0.3968, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [24/50], Step [464/469], Loss: 0.4408, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [24/50], Step [465/469], Loss: 0.3601, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [24/50], Step [466/469], Loss: 0.4833, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [24/50], Step [467/469], Loss: 0.4421, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [24/50], Step [468/469], Loss: 0.4203, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [24/50], Step [469/469], Loss: 0.3944, batch time: 0.68, accuracy:  87.50%\n",
      "Epoch [25/50], Step [1/469], Loss: 0.5562, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [25/50], Step [2/469], Loss: 0.3451, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [25/50], Step [3/469], Loss: 0.3941, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [25/50], Step [4/469], Loss: 0.4339, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [25/50], Step [5/469], Loss: 0.4408, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [25/50], Step [6/469], Loss: 0.4169, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [25/50], Step [7/469], Loss: 0.5861, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [25/50], Step [8/469], Loss: 0.6828, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [25/50], Step [9/469], Loss: 0.4722, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [25/50], Step [10/469], Loss: 0.4821, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [25/50], Step [11/469], Loss: 0.4661, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [25/50], Step [12/469], Loss: 0.5132, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [25/50], Step [13/469], Loss: 0.4700, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [25/50], Step [14/469], Loss: 0.3752, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [25/50], Step [15/469], Loss: 0.6992, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [25/50], Step [16/469], Loss: 0.4835, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [25/50], Step [17/469], Loss: 0.5751, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [25/50], Step [18/469], Loss: 0.5229, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [19/469], Loss: 0.3602, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [25/50], Step [20/469], Loss: 0.4881, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [25/50], Step [21/469], Loss: 0.5899, batch time: 0.58, accuracy:  78.91%\n",
      "Epoch [25/50], Step [22/469], Loss: 0.4993, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [25/50], Step [23/469], Loss: 0.3630, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [25/50], Step [24/469], Loss: 0.3905, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [25/469], Loss: 0.5529, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [25/50], Step [26/469], Loss: 0.5605, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [25/50], Step [27/469], Loss: 0.3030, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [25/50], Step [28/469], Loss: 0.3824, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [29/469], Loss: 0.4872, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [25/50], Step [30/469], Loss: 0.5534, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [25/50], Step [31/469], Loss: 0.4312, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [25/50], Step [32/469], Loss: 0.4903, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [25/50], Step [33/469], Loss: 0.4958, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [25/50], Step [34/469], Loss: 0.5303, batch time: 0.55, accuracy:  82.03%\n",
      "Epoch [25/50], Step [35/469], Loss: 0.5658, batch time: 0.55, accuracy:  81.25%\n",
      "Epoch [25/50], Step [36/469], Loss: 0.4102, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [25/50], Step [37/469], Loss: 0.3611, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [25/50], Step [38/469], Loss: 0.4993, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [25/50], Step [39/469], Loss: 0.4716, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [25/50], Step [40/469], Loss: 0.5289, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [41/469], Loss: 0.4853, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [42/469], Loss: 0.4510, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [25/50], Step [43/469], Loss: 0.4088, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [44/469], Loss: 0.5932, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [25/50], Step [45/469], Loss: 0.3914, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [25/50], Step [46/469], Loss: 0.4110, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [25/50], Step [47/469], Loss: 0.5152, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [25/50], Step [48/469], Loss: 0.4250, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [25/50], Step [49/469], Loss: 0.4282, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [50/469], Loss: 0.4129, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [25/50], Step [51/469], Loss: 0.5474, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [25/50], Step [52/469], Loss: 0.3152, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [25/50], Step [53/469], Loss: 0.4937, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [25/50], Step [54/469], Loss: 0.4095, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [25/50], Step [55/469], Loss: 0.5148, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [25/50], Step [56/469], Loss: 0.4785, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [25/50], Step [57/469], Loss: 0.4955, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [25/50], Step [58/469], Loss: 0.3581, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [25/50], Step [59/469], Loss: 0.5745, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [25/50], Step [60/469], Loss: 0.4674, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [61/469], Loss: 0.4334, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [25/50], Step [62/469], Loss: 0.6694, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [25/50], Step [63/469], Loss: 0.5556, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [25/50], Step [64/469], Loss: 0.3250, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [25/50], Step [65/469], Loss: 0.4868, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [25/50], Step [66/469], Loss: 0.5307, batch time: 1.03, accuracy:  81.25%\n",
      "Epoch [25/50], Step [67/469], Loss: 0.4973, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [25/50], Step [68/469], Loss: 0.4022, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [69/469], Loss: 0.5788, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [25/50], Step [70/469], Loss: 0.4270, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [25/50], Step [71/469], Loss: 0.3553, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [72/469], Loss: 0.5433, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [25/50], Step [73/469], Loss: 0.4719, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [25/50], Step [74/469], Loss: 0.5006, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [25/50], Step [75/469], Loss: 0.5591, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [25/50], Step [76/469], Loss: 0.2332, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [25/50], Step [77/469], Loss: 0.3055, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [25/50], Step [78/469], Loss: 0.4554, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [25/50], Step [79/469], Loss: 0.2497, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [25/50], Step [80/469], Loss: 0.4426, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [25/50], Step [81/469], Loss: 0.5406, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [25/50], Step [82/469], Loss: 0.3771, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [25/50], Step [83/469], Loss: 0.3741, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [25/50], Step [84/469], Loss: 0.5312, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [25/50], Step [85/469], Loss: 0.6794, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [25/50], Step [86/469], Loss: 0.4846, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [25/50], Step [87/469], Loss: 0.5065, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [25/50], Step [88/469], Loss: 0.4359, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [89/469], Loss: 0.4221, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [25/50], Step [90/469], Loss: 0.4301, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [91/469], Loss: 0.3457, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [25/50], Step [92/469], Loss: 0.4740, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [93/469], Loss: 0.3870, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [94/469], Loss: 0.6489, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [25/50], Step [95/469], Loss: 0.4938, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [25/50], Step [96/469], Loss: 0.3362, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [25/50], Step [97/469], Loss: 0.6545, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [25/50], Step [98/469], Loss: 0.4539, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [25/50], Step [99/469], Loss: 0.4822, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [25/50], Step [100/469], Loss: 0.4033, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [101/469], Loss: 0.6051, batch time: 0.61, accuracy:  82.81%\n",
      "Epoch [25/50], Step [102/469], Loss: 0.3858, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [25/50], Step [103/469], Loss: 0.2492, batch time: 0.78, accuracy:  94.53%\n",
      "Epoch [25/50], Step [104/469], Loss: 0.5372, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [25/50], Step [105/469], Loss: 0.3546, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [25/50], Step [106/469], Loss: 0.6667, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [25/50], Step [107/469], Loss: 0.3079, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [25/50], Step [108/469], Loss: 0.5840, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [25/50], Step [109/469], Loss: 0.5517, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [25/50], Step [110/469], Loss: 0.2768, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [25/50], Step [111/469], Loss: 0.5232, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [112/469], Loss: 0.3219, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [25/50], Step [113/469], Loss: 0.3599, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [25/50], Step [114/469], Loss: 0.4211, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [25/50], Step [115/469], Loss: 0.5296, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [25/50], Step [116/469], Loss: 0.4124, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [25/50], Step [117/469], Loss: 0.4375, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [25/50], Step [118/469], Loss: 0.5897, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [25/50], Step [119/469], Loss: 0.5214, batch time: 0.63, accuracy:  81.25%\n",
      "Epoch [25/50], Step [120/469], Loss: 0.3499, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [25/50], Step [121/469], Loss: 0.4516, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [25/50], Step [122/469], Loss: 0.4441, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [25/50], Step [123/469], Loss: 0.6160, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [25/50], Step [124/469], Loss: 0.4950, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [25/50], Step [125/469], Loss: 0.3801, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [25/50], Step [126/469], Loss: 0.7050, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [25/50], Step [127/469], Loss: 0.5310, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [25/50], Step [128/469], Loss: 0.4013, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [129/469], Loss: 0.6805, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [25/50], Step [130/469], Loss: 0.5154, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [25/50], Step [131/469], Loss: 0.3363, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [25/50], Step [132/469], Loss: 0.3402, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [25/50], Step [133/469], Loss: 0.3487, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [25/50], Step [134/469], Loss: 0.3880, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [25/50], Step [135/469], Loss: 0.4829, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [25/50], Step [136/469], Loss: 0.4728, batch time: 0.91, accuracy:  85.94%\n",
      "Epoch [25/50], Step [137/469], Loss: 0.5047, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [25/50], Step [138/469], Loss: 0.4959, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [139/469], Loss: 0.4595, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [25/50], Step [140/469], Loss: 0.6683, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [25/50], Step [141/469], Loss: 0.4965, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [25/50], Step [142/469], Loss: 0.4218, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [143/469], Loss: 0.3067, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [25/50], Step [144/469], Loss: 0.3842, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [25/50], Step [145/469], Loss: 0.5011, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [25/50], Step [146/469], Loss: 0.5690, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [147/469], Loss: 0.4984, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [148/469], Loss: 0.3814, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [149/469], Loss: 0.4115, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [25/50], Step [150/469], Loss: 0.5205, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [25/50], Step [151/469], Loss: 0.6116, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [25/50], Step [152/469], Loss: 0.5766, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [153/469], Loss: 0.5461, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [25/50], Step [154/469], Loss: 0.5005, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [25/50], Step [155/469], Loss: 0.3253, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [25/50], Step [156/469], Loss: 0.3849, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [25/50], Step [157/469], Loss: 0.4478, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [25/50], Step [158/469], Loss: 0.4089, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [25/50], Step [159/469], Loss: 0.3911, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [25/50], Step [160/469], Loss: 0.4476, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [25/50], Step [161/469], Loss: 0.7141, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [25/50], Step [162/469], Loss: 0.4775, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [25/50], Step [163/469], Loss: 0.5158, batch time: 0.52, accuracy:  80.47%\n",
      "Epoch [25/50], Step [164/469], Loss: 0.5459, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [165/469], Loss: 0.3475, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [25/50], Step [166/469], Loss: 0.6048, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [25/50], Step [167/469], Loss: 0.5189, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [25/50], Step [168/469], Loss: 0.4549, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [25/50], Step [169/469], Loss: 0.5308, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [25/50], Step [170/469], Loss: 0.5208, batch time: 0.55, accuracy:  81.25%\n",
      "Epoch [25/50], Step [171/469], Loss: 0.4398, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [25/50], Step [172/469], Loss: 0.4224, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [25/50], Step [173/469], Loss: 0.4962, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [25/50], Step [174/469], Loss: 0.4658, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [25/50], Step [175/469], Loss: 0.5716, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [25/50], Step [176/469], Loss: 0.4003, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [25/50], Step [177/469], Loss: 0.3123, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [25/50], Step [178/469], Loss: 0.3547, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [25/50], Step [179/469], Loss: 0.4269, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [25/50], Step [180/469], Loss: 0.4929, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [25/50], Step [181/469], Loss: 0.5793, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [25/50], Step [182/469], Loss: 0.4595, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [25/50], Step [183/469], Loss: 0.4599, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [184/469], Loss: 0.3851, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [25/50], Step [185/469], Loss: 0.5634, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [25/50], Step [186/469], Loss: 0.4455, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [25/50], Step [187/469], Loss: 0.5069, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [25/50], Step [188/469], Loss: 0.4203, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [25/50], Step [189/469], Loss: 0.3980, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [25/50], Step [190/469], Loss: 0.4026, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [25/50], Step [191/469], Loss: 0.3720, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [25/50], Step [192/469], Loss: 0.4051, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [25/50], Step [193/469], Loss: 0.5158, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [194/469], Loss: 0.5256, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [195/469], Loss: 0.3200, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [25/50], Step [196/469], Loss: 0.3587, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [197/469], Loss: 0.6452, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [25/50], Step [198/469], Loss: 0.4938, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [25/50], Step [199/469], Loss: 0.6394, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [200/469], Loss: 0.3227, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [25/50], Step [201/469], Loss: 0.6699, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [25/50], Step [202/469], Loss: 0.4308, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [25/50], Step [203/469], Loss: 0.6820, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [25/50], Step [204/469], Loss: 0.4249, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [25/50], Step [205/469], Loss: 0.5137, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [25/50], Step [206/469], Loss: 0.1971, batch time: 0.73, accuracy:  93.75%\n",
      "Epoch [25/50], Step [207/469], Loss: 0.6033, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [25/50], Step [208/469], Loss: 0.4302, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [209/469], Loss: 0.4720, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [25/50], Step [210/469], Loss: 0.5530, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [25/50], Step [211/469], Loss: 0.4560, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [25/50], Step [212/469], Loss: 0.6243, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [25/50], Step [213/469], Loss: 0.7253, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [214/469], Loss: 0.4990, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [25/50], Step [215/469], Loss: 0.3679, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [25/50], Step [216/469], Loss: 0.5995, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [217/469], Loss: 0.4489, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [218/469], Loss: 0.4947, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [219/469], Loss: 0.3274, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [25/50], Step [220/469], Loss: 0.4793, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [25/50], Step [221/469], Loss: 0.4915, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [222/469], Loss: 0.4950, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [25/50], Step [223/469], Loss: 0.5830, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [25/50], Step [224/469], Loss: 0.4677, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [25/50], Step [225/469], Loss: 0.4715, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [226/469], Loss: 0.6772, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [25/50], Step [227/469], Loss: 0.4485, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [25/50], Step [228/469], Loss: 0.3866, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [229/469], Loss: 0.4289, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [25/50], Step [230/469], Loss: 0.3774, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [25/50], Step [231/469], Loss: 0.4843, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [25/50], Step [232/469], Loss: 0.4001, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [25/50], Step [233/469], Loss: 0.4327, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [25/50], Step [234/469], Loss: 0.4928, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [25/50], Step [235/469], Loss: 0.4247, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [25/50], Step [236/469], Loss: 0.6972, batch time: 0.67, accuracy:  85.16%\n",
      "Epoch [25/50], Step [237/469], Loss: 0.4053, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [238/469], Loss: 0.4855, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [25/50], Step [239/469], Loss: 0.3839, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [25/50], Step [240/469], Loss: 0.4415, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [25/50], Step [241/469], Loss: 0.2829, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [25/50], Step [242/469], Loss: 0.4169, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [243/469], Loss: 0.4526, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [244/469], Loss: 0.4067, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [25/50], Step [245/469], Loss: 0.3419, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [25/50], Step [246/469], Loss: 0.3216, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [25/50], Step [247/469], Loss: 0.5215, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [248/469], Loss: 0.5478, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [249/469], Loss: 0.3929, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [25/50], Step [250/469], Loss: 0.5189, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [25/50], Step [251/469], Loss: 0.5320, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [252/469], Loss: 0.6525, batch time: 0.50, accuracy:  77.34%\n",
      "Epoch [25/50], Step [253/469], Loss: 0.3829, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [25/50], Step [254/469], Loss: 0.3925, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [25/50], Step [255/469], Loss: 0.3137, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [25/50], Step [256/469], Loss: 0.3955, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [257/469], Loss: 0.3870, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [25/50], Step [258/469], Loss: 0.4505, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [259/469], Loss: 0.4147, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [25/50], Step [260/469], Loss: 0.4881, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [25/50], Step [261/469], Loss: 0.5146, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [262/469], Loss: 0.3703, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [25/50], Step [263/469], Loss: 0.5634, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [25/50], Step [264/469], Loss: 0.4124, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [25/50], Step [265/469], Loss: 0.4981, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [25/50], Step [266/469], Loss: 0.4574, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [25/50], Step [267/469], Loss: 0.3888, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [25/50], Step [268/469], Loss: 0.4393, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [25/50], Step [269/469], Loss: 0.4543, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [25/50], Step [270/469], Loss: 0.4853, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [25/50], Step [271/469], Loss: 0.4031, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [25/50], Step [272/469], Loss: 0.4485, batch time: 0.58, accuracy:  82.03%\n",
      "Epoch [25/50], Step [273/469], Loss: 0.5548, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [25/50], Step [274/469], Loss: 0.4336, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [25/50], Step [275/469], Loss: 0.3996, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [276/469], Loss: 0.4475, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [277/469], Loss: 0.4427, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [25/50], Step [278/469], Loss: 0.3776, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [25/50], Step [279/469], Loss: 0.4894, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [25/50], Step [280/469], Loss: 0.5076, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [25/50], Step [281/469], Loss: 0.4220, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [25/50], Step [282/469], Loss: 0.5843, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [25/50], Step [283/469], Loss: 0.5379, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [25/50], Step [284/469], Loss: 0.5223, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [25/50], Step [285/469], Loss: 0.5622, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [25/50], Step [286/469], Loss: 0.4939, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [25/50], Step [287/469], Loss: 0.4836, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [25/50], Step [288/469], Loss: 0.5336, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [25/50], Step [289/469], Loss: 0.5685, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [25/50], Step [290/469], Loss: 0.4085, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [25/50], Step [291/469], Loss: 0.5178, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [292/469], Loss: 0.2734, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [25/50], Step [293/469], Loss: 0.4391, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [294/469], Loss: 0.3855, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [25/50], Step [295/469], Loss: 0.3934, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [25/50], Step [296/469], Loss: 0.4750, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [25/50], Step [297/469], Loss: 0.5744, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [25/50], Step [298/469], Loss: 0.2490, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [25/50], Step [299/469], Loss: 0.6543, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [25/50], Step [300/469], Loss: 0.4284, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [301/469], Loss: 0.6243, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [25/50], Step [302/469], Loss: 0.4863, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [25/50], Step [303/469], Loss: 0.4239, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [25/50], Step [304/469], Loss: 0.6618, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [25/50], Step [305/469], Loss: 0.3216, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [25/50], Step [306/469], Loss: 0.4440, batch time: 0.70, accuracy:  88.28%\n",
      "Epoch [25/50], Step [307/469], Loss: 0.4552, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [25/50], Step [308/469], Loss: 0.4804, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [25/50], Step [309/469], Loss: 0.4651, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [25/50], Step [310/469], Loss: 0.5191, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [25/50], Step [311/469], Loss: 0.3657, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [25/50], Step [312/469], Loss: 0.4440, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [25/50], Step [313/469], Loss: 0.6129, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [25/50], Step [314/469], Loss: 0.4767, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [25/50], Step [315/469], Loss: 0.3476, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [25/50], Step [316/469], Loss: 0.4991, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [317/469], Loss: 0.6155, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [25/50], Step [318/469], Loss: 0.4118, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [25/50], Step [319/469], Loss: 0.4393, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [25/50], Step [320/469], Loss: 0.4346, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [25/50], Step [321/469], Loss: 0.5939, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [25/50], Step [322/469], Loss: 0.4684, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [25/50], Step [323/469], Loss: 0.4374, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [324/469], Loss: 0.3355, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [25/50], Step [325/469], Loss: 0.4346, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [25/50], Step [326/469], Loss: 0.3631, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [25/50], Step [327/469], Loss: 0.3525, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [25/50], Step [328/469], Loss: 0.4521, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [25/50], Step [329/469], Loss: 0.5109, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [25/50], Step [330/469], Loss: 0.3731, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [25/50], Step [331/469], Loss: 0.4540, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [25/50], Step [332/469], Loss: 0.4867, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [25/50], Step [333/469], Loss: 0.5918, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [334/469], Loss: 0.3486, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [25/50], Step [335/469], Loss: 0.5083, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [25/50], Step [336/469], Loss: 0.3726, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [25/50], Step [337/469], Loss: 0.4938, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [25/50], Step [338/469], Loss: 0.5226, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [25/50], Step [339/469], Loss: 0.4192, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [25/50], Step [340/469], Loss: 0.4739, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [25/50], Step [341/469], Loss: 0.5039, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [25/50], Step [342/469], Loss: 0.5240, batch time: 0.56, accuracy:  82.81%\n",
      "Epoch [25/50], Step [343/469], Loss: 0.3617, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [25/50], Step [344/469], Loss: 0.6415, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [25/50], Step [345/469], Loss: 0.4037, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [25/50], Step [346/469], Loss: 0.5564, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [25/50], Step [347/469], Loss: 0.4967, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [25/50], Step [348/469], Loss: 0.5850, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [25/50], Step [349/469], Loss: 0.4611, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [25/50], Step [350/469], Loss: 0.3765, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [25/50], Step [351/469], Loss: 0.4564, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [352/469], Loss: 0.3736, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [353/469], Loss: 0.5498, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [25/50], Step [354/469], Loss: 0.4504, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [25/50], Step [355/469], Loss: 0.3944, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [25/50], Step [356/469], Loss: 0.3602, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [357/469], Loss: 0.3505, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [25/50], Step [358/469], Loss: 0.4339, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [25/50], Step [359/469], Loss: 0.6455, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [25/50], Step [360/469], Loss: 0.5826, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [25/50], Step [361/469], Loss: 0.4488, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [25/50], Step [362/469], Loss: 0.4254, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [25/50], Step [363/469], Loss: 0.3687, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [364/469], Loss: 0.4814, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [25/50], Step [365/469], Loss: 0.3866, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [25/50], Step [366/469], Loss: 0.4080, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [25/50], Step [367/469], Loss: 0.4904, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [25/50], Step [368/469], Loss: 0.4823, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [369/469], Loss: 0.5881, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [370/469], Loss: 0.6244, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [25/50], Step [371/469], Loss: 0.5097, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [25/50], Step [372/469], Loss: 0.3414, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [25/50], Step [373/469], Loss: 0.4370, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [25/50], Step [374/469], Loss: 0.4667, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [25/50], Step [375/469], Loss: 0.4342, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [25/50], Step [376/469], Loss: 0.4752, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [25/50], Step [377/469], Loss: 0.2964, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [25/50], Step [378/469], Loss: 0.4355, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [25/50], Step [379/469], Loss: 0.2523, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [25/50], Step [380/469], Loss: 0.6436, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [25/50], Step [381/469], Loss: 0.4301, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [382/469], Loss: 0.6242, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [25/50], Step [383/469], Loss: 0.4677, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [384/469], Loss: 0.5458, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [25/50], Step [385/469], Loss: 0.3575, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [25/50], Step [386/469], Loss: 0.3607, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [25/50], Step [387/469], Loss: 0.4381, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [388/469], Loss: 0.4348, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [389/469], Loss: 0.2507, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [25/50], Step [390/469], Loss: 0.5775, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [25/50], Step [391/469], Loss: 0.5211, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [25/50], Step [392/469], Loss: 0.5780, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [393/469], Loss: 0.5977, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [25/50], Step [394/469], Loss: 0.5663, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [25/50], Step [395/469], Loss: 0.4078, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [396/469], Loss: 0.4584, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [397/469], Loss: 0.5462, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [398/469], Loss: 0.3799, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [25/50], Step [399/469], Loss: 0.4915, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [25/50], Step [400/469], Loss: 0.4742, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [25/50], Step [401/469], Loss: 0.4383, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [25/50], Step [402/469], Loss: 0.4855, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [403/469], Loss: 0.6406, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [404/469], Loss: 0.4644, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [25/50], Step [405/469], Loss: 0.4228, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [25/50], Step [406/469], Loss: 0.4450, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [407/469], Loss: 0.3916, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [25/50], Step [408/469], Loss: 0.4555, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [25/50], Step [409/469], Loss: 0.5435, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [25/50], Step [410/469], Loss: 0.5055, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [411/469], Loss: 0.4861, batch time: 0.63, accuracy:  81.25%\n",
      "Epoch [25/50], Step [412/469], Loss: 0.3751, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [25/50], Step [413/469], Loss: 0.4470, batch time: 0.57, accuracy:  83.59%\n",
      "Epoch [25/50], Step [414/469], Loss: 0.5400, batch time: 0.68, accuracy:  86.72%\n",
      "Epoch [25/50], Step [415/469], Loss: 0.4474, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [25/50], Step [416/469], Loss: 0.5843, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [25/50], Step [417/469], Loss: 0.6598, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [25/50], Step [418/469], Loss: 0.4019, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [25/50], Step [419/469], Loss: 0.4872, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [420/469], Loss: 0.5136, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [25/50], Step [421/469], Loss: 0.4149, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [25/50], Step [422/469], Loss: 0.3570, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [25/50], Step [423/469], Loss: 0.4291, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [25/50], Step [424/469], Loss: 0.4336, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [425/469], Loss: 0.3940, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [426/469], Loss: 0.6526, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [25/50], Step [427/469], Loss: 0.5586, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [428/469], Loss: 0.3614, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [429/469], Loss: 0.3578, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [25/50], Step [430/469], Loss: 0.5421, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [25/50], Step [431/469], Loss: 0.4621, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [25/50], Step [432/469], Loss: 0.4643, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [25/50], Step [433/469], Loss: 0.4341, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [25/50], Step [434/469], Loss: 0.5382, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [25/50], Step [435/469], Loss: 0.5524, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [436/469], Loss: 0.5988, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [25/50], Step [437/469], Loss: 0.4486, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [438/469], Loss: 0.4517, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [25/50], Step [439/469], Loss: 0.3688, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [25/50], Step [440/469], Loss: 0.4518, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [25/50], Step [441/469], Loss: 0.5203, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [25/50], Step [442/469], Loss: 0.3999, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [25/50], Step [443/469], Loss: 0.5409, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [25/50], Step [444/469], Loss: 0.4858, batch time: 0.60, accuracy:  85.16%\n",
      "Epoch [25/50], Step [445/469], Loss: 0.3867, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [25/50], Step [446/469], Loss: 0.4682, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [25/50], Step [447/469], Loss: 0.3528, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [25/50], Step [448/469], Loss: 0.5956, batch time: 0.55, accuracy:  82.03%\n",
      "Epoch [25/50], Step [449/469], Loss: 0.3334, batch time: 0.66, accuracy:  89.06%\n",
      "Epoch [25/50], Step [450/469], Loss: 0.5213, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [25/50], Step [451/469], Loss: 0.4818, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [25/50], Step [452/469], Loss: 0.4184, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [25/50], Step [453/469], Loss: 0.3878, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [25/50], Step [454/469], Loss: 0.2883, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [25/50], Step [455/469], Loss: 0.5716, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [25/50], Step [456/469], Loss: 0.5450, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [25/50], Step [457/469], Loss: 0.5386, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [25/50], Step [458/469], Loss: 0.4389, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [25/50], Step [459/469], Loss: 0.4300, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [25/50], Step [460/469], Loss: 0.4499, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [25/50], Step [461/469], Loss: 0.4911, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [25/50], Step [462/469], Loss: 0.5570, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [463/469], Loss: 0.4751, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [25/50], Step [464/469], Loss: 0.5945, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [25/50], Step [465/469], Loss: 0.3320, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [25/50], Step [466/469], Loss: 0.5887, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [25/50], Step [467/469], Loss: 0.4355, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [25/50], Step [468/469], Loss: 0.5410, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [25/50], Step [469/469], Loss: 0.2346, batch time: 0.44, accuracy:  94.79%\n",
      "Epoch [26/50], Step [1/469], Loss: 0.5214, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [2/469], Loss: 0.4947, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [26/50], Step [3/469], Loss: 0.5899, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [4/469], Loss: 0.3861, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [26/50], Step [5/469], Loss: 0.3918, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [26/50], Step [6/469], Loss: 0.6618, batch time: 0.45, accuracy:  77.34%\n",
      "Epoch [26/50], Step [7/469], Loss: 0.2999, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [26/50], Step [8/469], Loss: 0.6771, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [26/50], Step [9/469], Loss: 0.4146, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [26/50], Step [10/469], Loss: 0.4857, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [26/50], Step [11/469], Loss: 0.4431, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [26/50], Step [12/469], Loss: 0.4839, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [26/50], Step [13/469], Loss: 0.5309, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [26/50], Step [14/469], Loss: 0.4622, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [26/50], Step [15/469], Loss: 0.4046, batch time: 0.70, accuracy:  86.72%\n",
      "Epoch [26/50], Step [16/469], Loss: 0.4533, batch time: 0.73, accuracy:  85.16%\n",
      "Epoch [26/50], Step [17/469], Loss: 0.4977, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [26/50], Step [18/469], Loss: 0.4678, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [26/50], Step [19/469], Loss: 0.5199, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [26/50], Step [20/469], Loss: 0.4665, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [26/50], Step [21/469], Loss: 0.5730, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [26/50], Step [22/469], Loss: 0.4828, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [26/50], Step [23/469], Loss: 0.4736, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [24/469], Loss: 0.5537, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [26/50], Step [25/469], Loss: 0.5784, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [26/50], Step [26/469], Loss: 0.3748, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [27/469], Loss: 0.4022, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [26/50], Step [28/469], Loss: 0.4963, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [26/50], Step [29/469], Loss: 0.7049, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [26/50], Step [30/469], Loss: 0.3738, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [31/469], Loss: 0.6629, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [26/50], Step [32/469], Loss: 0.4539, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [33/469], Loss: 0.4744, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [26/50], Step [34/469], Loss: 0.3721, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [26/50], Step [35/469], Loss: 0.6907, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [26/50], Step [36/469], Loss: 0.4621, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [26/50], Step [37/469], Loss: 0.5565, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [26/50], Step [38/469], Loss: 0.5386, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [39/469], Loss: 0.6280, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [40/469], Loss: 0.4101, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [41/469], Loss: 0.4136, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [26/50], Step [42/469], Loss: 0.4249, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [26/50], Step [43/469], Loss: 0.3871, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [26/50], Step [44/469], Loss: 0.3892, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [26/50], Step [45/469], Loss: 0.3253, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [26/50], Step [46/469], Loss: 0.6049, batch time: 0.46, accuracy:  79.69%\n",
      "Epoch [26/50], Step [47/469], Loss: 0.5157, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [26/50], Step [48/469], Loss: 0.4689, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [49/469], Loss: 0.5363, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [26/50], Step [50/469], Loss: 0.3793, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [26/50], Step [51/469], Loss: 0.5385, batch time: 0.61, accuracy:  84.38%\n",
      "Epoch [26/50], Step [52/469], Loss: 0.4575, batch time: 0.61, accuracy:  85.16%\n",
      "Epoch [26/50], Step [53/469], Loss: 0.4666, batch time: 0.69, accuracy:  87.50%\n",
      "Epoch [26/50], Step [54/469], Loss: 0.4679, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [26/50], Step [55/469], Loss: 0.4070, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [56/469], Loss: 0.3489, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [26/50], Step [57/469], Loss: 0.4836, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [58/469], Loss: 0.4368, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [26/50], Step [59/469], Loss: 0.3800, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [26/50], Step [60/469], Loss: 0.4256, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [26/50], Step [61/469], Loss: 0.4580, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [26/50], Step [62/469], Loss: 0.4426, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [26/50], Step [63/469], Loss: 0.5865, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [26/50], Step [64/469], Loss: 0.4553, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [26/50], Step [65/469], Loss: 0.4474, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [26/50], Step [66/469], Loss: 0.5149, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [26/50], Step [67/469], Loss: 0.3294, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [26/50], Step [68/469], Loss: 0.4315, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [69/469], Loss: 0.5569, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [26/50], Step [70/469], Loss: 0.3817, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [26/50], Step [71/469], Loss: 0.4181, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [26/50], Step [72/469], Loss: 0.5430, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [26/50], Step [73/469], Loss: 0.4424, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [26/50], Step [74/469], Loss: 0.3461, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [75/469], Loss: 0.3035, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [26/50], Step [76/469], Loss: 0.4708, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [77/469], Loss: 0.4331, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [26/50], Step [78/469], Loss: 0.5091, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [26/50], Step [79/469], Loss: 0.4137, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [26/50], Step [80/469], Loss: 0.3277, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [26/50], Step [81/469], Loss: 0.3261, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [26/50], Step [82/469], Loss: 0.5531, batch time: 0.81, accuracy:  84.38%\n",
      "Epoch [26/50], Step [83/469], Loss: 0.4624, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [26/50], Step [84/469], Loss: 0.6048, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [26/50], Step [85/469], Loss: 0.4241, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [86/469], Loss: 0.4036, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [87/469], Loss: 0.3135, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [26/50], Step [88/469], Loss: 0.4534, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [26/50], Step [89/469], Loss: 0.4258, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [26/50], Step [90/469], Loss: 0.3755, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [91/469], Loss: 0.4146, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [26/50], Step [92/469], Loss: 0.4898, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [26/50], Step [93/469], Loss: 0.4293, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [26/50], Step [94/469], Loss: 0.6077, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [26/50], Step [95/469], Loss: 0.4953, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [26/50], Step [96/469], Loss: 0.3786, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [26/50], Step [97/469], Loss: 0.3545, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [26/50], Step [98/469], Loss: 0.4606, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [26/50], Step [99/469], Loss: 0.4837, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [26/50], Step [100/469], Loss: 0.4045, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [101/469], Loss: 0.2994, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [26/50], Step [102/469], Loss: 0.4917, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [26/50], Step [103/469], Loss: 0.3923, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [26/50], Step [104/469], Loss: 0.3964, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [105/469], Loss: 0.5305, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [26/50], Step [106/469], Loss: 0.3826, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [107/469], Loss: 0.5767, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [26/50], Step [108/469], Loss: 0.4736, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [26/50], Step [109/469], Loss: 0.4009, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [26/50], Step [110/469], Loss: 0.3951, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [26/50], Step [111/469], Loss: 0.3724, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [26/50], Step [112/469], Loss: 0.6201, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [26/50], Step [113/469], Loss: 0.4685, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [26/50], Step [114/469], Loss: 0.4177, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [26/50], Step [115/469], Loss: 0.4621, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [26/50], Step [116/469], Loss: 0.4890, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [117/469], Loss: 0.4726, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [26/50], Step [118/469], Loss: 0.4371, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [26/50], Step [119/469], Loss: 0.4139, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [26/50], Step [120/469], Loss: 0.3759, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [26/50], Step [121/469], Loss: 0.3211, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [122/469], Loss: 0.5233, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [26/50], Step [123/469], Loss: 0.5270, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [26/50], Step [124/469], Loss: 0.5517, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [125/469], Loss: 0.6198, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [126/469], Loss: 0.5884, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [26/50], Step [127/469], Loss: 0.4093, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [26/50], Step [128/469], Loss: 0.4191, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [26/50], Step [129/469], Loss: 0.5102, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [26/50], Step [130/469], Loss: 0.5133, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [26/50], Step [131/469], Loss: 0.4889, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [26/50], Step [132/469], Loss: 0.4822, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [26/50], Step [133/469], Loss: 0.4576, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [26/50], Step [134/469], Loss: 0.3623, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [135/469], Loss: 0.4897, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [26/50], Step [136/469], Loss: 0.4305, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [26/50], Step [137/469], Loss: 0.4563, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [26/50], Step [138/469], Loss: 0.4441, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [26/50], Step [139/469], Loss: 0.4142, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [26/50], Step [140/469], Loss: 0.3505, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [26/50], Step [141/469], Loss: 0.4925, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [26/50], Step [142/469], Loss: 0.4314, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [143/469], Loss: 0.3254, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [26/50], Step [144/469], Loss: 0.3756, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [26/50], Step [145/469], Loss: 0.4956, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [26/50], Step [146/469], Loss: 0.4555, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [26/50], Step [147/469], Loss: 0.7518, batch time: 0.87, accuracy:  82.81%\n",
      "Epoch [26/50], Step [148/469], Loss: 0.5352, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [26/50], Step [149/469], Loss: 0.3214, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [26/50], Step [150/469], Loss: 0.4773, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [151/469], Loss: 0.5019, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [26/50], Step [152/469], Loss: 0.4399, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [26/50], Step [153/469], Loss: 0.5406, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [26/50], Step [154/469], Loss: 0.5865, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [26/50], Step [155/469], Loss: 0.4411, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [26/50], Step [156/469], Loss: 0.2764, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [26/50], Step [157/469], Loss: 0.3836, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [26/50], Step [158/469], Loss: 0.2997, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [26/50], Step [159/469], Loss: 0.3968, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [26/50], Step [160/469], Loss: 0.4649, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [26/50], Step [161/469], Loss: 0.3984, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [26/50], Step [162/469], Loss: 0.4110, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [163/469], Loss: 0.5481, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [26/50], Step [164/469], Loss: 0.3474, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [165/469], Loss: 0.3295, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [26/50], Step [166/469], Loss: 0.6706, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [26/50], Step [167/469], Loss: 0.5144, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [26/50], Step [168/469], Loss: 0.4088, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [26/50], Step [169/469], Loss: 0.4173, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [26/50], Step [170/469], Loss: 0.3985, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [171/469], Loss: 0.3942, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [26/50], Step [172/469], Loss: 0.4019, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [26/50], Step [173/469], Loss: 0.7251, batch time: 0.52, accuracy:  79.69%\n",
      "Epoch [26/50], Step [174/469], Loss: 0.4914, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [26/50], Step [175/469], Loss: 0.6291, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [26/50], Step [176/469], Loss: 0.3364, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [26/50], Step [177/469], Loss: 0.4945, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [26/50], Step [178/469], Loss: 0.4825, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [26/50], Step [179/469], Loss: 0.5407, batch time: 0.62, accuracy:  80.47%\n",
      "Epoch [26/50], Step [180/469], Loss: 0.5169, batch time: 0.60, accuracy:  82.81%\n",
      "Epoch [26/50], Step [181/469], Loss: 0.4202, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [26/50], Step [182/469], Loss: 0.4132, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [26/50], Step [183/469], Loss: 0.4542, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [26/50], Step [184/469], Loss: 0.6360, batch time: 0.62, accuracy:  80.47%\n",
      "Epoch [26/50], Step [185/469], Loss: 0.3736, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [26/50], Step [186/469], Loss: 0.5776, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [187/469], Loss: 0.7362, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [26/50], Step [188/469], Loss: 0.4101, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [189/469], Loss: 0.3927, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [26/50], Step [190/469], Loss: 0.2371, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [26/50], Step [191/469], Loss: 0.6383, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [26/50], Step [192/469], Loss: 0.2645, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [26/50], Step [193/469], Loss: 0.3753, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [26/50], Step [194/469], Loss: 0.3577, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [26/50], Step [195/469], Loss: 0.6062, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [196/469], Loss: 0.4265, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [26/50], Step [197/469], Loss: 0.5323, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [26/50], Step [198/469], Loss: 0.3839, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [26/50], Step [199/469], Loss: 0.3885, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [200/469], Loss: 0.4150, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [26/50], Step [201/469], Loss: 0.6957, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [26/50], Step [202/469], Loss: 0.3972, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [26/50], Step [203/469], Loss: 0.4109, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [204/469], Loss: 0.3990, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [26/50], Step [205/469], Loss: 0.7436, batch time: 0.44, accuracy:  77.34%\n",
      "Epoch [26/50], Step [206/469], Loss: 0.4669, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [207/469], Loss: 0.6275, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [26/50], Step [208/469], Loss: 0.4317, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [26/50], Step [209/469], Loss: 0.3065, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [26/50], Step [210/469], Loss: 0.5819, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [26/50], Step [211/469], Loss: 0.4766, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [26/50], Step [212/469], Loss: 0.5174, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [26/50], Step [213/469], Loss: 0.5077, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [26/50], Step [214/469], Loss: 0.3812, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [26/50], Step [215/469], Loss: 0.3160, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [26/50], Step [216/469], Loss: 0.6495, batch time: 0.54, accuracy:  78.12%\n",
      "Epoch [26/50], Step [217/469], Loss: 0.4188, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [26/50], Step [218/469], Loss: 0.4409, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [26/50], Step [219/469], Loss: 0.4563, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [26/50], Step [220/469], Loss: 0.5657, batch time: 0.64, accuracy:  84.38%\n",
      "Epoch [26/50], Step [221/469], Loss: 0.4382, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [26/50], Step [222/469], Loss: 0.4534, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [26/50], Step [223/469], Loss: 0.2921, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [26/50], Step [224/469], Loss: 0.4406, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [225/469], Loss: 0.5473, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [26/50], Step [226/469], Loss: 0.4810, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [26/50], Step [227/469], Loss: 0.4593, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [26/50], Step [228/469], Loss: 0.4487, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [229/469], Loss: 0.3264, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [230/469], Loss: 0.4814, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [26/50], Step [231/469], Loss: 0.6828, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [26/50], Step [232/469], Loss: 0.3979, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [26/50], Step [233/469], Loss: 0.3940, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [234/469], Loss: 0.6673, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [26/50], Step [235/469], Loss: 0.4688, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [26/50], Step [236/469], Loss: 0.2455, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [26/50], Step [237/469], Loss: 0.3802, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [26/50], Step [238/469], Loss: 0.6069, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [239/469], Loss: 0.5110, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [26/50], Step [240/469], Loss: 0.4732, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [26/50], Step [241/469], Loss: 0.3271, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [26/50], Step [242/469], Loss: 0.4676, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [243/469], Loss: 0.6311, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [26/50], Step [244/469], Loss: 0.3658, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [26/50], Step [245/469], Loss: 0.4476, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [26/50], Step [246/469], Loss: 0.3249, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [26/50], Step [247/469], Loss: 0.3788, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [26/50], Step [248/469], Loss: 0.3893, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [26/50], Step [249/469], Loss: 0.2978, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [26/50], Step [250/469], Loss: 0.4349, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [26/50], Step [251/469], Loss: 0.3551, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [26/50], Step [252/469], Loss: 0.5214, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [253/469], Loss: 0.4390, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [26/50], Step [254/469], Loss: 0.3373, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [26/50], Step [255/469], Loss: 0.3965, batch time: 0.69, accuracy:  86.72%\n",
      "Epoch [26/50], Step [256/469], Loss: 0.4318, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [26/50], Step [257/469], Loss: 0.4204, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [26/50], Step [258/469], Loss: 0.3140, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [26/50], Step [259/469], Loss: 0.3696, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [26/50], Step [260/469], Loss: 0.4952, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [26/50], Step [261/469], Loss: 0.6977, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [26/50], Step [262/469], Loss: 0.3020, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [263/469], Loss: 0.3503, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [264/469], Loss: 0.4716, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [26/50], Step [265/469], Loss: 0.5414, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [26/50], Step [266/469], Loss: 0.3864, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [26/50], Step [267/469], Loss: 0.3526, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [26/50], Step [268/469], Loss: 0.4481, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [26/50], Step [269/469], Loss: 0.3269, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [270/469], Loss: 0.4294, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [271/469], Loss: 0.3554, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [26/50], Step [272/469], Loss: 0.4153, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [26/50], Step [273/469], Loss: 0.3058, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [26/50], Step [274/469], Loss: 0.3580, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [26/50], Step [275/469], Loss: 0.4730, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [276/469], Loss: 0.4898, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [26/50], Step [277/469], Loss: 0.3436, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [26/50], Step [278/469], Loss: 0.4133, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [279/469], Loss: 0.7034, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [26/50], Step [280/469], Loss: 0.3331, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [26/50], Step [281/469], Loss: 0.4412, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [26/50], Step [282/469], Loss: 0.5640, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [26/50], Step [283/469], Loss: 0.6524, batch time: 0.95, accuracy:  82.81%\n",
      "Epoch [26/50], Step [284/469], Loss: 0.4130, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [26/50], Step [285/469], Loss: 0.4574, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [26/50], Step [286/469], Loss: 0.3261, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [26/50], Step [287/469], Loss: 0.5864, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [26/50], Step [288/469], Loss: 0.5456, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [26/50], Step [289/469], Loss: 0.5185, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [290/469], Loss: 0.3820, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [291/469], Loss: 0.3732, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [26/50], Step [292/469], Loss: 0.3931, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [26/50], Step [293/469], Loss: 0.6553, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [26/50], Step [294/469], Loss: 0.4974, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [26/50], Step [295/469], Loss: 0.5254, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [26/50], Step [296/469], Loss: 0.3677, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [26/50], Step [297/469], Loss: 0.3976, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [26/50], Step [298/469], Loss: 0.5143, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [26/50], Step [299/469], Loss: 0.5163, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [26/50], Step [300/469], Loss: 0.4521, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [26/50], Step [301/469], Loss: 0.4155, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [26/50], Step [302/469], Loss: 0.4148, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [26/50], Step [303/469], Loss: 0.4429, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [26/50], Step [304/469], Loss: 0.4886, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [26/50], Step [305/469], Loss: 0.6776, batch time: 0.45, accuracy:  78.91%\n",
      "Epoch [26/50], Step [306/469], Loss: 0.5154, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [26/50], Step [307/469], Loss: 0.4223, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [26/50], Step [308/469], Loss: 0.3131, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [26/50], Step [309/469], Loss: 0.4385, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [26/50], Step [310/469], Loss: 0.5795, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [26/50], Step [311/469], Loss: 0.6413, batch time: 0.60, accuracy:  81.25%\n",
      "Epoch [26/50], Step [312/469], Loss: 0.3937, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [26/50], Step [313/469], Loss: 0.4506, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [26/50], Step [314/469], Loss: 0.4414, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [26/50], Step [315/469], Loss: 0.3771, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [26/50], Step [316/469], Loss: 0.5647, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [317/469], Loss: 0.4882, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [26/50], Step [318/469], Loss: 0.3483, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [26/50], Step [319/469], Loss: 0.3720, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [26/50], Step [320/469], Loss: 0.5773, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [26/50], Step [321/469], Loss: 0.3867, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [26/50], Step [322/469], Loss: 0.4714, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [26/50], Step [323/469], Loss: 0.2307, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [26/50], Step [324/469], Loss: 0.3853, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [26/50], Step [325/469], Loss: 0.3254, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [26/50], Step [326/469], Loss: 0.5196, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [26/50], Step [327/469], Loss: 0.4711, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [328/469], Loss: 0.3538, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [26/50], Step [329/469], Loss: 0.4608, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [26/50], Step [330/469], Loss: 0.3877, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [26/50], Step [331/469], Loss: 0.3396, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [26/50], Step [332/469], Loss: 0.6112, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [26/50], Step [333/469], Loss: 0.3998, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [26/50], Step [334/469], Loss: 0.4296, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [335/469], Loss: 0.4557, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [336/469], Loss: 0.5018, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [26/50], Step [337/469], Loss: 0.7096, batch time: 0.45, accuracy:  76.56%\n",
      "Epoch [26/50], Step [338/469], Loss: 0.5395, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [26/50], Step [339/469], Loss: 0.6166, batch time: 0.55, accuracy:  82.03%\n",
      "Epoch [26/50], Step [340/469], Loss: 0.3413, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [26/50], Step [341/469], Loss: 0.4190, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [26/50], Step [342/469], Loss: 0.3794, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [26/50], Step [343/469], Loss: 0.4064, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [26/50], Step [344/469], Loss: 0.3485, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [26/50], Step [345/469], Loss: 0.7130, batch time: 0.58, accuracy:  81.25%\n",
      "Epoch [26/50], Step [346/469], Loss: 0.4009, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [26/50], Step [347/469], Loss: 0.3191, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [26/50], Step [348/469], Loss: 0.4653, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [26/50], Step [349/469], Loss: 0.3040, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [26/50], Step [350/469], Loss: 0.3498, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [26/50], Step [351/469], Loss: 0.4603, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [26/50], Step [352/469], Loss: 0.4455, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [26/50], Step [353/469], Loss: 0.5406, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [26/50], Step [354/469], Loss: 0.4600, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [26/50], Step [355/469], Loss: 0.4672, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [26/50], Step [356/469], Loss: 0.5554, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [26/50], Step [357/469], Loss: 0.3737, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [358/469], Loss: 0.3213, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [26/50], Step [359/469], Loss: 0.5681, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [26/50], Step [360/469], Loss: 0.4395, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [26/50], Step [361/469], Loss: 0.5699, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [26/50], Step [362/469], Loss: 0.3830, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [363/469], Loss: 0.5386, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [26/50], Step [364/469], Loss: 0.4466, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [26/50], Step [365/469], Loss: 0.4425, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [366/469], Loss: 0.6439, batch time: 0.44, accuracy:  78.12%\n",
      "Epoch [26/50], Step [367/469], Loss: 0.4901, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [26/50], Step [368/469], Loss: 0.4224, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [26/50], Step [369/469], Loss: 0.5100, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [370/469], Loss: 0.4409, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [26/50], Step [371/469], Loss: 0.6184, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [26/50], Step [372/469], Loss: 0.6923, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [26/50], Step [373/469], Loss: 0.3326, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [374/469], Loss: 0.3750, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [26/50], Step [375/469], Loss: 0.3612, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [26/50], Step [376/469], Loss: 0.3732, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [26/50], Step [377/469], Loss: 0.5637, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [26/50], Step [378/469], Loss: 0.3805, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [26/50], Step [379/469], Loss: 0.5309, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [26/50], Step [380/469], Loss: 0.5140, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [26/50], Step [381/469], Loss: 0.4574, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [26/50], Step [382/469], Loss: 0.3891, batch time: 0.74, accuracy:  90.62%\n",
      "Epoch [26/50], Step [383/469], Loss: 0.6309, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [26/50], Step [384/469], Loss: 0.5746, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [26/50], Step [385/469], Loss: 0.4254, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [26/50], Step [386/469], Loss: 0.4027, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [387/469], Loss: 0.3589, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [26/50], Step [388/469], Loss: 0.4136, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [26/50], Step [389/469], Loss: 0.3806, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [390/469], Loss: 0.4358, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [26/50], Step [391/469], Loss: 0.4582, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [26/50], Step [392/469], Loss: 0.5619, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [26/50], Step [393/469], Loss: 0.6553, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [26/50], Step [394/469], Loss: 0.6182, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [395/469], Loss: 0.4409, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [26/50], Step [396/469], Loss: 0.3574, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [26/50], Step [397/469], Loss: 0.3297, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [26/50], Step [398/469], Loss: 0.5308, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [26/50], Step [399/469], Loss: 0.4376, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [26/50], Step [400/469], Loss: 0.4143, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [26/50], Step [401/469], Loss: 0.3777, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [26/50], Step [402/469], Loss: 0.3444, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [26/50], Step [403/469], Loss: 0.4707, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [26/50], Step [404/469], Loss: 0.4279, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [26/50], Step [405/469], Loss: 0.3786, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [26/50], Step [406/469], Loss: 0.4928, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [26/50], Step [407/469], Loss: 0.4456, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [26/50], Step [408/469], Loss: 0.3262, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [26/50], Step [409/469], Loss: 0.4437, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [26/50], Step [410/469], Loss: 0.4138, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [26/50], Step [411/469], Loss: 0.6537, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [26/50], Step [412/469], Loss: 0.3837, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [26/50], Step [413/469], Loss: 0.4394, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [26/50], Step [414/469], Loss: 0.4175, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [26/50], Step [415/469], Loss: 0.4752, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [26/50], Step [416/469], Loss: 0.3510, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [26/50], Step [417/469], Loss: 0.3579, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [26/50], Step [418/469], Loss: 0.5406, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [419/469], Loss: 0.5073, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [26/50], Step [420/469], Loss: 0.3907, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [26/50], Step [421/469], Loss: 0.4172, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [26/50], Step [422/469], Loss: 0.2769, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [26/50], Step [423/469], Loss: 0.3319, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [26/50], Step [424/469], Loss: 0.3040, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [26/50], Step [425/469], Loss: 0.3979, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [26/50], Step [426/469], Loss: 0.3913, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [26/50], Step [427/469], Loss: 0.7654, batch time: 0.49, accuracy:  76.56%\n",
      "Epoch [26/50], Step [428/469], Loss: 0.4518, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [26/50], Step [429/469], Loss: 0.3383, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [26/50], Step [430/469], Loss: 0.3045, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [26/50], Step [431/469], Loss: 0.3433, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [26/50], Step [432/469], Loss: 0.3508, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [433/469], Loss: 0.5358, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [26/50], Step [434/469], Loss: 0.4569, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [26/50], Step [435/469], Loss: 0.3807, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [436/469], Loss: 0.4224, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [26/50], Step [437/469], Loss: 0.2996, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [26/50], Step [438/469], Loss: 0.5223, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [26/50], Step [439/469], Loss: 0.5861, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [26/50], Step [440/469], Loss: 0.4356, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [26/50], Step [441/469], Loss: 0.5145, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [26/50], Step [442/469], Loss: 0.3708, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [26/50], Step [443/469], Loss: 0.3831, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [26/50], Step [444/469], Loss: 0.4153, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [26/50], Step [445/469], Loss: 0.5780, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [26/50], Step [446/469], Loss: 0.3209, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [26/50], Step [447/469], Loss: 0.4483, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [26/50], Step [448/469], Loss: 0.3666, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [26/50], Step [449/469], Loss: 0.4150, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [26/50], Step [450/469], Loss: 0.4435, batch time: 0.73, accuracy:  84.38%\n",
      "Epoch [26/50], Step [451/469], Loss: 0.2934, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [26/50], Step [452/469], Loss: 0.4793, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [26/50], Step [453/469], Loss: 0.3800, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [26/50], Step [454/469], Loss: 0.4578, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [26/50], Step [455/469], Loss: 0.4515, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [26/50], Step [456/469], Loss: 0.4164, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [26/50], Step [457/469], Loss: 0.5729, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [26/50], Step [458/469], Loss: 0.3024, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [26/50], Step [459/469], Loss: 0.4715, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [26/50], Step [460/469], Loss: 0.4603, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [26/50], Step [461/469], Loss: 0.4315, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [26/50], Step [462/469], Loss: 0.4638, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [26/50], Step [463/469], Loss: 0.4398, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [26/50], Step [464/469], Loss: 0.4991, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [26/50], Step [465/469], Loss: 0.4209, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [26/50], Step [466/469], Loss: 0.5344, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [26/50], Step [467/469], Loss: 0.4606, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [26/50], Step [468/469], Loss: 0.3233, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [26/50], Step [469/469], Loss: 0.5349, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [27/50], Step [1/469], Loss: 0.3735, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [27/50], Step [2/469], Loss: 0.7326, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [27/50], Step [3/469], Loss: 0.5803, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [27/50], Step [4/469], Loss: 0.5710, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [27/50], Step [5/469], Loss: 0.5125, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [27/50], Step [6/469], Loss: 0.3982, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [27/50], Step [7/469], Loss: 0.4723, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [27/50], Step [8/469], Loss: 0.5400, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [27/50], Step [9/469], Loss: 0.4136, batch time: 0.76, accuracy:  88.28%\n",
      "Epoch [27/50], Step [10/469], Loss: 0.4323, batch time: 0.60, accuracy:  85.94%\n",
      "Epoch [27/50], Step [11/469], Loss: 0.4838, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [27/50], Step [12/469], Loss: 0.3364, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [27/50], Step [13/469], Loss: 0.6612, batch time: 0.44, accuracy:  75.78%\n",
      "Epoch [27/50], Step [14/469], Loss: 0.5359, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [27/50], Step [15/469], Loss: 0.4836, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [16/469], Loss: 0.2728, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [17/469], Loss: 0.3791, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [27/50], Step [18/469], Loss: 0.3598, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [27/50], Step [19/469], Loss: 0.6323, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [27/50], Step [20/469], Loss: 0.4334, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [21/469], Loss: 0.3897, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [27/50], Step [22/469], Loss: 0.5294, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [27/50], Step [23/469], Loss: 0.4617, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [27/50], Step [24/469], Loss: 0.4626, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [27/50], Step [25/469], Loss: 0.4253, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [27/50], Step [26/469], Loss: 0.4737, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [27/50], Step [27/469], Loss: 0.3980, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [27/50], Step [28/469], Loss: 0.3775, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [27/50], Step [29/469], Loss: 0.4173, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [27/50], Step [30/469], Loss: 0.3687, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [27/50], Step [31/469], Loss: 0.2668, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [27/50], Step [32/469], Loss: 0.4250, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [27/50], Step [33/469], Loss: 0.5133, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [27/50], Step [34/469], Loss: 0.3211, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [27/50], Step [35/469], Loss: 0.4268, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [36/469], Loss: 0.5194, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [27/50], Step [37/469], Loss: 0.5133, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [27/50], Step [38/469], Loss: 0.3795, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [27/50], Step [39/469], Loss: 0.4827, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [27/50], Step [40/469], Loss: 0.3841, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [27/50], Step [41/469], Loss: 0.4103, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [27/50], Step [42/469], Loss: 0.5317, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [27/50], Step [43/469], Loss: 0.3100, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [27/50], Step [44/469], Loss: 0.2981, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [27/50], Step [45/469], Loss: 0.4312, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [27/50], Step [46/469], Loss: 0.3438, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [27/50], Step [47/469], Loss: 0.4788, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [27/50], Step [48/469], Loss: 0.3887, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [27/50], Step [49/469], Loss: 0.5268, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [27/50], Step [50/469], Loss: 0.4085, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [27/50], Step [51/469], Loss: 0.4281, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [52/469], Loss: 0.3544, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [27/50], Step [53/469], Loss: 0.4276, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [27/50], Step [54/469], Loss: 0.4639, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [27/50], Step [55/469], Loss: 0.3643, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [27/50], Step [56/469], Loss: 0.4353, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [27/50], Step [57/469], Loss: 0.3258, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [27/50], Step [58/469], Loss: 0.4288, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [27/50], Step [59/469], Loss: 0.3659, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [27/50], Step [60/469], Loss: 0.5829, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [27/50], Step [61/469], Loss: 0.5284, batch time: 0.42, accuracy:  85.16%\n",
      "Epoch [27/50], Step [62/469], Loss: 0.3283, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [27/50], Step [63/469], Loss: 0.5492, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [27/50], Step [64/469], Loss: 0.3833, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [27/50], Step [65/469], Loss: 0.5846, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [27/50], Step [66/469], Loss: 0.4587, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [27/50], Step [67/469], Loss: 0.2949, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [27/50], Step [68/469], Loss: 0.5416, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [69/469], Loss: 0.4457, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [70/469], Loss: 0.5700, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [27/50], Step [71/469], Loss: 0.4329, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [27/50], Step [72/469], Loss: 0.3830, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [27/50], Step [73/469], Loss: 0.3343, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [27/50], Step [74/469], Loss: 0.4599, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [27/50], Step [75/469], Loss: 0.6140, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [27/50], Step [76/469], Loss: 0.4606, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [27/50], Step [77/469], Loss: 0.3138, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [27/50], Step [78/469], Loss: 0.3633, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [27/50], Step [79/469], Loss: 0.3223, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [27/50], Step [80/469], Loss: 0.4453, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [27/50], Step [81/469], Loss: 0.5123, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [27/50], Step [82/469], Loss: 0.3170, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [27/50], Step [83/469], Loss: 0.4832, batch time: 0.66, accuracy:  86.72%\n",
      "Epoch [27/50], Step [84/469], Loss: 0.5168, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [27/50], Step [85/469], Loss: 0.4622, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [86/469], Loss: 0.4448, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [87/469], Loss: 0.4662, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [88/469], Loss: 0.4989, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [27/50], Step [89/469], Loss: 0.3118, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [27/50], Step [90/469], Loss: 0.4568, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [27/50], Step [91/469], Loss: 0.3670, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [27/50], Step [92/469], Loss: 0.4077, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [27/50], Step [93/469], Loss: 0.3795, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [27/50], Step [94/469], Loss: 0.3039, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [27/50], Step [95/469], Loss: 0.4678, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [96/469], Loss: 0.4733, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [97/469], Loss: 0.3770, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [98/469], Loss: 0.4240, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [27/50], Step [99/469], Loss: 0.3148, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [27/50], Step [100/469], Loss: 0.4995, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [27/50], Step [101/469], Loss: 0.3079, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [27/50], Step [102/469], Loss: 0.4631, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [103/469], Loss: 0.6690, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [27/50], Step [104/469], Loss: 0.4787, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [27/50], Step [105/469], Loss: 0.4860, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [27/50], Step [106/469], Loss: 0.3946, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [107/469], Loss: 0.4867, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [108/469], Loss: 0.5075, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [109/469], Loss: 0.5042, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [27/50], Step [110/469], Loss: 0.5489, batch time: 0.46, accuracy:  78.12%\n",
      "Epoch [27/50], Step [111/469], Loss: 0.7009, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [27/50], Step [112/469], Loss: 0.5726, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [27/50], Step [113/469], Loss: 0.3513, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [27/50], Step [114/469], Loss: 0.3534, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [27/50], Step [115/469], Loss: 0.5315, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [27/50], Step [116/469], Loss: 0.5514, batch time: 0.85, accuracy:  83.59%\n",
      "Epoch [27/50], Step [117/469], Loss: 0.4622, batch time: 0.55, accuracy:  80.47%\n",
      "Epoch [27/50], Step [118/469], Loss: 0.3045, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [27/50], Step [119/469], Loss: 0.4296, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [27/50], Step [120/469], Loss: 0.3661, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [27/50], Step [121/469], Loss: 0.3600, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [27/50], Step [122/469], Loss: 0.6243, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [27/50], Step [123/469], Loss: 0.5157, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [27/50], Step [124/469], Loss: 0.4131, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [27/50], Step [125/469], Loss: 0.3759, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [27/50], Step [126/469], Loss: 0.5165, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [27/50], Step [127/469], Loss: 0.4631, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [27/50], Step [128/469], Loss: 0.4377, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [27/50], Step [129/469], Loss: 0.6832, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [27/50], Step [130/469], Loss: 0.4422, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [27/50], Step [131/469], Loss: 0.3474, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [27/50], Step [132/469], Loss: 0.5548, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [27/50], Step [133/469], Loss: 0.7418, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [27/50], Step [134/469], Loss: 0.4652, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [27/50], Step [135/469], Loss: 0.5251, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [136/469], Loss: 0.3432, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [27/50], Step [137/469], Loss: 0.3237, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [27/50], Step [138/469], Loss: 0.3748, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [27/50], Step [139/469], Loss: 0.3352, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [27/50], Step [140/469], Loss: 0.5044, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [141/469], Loss: 0.4118, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [27/50], Step [142/469], Loss: 0.3369, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [27/50], Step [143/469], Loss: 0.5540, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [144/469], Loss: 0.3903, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [145/469], Loss: 0.3153, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [27/50], Step [146/469], Loss: 0.4950, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [27/50], Step [147/469], Loss: 0.3820, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [148/469], Loss: 0.5476, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [27/50], Step [149/469], Loss: 0.6173, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [27/50], Step [150/469], Loss: 0.5440, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [27/50], Step [151/469], Loss: 0.5691, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [27/50], Step [152/469], Loss: 0.4911, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [27/50], Step [153/469], Loss: 0.3408, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [27/50], Step [154/469], Loss: 0.4673, batch time: 0.69, accuracy:  85.16%\n",
      "Epoch [27/50], Step [155/469], Loss: 0.4422, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [27/50], Step [156/469], Loss: 0.4283, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [27/50], Step [157/469], Loss: 0.5240, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [158/469], Loss: 0.4068, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [27/50], Step [159/469], Loss: 0.3999, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [27/50], Step [160/469], Loss: 0.4273, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [161/469], Loss: 0.5944, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [27/50], Step [162/469], Loss: 0.5824, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [27/50], Step [163/469], Loss: 0.4022, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [27/50], Step [164/469], Loss: 0.4913, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [27/50], Step [165/469], Loss: 0.5575, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [27/50], Step [166/469], Loss: 0.3389, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [27/50], Step [167/469], Loss: 0.4871, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [168/469], Loss: 0.4711, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [27/50], Step [169/469], Loss: 0.4943, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [27/50], Step [170/469], Loss: 0.3786, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [171/469], Loss: 0.4951, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [27/50], Step [172/469], Loss: 0.3031, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [27/50], Step [173/469], Loss: 0.5512, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [27/50], Step [174/469], Loss: 0.3556, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [27/50], Step [175/469], Loss: 0.4118, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [27/50], Step [176/469], Loss: 0.4349, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [27/50], Step [177/469], Loss: 0.4932, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [27/50], Step [178/469], Loss: 0.3306, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [179/469], Loss: 0.4581, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [27/50], Step [180/469], Loss: 0.3657, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [27/50], Step [181/469], Loss: 0.3744, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [27/50], Step [182/469], Loss: 0.4011, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [27/50], Step [183/469], Loss: 0.3459, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [27/50], Step [184/469], Loss: 0.7599, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [27/50], Step [185/469], Loss: 0.5338, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [27/50], Step [186/469], Loss: 0.5218, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [27/50], Step [187/469], Loss: 0.3506, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [27/50], Step [188/469], Loss: 0.7377, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [27/50], Step [189/469], Loss: 0.3625, batch time: 0.91, accuracy:  89.06%\n",
      "Epoch [27/50], Step [190/469], Loss: 0.5476, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [27/50], Step [191/469], Loss: 0.3181, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [27/50], Step [192/469], Loss: 0.4898, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [27/50], Step [193/469], Loss: 0.3787, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [194/469], Loss: 0.3309, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [195/469], Loss: 0.4898, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [27/50], Step [196/469], Loss: 0.5585, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [27/50], Step [197/469], Loss: 0.3774, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [198/469], Loss: 0.5534, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [27/50], Step [199/469], Loss: 0.5097, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [200/469], Loss: 0.5585, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [27/50], Step [201/469], Loss: 0.4469, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [27/50], Step [202/469], Loss: 0.5127, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [27/50], Step [203/469], Loss: 0.4675, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [204/469], Loss: 0.6211, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [27/50], Step [205/469], Loss: 0.5478, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [206/469], Loss: 0.4387, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [207/469], Loss: 0.3957, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [208/469], Loss: 0.5163, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [27/50], Step [209/469], Loss: 0.3068, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [27/50], Step [210/469], Loss: 0.5293, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [27/50], Step [211/469], Loss: 0.3217, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [27/50], Step [212/469], Loss: 0.3323, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [27/50], Step [213/469], Loss: 0.5980, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [27/50], Step [214/469], Loss: 0.5029, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [27/50], Step [215/469], Loss: 0.4067, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [216/469], Loss: 0.3879, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [27/50], Step [217/469], Loss: 0.6091, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [27/50], Step [218/469], Loss: 0.4770, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [27/50], Step [219/469], Loss: 0.3868, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [27/50], Step [220/469], Loss: 0.4519, batch time: 0.64, accuracy:  85.94%\n",
      "Epoch [27/50], Step [221/469], Loss: 0.3739, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [27/50], Step [222/469], Loss: 0.4097, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [27/50], Step [223/469], Loss: 0.3284, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [27/50], Step [224/469], Loss: 0.3609, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [27/50], Step [225/469], Loss: 0.3640, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [27/50], Step [226/469], Loss: 0.4120, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [27/50], Step [227/469], Loss: 0.4659, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [27/50], Step [228/469], Loss: 0.6063, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [229/469], Loss: 0.4061, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [27/50], Step [230/469], Loss: 0.4941, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [27/50], Step [231/469], Loss: 0.4089, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [27/50], Step [232/469], Loss: 0.5391, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [27/50], Step [233/469], Loss: 0.3659, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [27/50], Step [234/469], Loss: 0.2925, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [27/50], Step [235/469], Loss: 0.5406, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [27/50], Step [236/469], Loss: 0.5027, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [27/50], Step [237/469], Loss: 0.5113, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [27/50], Step [238/469], Loss: 0.5865, batch time: 0.42, accuracy:  78.12%\n",
      "Epoch [27/50], Step [239/469], Loss: 0.4143, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [240/469], Loss: 0.3401, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [27/50], Step [241/469], Loss: 0.3847, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [242/469], Loss: 0.3777, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [27/50], Step [243/469], Loss: 0.3486, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [244/469], Loss: 0.4553, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [245/469], Loss: 0.5450, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [27/50], Step [246/469], Loss: 0.5901, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [27/50], Step [247/469], Loss: 0.3278, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [27/50], Step [248/469], Loss: 0.3403, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [27/50], Step [249/469], Loss: 0.4509, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [27/50], Step [250/469], Loss: 0.4303, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [27/50], Step [251/469], Loss: 0.3865, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [252/469], Loss: 0.4601, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [253/469], Loss: 0.3594, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [27/50], Step [254/469], Loss: 0.5404, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [27/50], Step [255/469], Loss: 0.4240, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [27/50], Step [256/469], Loss: 0.4195, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [27/50], Step [257/469], Loss: 0.4841, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [27/50], Step [258/469], Loss: 0.2399, batch time: 0.72, accuracy:  92.97%\n",
      "Epoch [27/50], Step [259/469], Loss: 0.4271, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [27/50], Step [260/469], Loss: 0.4830, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [27/50], Step [261/469], Loss: 0.3491, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [27/50], Step [262/469], Loss: 0.4298, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [263/469], Loss: 0.3720, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [27/50], Step [264/469], Loss: 0.4479, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [27/50], Step [265/469], Loss: 0.2933, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [27/50], Step [266/469], Loss: 0.4192, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [27/50], Step [267/469], Loss: 0.4178, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [27/50], Step [268/469], Loss: 0.4047, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [27/50], Step [269/469], Loss: 0.3406, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [270/469], Loss: 0.6633, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [271/469], Loss: 0.3936, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [27/50], Step [272/469], Loss: 0.4763, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [27/50], Step [273/469], Loss: 0.5238, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [274/469], Loss: 0.3817, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [27/50], Step [275/469], Loss: 0.2953, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [27/50], Step [276/469], Loss: 0.3080, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [27/50], Step [277/469], Loss: 0.5198, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [27/50], Step [278/469], Loss: 0.3169, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [27/50], Step [279/469], Loss: 0.5779, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [27/50], Step [280/469], Loss: 0.3708, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [281/469], Loss: 0.5025, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [27/50], Step [282/469], Loss: 0.5422, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [27/50], Step [283/469], Loss: 0.4253, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [27/50], Step [284/469], Loss: 0.2568, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [27/50], Step [285/469], Loss: 0.4975, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [27/50], Step [286/469], Loss: 0.4018, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [27/50], Step [287/469], Loss: 0.3106, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [27/50], Step [288/469], Loss: 0.4422, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [27/50], Step [289/469], Loss: 0.4775, batch time: 0.59, accuracy:  83.59%\n",
      "Epoch [27/50], Step [290/469], Loss: 0.4582, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [27/50], Step [291/469], Loss: 0.4977, batch time: 0.71, accuracy:  85.16%\n",
      "Epoch [27/50], Step [292/469], Loss: 0.4397, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [27/50], Step [293/469], Loss: 0.4489, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [27/50], Step [294/469], Loss: 0.4660, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [27/50], Step [295/469], Loss: 0.4474, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [27/50], Step [296/469], Loss: 0.4659, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [297/469], Loss: 0.4289, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [298/469], Loss: 0.3690, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [27/50], Step [299/469], Loss: 0.4640, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [27/50], Step [300/469], Loss: 0.4897, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [27/50], Step [301/469], Loss: 0.3239, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [27/50], Step [302/469], Loss: 0.4365, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [27/50], Step [303/469], Loss: 0.4680, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [27/50], Step [304/469], Loss: 0.4640, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [305/469], Loss: 0.4757, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [306/469], Loss: 0.6078, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [307/469], Loss: 0.4232, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [27/50], Step [308/469], Loss: 0.4139, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [27/50], Step [309/469], Loss: 0.4730, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [310/469], Loss: 0.6313, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [311/469], Loss: 0.3157, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [312/469], Loss: 0.6160, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [27/50], Step [313/469], Loss: 0.5094, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [314/469], Loss: 0.3360, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [27/50], Step [315/469], Loss: 0.4290, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [27/50], Step [316/469], Loss: 0.3227, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [27/50], Step [317/469], Loss: 0.4173, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [27/50], Step [318/469], Loss: 0.3703, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [27/50], Step [319/469], Loss: 0.4290, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [27/50], Step [320/469], Loss: 0.4970, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [27/50], Step [321/469], Loss: 0.2780, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [27/50], Step [322/469], Loss: 0.4372, batch time: 0.74, accuracy:  85.94%\n",
      "Epoch [27/50], Step [323/469], Loss: 0.4315, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [27/50], Step [324/469], Loss: 0.2496, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [27/50], Step [325/469], Loss: 0.5213, batch time: 0.45, accuracy:  78.12%\n",
      "Epoch [27/50], Step [326/469], Loss: 0.4620, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [27/50], Step [327/469], Loss: 0.4074, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [27/50], Step [328/469], Loss: 0.3438, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [329/469], Loss: 0.3967, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [330/469], Loss: 0.3947, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [27/50], Step [331/469], Loss: 0.2849, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [27/50], Step [332/469], Loss: 0.3646, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [27/50], Step [333/469], Loss: 0.3070, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [27/50], Step [334/469], Loss: 0.4908, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [335/469], Loss: 0.4097, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [336/469], Loss: 0.4603, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [337/469], Loss: 0.4179, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [27/50], Step [338/469], Loss: 0.4271, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [27/50], Step [339/469], Loss: 0.3049, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [27/50], Step [340/469], Loss: 0.4043, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [27/50], Step [341/469], Loss: 0.4766, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [342/469], Loss: 0.3473, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [27/50], Step [343/469], Loss: 0.6019, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [344/469], Loss: 0.5396, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [27/50], Step [345/469], Loss: 0.4785, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [346/469], Loss: 0.3591, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [27/50], Step [347/469], Loss: 0.4480, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [348/469], Loss: 0.4518, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [349/469], Loss: 0.2077, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [27/50], Step [350/469], Loss: 0.5591, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [27/50], Step [351/469], Loss: 0.4516, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [27/50], Step [352/469], Loss: 0.3107, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [27/50], Step [353/469], Loss: 0.3969, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [27/50], Step [354/469], Loss: 0.4361, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [27/50], Step [355/469], Loss: 0.3813, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [27/50], Step [356/469], Loss: 0.4544, batch time: 0.67, accuracy:  87.50%\n",
      "Epoch [27/50], Step [357/469], Loss: 0.3692, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [27/50], Step [358/469], Loss: 0.5176, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [27/50], Step [359/469], Loss: 0.4386, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [27/50], Step [360/469], Loss: 0.4581, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [27/50], Step [361/469], Loss: 0.3103, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [27/50], Step [362/469], Loss: 0.4006, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [27/50], Step [363/469], Loss: 0.5794, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [27/50], Step [364/469], Loss: 0.4744, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [27/50], Step [365/469], Loss: 0.4627, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [27/50], Step [366/469], Loss: 0.4628, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [27/50], Step [367/469], Loss: 0.3114, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [27/50], Step [368/469], Loss: 0.3698, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [27/50], Step [369/469], Loss: 0.4104, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [27/50], Step [370/469], Loss: 0.4828, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [27/50], Step [371/469], Loss: 0.5913, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [27/50], Step [372/469], Loss: 0.7233, batch time: 0.51, accuracy:  79.69%\n",
      "Epoch [27/50], Step [373/469], Loss: 0.5536, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [27/50], Step [374/469], Loss: 0.3820, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [27/50], Step [375/469], Loss: 0.5794, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [27/50], Step [376/469], Loss: 0.4074, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [377/469], Loss: 0.3870, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [27/50], Step [378/469], Loss: 0.4905, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [27/50], Step [379/469], Loss: 0.3386, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [27/50], Step [380/469], Loss: 0.3741, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [27/50], Step [381/469], Loss: 0.3660, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [27/50], Step [382/469], Loss: 0.3483, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [27/50], Step [383/469], Loss: 0.3089, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [27/50], Step [384/469], Loss: 0.3808, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [27/50], Step [385/469], Loss: 0.4628, batch time: 0.77, accuracy:  88.28%\n",
      "Epoch [27/50], Step [386/469], Loss: 0.5829, batch time: 0.57, accuracy:  83.59%\n",
      "Epoch [27/50], Step [387/469], Loss: 0.5245, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [27/50], Step [388/469], Loss: 0.3997, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [27/50], Step [389/469], Loss: 0.4425, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [27/50], Step [390/469], Loss: 0.3919, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [27/50], Step [391/469], Loss: 0.4424, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [27/50], Step [392/469], Loss: 0.2964, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [27/50], Step [393/469], Loss: 0.3997, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [27/50], Step [394/469], Loss: 0.3369, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [27/50], Step [395/469], Loss: 0.7142, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [27/50], Step [396/469], Loss: 0.3541, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [27/50], Step [397/469], Loss: 0.3715, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [27/50], Step [398/469], Loss: 0.3916, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [27/50], Step [399/469], Loss: 0.4855, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [27/50], Step [400/469], Loss: 0.3309, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [27/50], Step [401/469], Loss: 0.5010, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [27/50], Step [402/469], Loss: 0.2664, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [27/50], Step [403/469], Loss: 0.5828, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [27/50], Step [404/469], Loss: 0.4241, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [405/469], Loss: 0.3818, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [27/50], Step [406/469], Loss: 0.4909, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [407/469], Loss: 0.4944, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [27/50], Step [408/469], Loss: 0.2419, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [27/50], Step [409/469], Loss: 0.5146, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [27/50], Step [410/469], Loss: 0.3413, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [27/50], Step [411/469], Loss: 0.4214, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [27/50], Step [412/469], Loss: 0.5360, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [27/50], Step [413/469], Loss: 0.4779, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [27/50], Step [414/469], Loss: 0.3405, batch time: 0.86, accuracy:  87.50%\n",
      "Epoch [27/50], Step [415/469], Loss: 0.4658, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [27/50], Step [416/469], Loss: 0.4218, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [27/50], Step [417/469], Loss: 0.3444, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [27/50], Step [418/469], Loss: 0.3955, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [27/50], Step [419/469], Loss: 0.5650, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [27/50], Step [420/469], Loss: 0.3813, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [27/50], Step [421/469], Loss: 0.4991, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [27/50], Step [422/469], Loss: 0.3515, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [27/50], Step [423/469], Loss: 0.5263, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [27/50], Step [424/469], Loss: 0.3306, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [27/50], Step [425/469], Loss: 0.6011, batch time: 0.51, accuracy:  80.47%\n",
      "Epoch [27/50], Step [426/469], Loss: 0.5163, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [27/50], Step [427/469], Loss: 0.5335, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [27/50], Step [428/469], Loss: 0.4821, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [27/50], Step [429/469], Loss: 0.5713, batch time: 0.50, accuracy:  79.69%\n",
      "Epoch [27/50], Step [430/469], Loss: 0.4417, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [27/50], Step [431/469], Loss: 0.4609, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [27/50], Step [432/469], Loss: 0.4471, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [27/50], Step [433/469], Loss: 0.5659, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [27/50], Step [434/469], Loss: 0.3777, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [27/50], Step [435/469], Loss: 0.3147, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [27/50], Step [436/469], Loss: 0.3450, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [27/50], Step [437/469], Loss: 0.4570, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [438/469], Loss: 0.4683, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [27/50], Step [439/469], Loss: 0.3407, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [27/50], Step [440/469], Loss: 0.3962, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [27/50], Step [441/469], Loss: 0.4140, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [27/50], Step [442/469], Loss: 0.4587, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [27/50], Step [443/469], Loss: 0.3474, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [27/50], Step [444/469], Loss: 0.4497, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [27/50], Step [445/469], Loss: 0.3354, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [27/50], Step [446/469], Loss: 0.3963, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [27/50], Step [447/469], Loss: 0.4977, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [27/50], Step [448/469], Loss: 0.4290, batch time: 0.58, accuracy:  82.81%\n",
      "Epoch [27/50], Step [449/469], Loss: 0.3104, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [27/50], Step [450/469], Loss: 0.5573, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [27/50], Step [451/469], Loss: 0.4245, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [27/50], Step [452/469], Loss: 0.4143, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [27/50], Step [453/469], Loss: 0.4159, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [454/469], Loss: 0.3617, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [27/50], Step [455/469], Loss: 0.4941, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [456/469], Loss: 0.5438, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [457/469], Loss: 0.3467, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [27/50], Step [458/469], Loss: 0.3523, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [27/50], Step [459/469], Loss: 0.5125, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [27/50], Step [460/469], Loss: 0.4653, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [27/50], Step [461/469], Loss: 0.3929, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [27/50], Step [462/469], Loss: 0.4481, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [27/50], Step [463/469], Loss: 0.5388, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [27/50], Step [464/469], Loss: 0.4579, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [27/50], Step [465/469], Loss: 0.3172, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [27/50], Step [466/469], Loss: 0.4556, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [27/50], Step [467/469], Loss: 0.4544, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [27/50], Step [468/469], Loss: 0.2978, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [27/50], Step [469/469], Loss: 0.7591, batch time: 0.44, accuracy:  85.42%\n",
      "Epoch [28/50], Step [1/469], Loss: 0.4160, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [2/469], Loss: 0.4210, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [3/469], Loss: 0.4467, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [28/50], Step [4/469], Loss: 0.4956, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [5/469], Loss: 0.3725, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [28/50], Step [6/469], Loss: 0.2936, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [28/50], Step [7/469], Loss: 0.5694, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [28/50], Step [8/469], Loss: 0.4420, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [28/50], Step [9/469], Loss: 0.6233, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [28/50], Step [10/469], Loss: 0.3654, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [28/50], Step [11/469], Loss: 0.3337, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [28/50], Step [12/469], Loss: 0.3899, batch time: 0.67, accuracy:  85.94%\n",
      "Epoch [28/50], Step [13/469], Loss: 0.5404, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [28/50], Step [14/469], Loss: 0.4327, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [28/50], Step [15/469], Loss: 0.3235, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [28/50], Step [16/469], Loss: 0.5258, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [28/50], Step [17/469], Loss: 0.4647, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [18/469], Loss: 0.4244, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [28/50], Step [19/469], Loss: 0.5024, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [28/50], Step [20/469], Loss: 0.5421, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [28/50], Step [21/469], Loss: 0.4515, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [22/469], Loss: 0.2538, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [28/50], Step [23/469], Loss: 0.4335, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [28/50], Step [24/469], Loss: 0.4594, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [28/50], Step [25/469], Loss: 0.3566, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [28/50], Step [26/469], Loss: 0.5698, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [28/50], Step [27/469], Loss: 0.5147, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [28/50], Step [28/469], Loss: 0.4657, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [29/469], Loss: 0.3656, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [28/50], Step [30/469], Loss: 0.5451, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [28/50], Step [31/469], Loss: 0.6701, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [28/50], Step [32/469], Loss: 0.4745, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [28/50], Step [33/469], Loss: 0.5047, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [28/50], Step [34/469], Loss: 0.4237, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [28/50], Step [35/469], Loss: 0.3785, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [28/50], Step [36/469], Loss: 0.5273, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [28/50], Step [37/469], Loss: 0.6187, batch time: 0.49, accuracy:  80.47%\n",
      "Epoch [28/50], Step [38/469], Loss: 0.4542, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [28/50], Step [39/469], Loss: 0.4134, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [40/469], Loss: 0.5300, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [41/469], Loss: 0.4518, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [28/50], Step [42/469], Loss: 0.5294, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [28/50], Step [43/469], Loss: 0.4472, batch time: 0.93, accuracy:  87.50%\n",
      "Epoch [28/50], Step [44/469], Loss: 0.3598, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [28/50], Step [45/469], Loss: 0.5038, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [46/469], Loss: 0.5058, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [28/50], Step [47/469], Loss: 0.3109, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [28/50], Step [48/469], Loss: 0.4109, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [28/50], Step [49/469], Loss: 0.3619, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [28/50], Step [50/469], Loss: 0.4007, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [28/50], Step [51/469], Loss: 0.4492, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [28/50], Step [52/469], Loss: 0.5203, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [28/50], Step [53/469], Loss: 0.4382, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [28/50], Step [54/469], Loss: 0.5945, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [28/50], Step [55/469], Loss: 0.4568, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [28/50], Step [56/469], Loss: 0.3072, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [28/50], Step [57/469], Loss: 0.4679, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [28/50], Step [58/469], Loss: 0.3896, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [28/50], Step [59/469], Loss: 0.5902, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [28/50], Step [60/469], Loss: 0.4272, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [28/50], Step [61/469], Loss: 0.3995, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [62/469], Loss: 0.4921, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [28/50], Step [63/469], Loss: 0.3139, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [28/50], Step [64/469], Loss: 0.3899, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [65/469], Loss: 0.3580, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [28/50], Step [66/469], Loss: 0.4364, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [28/50], Step [67/469], Loss: 0.4776, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [28/50], Step [68/469], Loss: 0.4903, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [28/50], Step [69/469], Loss: 0.4158, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [70/469], Loss: 0.3942, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [28/50], Step [71/469], Loss: 0.4156, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [28/50], Step [72/469], Loss: 0.6213, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [28/50], Step [73/469], Loss: 0.2988, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [28/50], Step [74/469], Loss: 0.2857, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [28/50], Step [75/469], Loss: 0.3915, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [28/50], Step [76/469], Loss: 0.3203, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [28/50], Step [77/469], Loss: 0.5253, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [28/50], Step [78/469], Loss: 0.3754, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [28/50], Step [79/469], Loss: 0.7393, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [28/50], Step [80/469], Loss: 0.3522, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [81/469], Loss: 0.3515, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [82/469], Loss: 0.3729, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [83/469], Loss: 0.4408, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [28/50], Step [84/469], Loss: 0.4488, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [28/50], Step [85/469], Loss: 0.5680, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [86/469], Loss: 0.3642, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [87/469], Loss: 0.5946, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [88/469], Loss: 0.3960, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [89/469], Loss: 0.4616, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [90/469], Loss: 0.3637, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [28/50], Step [91/469], Loss: 0.3595, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [92/469], Loss: 0.4832, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [28/50], Step [93/469], Loss: 0.5012, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [94/469], Loss: 0.3485, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [28/50], Step [95/469], Loss: 0.4178, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [28/50], Step [96/469], Loss: 0.4252, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [28/50], Step [97/469], Loss: 0.4564, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [28/50], Step [98/469], Loss: 0.6118, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [28/50], Step [99/469], Loss: 0.3828, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [28/50], Step [100/469], Loss: 0.4307, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [101/469], Loss: 0.3786, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [28/50], Step [102/469], Loss: 0.3823, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [28/50], Step [103/469], Loss: 0.4962, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [28/50], Step [104/469], Loss: 0.3834, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [28/50], Step [105/469], Loss: 0.4632, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [28/50], Step [106/469], Loss: 0.4018, batch time: 0.70, accuracy:  89.84%\n",
      "Epoch [28/50], Step [107/469], Loss: 0.2951, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [28/50], Step [108/469], Loss: 0.4008, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [109/469], Loss: 0.3109, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [28/50], Step [110/469], Loss: 0.3810, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [28/50], Step [111/469], Loss: 0.4061, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [28/50], Step [112/469], Loss: 0.4577, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [28/50], Step [113/469], Loss: 0.3121, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [28/50], Step [114/469], Loss: 0.2544, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [28/50], Step [115/469], Loss: 0.6497, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [28/50], Step [116/469], Loss: 0.4171, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [117/469], Loss: 0.4721, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [28/50], Step [118/469], Loss: 0.4149, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [28/50], Step [119/469], Loss: 0.4995, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [120/469], Loss: 0.4870, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [121/469], Loss: 0.3728, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [122/469], Loss: 0.4297, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [28/50], Step [123/469], Loss: 0.3917, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [124/469], Loss: 0.3815, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [125/469], Loss: 0.4171, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [28/50], Step [126/469], Loss: 0.3658, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [127/469], Loss: 0.4341, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [128/469], Loss: 0.3683, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [129/469], Loss: 0.3423, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [28/50], Step [130/469], Loss: 0.3545, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [131/469], Loss: 0.4248, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [132/469], Loss: 0.4033, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [28/50], Step [133/469], Loss: 0.3816, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [28/50], Step [134/469], Loss: 0.3033, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [28/50], Step [135/469], Loss: 0.3214, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [28/50], Step [136/469], Loss: 0.3084, batch time: 0.75, accuracy:  92.97%\n",
      "Epoch [28/50], Step [137/469], Loss: 0.4517, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [28/50], Step [138/469], Loss: 0.3840, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [28/50], Step [139/469], Loss: 0.3560, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [140/469], Loss: 0.3662, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [28/50], Step [141/469], Loss: 0.3261, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [28/50], Step [142/469], Loss: 0.6145, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [143/469], Loss: 0.4330, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [28/50], Step [144/469], Loss: 0.5374, batch time: 0.48, accuracy:  80.47%\n",
      "Epoch [28/50], Step [145/469], Loss: 0.4087, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [28/50], Step [146/469], Loss: 0.5710, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [28/50], Step [147/469], Loss: 0.3942, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [28/50], Step [148/469], Loss: 0.5160, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [28/50], Step [149/469], Loss: 0.2750, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [28/50], Step [150/469], Loss: 0.3792, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [28/50], Step [151/469], Loss: 0.4808, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [28/50], Step [152/469], Loss: 0.4593, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [28/50], Step [153/469], Loss: 0.3412, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [28/50], Step [154/469], Loss: 0.3905, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [28/50], Step [155/469], Loss: 0.4328, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [28/50], Step [156/469], Loss: 0.4929, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [28/50], Step [157/469], Loss: 0.3969, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [28/50], Step [158/469], Loss: 0.3812, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [28/50], Step [159/469], Loss: 0.5497, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [28/50], Step [160/469], Loss: 0.6119, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [28/50], Step [161/469], Loss: 0.5668, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [28/50], Step [162/469], Loss: 0.3398, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [28/50], Step [163/469], Loss: 0.4911, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [28/50], Step [164/469], Loss: 0.2877, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [28/50], Step [165/469], Loss: 0.4246, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [166/469], Loss: 0.5841, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [28/50], Step [167/469], Loss: 0.2774, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [28/50], Step [168/469], Loss: 0.2700, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [28/50], Step [169/469], Loss: 0.4816, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [28/50], Step [170/469], Loss: 0.4944, batch time: 0.83, accuracy:  83.59%\n",
      "Epoch [28/50], Step [171/469], Loss: 0.3835, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [28/50], Step [172/469], Loss: 0.3829, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [173/469], Loss: 0.5092, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [28/50], Step [174/469], Loss: 0.3955, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [175/469], Loss: 0.2936, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [28/50], Step [176/469], Loss: 0.3420, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [177/469], Loss: 0.4300, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [28/50], Step [178/469], Loss: 0.4838, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [28/50], Step [179/469], Loss: 0.5111, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [28/50], Step [180/469], Loss: 0.3676, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [181/469], Loss: 0.6276, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [28/50], Step [182/469], Loss: 0.4104, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [28/50], Step [183/469], Loss: 0.3371, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [28/50], Step [184/469], Loss: 0.4856, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [28/50], Step [185/469], Loss: 0.3916, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [186/469], Loss: 0.3354, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [28/50], Step [187/469], Loss: 0.2712, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [28/50], Step [188/469], Loss: 0.4036, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [28/50], Step [189/469], Loss: 0.2989, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [190/469], Loss: 0.3230, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [191/469], Loss: 0.4350, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [192/469], Loss: 0.4508, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [193/469], Loss: 0.5301, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [28/50], Step [194/469], Loss: 0.4529, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [195/469], Loss: 0.3264, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [28/50], Step [196/469], Loss: 0.3238, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [28/50], Step [197/469], Loss: 0.3229, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [28/50], Step [198/469], Loss: 0.4565, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [28/50], Step [199/469], Loss: 0.3575, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [28/50], Step [200/469], Loss: 0.3846, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [28/50], Step [201/469], Loss: 0.3852, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [28/50], Step [202/469], Loss: 0.5364, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [203/469], Loss: 0.3726, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [28/50], Step [204/469], Loss: 0.3568, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [28/50], Step [205/469], Loss: 0.3496, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [28/50], Step [206/469], Loss: 0.3331, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [28/50], Step [207/469], Loss: 0.2490, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [28/50], Step [208/469], Loss: 0.4626, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [28/50], Step [209/469], Loss: 0.3190, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [28/50], Step [210/469], Loss: 0.3617, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [28/50], Step [211/469], Loss: 0.5055, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [28/50], Step [212/469], Loss: 0.6382, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [28/50], Step [213/469], Loss: 0.4897, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [28/50], Step [214/469], Loss: 0.4186, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [28/50], Step [215/469], Loss: 0.3910, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [216/469], Loss: 0.4722, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [28/50], Step [217/469], Loss: 0.3333, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [218/469], Loss: 0.3997, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [219/469], Loss: 0.4730, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [220/469], Loss: 0.3171, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [221/469], Loss: 0.3854, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [28/50], Step [222/469], Loss: 0.4562, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [223/469], Loss: 0.4568, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [28/50], Step [224/469], Loss: 0.4909, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [28/50], Step [225/469], Loss: 0.5465, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [28/50], Step [226/469], Loss: 0.5668, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [227/469], Loss: 0.2685, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [228/469], Loss: 0.3688, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [28/50], Step [229/469], Loss: 0.2849, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [28/50], Step [230/469], Loss: 0.4703, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [231/469], Loss: 0.3003, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [232/469], Loss: 0.4634, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [28/50], Step [233/469], Loss: 0.4187, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [28/50], Step [234/469], Loss: 0.5187, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [28/50], Step [235/469], Loss: 0.9054, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [28/50], Step [236/469], Loss: 0.3387, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [28/50], Step [237/469], Loss: 0.4101, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [28/50], Step [238/469], Loss: 0.3718, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [28/50], Step [239/469], Loss: 0.3168, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [28/50], Step [240/469], Loss: 0.5058, batch time: 0.64, accuracy:  89.84%\n",
      "Epoch [28/50], Step [241/469], Loss: 0.5682, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [28/50], Step [242/469], Loss: 0.4800, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [28/50], Step [243/469], Loss: 0.3838, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [244/469], Loss: 0.4559, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [28/50], Step [245/469], Loss: 0.4304, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [28/50], Step [246/469], Loss: 0.4708, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [28/50], Step [247/469], Loss: 0.4827, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [248/469], Loss: 0.3120, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [28/50], Step [249/469], Loss: 0.4887, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [28/50], Step [250/469], Loss: 0.5390, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [251/469], Loss: 0.3142, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [28/50], Step [252/469], Loss: 0.4216, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [28/50], Step [253/469], Loss: 0.6948, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [28/50], Step [254/469], Loss: 0.3001, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [28/50], Step [255/469], Loss: 0.5589, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [256/469], Loss: 0.4045, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [257/469], Loss: 0.3479, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [258/469], Loss: 0.3553, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [28/50], Step [259/469], Loss: 0.5630, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [28/50], Step [260/469], Loss: 0.3622, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [28/50], Step [261/469], Loss: 0.5442, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [28/50], Step [262/469], Loss: 0.3582, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [28/50], Step [263/469], Loss: 0.2806, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [28/50], Step [264/469], Loss: 0.4422, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [28/50], Step [265/469], Loss: 0.4684, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [266/469], Loss: 0.4182, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [267/469], Loss: 0.5269, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [28/50], Step [268/469], Loss: 0.3691, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [28/50], Step [269/469], Loss: 0.3819, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [28/50], Step [270/469], Loss: 0.5611, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [28/50], Step [271/469], Loss: 0.2556, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [28/50], Step [272/469], Loss: 0.6243, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [28/50], Step [273/469], Loss: 0.3161, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [28/50], Step [274/469], Loss: 0.2001, batch time: 0.60, accuracy:  95.31%\n",
      "Epoch [28/50], Step [275/469], Loss: 0.3692, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [28/50], Step [276/469], Loss: 0.3933, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [28/50], Step [277/469], Loss: 0.4903, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [28/50], Step [278/469], Loss: 0.3177, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [28/50], Step [279/469], Loss: 0.2936, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [28/50], Step [280/469], Loss: 0.5637, batch time: 0.45, accuracy:  80.47%\n",
      "Epoch [28/50], Step [281/469], Loss: 0.5426, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [28/50], Step [282/469], Loss: 0.3177, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [28/50], Step [283/469], Loss: 0.3530, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [284/469], Loss: 0.6576, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [285/469], Loss: 0.3209, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [286/469], Loss: 0.3952, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [28/50], Step [287/469], Loss: 0.4486, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [288/469], Loss: 0.4794, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [289/469], Loss: 0.3383, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [28/50], Step [290/469], Loss: 0.3608, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [28/50], Step [291/469], Loss: 0.3545, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [28/50], Step [292/469], Loss: 0.5266, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [28/50], Step [293/469], Loss: 0.5006, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [28/50], Step [294/469], Loss: 0.3356, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [28/50], Step [295/469], Loss: 0.2690, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [28/50], Step [296/469], Loss: 0.3816, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [297/469], Loss: 0.3107, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [28/50], Step [298/469], Loss: 0.3809, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [299/469], Loss: 0.4505, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [300/469], Loss: 0.5002, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [301/469], Loss: 0.4419, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [28/50], Step [302/469], Loss: 0.4189, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [28/50], Step [303/469], Loss: 0.7518, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [28/50], Step [304/469], Loss: 0.3867, batch time: 0.85, accuracy:  88.28%\n",
      "Epoch [28/50], Step [305/469], Loss: 0.4062, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [28/50], Step [306/469], Loss: 0.3470, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [28/50], Step [307/469], Loss: 0.3256, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [28/50], Step [308/469], Loss: 0.2909, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [309/469], Loss: 0.4217, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [310/469], Loss: 0.3109, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [311/469], Loss: 0.4600, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [312/469], Loss: 0.4466, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [313/469], Loss: 0.7031, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [28/50], Step [314/469], Loss: 0.3990, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [315/469], Loss: 0.5926, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [28/50], Step [316/469], Loss: 0.4076, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [317/469], Loss: 0.5020, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [318/469], Loss: 0.5508, batch time: 0.43, accuracy:  79.69%\n",
      "Epoch [28/50], Step [319/469], Loss: 0.3594, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [28/50], Step [320/469], Loss: 0.4538, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [321/469], Loss: 0.3658, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [28/50], Step [322/469], Loss: 0.2838, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [28/50], Step [323/469], Loss: 0.3812, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [28/50], Step [324/469], Loss: 0.5707, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [28/50], Step [325/469], Loss: 0.4385, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [28/50], Step [326/469], Loss: 0.3353, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [28/50], Step [327/469], Loss: 0.4658, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [28/50], Step [328/469], Loss: 0.3595, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [28/50], Step [329/469], Loss: 0.4640, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [28/50], Step [330/469], Loss: 0.4467, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [28/50], Step [331/469], Loss: 0.5880, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [28/50], Step [332/469], Loss: 0.3658, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [28/50], Step [333/469], Loss: 0.5290, batch time: 0.62, accuracy:  79.69%\n",
      "Epoch [28/50], Step [334/469], Loss: 0.3310, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [28/50], Step [335/469], Loss: 0.3751, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [28/50], Step [336/469], Loss: 0.2914, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [28/50], Step [337/469], Loss: 0.4598, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [28/50], Step [338/469], Loss: 0.3457, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [28/50], Step [339/469], Loss: 0.4752, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [28/50], Step [340/469], Loss: 0.4428, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [28/50], Step [341/469], Loss: 0.4734, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [28/50], Step [342/469], Loss: 0.5225, batch time: 0.56, accuracy:  79.69%\n",
      "Epoch [28/50], Step [343/469], Loss: 0.4994, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [28/50], Step [344/469], Loss: 0.4300, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [28/50], Step [345/469], Loss: 0.2627, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [28/50], Step [346/469], Loss: 0.3436, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [347/469], Loss: 0.4558, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [348/469], Loss: 0.5609, batch time: 0.43, accuracy:  80.47%\n",
      "Epoch [28/50], Step [349/469], Loss: 0.4729, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [350/469], Loss: 0.3704, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [28/50], Step [351/469], Loss: 0.4069, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [352/469], Loss: 0.3850, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [28/50], Step [353/469], Loss: 0.3459, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [354/469], Loss: 0.3158, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [28/50], Step [355/469], Loss: 0.2571, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [28/50], Step [356/469], Loss: 0.4431, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [28/50], Step [357/469], Loss: 0.6622, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [28/50], Step [358/469], Loss: 0.4756, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [28/50], Step [359/469], Loss: 0.2808, batch time: 0.63, accuracy:  92.19%\n",
      "Epoch [28/50], Step [360/469], Loss: 0.6486, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [28/50], Step [361/469], Loss: 0.2457, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [28/50], Step [362/469], Loss: 0.3141, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [28/50], Step [363/469], Loss: 0.5980, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [28/50], Step [364/469], Loss: 0.3517, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [28/50], Step [365/469], Loss: 0.6452, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [366/469], Loss: 0.4035, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [28/50], Step [367/469], Loss: 0.5256, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [28/50], Step [368/469], Loss: 0.4159, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [28/50], Step [369/469], Loss: 0.4021, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [28/50], Step [370/469], Loss: 0.4877, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [28/50], Step [371/469], Loss: 0.4045, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [28/50], Step [372/469], Loss: 0.4144, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [28/50], Step [373/469], Loss: 0.4616, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [28/50], Step [374/469], Loss: 0.3709, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [28/50], Step [375/469], Loss: 0.5329, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [28/50], Step [376/469], Loss: 0.4216, batch time: 0.68, accuracy:  86.72%\n",
      "Epoch [28/50], Step [377/469], Loss: 0.4428, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [28/50], Step [378/469], Loss: 0.6712, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [379/469], Loss: 0.3649, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [28/50], Step [380/469], Loss: 0.4595, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [381/469], Loss: 0.3312, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [28/50], Step [382/469], Loss: 0.5422, batch time: 0.44, accuracy:  80.47%\n",
      "Epoch [28/50], Step [383/469], Loss: 0.3987, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [384/469], Loss: 0.5055, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [385/469], Loss: 0.4444, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [386/469], Loss: 0.2781, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [28/50], Step [387/469], Loss: 0.3755, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [28/50], Step [388/469], Loss: 0.3041, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [389/469], Loss: 0.5141, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [390/469], Loss: 0.2951, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [391/469], Loss: 0.3821, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [28/50], Step [392/469], Loss: 0.6018, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [28/50], Step [393/469], Loss: 0.4305, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [394/469], Loss: 0.3917, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [395/469], Loss: 0.4432, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [28/50], Step [396/469], Loss: 0.5074, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [28/50], Step [397/469], Loss: 0.4846, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [28/50], Step [398/469], Loss: 0.5807, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [28/50], Step [399/469], Loss: 0.4620, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [28/50], Step [400/469], Loss: 0.3410, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [28/50], Step [401/469], Loss: 0.4664, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [28/50], Step [402/469], Loss: 0.4713, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [28/50], Step [403/469], Loss: 0.5755, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [28/50], Step [404/469], Loss: 0.3482, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [405/469], Loss: 0.2893, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [28/50], Step [406/469], Loss: 0.5755, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [28/50], Step [407/469], Loss: 0.4230, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [28/50], Step [408/469], Loss: 0.4864, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [28/50], Step [409/469], Loss: 0.5973, batch time: 0.74, accuracy:  83.59%\n",
      "Epoch [28/50], Step [410/469], Loss: 0.4828, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [28/50], Step [411/469], Loss: 0.4268, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [28/50], Step [412/469], Loss: 0.6423, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [28/50], Step [413/469], Loss: 0.3660, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [28/50], Step [414/469], Loss: 0.4094, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [28/50], Step [415/469], Loss: 0.4985, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [28/50], Step [416/469], Loss: 0.2893, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [28/50], Step [417/469], Loss: 0.5161, batch time: 0.52, accuracy:  78.91%\n",
      "Epoch [28/50], Step [418/469], Loss: 0.3187, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [28/50], Step [419/469], Loss: 0.4004, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [28/50], Step [420/469], Loss: 0.4598, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [28/50], Step [421/469], Loss: 0.4822, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [28/50], Step [422/469], Loss: 0.3011, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [28/50], Step [423/469], Loss: 0.4843, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [28/50], Step [424/469], Loss: 0.4374, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [28/50], Step [425/469], Loss: 0.4400, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [28/50], Step [426/469], Loss: 0.4931, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [28/50], Step [427/469], Loss: 0.3826, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [28/50], Step [428/469], Loss: 0.3717, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [429/469], Loss: 0.4657, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [430/469], Loss: 0.4326, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [28/50], Step [431/469], Loss: 0.3525, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [28/50], Step [432/469], Loss: 0.3969, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [28/50], Step [433/469], Loss: 0.4109, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [28/50], Step [434/469], Loss: 0.6533, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [28/50], Step [435/469], Loss: 0.4353, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [28/50], Step [436/469], Loss: 0.5437, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [28/50], Step [437/469], Loss: 0.2965, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [28/50], Step [438/469], Loss: 0.3628, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [28/50], Step [439/469], Loss: 0.5742, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [28/50], Step [440/469], Loss: 0.3897, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [441/469], Loss: 0.4010, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [28/50], Step [442/469], Loss: 0.2824, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [28/50], Step [443/469], Loss: 0.3356, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [28/50], Step [444/469], Loss: 0.3799, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [28/50], Step [445/469], Loss: 0.4978, batch time: 0.77, accuracy:  87.50%\n",
      "Epoch [28/50], Step [446/469], Loss: 0.2789, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [28/50], Step [447/469], Loss: 0.4168, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [28/50], Step [448/469], Loss: 0.3620, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [28/50], Step [449/469], Loss: 0.3926, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [28/50], Step [450/469], Loss: 0.3483, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [28/50], Step [451/469], Loss: 0.5282, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [28/50], Step [452/469], Loss: 0.6219, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [28/50], Step [453/469], Loss: 0.3561, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [28/50], Step [454/469], Loss: 0.2200, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [28/50], Step [455/469], Loss: 0.3695, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [456/469], Loss: 0.3655, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [457/469], Loss: 0.4570, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [28/50], Step [458/469], Loss: 0.4083, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [28/50], Step [459/469], Loss: 0.8078, batch time: 0.48, accuracy:  78.91%\n",
      "Epoch [28/50], Step [460/469], Loss: 0.3583, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [28/50], Step [461/469], Loss: 0.3968, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [28/50], Step [462/469], Loss: 0.4940, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [28/50], Step [463/469], Loss: 0.4374, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [28/50], Step [464/469], Loss: 0.4082, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [28/50], Step [465/469], Loss: 0.4014, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [28/50], Step [466/469], Loss: 0.3677, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [467/469], Loss: 0.2938, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [28/50], Step [468/469], Loss: 0.4431, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [28/50], Step [469/469], Loss: 0.4246, batch time: 0.43, accuracy:  88.54%\n",
      "Epoch [29/50], Step [1/469], Loss: 0.3963, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [29/50], Step [2/469], Loss: 0.4010, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [29/50], Step [3/469], Loss: 0.3985, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [29/50], Step [4/469], Loss: 0.2331, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [29/50], Step [5/469], Loss: 0.2405, batch time: 0.84, accuracy:  92.19%\n",
      "Epoch [29/50], Step [6/469], Loss: 0.2744, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [29/50], Step [7/469], Loss: 0.2731, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [29/50], Step [8/469], Loss: 0.5183, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [29/50], Step [9/469], Loss: 0.4184, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [29/50], Step [10/469], Loss: 0.2974, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [29/50], Step [11/469], Loss: 0.3403, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [29/50], Step [12/469], Loss: 0.3504, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [29/50], Step [13/469], Loss: 0.5348, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [29/50], Step [14/469], Loss: 0.5494, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [29/50], Step [15/469], Loss: 0.2813, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [29/50], Step [16/469], Loss: 0.3826, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [29/50], Step [17/469], Loss: 0.4255, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [29/50], Step [18/469], Loss: 0.4901, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [29/50], Step [19/469], Loss: 0.3301, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [29/50], Step [20/469], Loss: 0.3191, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [29/50], Step [21/469], Loss: 0.3623, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [29/50], Step [22/469], Loss: 0.4629, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [29/50], Step [23/469], Loss: 0.4418, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [29/50], Step [24/469], Loss: 0.4154, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [29/50], Step [25/469], Loss: 0.2844, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [29/50], Step [26/469], Loss: 0.4322, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [29/50], Step [27/469], Loss: 0.4506, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [29/50], Step [28/469], Loss: 0.3895, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [29/50], Step [29/469], Loss: 0.2503, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [29/50], Step [30/469], Loss: 0.4602, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [29/50], Step [31/469], Loss: 0.3901, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [29/50], Step [32/469], Loss: 0.4454, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [29/50], Step [33/469], Loss: 0.3853, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [29/50], Step [34/469], Loss: 0.4314, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [29/50], Step [35/469], Loss: 0.3834, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [29/50], Step [36/469], Loss: 0.3686, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [29/50], Step [37/469], Loss: 0.4045, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [29/50], Step [38/469], Loss: 0.3264, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [29/50], Step [39/469], Loss: 0.4142, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [29/50], Step [40/469], Loss: 0.3632, batch time: 0.70, accuracy:  86.72%\n",
      "Epoch [29/50], Step [41/469], Loss: 0.3281, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [29/50], Step [42/469], Loss: 0.5724, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [29/50], Step [43/469], Loss: 0.3839, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [29/50], Step [44/469], Loss: 0.4181, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [29/50], Step [45/469], Loss: 0.3650, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [29/50], Step [46/469], Loss: 0.4371, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [29/50], Step [47/469], Loss: 0.4883, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [29/50], Step [48/469], Loss: 0.3497, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [29/50], Step [49/469], Loss: 0.3767, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [29/50], Step [50/469], Loss: 0.3440, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [29/50], Step [51/469], Loss: 0.4405, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [29/50], Step [52/469], Loss: 0.5094, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [29/50], Step [53/469], Loss: 0.4142, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [29/50], Step [54/469], Loss: 0.4142, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [29/50], Step [55/469], Loss: 0.4498, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [29/50], Step [56/469], Loss: 0.3036, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [29/50], Step [57/469], Loss: 0.3221, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [29/50], Step [58/469], Loss: 0.5764, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [29/50], Step [59/469], Loss: 0.4263, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [29/50], Step [60/469], Loss: 0.4041, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [29/50], Step [61/469], Loss: 0.4884, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [29/50], Step [62/469], Loss: 0.3777, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [29/50], Step [63/469], Loss: 0.3704, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [29/50], Step [64/469], Loss: 0.2906, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [29/50], Step [65/469], Loss: 0.3803, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [29/50], Step [66/469], Loss: 0.3326, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [29/50], Step [67/469], Loss: 0.5368, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [29/50], Step [68/469], Loss: 0.4741, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [29/50], Step [69/469], Loss: 0.4698, batch time: 1.03, accuracy:  86.72%\n",
      "Epoch [29/50], Step [70/469], Loss: 0.4952, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [29/50], Step [71/469], Loss: 0.3415, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [29/50], Step [72/469], Loss: 0.5102, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [29/50], Step [73/469], Loss: 0.3307, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [29/50], Step [74/469], Loss: 0.3876, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [29/50], Step [75/469], Loss: 0.3833, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [29/50], Step [76/469], Loss: 0.3988, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [29/50], Step [77/469], Loss: 0.5103, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [29/50], Step [78/469], Loss: 0.4824, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [29/50], Step [79/469], Loss: 0.5713, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [29/50], Step [80/469], Loss: 0.3893, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [29/50], Step [81/469], Loss: 0.3538, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [29/50], Step [82/469], Loss: 0.3620, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [29/50], Step [83/469], Loss: 0.4152, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [29/50], Step [84/469], Loss: 0.3738, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [29/50], Step [85/469], Loss: 0.4102, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [29/50], Step [86/469], Loss: 0.3882, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [29/50], Step [87/469], Loss: 0.2597, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [29/50], Step [88/469], Loss: 0.2824, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [29/50], Step [89/469], Loss: 0.3746, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [29/50], Step [90/469], Loss: 0.4690, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [29/50], Step [91/469], Loss: 0.5758, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [29/50], Step [92/469], Loss: 0.4125, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [29/50], Step [93/469], Loss: 0.4181, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [29/50], Step [94/469], Loss: 0.4953, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [29/50], Step [95/469], Loss: 0.2735, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [29/50], Step [96/469], Loss: 0.5545, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [29/50], Step [97/469], Loss: 0.2482, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [29/50], Step [98/469], Loss: 0.4048, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [29/50], Step [99/469], Loss: 0.5318, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [29/50], Step [100/469], Loss: 0.3340, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [29/50], Step [101/469], Loss: 0.3609, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [29/50], Step [102/469], Loss: 0.4001, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [29/50], Step [103/469], Loss: 0.4482, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [29/50], Step [104/469], Loss: 0.3532, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [29/50], Step [105/469], Loss: 0.4740, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [29/50], Step [106/469], Loss: 0.3656, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [29/50], Step [107/469], Loss: 0.3077, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [29/50], Step [108/469], Loss: 0.5118, batch time: 0.63, accuracy:  86.72%\n",
      "Epoch [29/50], Step [109/469], Loss: 0.3800, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [29/50], Step [110/469], Loss: 0.4707, batch time: 0.63, accuracy:  84.38%\n",
      "Epoch [29/50], Step [111/469], Loss: 0.4364, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [29/50], Step [112/469], Loss: 0.2805, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [29/50], Step [113/469], Loss: 0.3604, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [29/50], Step [114/469], Loss: 0.4374, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [29/50], Step [115/469], Loss: 0.2701, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [29/50], Step [116/469], Loss: 0.5892, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [29/50], Step [117/469], Loss: 0.3141, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [29/50], Step [118/469], Loss: 0.5801, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [29/50], Step [119/469], Loss: 0.3858, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [29/50], Step [120/469], Loss: 0.3967, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [29/50], Step [121/469], Loss: 0.5243, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [29/50], Step [122/469], Loss: 0.3846, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [29/50], Step [123/469], Loss: 0.4867, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [29/50], Step [124/469], Loss: 0.6676, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [29/50], Step [125/469], Loss: 0.4804, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [29/50], Step [126/469], Loss: 0.4301, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [29/50], Step [127/469], Loss: 0.4138, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [29/50], Step [128/469], Loss: 0.5064, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [29/50], Step [129/469], Loss: 0.3513, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [29/50], Step [130/469], Loss: 0.5192, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [29/50], Step [131/469], Loss: 0.2281, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [29/50], Step [132/469], Loss: 0.4012, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [29/50], Step [133/469], Loss: 0.2501, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [29/50], Step [134/469], Loss: 0.4060, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [29/50], Step [135/469], Loss: 0.5273, batch time: 0.47, accuracy:  81.25%\n",
      "Epoch [29/50], Step [136/469], Loss: 0.5353, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [29/50], Step [137/469], Loss: 0.4281, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [29/50], Step [138/469], Loss: 0.4361, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [29/50], Step [139/469], Loss: 0.4486, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [29/50], Step [140/469], Loss: 0.3530, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [29/50], Step [141/469], Loss: 0.3776, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [29/50], Step [142/469], Loss: 0.3541, batch time: 0.91, accuracy:  89.06%\n",
      "Epoch [29/50], Step [143/469], Loss: 0.2362, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [29/50], Step [144/469], Loss: 0.3766, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [29/50], Step [145/469], Loss: 0.4615, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [29/50], Step [146/469], Loss: 0.6532, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [29/50], Step [147/469], Loss: 0.3172, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [29/50], Step [148/469], Loss: 0.3513, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [29/50], Step [149/469], Loss: 0.3209, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [29/50], Step [150/469], Loss: 0.5596, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [29/50], Step [151/469], Loss: 0.5547, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [29/50], Step [152/469], Loss: 0.4127, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [29/50], Step [153/469], Loss: 0.3312, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [29/50], Step [154/469], Loss: 0.3631, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [29/50], Step [155/469], Loss: 0.3379, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [29/50], Step [156/469], Loss: 0.5844, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [29/50], Step [157/469], Loss: 0.4127, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [29/50], Step [158/469], Loss: 0.4379, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [29/50], Step [159/469], Loss: 0.3462, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [29/50], Step [160/469], Loss: 0.3612, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [29/50], Step [161/469], Loss: 0.4067, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [29/50], Step [162/469], Loss: 0.5011, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [29/50], Step [163/469], Loss: 0.4215, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [29/50], Step [164/469], Loss: 0.3431, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [29/50], Step [165/469], Loss: 0.3314, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [29/50], Step [166/469], Loss: 0.4201, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [29/50], Step [167/469], Loss: 0.2727, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [29/50], Step [168/469], Loss: 0.4208, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [29/50], Step [169/469], Loss: 0.3759, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [29/50], Step [170/469], Loss: 0.3593, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [29/50], Step [171/469], Loss: 0.3023, batch time: 0.79, accuracy:  89.84%\n",
      "Epoch [29/50], Step [172/469], Loss: 0.3402, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [29/50], Step [173/469], Loss: 0.4676, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [29/50], Step [174/469], Loss: 0.3355, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [29/50], Step [175/469], Loss: 0.6853, batch time: 0.46, accuracy:  80.47%\n",
      "Epoch [29/50], Step [176/469], Loss: 0.3635, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [29/50], Step [177/469], Loss: 0.3354, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [29/50], Step [178/469], Loss: 0.3461, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [29/50], Step [179/469], Loss: 0.4643, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [29/50], Step [180/469], Loss: 0.3925, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [29/50], Step [181/469], Loss: 0.3677, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [29/50], Step [182/469], Loss: 0.4611, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [29/50], Step [183/469], Loss: 0.4144, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [29/50], Step [184/469], Loss: 0.3138, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [29/50], Step [185/469], Loss: 0.4212, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [29/50], Step [186/469], Loss: 0.3485, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [29/50], Step [187/469], Loss: 0.4514, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [29/50], Step [188/469], Loss: 0.4304, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [29/50], Step [189/469], Loss: 0.4229, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [29/50], Step [190/469], Loss: 0.4096, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [29/50], Step [191/469], Loss: 0.5881, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [29/50], Step [192/469], Loss: 0.4454, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [29/50], Step [193/469], Loss: 0.4897, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [29/50], Step [194/469], Loss: 0.5895, batch time: 0.43, accuracy:  82.03%\n",
      "Epoch [29/50], Step [195/469], Loss: 0.4453, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [29/50], Step [196/469], Loss: 0.4890, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [29/50], Step [197/469], Loss: 0.2877, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [29/50], Step [198/469], Loss: 0.3864, batch time: 0.64, accuracy:  89.06%\n",
      "Epoch [29/50], Step [199/469], Loss: 0.2758, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [29/50], Step [200/469], Loss: 0.3840, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [29/50], Step [201/469], Loss: 0.3591, batch time: 0.80, accuracy:  89.06%\n",
      "Epoch [29/50], Step [202/469], Loss: 0.3177, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [29/50], Step [203/469], Loss: 0.4197, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [29/50], Step [204/469], Loss: 0.4578, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [29/50], Step [205/469], Loss: 0.2770, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [29/50], Step [206/469], Loss: 0.4054, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [29/50], Step [207/469], Loss: 0.3409, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [29/50], Step [208/469], Loss: 0.3644, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [29/50], Step [209/469], Loss: 0.4042, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [29/50], Step [210/469], Loss: 0.4187, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [29/50], Step [211/469], Loss: 0.4574, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [29/50], Step [212/469], Loss: 0.5226, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [29/50], Step [213/469], Loss: 0.3540, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [29/50], Step [214/469], Loss: 0.3587, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [29/50], Step [215/469], Loss: 0.4984, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [29/50], Step [216/469], Loss: 0.3201, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [29/50], Step [217/469], Loss: 0.5332, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [29/50], Step [218/469], Loss: 0.4690, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [29/50], Step [219/469], Loss: 0.3846, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [29/50], Step [220/469], Loss: 0.4799, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [29/50], Step [221/469], Loss: 0.4494, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [29/50], Step [222/469], Loss: 0.5873, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [29/50], Step [223/469], Loss: 0.5667, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [29/50], Step [224/469], Loss: 0.4215, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [29/50], Step [225/469], Loss: 0.3299, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [29/50], Step [226/469], Loss: 0.3556, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [29/50], Step [227/469], Loss: 0.3703, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [29/50], Step [228/469], Loss: 0.5965, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [29/50], Step [229/469], Loss: 0.5141, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [29/50], Step [230/469], Loss: 0.3862, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [29/50], Step [231/469], Loss: 0.5290, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [29/50], Step [232/469], Loss: 0.4135, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [29/50], Step [233/469], Loss: 0.7244, batch time: 0.92, accuracy:  85.16%\n",
      "Epoch [29/50], Step [234/469], Loss: 0.4531, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [29/50], Step [235/469], Loss: 0.4353, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [29/50], Step [236/469], Loss: 0.4381, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [29/50], Step [237/469], Loss: 0.4255, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [29/50], Step [238/469], Loss: 0.5925, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [29/50], Step [239/469], Loss: 0.4625, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [29/50], Step [240/469], Loss: 0.4032, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [29/50], Step [241/469], Loss: 0.3561, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [29/50], Step [242/469], Loss: 0.3828, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [29/50], Step [243/469], Loss: 0.5724, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [29/50], Step [244/469], Loss: 0.2245, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [29/50], Step [245/469], Loss: 0.4826, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [29/50], Step [246/469], Loss: 0.3398, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [29/50], Step [247/469], Loss: 0.3458, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [29/50], Step [248/469], Loss: 0.4143, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [29/50], Step [249/469], Loss: 0.3031, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [29/50], Step [250/469], Loss: 0.3593, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [29/50], Step [251/469], Loss: 0.4114, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [29/50], Step [252/469], Loss: 0.4594, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [29/50], Step [253/469], Loss: 0.4849, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [29/50], Step [254/469], Loss: 0.5637, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [29/50], Step [255/469], Loss: 0.3629, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [29/50], Step [256/469], Loss: 0.4938, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [29/50], Step [257/469], Loss: 0.4430, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [29/50], Step [258/469], Loss: 0.3439, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [29/50], Step [259/469], Loss: 0.2557, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [29/50], Step [260/469], Loss: 0.3829, batch time: 0.64, accuracy:  88.28%\n",
      "Epoch [29/50], Step [261/469], Loss: 0.4024, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [29/50], Step [262/469], Loss: 0.5298, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [29/50], Step [263/469], Loss: 0.3884, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [29/50], Step [264/469], Loss: 0.4322, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [29/50], Step [265/469], Loss: 0.4258, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [29/50], Step [266/469], Loss: 0.3563, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [29/50], Step [267/469], Loss: 0.4476, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [29/50], Step [268/469], Loss: 0.3333, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [29/50], Step [269/469], Loss: 0.4675, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [29/50], Step [270/469], Loss: 0.4103, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [29/50], Step [271/469], Loss: 0.3879, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [29/50], Step [272/469], Loss: 0.3196, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [29/50], Step [273/469], Loss: 0.3576, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [29/50], Step [274/469], Loss: 0.5588, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [29/50], Step [275/469], Loss: 0.7026, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [29/50], Step [276/469], Loss: 0.4511, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [29/50], Step [277/469], Loss: 0.3525, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [29/50], Step [278/469], Loss: 0.4136, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [29/50], Step [279/469], Loss: 0.3374, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [29/50], Step [280/469], Loss: 0.3670, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [29/50], Step [281/469], Loss: 0.4257, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [29/50], Step [282/469], Loss: 0.2865, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [29/50], Step [283/469], Loss: 0.2830, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [29/50], Step [284/469], Loss: 0.4440, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [29/50], Step [285/469], Loss: 0.4768, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [29/50], Step [286/469], Loss: 0.4254, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [29/50], Step [287/469], Loss: 0.5689, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [29/50], Step [288/469], Loss: 0.4596, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [29/50], Step [289/469], Loss: 0.4491, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [29/50], Step [290/469], Loss: 0.1946, batch time: 0.54, accuracy:  96.09%\n",
      "Epoch [29/50], Step [291/469], Loss: 0.4567, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [29/50], Step [292/469], Loss: 0.3298, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [29/50], Step [293/469], Loss: 0.6414, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [29/50], Step [294/469], Loss: 0.4169, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [29/50], Step [295/469], Loss: 0.5041, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [29/50], Step [296/469], Loss: 0.3900, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [29/50], Step [297/469], Loss: 0.3529, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [29/50], Step [298/469], Loss: 0.5235, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [29/50], Step [299/469], Loss: 0.4780, batch time: 0.60, accuracy:  84.38%\n",
      "Epoch [29/50], Step [300/469], Loss: 0.5508, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [29/50], Step [301/469], Loss: 0.3381, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [29/50], Step [302/469], Loss: 0.5252, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [29/50], Step [303/469], Loss: 0.3312, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [29/50], Step [304/469], Loss: 0.3772, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [29/50], Step [305/469], Loss: 0.3795, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [29/50], Step [306/469], Loss: 0.2710, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [29/50], Step [307/469], Loss: 0.4639, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [29/50], Step [308/469], Loss: 0.2519, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [29/50], Step [309/469], Loss: 0.4937, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [29/50], Step [310/469], Loss: 0.3709, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [29/50], Step [311/469], Loss: 0.5773, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [29/50], Step [312/469], Loss: 0.3937, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [29/50], Step [313/469], Loss: 0.4300, batch time: 0.65, accuracy:  88.28%\n",
      "Epoch [29/50], Step [314/469], Loss: 0.4021, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [29/50], Step [315/469], Loss: 0.4308, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [29/50], Step [316/469], Loss: 0.3392, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [29/50], Step [317/469], Loss: 0.2697, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [29/50], Step [318/469], Loss: 0.4553, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [29/50], Step [319/469], Loss: 0.4457, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [29/50], Step [320/469], Loss: 0.3037, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [29/50], Step [321/469], Loss: 0.5136, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [29/50], Step [322/469], Loss: 0.4553, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [29/50], Step [323/469], Loss: 0.4967, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [29/50], Step [324/469], Loss: 0.2597, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [29/50], Step [325/469], Loss: 0.3418, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [29/50], Step [326/469], Loss: 0.4061, batch time: 1.14, accuracy:  87.50%\n",
      "Epoch [29/50], Step [327/469], Loss: 0.2111, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [29/50], Step [328/469], Loss: 0.3444, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [29/50], Step [329/469], Loss: 0.4685, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [29/50], Step [330/469], Loss: 0.3984, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [29/50], Step [331/469], Loss: 0.4783, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [29/50], Step [332/469], Loss: 0.3243, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [29/50], Step [333/469], Loss: 0.3731, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [29/50], Step [334/469], Loss: 0.2642, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [29/50], Step [335/469], Loss: 0.4051, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [29/50], Step [336/469], Loss: 0.5324, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [29/50], Step [337/469], Loss: 0.5910, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [29/50], Step [338/469], Loss: 0.5395, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [29/50], Step [339/469], Loss: 0.4749, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [29/50], Step [340/469], Loss: 0.5004, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [29/50], Step [341/469], Loss: 0.3933, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [29/50], Step [342/469], Loss: 0.5309, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [29/50], Step [343/469], Loss: 0.3795, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [29/50], Step [344/469], Loss: 0.7169, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [29/50], Step [345/469], Loss: 0.4035, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [29/50], Step [346/469], Loss: 0.3333, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [29/50], Step [347/469], Loss: 0.3130, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [29/50], Step [348/469], Loss: 0.4869, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [29/50], Step [349/469], Loss: 0.4286, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [29/50], Step [350/469], Loss: 0.4922, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [29/50], Step [351/469], Loss: 0.4229, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [29/50], Step [352/469], Loss: 0.4338, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [29/50], Step [353/469], Loss: 0.2436, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [29/50], Step [354/469], Loss: 0.3260, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [29/50], Step [355/469], Loss: 0.4287, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [29/50], Step [356/469], Loss: 0.4629, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [29/50], Step [357/469], Loss: 0.2486, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [29/50], Step [358/469], Loss: 0.3766, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [29/50], Step [359/469], Loss: 0.4366, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [29/50], Step [360/469], Loss: 0.3503, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [29/50], Step [361/469], Loss: 0.4912, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [29/50], Step [362/469], Loss: 0.5031, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [29/50], Step [363/469], Loss: 0.3110, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [29/50], Step [364/469], Loss: 0.4504, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [29/50], Step [365/469], Loss: 0.3131, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [29/50], Step [366/469], Loss: 0.3145, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [29/50], Step [367/469], Loss: 0.3447, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [29/50], Step [368/469], Loss: 0.3044, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [29/50], Step [369/469], Loss: 0.3597, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [29/50], Step [370/469], Loss: 0.4931, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [29/50], Step [371/469], Loss: 0.4737, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [29/50], Step [372/469], Loss: 0.2753, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [29/50], Step [373/469], Loss: 0.4044, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [29/50], Step [374/469], Loss: 0.4396, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [29/50], Step [375/469], Loss: 0.3151, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [29/50], Step [376/469], Loss: 0.3091, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [29/50], Step [377/469], Loss: 0.3204, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [29/50], Step [378/469], Loss: 0.6219, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [29/50], Step [379/469], Loss: 0.4768, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [29/50], Step [380/469], Loss: 0.3078, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [29/50], Step [381/469], Loss: 0.3202, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [29/50], Step [382/469], Loss: 0.3354, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [29/50], Step [383/469], Loss: 0.5115, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [29/50], Step [384/469], Loss: 0.4172, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [29/50], Step [385/469], Loss: 0.3907, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [29/50], Step [386/469], Loss: 0.4700, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [29/50], Step [387/469], Loss: 0.3877, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [29/50], Step [388/469], Loss: 0.3540, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [29/50], Step [389/469], Loss: 0.3173, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [29/50], Step [390/469], Loss: 0.3494, batch time: 0.81, accuracy:  88.28%\n",
      "Epoch [29/50], Step [391/469], Loss: 0.4091, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [29/50], Step [392/469], Loss: 0.5645, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [29/50], Step [393/469], Loss: 0.3151, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [29/50], Step [394/469], Loss: 0.4428, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [29/50], Step [395/469], Loss: 0.6970, batch time: 0.46, accuracy:  78.91%\n",
      "Epoch [29/50], Step [396/469], Loss: 0.3132, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [29/50], Step [397/469], Loss: 0.4867, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [29/50], Step [398/469], Loss: 0.2586, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [29/50], Step [399/469], Loss: 0.3910, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [29/50], Step [400/469], Loss: 0.4437, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [29/50], Step [401/469], Loss: 0.3839, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [29/50], Step [402/469], Loss: 0.5224, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [29/50], Step [403/469], Loss: 0.3889, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [29/50], Step [404/469], Loss: 0.4689, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [29/50], Step [405/469], Loss: 0.4524, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [29/50], Step [406/469], Loss: 0.3946, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [29/50], Step [407/469], Loss: 0.4061, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [29/50], Step [408/469], Loss: 0.2766, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [29/50], Step [409/469], Loss: 0.5356, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [29/50], Step [410/469], Loss: 0.5253, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [29/50], Step [411/469], Loss: 0.5075, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [29/50], Step [412/469], Loss: 0.4437, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [29/50], Step [413/469], Loss: 0.4771, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [29/50], Step [414/469], Loss: 0.5186, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [29/50], Step [415/469], Loss: 0.2835, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [29/50], Step [416/469], Loss: 0.2982, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [29/50], Step [417/469], Loss: 0.4448, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [29/50], Step [418/469], Loss: 0.4911, batch time: 0.93, accuracy:  82.03%\n",
      "Epoch [29/50], Step [419/469], Loss: 0.3337, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [29/50], Step [420/469], Loss: 0.3153, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [29/50], Step [421/469], Loss: 0.5080, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [29/50], Step [422/469], Loss: 0.4603, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [29/50], Step [423/469], Loss: 0.5083, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [29/50], Step [424/469], Loss: 0.4574, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [29/50], Step [425/469], Loss: 0.3937, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [29/50], Step [426/469], Loss: 0.4603, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [29/50], Step [427/469], Loss: 0.3803, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [29/50], Step [428/469], Loss: 0.4517, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [29/50], Step [429/469], Loss: 0.4984, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [29/50], Step [430/469], Loss: 0.4119, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [29/50], Step [431/469], Loss: 0.5382, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [29/50], Step [432/469], Loss: 0.4399, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [29/50], Step [433/469], Loss: 0.4395, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [29/50], Step [434/469], Loss: 0.4242, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [29/50], Step [435/469], Loss: 0.4408, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [29/50], Step [436/469], Loss: 0.3767, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [29/50], Step [437/469], Loss: 0.3430, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [29/50], Step [438/469], Loss: 0.4655, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [29/50], Step [439/469], Loss: 0.4594, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [29/50], Step [440/469], Loss: 0.3877, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [29/50], Step [441/469], Loss: 0.4262, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [29/50], Step [442/469], Loss: 0.3830, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [29/50], Step [443/469], Loss: 0.2883, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [29/50], Step [444/469], Loss: 0.3655, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [29/50], Step [445/469], Loss: 0.5676, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [29/50], Step [446/469], Loss: 0.3693, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [29/50], Step [447/469], Loss: 0.3490, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [29/50], Step [448/469], Loss: 0.3390, batch time: 0.66, accuracy:  90.62%\n",
      "Epoch [29/50], Step [449/469], Loss: 0.6093, batch time: 0.63, accuracy:  82.03%\n",
      "Epoch [29/50], Step [450/469], Loss: 0.4677, batch time: 0.58, accuracy:  81.25%\n",
      "Epoch [29/50], Step [451/469], Loss: 0.5069, batch time: 0.62, accuracy:  86.72%\n",
      "Epoch [29/50], Step [452/469], Loss: 0.4889, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [29/50], Step [453/469], Loss: 0.4168, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [29/50], Step [454/469], Loss: 0.3161, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [29/50], Step [455/469], Loss: 0.3854, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [29/50], Step [456/469], Loss: 0.3284, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [29/50], Step [457/469], Loss: 0.6260, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [29/50], Step [458/469], Loss: 0.3269, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [29/50], Step [459/469], Loss: 0.3808, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [29/50], Step [460/469], Loss: 0.4364, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [29/50], Step [461/469], Loss: 0.4023, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [29/50], Step [462/469], Loss: 0.5684, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [29/50], Step [463/469], Loss: 0.2648, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [29/50], Step [464/469], Loss: 0.4265, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [29/50], Step [465/469], Loss: 0.4841, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [29/50], Step [466/469], Loss: 0.6165, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [29/50], Step [467/469], Loss: 0.3755, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [29/50], Step [468/469], Loss: 0.4745, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [29/50], Step [469/469], Loss: 0.4260, batch time: 0.47, accuracy:  88.54%\n",
      "Epoch [30/50], Step [1/469], Loss: 0.2594, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [30/50], Step [2/469], Loss: 0.2990, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [30/50], Step [3/469], Loss: 0.3492, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [30/50], Step [4/469], Loss: 0.3729, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [30/50], Step [5/469], Loss: 0.7707, batch time: 0.44, accuracy:  78.91%\n",
      "Epoch [30/50], Step [6/469], Loss: 0.3506, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [30/50], Step [7/469], Loss: 0.3360, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [30/50], Step [8/469], Loss: 0.2774, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [30/50], Step [9/469], Loss: 0.5017, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [30/50], Step [10/469], Loss: 0.3966, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [11/469], Loss: 0.4933, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [30/50], Step [12/469], Loss: 0.3411, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [30/50], Step [13/469], Loss: 0.4089, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [30/50], Step [14/469], Loss: 0.4023, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [30/50], Step [15/469], Loss: 0.3371, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [30/50], Step [16/469], Loss: 0.4021, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [30/50], Step [17/469], Loss: 0.4359, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [30/50], Step [18/469], Loss: 0.2346, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [30/50], Step [19/469], Loss: 0.2941, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [30/50], Step [20/469], Loss: 0.6181, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [30/50], Step [21/469], Loss: 0.5211, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [30/50], Step [22/469], Loss: 0.5235, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [30/50], Step [23/469], Loss: 0.5617, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [30/50], Step [24/469], Loss: 0.3849, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [30/50], Step [25/469], Loss: 0.3297, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [30/50], Step [26/469], Loss: 0.3688, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [30/50], Step [27/469], Loss: 0.4984, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [30/50], Step [28/469], Loss: 0.5580, batch time: 0.54, accuracy:  81.25%\n",
      "Epoch [30/50], Step [29/469], Loss: 0.4605, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [30/50], Step [30/469], Loss: 0.3979, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [30/50], Step [31/469], Loss: 0.2048, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [30/50], Step [32/469], Loss: 0.4589, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [30/50], Step [33/469], Loss: 0.4546, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [30/50], Step [34/469], Loss: 0.2461, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [30/50], Step [35/469], Loss: 0.2810, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [36/469], Loss: 0.5519, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [30/50], Step [37/469], Loss: 0.4080, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [30/50], Step [38/469], Loss: 0.3400, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [30/50], Step [39/469], Loss: 0.3359, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [30/50], Step [40/469], Loss: 0.3295, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [30/50], Step [41/469], Loss: 0.4671, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [30/50], Step [42/469], Loss: 0.2775, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [30/50], Step [43/469], Loss: 0.5271, batch time: 0.62, accuracy:  83.59%\n",
      "Epoch [30/50], Step [44/469], Loss: 0.4382, batch time: 0.71, accuracy:  87.50%\n",
      "Epoch [30/50], Step [45/469], Loss: 0.3920, batch time: 0.68, accuracy:  91.41%\n",
      "Epoch [30/50], Step [46/469], Loss: 0.4695, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [30/50], Step [47/469], Loss: 0.3983, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [48/469], Loss: 0.3668, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [30/50], Step [49/469], Loss: 0.5005, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [30/50], Step [50/469], Loss: 0.4771, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [30/50], Step [51/469], Loss: 0.3798, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [30/50], Step [52/469], Loss: 0.3264, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [30/50], Step [53/469], Loss: 0.4539, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [30/50], Step [54/469], Loss: 0.3665, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [30/50], Step [55/469], Loss: 0.3625, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [30/50], Step [56/469], Loss: 0.4467, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [30/50], Step [57/469], Loss: 0.3474, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [30/50], Step [58/469], Loss: 0.4877, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [59/469], Loss: 0.5503, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [30/50], Step [60/469], Loss: 0.3205, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [30/50], Step [61/469], Loss: 0.4644, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [30/50], Step [62/469], Loss: 0.4441, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [30/50], Step [63/469], Loss: 0.3560, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [30/50], Step [64/469], Loss: 0.3791, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [30/50], Step [65/469], Loss: 0.2433, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [30/50], Step [66/469], Loss: 0.3477, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [30/50], Step [67/469], Loss: 0.4381, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [30/50], Step [68/469], Loss: 0.3228, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [30/50], Step [69/469], Loss: 0.4389, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [70/469], Loss: 0.3273, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [30/50], Step [71/469], Loss: 0.2409, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [30/50], Step [72/469], Loss: 0.3653, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [30/50], Step [73/469], Loss: 0.4456, batch time: 0.71, accuracy:  83.59%\n",
      "Epoch [30/50], Step [74/469], Loss: 0.4789, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [30/50], Step [75/469], Loss: 0.6160, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [30/50], Step [76/469], Loss: 0.3266, batch time: 0.66, accuracy:  92.19%\n",
      "Epoch [30/50], Step [77/469], Loss: 0.4503, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [78/469], Loss: 0.2431, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [30/50], Step [79/469], Loss: 0.4381, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [30/50], Step [80/469], Loss: 0.3895, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [30/50], Step [81/469], Loss: 0.3583, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [30/50], Step [82/469], Loss: 0.3704, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [30/50], Step [83/469], Loss: 0.3701, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [30/50], Step [84/469], Loss: 0.2872, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [30/50], Step [85/469], Loss: 0.4006, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [30/50], Step [86/469], Loss: 0.3114, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [30/50], Step [87/469], Loss: 0.3353, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [88/469], Loss: 0.4505, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [30/50], Step [89/469], Loss: 0.3395, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [90/469], Loss: 0.4698, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [30/50], Step [91/469], Loss: 0.2957, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [30/50], Step [92/469], Loss: 0.3115, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [93/469], Loss: 0.3637, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [94/469], Loss: 0.5342, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [30/50], Step [95/469], Loss: 0.4171, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [30/50], Step [96/469], Loss: 0.3537, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [97/469], Loss: 0.3579, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [30/50], Step [98/469], Loss: 0.3695, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [99/469], Loss: 0.5207, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [30/50], Step [100/469], Loss: 0.3344, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [30/50], Step [101/469], Loss: 0.3499, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [30/50], Step [102/469], Loss: 0.2978, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [30/50], Step [103/469], Loss: 0.3839, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [30/50], Step [104/469], Loss: 0.4149, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [30/50], Step [105/469], Loss: 0.2226, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [30/50], Step [106/469], Loss: 0.3172, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [30/50], Step [107/469], Loss: 0.4139, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [30/50], Step [108/469], Loss: 0.2493, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [30/50], Step [109/469], Loss: 0.4026, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [30/50], Step [110/469], Loss: 0.6624, batch time: 0.66, accuracy:  82.81%\n",
      "Epoch [30/50], Step [111/469], Loss: 0.4130, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [30/50], Step [112/469], Loss: 0.3460, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [30/50], Step [113/469], Loss: 0.3740, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [30/50], Step [114/469], Loss: 0.3889, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [30/50], Step [115/469], Loss: 0.3835, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [30/50], Step [116/469], Loss: 0.4973, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [30/50], Step [117/469], Loss: 0.5286, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [118/469], Loss: 0.3531, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [119/469], Loss: 0.4792, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [30/50], Step [120/469], Loss: 0.4500, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [30/50], Step [121/469], Loss: 0.3305, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [30/50], Step [122/469], Loss: 0.2745, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [30/50], Step [123/469], Loss: 0.4271, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [30/50], Step [124/469], Loss: 0.5307, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [30/50], Step [125/469], Loss: 0.3520, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [30/50], Step [126/469], Loss: 0.3329, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [30/50], Step [127/469], Loss: 0.4934, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [30/50], Step [128/469], Loss: 0.3830, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [30/50], Step [129/469], Loss: 0.4628, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [30/50], Step [130/469], Loss: 0.3471, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [30/50], Step [131/469], Loss: 0.3935, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [132/469], Loss: 0.3831, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [30/50], Step [133/469], Loss: 0.4217, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [30/50], Step [134/469], Loss: 0.6301, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [30/50], Step [135/469], Loss: 0.4218, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [30/50], Step [136/469], Loss: 0.6984, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [30/50], Step [137/469], Loss: 0.2599, batch time: 0.64, accuracy:  92.97%\n",
      "Epoch [30/50], Step [138/469], Loss: 0.2604, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [30/50], Step [139/469], Loss: 0.4971, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [30/50], Step [140/469], Loss: 0.4209, batch time: 0.95, accuracy:  85.16%\n",
      "Epoch [30/50], Step [141/469], Loss: 0.4547, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [30/50], Step [142/469], Loss: 0.4268, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [30/50], Step [143/469], Loss: 0.5116, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [30/50], Step [144/469], Loss: 0.3716, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [30/50], Step [145/469], Loss: 0.2918, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [30/50], Step [146/469], Loss: 0.3840, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [30/50], Step [147/469], Loss: 0.3913, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [30/50], Step [148/469], Loss: 0.2537, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [30/50], Step [149/469], Loss: 0.3801, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [150/469], Loss: 0.3655, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [30/50], Step [151/469], Loss: 0.5626, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [30/50], Step [152/469], Loss: 0.3224, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [30/50], Step [153/469], Loss: 0.4396, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [30/50], Step [154/469], Loss: 0.3449, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [30/50], Step [155/469], Loss: 0.5769, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [30/50], Step [156/469], Loss: 0.4757, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [30/50], Step [157/469], Loss: 0.3666, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [30/50], Step [158/469], Loss: 0.4309, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [30/50], Step [159/469], Loss: 0.3788, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [30/50], Step [160/469], Loss: 0.3957, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [30/50], Step [161/469], Loss: 0.4671, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [162/469], Loss: 0.3703, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [163/469], Loss: 0.3892, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [30/50], Step [164/469], Loss: 0.3893, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [30/50], Step [165/469], Loss: 0.4578, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [30/50], Step [166/469], Loss: 0.4250, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [30/50], Step [167/469], Loss: 0.3349, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [30/50], Step [168/469], Loss: 0.3820, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [30/50], Step [169/469], Loss: 0.4457, batch time: 0.67, accuracy:  85.94%\n",
      "Epoch [30/50], Step [170/469], Loss: 0.2866, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [30/50], Step [171/469], Loss: 0.3230, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [30/50], Step [172/469], Loss: 0.4020, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [173/469], Loss: 0.4921, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [30/50], Step [174/469], Loss: 0.3253, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [30/50], Step [175/469], Loss: 0.2689, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [30/50], Step [176/469], Loss: 0.4590, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [30/50], Step [177/469], Loss: 0.3384, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [30/50], Step [178/469], Loss: 0.5075, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [30/50], Step [179/469], Loss: 0.3895, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [30/50], Step [180/469], Loss: 0.4733, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [30/50], Step [181/469], Loss: 0.3136, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [30/50], Step [182/469], Loss: 0.5089, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [30/50], Step [183/469], Loss: 0.4974, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [30/50], Step [184/469], Loss: 0.3875, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [185/469], Loss: 0.2995, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [30/50], Step [186/469], Loss: 0.2666, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [30/50], Step [187/469], Loss: 0.3571, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [30/50], Step [188/469], Loss: 0.4768, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [189/469], Loss: 0.4420, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [30/50], Step [190/469], Loss: 0.3937, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [30/50], Step [191/469], Loss: 0.3766, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [30/50], Step [192/469], Loss: 0.4902, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [30/50], Step [193/469], Loss: 0.3122, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [30/50], Step [194/469], Loss: 0.4958, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [30/50], Step [195/469], Loss: 0.3371, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [30/50], Step [196/469], Loss: 0.3204, batch time: 0.90, accuracy:  89.84%\n",
      "Epoch [30/50], Step [197/469], Loss: 0.4045, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [30/50], Step [198/469], Loss: 0.6270, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [199/469], Loss: 0.2266, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [30/50], Step [200/469], Loss: 0.4653, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [201/469], Loss: 0.2945, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [30/50], Step [202/469], Loss: 0.5223, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [30/50], Step [203/469], Loss: 0.4348, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [30/50], Step [204/469], Loss: 0.4330, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [30/50], Step [205/469], Loss: 0.3895, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [30/50], Step [206/469], Loss: 0.3784, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [30/50], Step [207/469], Loss: 0.3666, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [30/50], Step [208/469], Loss: 0.5009, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [209/469], Loss: 0.3918, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [210/469], Loss: 0.3562, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [30/50], Step [211/469], Loss: 0.2502, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [30/50], Step [212/469], Loss: 0.3858, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [30/50], Step [213/469], Loss: 0.2965, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [30/50], Step [214/469], Loss: 0.2847, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [30/50], Step [215/469], Loss: 0.4608, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [30/50], Step [216/469], Loss: 0.3833, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [30/50], Step [217/469], Loss: 0.3271, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [30/50], Step [218/469], Loss: 0.3701, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [30/50], Step [219/469], Loss: 0.4779, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [30/50], Step [220/469], Loss: 0.3643, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [221/469], Loss: 0.3842, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [30/50], Step [222/469], Loss: 0.2737, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [30/50], Step [223/469], Loss: 0.2923, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [30/50], Step [224/469], Loss: 0.4589, batch time: 0.64, accuracy:  82.03%\n",
      "Epoch [30/50], Step [225/469], Loss: 0.5092, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [30/50], Step [226/469], Loss: 0.3675, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [30/50], Step [227/469], Loss: 0.3502, batch time: 0.63, accuracy:  86.72%\n",
      "Epoch [30/50], Step [228/469], Loss: 0.6745, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [30/50], Step [229/469], Loss: 0.3900, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [30/50], Step [230/469], Loss: 0.2522, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [30/50], Step [231/469], Loss: 0.4208, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [232/469], Loss: 0.4865, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [30/50], Step [233/469], Loss: 0.4037, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [30/50], Step [234/469], Loss: 0.3598, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [30/50], Step [235/469], Loss: 0.5996, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [30/50], Step [236/469], Loss: 0.3761, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [30/50], Step [237/469], Loss: 0.4032, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [30/50], Step [238/469], Loss: 0.5973, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [30/50], Step [239/469], Loss: 0.4215, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [30/50], Step [240/469], Loss: 0.3474, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [30/50], Step [241/469], Loss: 0.4153, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [30/50], Step [242/469], Loss: 0.6653, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [30/50], Step [243/469], Loss: 0.4526, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [30/50], Step [244/469], Loss: 0.2671, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [30/50], Step [245/469], Loss: 0.3892, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [30/50], Step [246/469], Loss: 0.4961, batch time: 0.56, accuracy:  80.47%\n",
      "Epoch [30/50], Step [247/469], Loss: 0.3137, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [30/50], Step [248/469], Loss: 0.4430, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [30/50], Step [249/469], Loss: 0.3291, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [30/50], Step [250/469], Loss: 0.5651, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [30/50], Step [251/469], Loss: 0.2054, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [30/50], Step [252/469], Loss: 0.4915, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [253/469], Loss: 0.4586, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [30/50], Step [254/469], Loss: 0.2275, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [30/50], Step [255/469], Loss: 0.2491, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [30/50], Step [256/469], Loss: 0.4038, batch time: 1.00, accuracy:  85.16%\n",
      "Epoch [30/50], Step [257/469], Loss: 0.4915, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [30/50], Step [258/469], Loss: 0.3974, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [30/50], Step [259/469], Loss: 0.5594, batch time: 0.52, accuracy:  82.81%\n",
      "Epoch [30/50], Step [260/469], Loss: 0.4329, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [30/50], Step [261/469], Loss: 0.5516, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [30/50], Step [262/469], Loss: 0.5914, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [30/50], Step [263/469], Loss: 0.4092, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [264/469], Loss: 0.4352, batch time: 0.62, accuracy:  84.38%\n",
      "Epoch [30/50], Step [265/469], Loss: 0.3805, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [30/50], Step [266/469], Loss: 0.2857, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [30/50], Step [267/469], Loss: 0.2705, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [30/50], Step [268/469], Loss: 0.3778, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [30/50], Step [269/469], Loss: 0.5466, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [30/50], Step [270/469], Loss: 0.4309, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [30/50], Step [271/469], Loss: 0.2901, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [30/50], Step [272/469], Loss: 0.3932, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [30/50], Step [273/469], Loss: 0.4375, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [274/469], Loss: 0.3299, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [30/50], Step [275/469], Loss: 0.4586, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [30/50], Step [276/469], Loss: 0.4244, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [277/469], Loss: 0.3753, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [30/50], Step [278/469], Loss: 0.4380, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [30/50], Step [279/469], Loss: 0.3734, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [30/50], Step [280/469], Loss: 0.3176, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [30/50], Step [281/469], Loss: 0.2625, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [30/50], Step [282/469], Loss: 0.4850, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [30/50], Step [283/469], Loss: 0.4112, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [30/50], Step [284/469], Loss: 0.5370, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [30/50], Step [285/469], Loss: 0.3677, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [30/50], Step [286/469], Loss: 0.3532, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [30/50], Step [287/469], Loss: 0.4134, batch time: 0.77, accuracy:  90.62%\n",
      "Epoch [30/50], Step [288/469], Loss: 0.3357, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [30/50], Step [289/469], Loss: 0.5056, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [30/50], Step [290/469], Loss: 0.5265, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [30/50], Step [291/469], Loss: 0.5586, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [30/50], Step [292/469], Loss: 0.4458, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [30/50], Step [293/469], Loss: 0.4624, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [30/50], Step [294/469], Loss: 0.3896, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [30/50], Step [295/469], Loss: 0.2632, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [30/50], Step [296/469], Loss: 0.5118, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [30/50], Step [297/469], Loss: 0.2362, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [30/50], Step [298/469], Loss: 0.3643, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [30/50], Step [299/469], Loss: 0.2855, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [30/50], Step [300/469], Loss: 0.3614, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [30/50], Step [301/469], Loss: 0.3432, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [30/50], Step [302/469], Loss: 0.4520, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [30/50], Step [303/469], Loss: 0.3595, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [30/50], Step [304/469], Loss: 0.5346, batch time: 0.67, accuracy:  85.16%\n",
      "Epoch [30/50], Step [305/469], Loss: 0.4191, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [30/50], Step [306/469], Loss: 0.3744, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [30/50], Step [307/469], Loss: 0.3285, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [30/50], Step [308/469], Loss: 0.4033, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [30/50], Step [309/469], Loss: 0.4912, batch time: 0.51, accuracy:  82.81%\n",
      "Epoch [30/50], Step [310/469], Loss: 0.4104, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [30/50], Step [311/469], Loss: 0.5099, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [30/50], Step [312/469], Loss: 0.2834, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [30/50], Step [313/469], Loss: 0.3901, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [314/469], Loss: 0.5319, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [30/50], Step [315/469], Loss: 0.6448, batch time: 0.45, accuracy:  82.03%\n",
      "Epoch [30/50], Step [316/469], Loss: 0.4181, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [30/50], Step [317/469], Loss: 0.4094, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [30/50], Step [318/469], Loss: 0.4451, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [30/50], Step [319/469], Loss: 0.5839, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [30/50], Step [320/469], Loss: 0.2444, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [30/50], Step [321/469], Loss: 0.6251, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [30/50], Step [322/469], Loss: 0.4111, batch time: 0.62, accuracy:  85.94%\n",
      "Epoch [30/50], Step [323/469], Loss: 0.3105, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [30/50], Step [324/469], Loss: 0.2763, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [30/50], Step [325/469], Loss: 0.3155, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [30/50], Step [326/469], Loss: 0.3941, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [30/50], Step [327/469], Loss: 0.3644, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [30/50], Step [328/469], Loss: 0.6102, batch time: 0.46, accuracy:  77.34%\n",
      "Epoch [30/50], Step [329/469], Loss: 0.4157, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [30/50], Step [330/469], Loss: 0.4567, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [30/50], Step [331/469], Loss: 0.5242, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [30/50], Step [332/469], Loss: 0.4919, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [30/50], Step [333/469], Loss: 0.4209, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [30/50], Step [334/469], Loss: 0.5021, batch time: 0.44, accuracy:  82.03%\n",
      "Epoch [30/50], Step [335/469], Loss: 0.3036, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [30/50], Step [336/469], Loss: 0.3435, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [30/50], Step [337/469], Loss: 0.4464, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [30/50], Step [338/469], Loss: 0.4737, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [30/50], Step [339/469], Loss: 0.2470, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [30/50], Step [340/469], Loss: 0.4589, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [30/50], Step [341/469], Loss: 0.2529, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [30/50], Step [342/469], Loss: 0.3699, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [343/469], Loss: 0.4855, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [30/50], Step [344/469], Loss: 0.4389, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [30/50], Step [345/469], Loss: 0.4872, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [30/50], Step [346/469], Loss: 0.2941, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [30/50], Step [347/469], Loss: 0.4717, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [30/50], Step [348/469], Loss: 0.3296, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [30/50], Step [349/469], Loss: 0.3886, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [30/50], Step [350/469], Loss: 0.3718, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [30/50], Step [351/469], Loss: 0.3777, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [30/50], Step [352/469], Loss: 0.3862, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [30/50], Step [353/469], Loss: 0.4558, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [30/50], Step [354/469], Loss: 0.4057, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [30/50], Step [355/469], Loss: 0.5272, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [30/50], Step [356/469], Loss: 0.3876, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [30/50], Step [357/469], Loss: 0.4203, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [30/50], Step [358/469], Loss: 0.3230, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [30/50], Step [359/469], Loss: 0.4494, batch time: 0.67, accuracy:  89.84%\n",
      "Epoch [30/50], Step [360/469], Loss: 0.6398, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [30/50], Step [361/469], Loss: 0.4443, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [30/50], Step [362/469], Loss: 0.3206, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [30/50], Step [363/469], Loss: 0.5799, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [30/50], Step [364/469], Loss: 0.3688, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [30/50], Step [365/469], Loss: 0.3922, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [30/50], Step [366/469], Loss: 0.4014, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [30/50], Step [367/469], Loss: 0.3981, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [30/50], Step [368/469], Loss: 0.4211, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [30/50], Step [369/469], Loss: 0.3552, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [30/50], Step [370/469], Loss: 0.4442, batch time: 0.63, accuracy:  84.38%\n",
      "Epoch [30/50], Step [371/469], Loss: 0.4462, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [30/50], Step [372/469], Loss: 0.2993, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [30/50], Step [373/469], Loss: 0.4507, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [374/469], Loss: 0.3644, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [30/50], Step [375/469], Loss: 0.3786, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [30/50], Step [376/469], Loss: 0.4726, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [30/50], Step [377/469], Loss: 0.3373, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [30/50], Step [378/469], Loss: 0.3975, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [30/50], Step [379/469], Loss: 0.5250, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [30/50], Step [380/469], Loss: 0.3784, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [30/50], Step [381/469], Loss: 0.4126, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [30/50], Step [382/469], Loss: 0.4304, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [30/50], Step [383/469], Loss: 0.3592, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [30/50], Step [384/469], Loss: 0.4119, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [30/50], Step [385/469], Loss: 0.3463, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [30/50], Step [386/469], Loss: 0.2421, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [30/50], Step [387/469], Loss: 0.4841, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [30/50], Step [388/469], Loss: 0.4300, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [30/50], Step [389/469], Loss: 0.3081, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [30/50], Step [390/469], Loss: 0.4757, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [30/50], Step [391/469], Loss: 0.4407, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [30/50], Step [392/469], Loss: 0.2307, batch time: 0.64, accuracy:  92.97%\n",
      "Epoch [30/50], Step [393/469], Loss: 0.4218, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [30/50], Step [394/469], Loss: 0.4131, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [30/50], Step [395/469], Loss: 0.4285, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [30/50], Step [396/469], Loss: 0.2517, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [30/50], Step [397/469], Loss: 0.3204, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [30/50], Step [398/469], Loss: 0.4321, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [30/50], Step [399/469], Loss: 0.4324, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [30/50], Step [400/469], Loss: 0.3184, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [30/50], Step [401/469], Loss: 0.4219, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [30/50], Step [402/469], Loss: 0.5234, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [30/50], Step [403/469], Loss: 0.4490, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [404/469], Loss: 0.3716, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [30/50], Step [405/469], Loss: 0.3441, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [30/50], Step [406/469], Loss: 0.3971, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [30/50], Step [407/469], Loss: 0.5057, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [30/50], Step [408/469], Loss: 0.3955, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [30/50], Step [409/469], Loss: 0.4501, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [30/50], Step [410/469], Loss: 0.3161, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [30/50], Step [411/469], Loss: 0.8835, batch time: 0.48, accuracy:  77.34%\n",
      "Epoch [30/50], Step [412/469], Loss: 0.3705, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [30/50], Step [413/469], Loss: 0.5400, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [30/50], Step [414/469], Loss: 0.3591, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [30/50], Step [415/469], Loss: 0.5006, batch time: 0.47, accuracy:  82.03%\n",
      "Epoch [30/50], Step [416/469], Loss: 0.4221, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [30/50], Step [417/469], Loss: 0.4307, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [30/50], Step [418/469], Loss: 0.4572, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [30/50], Step [419/469], Loss: 0.4793, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [30/50], Step [420/469], Loss: 0.3091, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [30/50], Step [421/469], Loss: 0.3729, batch time: 0.69, accuracy:  87.50%\n",
      "Epoch [30/50], Step [422/469], Loss: 0.4615, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [30/50], Step [423/469], Loss: 0.4160, batch time: 0.67, accuracy:  88.28%\n",
      "Epoch [30/50], Step [424/469], Loss: 0.3709, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [30/50], Step [425/469], Loss: 0.3794, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [30/50], Step [426/469], Loss: 0.3273, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [30/50], Step [427/469], Loss: 0.4687, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [30/50], Step [428/469], Loss: 0.3275, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [30/50], Step [429/469], Loss: 0.3389, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [30/50], Step [430/469], Loss: 0.2615, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [30/50], Step [431/469], Loss: 0.2548, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [30/50], Step [432/469], Loss: 0.4022, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [30/50], Step [433/469], Loss: 0.4713, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [30/50], Step [434/469], Loss: 0.5554, batch time: 0.50, accuracy:  78.91%\n",
      "Epoch [30/50], Step [435/469], Loss: 0.2838, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [30/50], Step [436/469], Loss: 0.2914, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [30/50], Step [437/469], Loss: 0.3696, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [30/50], Step [438/469], Loss: 0.4062, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [30/50], Step [439/469], Loss: 0.4259, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [30/50], Step [440/469], Loss: 0.2448, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [30/50], Step [441/469], Loss: 0.3095, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [30/50], Step [442/469], Loss: 0.2998, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [30/50], Step [443/469], Loss: 0.3583, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [30/50], Step [444/469], Loss: 0.3083, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [30/50], Step [445/469], Loss: 0.4286, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [30/50], Step [446/469], Loss: 0.3566, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [30/50], Step [447/469], Loss: 0.5061, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [30/50], Step [448/469], Loss: 0.4353, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [30/50], Step [449/469], Loss: 0.3251, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [30/50], Step [450/469], Loss: 0.3827, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [30/50], Step [451/469], Loss: 0.3134, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [30/50], Step [452/469], Loss: 0.4763, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [30/50], Step [453/469], Loss: 0.3449, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [30/50], Step [454/469], Loss: 0.4644, batch time: 0.74, accuracy:  90.62%\n",
      "Epoch [30/50], Step [455/469], Loss: 0.4676, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [30/50], Step [456/469], Loss: 0.4349, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [30/50], Step [457/469], Loss: 0.3089, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [30/50], Step [458/469], Loss: 0.5236, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [30/50], Step [459/469], Loss: 0.3192, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [30/50], Step [460/469], Loss: 0.3098, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [30/50], Step [461/469], Loss: 0.3811, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [30/50], Step [462/469], Loss: 0.4454, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [30/50], Step [463/469], Loss: 0.3469, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [30/50], Step [464/469], Loss: 0.4323, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [30/50], Step [465/469], Loss: 0.3759, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [30/50], Step [466/469], Loss: 0.3892, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [30/50], Step [467/469], Loss: 0.5582, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [30/50], Step [468/469], Loss: 0.2674, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [30/50], Step [469/469], Loss: 0.4591, batch time: 0.52, accuracy:  88.54%\n",
      "Epoch [31/50], Step [1/469], Loss: 0.5751, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [31/50], Step [2/469], Loss: 0.4447, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [31/50], Step [3/469], Loss: 0.4943, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [31/50], Step [4/469], Loss: 0.2951, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [31/50], Step [5/469], Loss: 0.3103, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [31/50], Step [6/469], Loss: 0.2857, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [31/50], Step [7/469], Loss: 0.4085, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [8/469], Loss: 0.3621, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [31/50], Step [9/469], Loss: 0.2389, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [31/50], Step [10/469], Loss: 0.3104, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [31/50], Step [11/469], Loss: 0.3815, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [31/50], Step [12/469], Loss: 0.5471, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [31/50], Step [13/469], Loss: 0.4543, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [31/50], Step [14/469], Loss: 0.3732, batch time: 0.68, accuracy:  91.41%\n",
      "Epoch [31/50], Step [15/469], Loss: 0.4767, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [31/50], Step [16/469], Loss: 0.2719, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [31/50], Step [17/469], Loss: 0.2926, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [31/50], Step [18/469], Loss: 0.4866, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [31/50], Step [19/469], Loss: 0.5632, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [31/50], Step [20/469], Loss: 0.3238, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [31/50], Step [21/469], Loss: 0.4801, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [31/50], Step [22/469], Loss: 0.4465, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [31/50], Step [23/469], Loss: 0.5687, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [31/50], Step [24/469], Loss: 0.3062, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [31/50], Step [25/469], Loss: 0.2715, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [31/50], Step [26/469], Loss: 0.4154, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [31/50], Step [27/469], Loss: 0.4004, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [31/50], Step [28/469], Loss: 0.3898, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [31/50], Step [29/469], Loss: 0.3427, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [31/50], Step [30/469], Loss: 0.4589, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [31/50], Step [31/469], Loss: 0.3304, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [31/50], Step [32/469], Loss: 0.3708, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [31/50], Step [33/469], Loss: 0.3183, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [31/50], Step [34/469], Loss: 0.1922, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [31/50], Step [35/469], Loss: 0.3141, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [31/50], Step [36/469], Loss: 0.5033, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [31/50], Step [37/469], Loss: 0.3380, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [38/469], Loss: 0.3662, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [31/50], Step [39/469], Loss: 0.3549, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [31/50], Step [40/469], Loss: 0.4628, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [31/50], Step [41/469], Loss: 0.4143, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [42/469], Loss: 0.5092, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [31/50], Step [43/469], Loss: 0.4454, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [31/50], Step [44/469], Loss: 0.3195, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [31/50], Step [45/469], Loss: 0.4674, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [31/50], Step [46/469], Loss: 0.5009, batch time: 0.88, accuracy:  85.16%\n",
      "Epoch [31/50], Step [47/469], Loss: 0.5427, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [31/50], Step [48/469], Loss: 0.3705, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [31/50], Step [49/469], Loss: 0.3023, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [31/50], Step [50/469], Loss: 0.4076, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [31/50], Step [51/469], Loss: 0.3857, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [31/50], Step [52/469], Loss: 0.4582, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [31/50], Step [53/469], Loss: 0.3495, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [31/50], Step [54/469], Loss: 0.5428, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [31/50], Step [55/469], Loss: 0.4589, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [31/50], Step [56/469], Loss: 0.2845, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [31/50], Step [57/469], Loss: 0.4261, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [31/50], Step [58/469], Loss: 0.3226, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [31/50], Step [59/469], Loss: 0.5739, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [31/50], Step [60/469], Loss: 0.4564, batch time: 0.50, accuracy:  82.03%\n",
      "Epoch [31/50], Step [61/469], Loss: 0.2989, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [31/50], Step [62/469], Loss: 0.3875, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [31/50], Step [63/469], Loss: 0.3408, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [31/50], Step [64/469], Loss: 0.3918, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [31/50], Step [65/469], Loss: 0.5864, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [31/50], Step [66/469], Loss: 0.5288, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [31/50], Step [67/469], Loss: 0.3667, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [31/50], Step [68/469], Loss: 0.4474, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [31/50], Step [69/469], Loss: 0.3584, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [31/50], Step [70/469], Loss: 0.4307, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [31/50], Step [71/469], Loss: 0.4665, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [31/50], Step [72/469], Loss: 0.5070, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [31/50], Step [73/469], Loss: 0.4041, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [31/50], Step [74/469], Loss: 0.3367, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [31/50], Step [75/469], Loss: 0.4325, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [31/50], Step [76/469], Loss: 0.4587, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [31/50], Step [77/469], Loss: 0.4490, batch time: 0.68, accuracy:  85.94%\n",
      "Epoch [31/50], Step [78/469], Loss: 0.3905, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [31/50], Step [79/469], Loss: 0.4220, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [31/50], Step [80/469], Loss: 0.3986, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [31/50], Step [81/469], Loss: 0.5380, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [31/50], Step [82/469], Loss: 0.4716, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [31/50], Step [83/469], Loss: 0.4373, batch time: 0.56, accuracy:  82.81%\n",
      "Epoch [31/50], Step [84/469], Loss: 0.2762, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [31/50], Step [85/469], Loss: 0.5615, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [86/469], Loss: 0.5530, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [31/50], Step [87/469], Loss: 0.4217, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [31/50], Step [88/469], Loss: 0.2899, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [31/50], Step [89/469], Loss: 0.3491, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [31/50], Step [90/469], Loss: 0.4076, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [31/50], Step [91/469], Loss: 0.3337, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [31/50], Step [92/469], Loss: 0.3705, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [31/50], Step [93/469], Loss: 0.2419, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [31/50], Step [94/469], Loss: 0.3721, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [31/50], Step [95/469], Loss: 0.4390, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [31/50], Step [96/469], Loss: 0.3554, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [97/469], Loss: 0.4374, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [31/50], Step [98/469], Loss: 0.4796, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [31/50], Step [99/469], Loss: 0.3058, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [31/50], Step [100/469], Loss: 0.4671, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [31/50], Step [101/469], Loss: 0.3610, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [31/50], Step [102/469], Loss: 0.3551, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [31/50], Step [103/469], Loss: 0.2921, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [31/50], Step [104/469], Loss: 0.2406, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [31/50], Step [105/469], Loss: 0.3299, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [106/469], Loss: 0.3820, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [31/50], Step [107/469], Loss: 0.3969, batch time: 0.80, accuracy:  84.38%\n",
      "Epoch [31/50], Step [108/469], Loss: 0.4229, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [31/50], Step [109/469], Loss: 0.3951, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [31/50], Step [110/469], Loss: 0.3418, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [31/50], Step [111/469], Loss: 0.2949, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [31/50], Step [112/469], Loss: 0.4202, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [31/50], Step [113/469], Loss: 0.5331, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [31/50], Step [114/469], Loss: 0.2353, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [31/50], Step [115/469], Loss: 0.5547, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [31/50], Step [116/469], Loss: 0.5126, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [31/50], Step [117/469], Loss: 0.3197, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [118/469], Loss: 0.4081, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [31/50], Step [119/469], Loss: 0.3137, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [31/50], Step [120/469], Loss: 0.3652, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [31/50], Step [121/469], Loss: 0.3647, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [31/50], Step [122/469], Loss: 0.4920, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [31/50], Step [123/469], Loss: 0.4234, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [31/50], Step [124/469], Loss: 0.3880, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [31/50], Step [125/469], Loss: 0.3856, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [31/50], Step [126/469], Loss: 0.3825, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [31/50], Step [127/469], Loss: 0.4826, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [31/50], Step [128/469], Loss: 0.2243, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [31/50], Step [129/469], Loss: 0.3467, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [31/50], Step [130/469], Loss: 0.4430, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [31/50], Step [131/469], Loss: 0.4304, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [31/50], Step [132/469], Loss: 0.4525, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [31/50], Step [133/469], Loss: 0.4442, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [31/50], Step [134/469], Loss: 0.4029, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [31/50], Step [135/469], Loss: 0.3959, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [31/50], Step [136/469], Loss: 0.2951, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [31/50], Step [137/469], Loss: 0.3629, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [31/50], Step [138/469], Loss: 0.2549, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [31/50], Step [139/469], Loss: 0.3227, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [31/50], Step [140/469], Loss: 0.3779, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [31/50], Step [141/469], Loss: 0.3814, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [31/50], Step [142/469], Loss: 0.2977, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [31/50], Step [143/469], Loss: 0.3400, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [31/50], Step [144/469], Loss: 0.4116, batch time: 0.76, accuracy:  89.84%\n",
      "Epoch [31/50], Step [145/469], Loss: 0.3610, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [31/50], Step [146/469], Loss: 0.3066, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [31/50], Step [147/469], Loss: 0.4162, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [31/50], Step [148/469], Loss: 0.4147, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [31/50], Step [149/469], Loss: 0.3518, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [31/50], Step [150/469], Loss: 0.2931, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [31/50], Step [151/469], Loss: 0.2570, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [31/50], Step [152/469], Loss: 0.4667, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [31/50], Step [153/469], Loss: 0.5173, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [31/50], Step [154/469], Loss: 0.3603, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [31/50], Step [155/469], Loss: 0.3266, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [31/50], Step [156/469], Loss: 0.3130, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [31/50], Step [157/469], Loss: 0.5298, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [31/50], Step [158/469], Loss: 0.4036, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [31/50], Step [159/469], Loss: 0.3800, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [160/469], Loss: 0.4324, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [31/50], Step [161/469], Loss: 0.4625, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [31/50], Step [162/469], Loss: 0.4474, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [31/50], Step [163/469], Loss: 0.3167, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [31/50], Step [164/469], Loss: 0.3979, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [31/50], Step [165/469], Loss: 0.3143, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [31/50], Step [166/469], Loss: 0.4925, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [167/469], Loss: 0.4303, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [31/50], Step [168/469], Loss: 0.3508, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [31/50], Step [169/469], Loss: 0.5777, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [31/50], Step [170/469], Loss: 0.3332, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [31/50], Step [171/469], Loss: 0.4720, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [31/50], Step [172/469], Loss: 0.2234, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [31/50], Step [173/469], Loss: 0.3712, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [31/50], Step [174/469], Loss: 0.3673, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [31/50], Step [175/469], Loss: 0.4801, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [31/50], Step [176/469], Loss: 0.3939, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [31/50], Step [177/469], Loss: 0.3303, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [31/50], Step [178/469], Loss: 0.5085, batch time: 0.64, accuracy:  82.03%\n",
      "Epoch [31/50], Step [179/469], Loss: 0.3767, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [31/50], Step [180/469], Loss: 0.3607, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [31/50], Step [181/469], Loss: 0.2364, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [31/50], Step [182/469], Loss: 0.4093, batch time: 0.68, accuracy:  87.50%\n",
      "Epoch [31/50], Step [183/469], Loss: 0.5446, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [31/50], Step [184/469], Loss: 0.3098, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [31/50], Step [185/469], Loss: 0.4408, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [31/50], Step [186/469], Loss: 0.2959, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [31/50], Step [187/469], Loss: 0.3911, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [31/50], Step [188/469], Loss: 0.5087, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [31/50], Step [189/469], Loss: 0.5329, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [31/50], Step [190/469], Loss: 0.4159, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [31/50], Step [191/469], Loss: 0.4949, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [31/50], Step [192/469], Loss: 0.4750, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [31/50], Step [193/469], Loss: 0.2449, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [31/50], Step [194/469], Loss: 0.4773, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [31/50], Step [195/469], Loss: 0.4215, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [31/50], Step [196/469], Loss: 0.4361, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [31/50], Step [197/469], Loss: 0.3642, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [31/50], Step [198/469], Loss: 0.2954, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [31/50], Step [199/469], Loss: 0.4057, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [200/469], Loss: 0.3857, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [31/50], Step [201/469], Loss: 0.5420, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [31/50], Step [202/469], Loss: 0.4405, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [31/50], Step [203/469], Loss: 0.4140, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [31/50], Step [204/469], Loss: 0.4256, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [31/50], Step [205/469], Loss: 0.3396, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [31/50], Step [206/469], Loss: 0.3927, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [31/50], Step [207/469], Loss: 0.3314, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [31/50], Step [208/469], Loss: 0.3240, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [31/50], Step [209/469], Loss: 0.3416, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [31/50], Step [210/469], Loss: 0.3108, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [31/50], Step [211/469], Loss: 0.4122, batch time: 0.65, accuracy:  85.94%\n",
      "Epoch [31/50], Step [212/469], Loss: 0.2945, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [31/50], Step [213/469], Loss: 0.3118, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [31/50], Step [214/469], Loss: 0.4177, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [31/50], Step [215/469], Loss: 0.3625, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [31/50], Step [216/469], Loss: 0.3095, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [31/50], Step [217/469], Loss: 0.4110, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [31/50], Step [218/469], Loss: 0.4244, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [31/50], Step [219/469], Loss: 0.3690, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [31/50], Step [220/469], Loss: 0.3060, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [31/50], Step [221/469], Loss: 0.5975, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [31/50], Step [222/469], Loss: 0.4159, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [31/50], Step [223/469], Loss: 0.4275, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [31/50], Step [224/469], Loss: 0.4319, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [31/50], Step [225/469], Loss: 0.3082, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [31/50], Step [226/469], Loss: 0.2917, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [31/50], Step [227/469], Loss: 0.3977, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [31/50], Step [228/469], Loss: 0.6473, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [31/50], Step [229/469], Loss: 0.4347, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [31/50], Step [230/469], Loss: 0.2630, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [31/50], Step [231/469], Loss: 0.3366, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [31/50], Step [232/469], Loss: 0.3941, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [31/50], Step [233/469], Loss: 0.4850, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [31/50], Step [234/469], Loss: 0.4770, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [235/469], Loss: 0.4483, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [31/50], Step [236/469], Loss: 0.4100, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [31/50], Step [237/469], Loss: 0.3399, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [31/50], Step [238/469], Loss: 0.3131, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [31/50], Step [239/469], Loss: 0.5028, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [31/50], Step [240/469], Loss: 0.3324, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [31/50], Step [241/469], Loss: 0.3933, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [31/50], Step [242/469], Loss: 0.4593, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [31/50], Step [243/469], Loss: 0.4184, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [31/50], Step [244/469], Loss: 0.3319, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [31/50], Step [245/469], Loss: 0.4440, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [31/50], Step [246/469], Loss: 0.3780, batch time: 0.61, accuracy:  85.16%\n",
      "Epoch [31/50], Step [247/469], Loss: 0.4874, batch time: 0.61, accuracy:  82.81%\n",
      "Epoch [31/50], Step [248/469], Loss: 0.4799, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [31/50], Step [249/469], Loss: 0.4114, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [31/50], Step [250/469], Loss: 0.5225, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [31/50], Step [251/469], Loss: 0.4554, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [31/50], Step [252/469], Loss: 0.2711, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [31/50], Step [253/469], Loss: 0.4621, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [31/50], Step [254/469], Loss: 0.4682, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [31/50], Step [255/469], Loss: 0.6098, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [31/50], Step [256/469], Loss: 0.3379, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [31/50], Step [257/469], Loss: 0.2820, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [31/50], Step [258/469], Loss: 0.4504, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [31/50], Step [259/469], Loss: 0.3342, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [31/50], Step [260/469], Loss: 0.4436, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [261/469], Loss: 0.4385, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [31/50], Step [262/469], Loss: 0.2516, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [31/50], Step [263/469], Loss: 0.3799, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [31/50], Step [264/469], Loss: 0.3848, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [31/50], Step [265/469], Loss: 0.4166, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [31/50], Step [266/469], Loss: 0.4197, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [267/469], Loss: 0.3894, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [31/50], Step [268/469], Loss: 0.3984, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [31/50], Step [269/469], Loss: 0.2502, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [31/50], Step [270/469], Loss: 0.4097, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [31/50], Step [271/469], Loss: 0.3131, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [31/50], Step [272/469], Loss: 0.5375, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [31/50], Step [273/469], Loss: 0.2648, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [31/50], Step [274/469], Loss: 0.4662, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [31/50], Step [275/469], Loss: 0.5157, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [31/50], Step [276/469], Loss: 0.3797, batch time: 0.94, accuracy:  85.16%\n",
      "Epoch [31/50], Step [277/469], Loss: 0.2955, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [31/50], Step [278/469], Loss: 0.5062, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [31/50], Step [279/469], Loss: 0.3092, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [31/50], Step [280/469], Loss: 0.4757, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [31/50], Step [281/469], Loss: 0.3999, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [282/469], Loss: 0.3048, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [31/50], Step [283/469], Loss: 0.3214, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [31/50], Step [284/469], Loss: 0.5173, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [31/50], Step [285/469], Loss: 0.4535, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [31/50], Step [286/469], Loss: 0.3284, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [31/50], Step [287/469], Loss: 0.3811, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [31/50], Step [288/469], Loss: 0.3241, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [31/50], Step [289/469], Loss: 0.4800, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [31/50], Step [290/469], Loss: 0.2788, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [31/50], Step [291/469], Loss: 0.4273, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [31/50], Step [292/469], Loss: 0.2806, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [31/50], Step [293/469], Loss: 0.4537, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [31/50], Step [294/469], Loss: 0.2978, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [31/50], Step [295/469], Loss: 0.4664, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [31/50], Step [296/469], Loss: 0.3340, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [31/50], Step [297/469], Loss: 0.2768, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [31/50], Step [298/469], Loss: 0.3023, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [31/50], Step [299/469], Loss: 0.4349, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [31/50], Step [300/469], Loss: 0.3482, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [31/50], Step [301/469], Loss: 0.4081, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [31/50], Step [302/469], Loss: 0.3222, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [31/50], Step [303/469], Loss: 0.3994, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [31/50], Step [304/469], Loss: 0.3382, batch time: 0.85, accuracy:  89.06%\n",
      "Epoch [31/50], Step [305/469], Loss: 0.3397, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [31/50], Step [306/469], Loss: 0.2528, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [31/50], Step [307/469], Loss: 0.3684, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [31/50], Step [308/469], Loss: 0.3320, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [31/50], Step [309/469], Loss: 0.4190, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [31/50], Step [310/469], Loss: 0.3006, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [31/50], Step [311/469], Loss: 0.2716, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [312/469], Loss: 0.4451, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [31/50], Step [313/469], Loss: 0.4658, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [31/50], Step [314/469], Loss: 0.4712, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [31/50], Step [315/469], Loss: 0.4581, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [31/50], Step [316/469], Loss: 0.5862, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [31/50], Step [317/469], Loss: 0.4289, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [31/50], Step [318/469], Loss: 0.2648, batch time: 0.55, accuracy:  95.31%\n",
      "Epoch [31/50], Step [319/469], Loss: 0.2789, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [31/50], Step [320/469], Loss: 0.3449, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [31/50], Step [321/469], Loss: 0.3960, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [31/50], Step [322/469], Loss: 0.4558, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [31/50], Step [323/469], Loss: 0.4072, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [31/50], Step [324/469], Loss: 0.4483, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [31/50], Step [325/469], Loss: 0.5192, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [31/50], Step [326/469], Loss: 0.3294, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [31/50], Step [327/469], Loss: 0.3564, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [31/50], Step [328/469], Loss: 0.4614, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [31/50], Step [329/469], Loss: 0.4027, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [31/50], Step [330/469], Loss: 0.4194, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [31/50], Step [331/469], Loss: 0.4278, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [31/50], Step [332/469], Loss: 0.3354, batch time: 0.60, accuracy:  85.94%\n",
      "Epoch [31/50], Step [333/469], Loss: 0.3397, batch time: 0.68, accuracy:  91.41%\n",
      "Epoch [31/50], Step [334/469], Loss: 0.4101, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [31/50], Step [335/469], Loss: 0.2798, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [31/50], Step [336/469], Loss: 0.2675, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [31/50], Step [337/469], Loss: 0.4681, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [31/50], Step [338/469], Loss: 0.4899, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [31/50], Step [339/469], Loss: 0.3400, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [31/50], Step [340/469], Loss: 0.5744, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [31/50], Step [341/469], Loss: 0.3090, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [31/50], Step [342/469], Loss: 0.3998, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [31/50], Step [343/469], Loss: 0.3386, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [31/50], Step [344/469], Loss: 0.3131, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [31/50], Step [345/469], Loss: 0.3281, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [31/50], Step [346/469], Loss: 0.2620, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [31/50], Step [347/469], Loss: 0.4856, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [348/469], Loss: 0.4136, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [31/50], Step [349/469], Loss: 0.2627, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [31/50], Step [350/469], Loss: 0.3535, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [31/50], Step [351/469], Loss: 0.3740, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [31/50], Step [352/469], Loss: 0.3386, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [31/50], Step [353/469], Loss: 0.4734, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [31/50], Step [354/469], Loss: 0.4148, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [31/50], Step [355/469], Loss: 0.2642, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [31/50], Step [356/469], Loss: 0.4183, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [31/50], Step [357/469], Loss: 0.6358, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [31/50], Step [358/469], Loss: 0.4355, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [31/50], Step [359/469], Loss: 0.4742, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [31/50], Step [360/469], Loss: 0.5911, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [31/50], Step [361/469], Loss: 0.3356, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [31/50], Step [362/469], Loss: 0.3837, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [31/50], Step [363/469], Loss: 0.4244, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [364/469], Loss: 0.3049, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [31/50], Step [365/469], Loss: 0.3995, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [31/50], Step [366/469], Loss: 0.3484, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [31/50], Step [367/469], Loss: 0.5062, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [31/50], Step [368/469], Loss: 0.6194, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [31/50], Step [369/469], Loss: 0.4572, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [31/50], Step [370/469], Loss: 0.4278, batch time: 0.64, accuracy:  85.94%\n",
      "Epoch [31/50], Step [371/469], Loss: 0.3143, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [31/50], Step [372/469], Loss: 0.4014, batch time: 0.70, accuracy:  89.06%\n",
      "Epoch [31/50], Step [373/469], Loss: 0.4917, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [31/50], Step [374/469], Loss: 0.4324, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [31/50], Step [375/469], Loss: 0.3253, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [31/50], Step [376/469], Loss: 0.3835, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [31/50], Step [377/469], Loss: 0.3639, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [31/50], Step [378/469], Loss: 0.4770, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [31/50], Step [379/469], Loss: 0.4165, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [31/50], Step [380/469], Loss: 0.4449, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [381/469], Loss: 0.4088, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [31/50], Step [382/469], Loss: 0.3382, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [31/50], Step [383/469], Loss: 0.3360, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [31/50], Step [384/469], Loss: 0.2963, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [31/50], Step [385/469], Loss: 0.3749, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [31/50], Step [386/469], Loss: 0.5483, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [31/50], Step [387/469], Loss: 0.4150, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [31/50], Step [388/469], Loss: 0.3062, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [31/50], Step [389/469], Loss: 0.4253, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [31/50], Step [390/469], Loss: 0.3216, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [31/50], Step [391/469], Loss: 0.4462, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [31/50], Step [392/469], Loss: 0.1915, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [31/50], Step [393/469], Loss: 0.4653, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [31/50], Step [394/469], Loss: 0.3266, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [31/50], Step [395/469], Loss: 0.4138, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [31/50], Step [396/469], Loss: 0.3310, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [31/50], Step [397/469], Loss: 0.4496, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [398/469], Loss: 0.3184, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [31/50], Step [399/469], Loss: 0.5304, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [31/50], Step [400/469], Loss: 0.2803, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [31/50], Step [401/469], Loss: 0.4010, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [31/50], Step [402/469], Loss: 0.3726, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [31/50], Step [403/469], Loss: 0.3493, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [31/50], Step [404/469], Loss: 0.5132, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [31/50], Step [405/469], Loss: 0.3327, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [31/50], Step [406/469], Loss: 0.2806, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [31/50], Step [407/469], Loss: 0.3586, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [31/50], Step [408/469], Loss: 0.3169, batch time: 0.64, accuracy:  93.75%\n",
      "Epoch [31/50], Step [409/469], Loss: 0.3289, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [31/50], Step [410/469], Loss: 0.3774, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [31/50], Step [411/469], Loss: 0.4734, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [31/50], Step [412/469], Loss: 0.3795, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [31/50], Step [413/469], Loss: 0.3816, batch time: 0.73, accuracy:  86.72%\n",
      "Epoch [31/50], Step [414/469], Loss: 0.2865, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [31/50], Step [415/469], Loss: 0.6654, batch time: 0.62, accuracy:  84.38%\n",
      "Epoch [31/50], Step [416/469], Loss: 0.3012, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [31/50], Step [417/469], Loss: 0.3144, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [31/50], Step [418/469], Loss: 0.2899, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [31/50], Step [419/469], Loss: 0.2554, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [31/50], Step [420/469], Loss: 0.2965, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [31/50], Step [421/469], Loss: 0.5640, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [31/50], Step [422/469], Loss: 0.2787, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [31/50], Step [423/469], Loss: 0.3508, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [424/469], Loss: 0.3789, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [31/50], Step [425/469], Loss: 0.5828, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [31/50], Step [426/469], Loss: 0.3391, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [31/50], Step [427/469], Loss: 0.3991, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [31/50], Step [428/469], Loss: 0.3224, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [31/50], Step [429/469], Loss: 0.3603, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [31/50], Step [430/469], Loss: 0.4584, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [31/50], Step [431/469], Loss: 0.4370, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [31/50], Step [432/469], Loss: 0.3042, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [31/50], Step [433/469], Loss: 0.2895, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [31/50], Step [434/469], Loss: 0.4981, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [31/50], Step [435/469], Loss: 0.3075, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [31/50], Step [436/469], Loss: 0.4239, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [31/50], Step [437/469], Loss: 0.2309, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [31/50], Step [438/469], Loss: 0.2915, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [31/50], Step [439/469], Loss: 0.3854, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [31/50], Step [440/469], Loss: 0.2681, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [31/50], Step [441/469], Loss: 0.2762, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [31/50], Step [442/469], Loss: 0.4158, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [31/50], Step [443/469], Loss: 0.3718, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [31/50], Step [444/469], Loss: 0.3094, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [31/50], Step [445/469], Loss: 0.3737, batch time: 0.77, accuracy:  89.84%\n",
      "Epoch [31/50], Step [446/469], Loss: 0.4221, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [31/50], Step [447/469], Loss: 0.4193, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [31/50], Step [448/469], Loss: 0.4517, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [31/50], Step [449/469], Loss: 0.6433, batch time: 0.49, accuracy:  79.69%\n",
      "Epoch [31/50], Step [450/469], Loss: 0.3599, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [31/50], Step [451/469], Loss: 0.5014, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [31/50], Step [452/469], Loss: 0.4598, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [31/50], Step [453/469], Loss: 0.3625, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [31/50], Step [454/469], Loss: 0.3393, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [31/50], Step [455/469], Loss: 0.3019, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [31/50], Step [456/469], Loss: 0.3625, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [31/50], Step [457/469], Loss: 0.3847, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [31/50], Step [458/469], Loss: 0.2978, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [31/50], Step [459/469], Loss: 0.3505, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [31/50], Step [460/469], Loss: 0.3529, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [461/469], Loss: 0.3057, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [31/50], Step [462/469], Loss: 0.4841, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [31/50], Step [463/469], Loss: 0.3088, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [31/50], Step [464/469], Loss: 0.4790, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [31/50], Step [465/469], Loss: 0.4240, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [31/50], Step [466/469], Loss: 0.4778, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [31/50], Step [467/469], Loss: 0.5083, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [31/50], Step [468/469], Loss: 0.2777, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [31/50], Step [469/469], Loss: 0.6401, batch time: 0.43, accuracy:  79.17%\n",
      "Epoch [32/50], Step [1/469], Loss: 0.5391, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [32/50], Step [2/469], Loss: 0.3008, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [32/50], Step [3/469], Loss: 0.4864, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [32/50], Step [4/469], Loss: 0.3700, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [32/50], Step [5/469], Loss: 0.3188, batch time: 0.77, accuracy:  87.50%\n",
      "Epoch [32/50], Step [6/469], Loss: 0.3746, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [32/50], Step [7/469], Loss: 0.4715, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [32/50], Step [8/469], Loss: 0.3128, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [9/469], Loss: 0.2239, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [32/50], Step [10/469], Loss: 0.4162, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [32/50], Step [11/469], Loss: 0.4726, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [32/50], Step [12/469], Loss: 0.3993, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [32/50], Step [13/469], Loss: 0.4900, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [32/50], Step [14/469], Loss: 0.3055, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [32/50], Step [15/469], Loss: 0.3380, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [16/469], Loss: 0.4338, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [32/50], Step [17/469], Loss: 0.3368, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [32/50], Step [18/469], Loss: 0.3338, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [32/50], Step [19/469], Loss: 0.2881, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [20/469], Loss: 0.4730, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [32/50], Step [21/469], Loss: 0.4535, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [32/50], Step [22/469], Loss: 0.4335, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [32/50], Step [23/469], Loss: 0.3842, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [24/469], Loss: 0.3525, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [32/50], Step [25/469], Loss: 0.2220, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [32/50], Step [26/469], Loss: 0.3162, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [27/469], Loss: 0.4064, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [32/50], Step [28/469], Loss: 0.4053, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [32/50], Step [29/469], Loss: 0.3755, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [32/50], Step [30/469], Loss: 0.5322, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [32/50], Step [31/469], Loss: 0.3801, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [32/50], Step [32/469], Loss: 0.4167, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [32/50], Step [33/469], Loss: 0.2965, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [32/50], Step [34/469], Loss: 0.3555, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [32/50], Step [35/469], Loss: 0.3583, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [32/50], Step [36/469], Loss: 0.2729, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [32/50], Step [37/469], Loss: 0.2449, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [32/50], Step [38/469], Loss: 0.5097, batch time: 0.61, accuracy:  84.38%\n",
      "Epoch [32/50], Step [39/469], Loss: 0.4753, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [32/50], Step [40/469], Loss: 0.2517, batch time: 0.61, accuracy:  92.97%\n",
      "Epoch [32/50], Step [41/469], Loss: 0.4400, batch time: 0.67, accuracy:  89.06%\n",
      "Epoch [32/50], Step [42/469], Loss: 0.4137, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [32/50], Step [43/469], Loss: 0.3280, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [32/50], Step [44/469], Loss: 0.4322, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [32/50], Step [45/469], Loss: 0.4940, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [32/50], Step [46/469], Loss: 0.2711, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [32/50], Step [47/469], Loss: 0.6039, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [32/50], Step [48/469], Loss: 0.5303, batch time: 0.59, accuracy:  84.38%\n",
      "Epoch [32/50], Step [49/469], Loss: 0.3523, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [32/50], Step [50/469], Loss: 0.4045, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [32/50], Step [51/469], Loss: 0.3902, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [32/50], Step [52/469], Loss: 0.4317, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [32/50], Step [53/469], Loss: 0.2845, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [32/50], Step [54/469], Loss: 0.3901, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [32/50], Step [55/469], Loss: 0.3662, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [32/50], Step [56/469], Loss: 0.3010, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [32/50], Step [57/469], Loss: 0.1989, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [32/50], Step [58/469], Loss: 0.4742, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [32/50], Step [59/469], Loss: 0.4961, batch time: 0.53, accuracy:  82.03%\n",
      "Epoch [32/50], Step [60/469], Loss: 0.4846, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [32/50], Step [61/469], Loss: 0.3580, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [32/50], Step [62/469], Loss: 0.2456, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [32/50], Step [63/469], Loss: 0.3807, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [32/50], Step [64/469], Loss: 0.3401, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [32/50], Step [65/469], Loss: 0.6152, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [32/50], Step [66/469], Loss: 0.3565, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [32/50], Step [67/469], Loss: 0.4041, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [32/50], Step [68/469], Loss: 0.3649, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [69/469], Loss: 0.4528, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [32/50], Step [70/469], Loss: 0.2645, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [32/50], Step [71/469], Loss: 0.5424, batch time: 0.59, accuracy:  82.03%\n",
      "Epoch [32/50], Step [72/469], Loss: 0.4137, batch time: 0.85, accuracy:  85.94%\n",
      "Epoch [32/50], Step [73/469], Loss: 0.3681, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [32/50], Step [74/469], Loss: 0.3266, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [32/50], Step [75/469], Loss: 0.2550, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [32/50], Step [76/469], Loss: 0.3903, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [32/50], Step [77/469], Loss: 0.5025, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [32/50], Step [78/469], Loss: 0.3857, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [79/469], Loss: 0.3686, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [32/50], Step [80/469], Loss: 0.3000, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [32/50], Step [81/469], Loss: 0.3916, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [82/469], Loss: 0.4232, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [32/50], Step [83/469], Loss: 0.4868, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [32/50], Step [84/469], Loss: 0.3599, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [32/50], Step [85/469], Loss: 0.3730, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [32/50], Step [86/469], Loss: 0.2938, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [32/50], Step [87/469], Loss: 0.3701, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [32/50], Step [88/469], Loss: 0.2947, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [32/50], Step [89/469], Loss: 0.3479, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [32/50], Step [90/469], Loss: 0.3922, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [32/50], Step [91/469], Loss: 0.4253, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [32/50], Step [92/469], Loss: 0.3754, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [93/469], Loss: 0.4056, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [32/50], Step [94/469], Loss: 0.4013, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [32/50], Step [95/469], Loss: 0.4963, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [32/50], Step [96/469], Loss: 0.3582, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [97/469], Loss: 0.3584, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [32/50], Step [98/469], Loss: 0.3191, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [32/50], Step [99/469], Loss: 0.5169, batch time: 0.52, accuracy:  81.25%\n",
      "Epoch [32/50], Step [100/469], Loss: 0.5176, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [32/50], Step [101/469], Loss: 0.3551, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [32/50], Step [102/469], Loss: 0.2858, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [103/469], Loss: 0.4661, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [32/50], Step [104/469], Loss: 0.5942, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [32/50], Step [105/469], Loss: 0.2686, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [32/50], Step [106/469], Loss: 0.3353, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [32/50], Step [107/469], Loss: 0.3501, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [32/50], Step [108/469], Loss: 0.2938, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [32/50], Step [109/469], Loss: 0.2815, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [32/50], Step [110/469], Loss: 0.5463, batch time: 0.54, accuracy:  78.91%\n",
      "Epoch [32/50], Step [111/469], Loss: 0.3419, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [32/50], Step [112/469], Loss: 0.3442, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [32/50], Step [113/469], Loss: 0.4109, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [32/50], Step [114/469], Loss: 0.3789, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [32/50], Step [115/469], Loss: 0.3667, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [32/50], Step [116/469], Loss: 0.2982, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [117/469], Loss: 0.5872, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [32/50], Step [118/469], Loss: 0.3600, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [32/50], Step [119/469], Loss: 0.3367, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [32/50], Step [120/469], Loss: 0.3511, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [32/50], Step [121/469], Loss: 0.3240, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [32/50], Step [122/469], Loss: 0.3471, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [32/50], Step [123/469], Loss: 0.4313, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [32/50], Step [124/469], Loss: 0.3549, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [32/50], Step [125/469], Loss: 0.3449, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [32/50], Step [126/469], Loss: 0.2781, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [32/50], Step [127/469], Loss: 0.4346, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [32/50], Step [128/469], Loss: 0.2800, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [32/50], Step [129/469], Loss: 0.2599, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [32/50], Step [130/469], Loss: 0.4567, batch time: 0.49, accuracy:  82.03%\n",
      "Epoch [32/50], Step [131/469], Loss: 0.3756, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [32/50], Step [132/469], Loss: 0.3826, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [32/50], Step [133/469], Loss: 0.3633, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [32/50], Step [134/469], Loss: 0.4631, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [32/50], Step [135/469], Loss: 0.5243, batch time: 0.59, accuracy:  84.38%\n",
      "Epoch [32/50], Step [136/469], Loss: 0.5596, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [32/50], Step [137/469], Loss: 0.3355, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [32/50], Step [138/469], Loss: 0.3833, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [32/50], Step [139/469], Loss: 0.4645, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [32/50], Step [140/469], Loss: 0.4291, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [32/50], Step [141/469], Loss: 0.3016, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [32/50], Step [142/469], Loss: 0.3339, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [32/50], Step [143/469], Loss: 0.2486, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [32/50], Step [144/469], Loss: 0.3556, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [32/50], Step [145/469], Loss: 0.3987, batch time: 0.86, accuracy:  89.06%\n",
      "Epoch [32/50], Step [146/469], Loss: 0.2885, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [147/469], Loss: 0.3657, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [148/469], Loss: 0.4191, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [149/469], Loss: 0.1954, batch time: 0.54, accuracy:  96.88%\n",
      "Epoch [32/50], Step [150/469], Loss: 0.4279, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [32/50], Step [151/469], Loss: 0.2423, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [32/50], Step [152/469], Loss: 0.3523, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [32/50], Step [153/469], Loss: 0.3442, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [32/50], Step [154/469], Loss: 0.4014, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [32/50], Step [155/469], Loss: 0.3076, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [32/50], Step [156/469], Loss: 0.2613, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [157/469], Loss: 0.3503, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [32/50], Step [158/469], Loss: 0.3471, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [32/50], Step [159/469], Loss: 0.4798, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [32/50], Step [160/469], Loss: 0.4339, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [161/469], Loss: 0.4367, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [162/469], Loss: 0.3483, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [32/50], Step [163/469], Loss: 0.5113, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [32/50], Step [164/469], Loss: 0.3500, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [32/50], Step [165/469], Loss: 0.3206, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [32/50], Step [166/469], Loss: 0.3916, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [167/469], Loss: 0.4473, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [32/50], Step [168/469], Loss: 0.4359, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [32/50], Step [169/469], Loss: 0.3745, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [32/50], Step [170/469], Loss: 0.3964, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [32/50], Step [171/469], Loss: 0.3285, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [172/469], Loss: 0.3636, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [32/50], Step [173/469], Loss: 0.5821, batch time: 0.54, accuracy:  82.03%\n",
      "Epoch [32/50], Step [174/469], Loss: 0.2680, batch time: 0.84, accuracy:  90.62%\n",
      "Epoch [32/50], Step [175/469], Loss: 0.2833, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [32/50], Step [176/469], Loss: 0.4443, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [177/469], Loss: 0.5292, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [32/50], Step [178/469], Loss: 0.4408, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [179/469], Loss: 0.3395, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [180/469], Loss: 0.4215, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [32/50], Step [181/469], Loss: 0.4131, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [32/50], Step [182/469], Loss: 0.3792, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [32/50], Step [183/469], Loss: 0.5635, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [32/50], Step [184/469], Loss: 0.3513, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [32/50], Step [185/469], Loss: 0.4159, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [32/50], Step [186/469], Loss: 0.3755, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [32/50], Step [187/469], Loss: 0.3596, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [32/50], Step [188/469], Loss: 0.3962, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [32/50], Step [189/469], Loss: 0.3937, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [32/50], Step [190/469], Loss: 0.3875, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [32/50], Step [191/469], Loss: 0.3578, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [32/50], Step [192/469], Loss: 0.3961, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [32/50], Step [193/469], Loss: 0.4244, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [32/50], Step [194/469], Loss: 0.3229, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [32/50], Step [195/469], Loss: 0.3782, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [32/50], Step [196/469], Loss: 0.4073, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [32/50], Step [197/469], Loss: 0.5040, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [32/50], Step [198/469], Loss: 0.3926, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [32/50], Step [199/469], Loss: 0.3179, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [32/50], Step [200/469], Loss: 0.4212, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [32/50], Step [201/469], Loss: 0.5683, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [32/50], Step [202/469], Loss: 0.5953, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [32/50], Step [203/469], Loss: 0.3683, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [32/50], Step [204/469], Loss: 0.4015, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [32/50], Step [205/469], Loss: 0.3335, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [32/50], Step [206/469], Loss: 0.3257, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [32/50], Step [207/469], Loss: 0.4500, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [32/50], Step [208/469], Loss: 0.5198, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [32/50], Step [209/469], Loss: 0.3941, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [32/50], Step [210/469], Loss: 0.3730, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [32/50], Step [211/469], Loss: 0.5260, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [32/50], Step [212/469], Loss: 0.2935, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [32/50], Step [213/469], Loss: 0.3892, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [32/50], Step [214/469], Loss: 0.3517, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [32/50], Step [215/469], Loss: 0.3608, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [32/50], Step [216/469], Loss: 0.4935, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [32/50], Step [217/469], Loss: 0.2858, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [32/50], Step [218/469], Loss: 0.2978, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [32/50], Step [219/469], Loss: 0.5141, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [32/50], Step [220/469], Loss: 0.4433, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [32/50], Step [221/469], Loss: 0.3625, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [32/50], Step [222/469], Loss: 0.2410, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [32/50], Step [223/469], Loss: 0.3700, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [32/50], Step [224/469], Loss: 0.4495, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [32/50], Step [225/469], Loss: 0.2866, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [32/50], Step [226/469], Loss: 0.3670, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [32/50], Step [227/469], Loss: 0.2465, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [32/50], Step [228/469], Loss: 0.4931, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [32/50], Step [229/469], Loss: 0.4817, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [32/50], Step [230/469], Loss: 0.2399, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [32/50], Step [231/469], Loss: 0.5322, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [32/50], Step [232/469], Loss: 0.4653, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [32/50], Step [233/469], Loss: 0.2958, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [32/50], Step [234/469], Loss: 0.6549, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [32/50], Step [235/469], Loss: 0.4880, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [32/50], Step [236/469], Loss: 0.2877, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [237/469], Loss: 0.3367, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [238/469], Loss: 0.5049, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [239/469], Loss: 0.3355, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [32/50], Step [240/469], Loss: 0.3541, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [32/50], Step [241/469], Loss: 0.3728, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [242/469], Loss: 0.4029, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [243/469], Loss: 0.4279, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [244/469], Loss: 0.3299, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [245/469], Loss: 0.3344, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [32/50], Step [246/469], Loss: 0.5431, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [32/50], Step [247/469], Loss: 0.4031, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [32/50], Step [248/469], Loss: 0.2807, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [249/469], Loss: 0.3501, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [32/50], Step [250/469], Loss: 0.3658, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [32/50], Step [251/469], Loss: 0.3683, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [32/50], Step [252/469], Loss: 0.3208, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [32/50], Step [253/469], Loss: 0.5163, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [32/50], Step [254/469], Loss: 0.3002, batch time: 0.84, accuracy:  90.62%\n",
      "Epoch [32/50], Step [255/469], Loss: 0.4094, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [32/50], Step [256/469], Loss: 0.4540, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [32/50], Step [257/469], Loss: 0.5394, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [32/50], Step [258/469], Loss: 0.2931, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [32/50], Step [259/469], Loss: 0.2897, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [32/50], Step [260/469], Loss: 0.3525, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [32/50], Step [261/469], Loss: 0.4533, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [32/50], Step [262/469], Loss: 0.3915, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [32/50], Step [263/469], Loss: 0.3173, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [32/50], Step [264/469], Loss: 0.4744, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [32/50], Step [265/469], Loss: 0.5278, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [32/50], Step [266/469], Loss: 0.2603, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [32/50], Step [267/469], Loss: 0.3930, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [32/50], Step [268/469], Loss: 0.3569, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [32/50], Step [269/469], Loss: 0.4019, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [32/50], Step [270/469], Loss: 0.3496, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [32/50], Step [271/469], Loss: 0.3678, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [32/50], Step [272/469], Loss: 0.3891, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [32/50], Step [273/469], Loss: 0.4541, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [32/50], Step [274/469], Loss: 0.4374, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [32/50], Step [275/469], Loss: 0.3588, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [276/469], Loss: 0.5713, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [32/50], Step [277/469], Loss: 0.2287, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [32/50], Step [278/469], Loss: 0.3539, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [279/469], Loss: 0.3187, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [32/50], Step [280/469], Loss: 0.2744, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [32/50], Step [281/469], Loss: 0.5839, batch time: 0.54, accuracy:  80.47%\n",
      "Epoch [32/50], Step [282/469], Loss: 0.2805, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [32/50], Step [283/469], Loss: 0.4082, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [32/50], Step [284/469], Loss: 0.2315, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [32/50], Step [285/469], Loss: 0.5539, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [32/50], Step [286/469], Loss: 0.4724, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [32/50], Step [287/469], Loss: 0.3494, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [32/50], Step [288/469], Loss: 0.3328, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [32/50], Step [289/469], Loss: 0.4683, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [32/50], Step [290/469], Loss: 0.2966, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [32/50], Step [291/469], Loss: 0.4501, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [32/50], Step [292/469], Loss: 0.4809, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [32/50], Step [293/469], Loss: 0.3127, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [32/50], Step [294/469], Loss: 0.3029, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [32/50], Step [295/469], Loss: 0.4002, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [32/50], Step [296/469], Loss: 0.3023, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [32/50], Step [297/469], Loss: 0.3405, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [32/50], Step [298/469], Loss: 0.3445, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [32/50], Step [299/469], Loss: 0.3085, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [300/469], Loss: 0.3554, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [32/50], Step [301/469], Loss: 0.4356, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [32/50], Step [302/469], Loss: 0.3211, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [303/469], Loss: 0.3306, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [304/469], Loss: 0.3842, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [32/50], Step [305/469], Loss: 0.3635, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [32/50], Step [306/469], Loss: 0.3849, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [32/50], Step [307/469], Loss: 0.4433, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [32/50], Step [308/469], Loss: 0.3953, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [32/50], Step [309/469], Loss: 0.5511, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [310/469], Loss: 0.3893, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [32/50], Step [311/469], Loss: 0.3437, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [312/469], Loss: 0.4310, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [32/50], Step [313/469], Loss: 0.4658, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [32/50], Step [314/469], Loss: 0.2762, batch time: 0.81, accuracy:  92.19%\n",
      "Epoch [32/50], Step [315/469], Loss: 0.3708, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [32/50], Step [316/469], Loss: 0.3036, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [32/50], Step [317/469], Loss: 0.4338, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [318/469], Loss: 0.3250, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [32/50], Step [319/469], Loss: 0.4713, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [32/50], Step [320/469], Loss: 0.4294, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [32/50], Step [321/469], Loss: 0.4473, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [32/50], Step [322/469], Loss: 0.3446, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [32/50], Step [323/469], Loss: 0.2702, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [32/50], Step [324/469], Loss: 0.4929, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [32/50], Step [325/469], Loss: 0.5023, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [32/50], Step [326/469], Loss: 0.3312, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [32/50], Step [327/469], Loss: 0.4444, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [328/469], Loss: 0.3284, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [32/50], Step [329/469], Loss: 0.2825, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [330/469], Loss: 0.3259, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [331/469], Loss: 0.2993, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [32/50], Step [332/469], Loss: 0.4378, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [333/469], Loss: 0.4767, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [32/50], Step [334/469], Loss: 0.3979, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [335/469], Loss: 0.3339, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [336/469], Loss: 0.4472, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [337/469], Loss: 0.3881, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [32/50], Step [338/469], Loss: 0.5125, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [32/50], Step [339/469], Loss: 0.3953, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [32/50], Step [340/469], Loss: 0.2817, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [32/50], Step [341/469], Loss: 0.2511, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [32/50], Step [342/469], Loss: 0.2883, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [32/50], Step [343/469], Loss: 0.3677, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [32/50], Step [344/469], Loss: 0.2815, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [32/50], Step [345/469], Loss: 0.1824, batch time: 0.67, accuracy:  95.31%\n",
      "Epoch [32/50], Step [346/469], Loss: 0.4379, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [347/469], Loss: 0.3326, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [348/469], Loss: 0.5005, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [32/50], Step [349/469], Loss: 0.5571, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [32/50], Step [350/469], Loss: 0.3405, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [351/469], Loss: 0.3919, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [352/469], Loss: 0.2582, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [32/50], Step [353/469], Loss: 0.3892, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [32/50], Step [354/469], Loss: 0.3478, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [32/50], Step [355/469], Loss: 0.3538, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [32/50], Step [356/469], Loss: 0.3534, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [357/469], Loss: 0.3707, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [358/469], Loss: 0.3942, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [32/50], Step [359/469], Loss: 0.3584, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [32/50], Step [360/469], Loss: 0.3152, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [32/50], Step [361/469], Loss: 0.4804, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [32/50], Step [362/469], Loss: 0.3804, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [32/50], Step [363/469], Loss: 0.5211, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [32/50], Step [364/469], Loss: 0.2821, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [32/50], Step [365/469], Loss: 0.2888, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [32/50], Step [366/469], Loss: 0.3241, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [367/469], Loss: 0.4069, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [32/50], Step [368/469], Loss: 0.3958, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [32/50], Step [369/469], Loss: 0.3348, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [32/50], Step [370/469], Loss: 0.3694, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [32/50], Step [371/469], Loss: 0.3623, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [372/469], Loss: 0.3721, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [32/50], Step [373/469], Loss: 0.5129, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [32/50], Step [374/469], Loss: 0.4342, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [375/469], Loss: 0.3512, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [32/50], Step [376/469], Loss: 0.3049, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [377/469], Loss: 0.4194, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [32/50], Step [378/469], Loss: 0.2865, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [32/50], Step [379/469], Loss: 0.3050, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [32/50], Step [380/469], Loss: 0.3829, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [32/50], Step [381/469], Loss: 0.2841, batch time: 0.71, accuracy:  89.84%\n",
      "Epoch [32/50], Step [382/469], Loss: 0.2466, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [383/469], Loss: 0.4786, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [32/50], Step [384/469], Loss: 0.3162, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [385/469], Loss: 0.3563, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [386/469], Loss: 0.4229, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [32/50], Step [387/469], Loss: 0.4772, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [32/50], Step [388/469], Loss: 0.2696, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [32/50], Step [389/469], Loss: 0.5374, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [32/50], Step [390/469], Loss: 0.4145, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [391/469], Loss: 0.3509, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [32/50], Step [392/469], Loss: 0.3157, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [32/50], Step [393/469], Loss: 0.2953, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [32/50], Step [394/469], Loss: 0.3677, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [395/469], Loss: 0.5627, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [32/50], Step [396/469], Loss: 0.3496, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [397/469], Loss: 0.3163, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [32/50], Step [398/469], Loss: 0.3083, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [32/50], Step [399/469], Loss: 0.3521, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [32/50], Step [400/469], Loss: 0.2845, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [401/469], Loss: 0.4044, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [402/469], Loss: 0.4202, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [32/50], Step [403/469], Loss: 0.3826, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [404/469], Loss: 0.3367, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [32/50], Step [405/469], Loss: 0.3934, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [32/50], Step [406/469], Loss: 0.3404, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [32/50], Step [407/469], Loss: 0.2713, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [32/50], Step [408/469], Loss: 0.3139, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [32/50], Step [409/469], Loss: 0.4242, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [32/50], Step [410/469], Loss: 0.3509, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [32/50], Step [411/469], Loss: 0.4086, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [32/50], Step [412/469], Loss: 0.3245, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [32/50], Step [413/469], Loss: 0.3027, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [32/50], Step [414/469], Loss: 0.2754, batch time: 0.66, accuracy:  93.75%\n",
      "Epoch [32/50], Step [415/469], Loss: 0.2875, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [32/50], Step [416/469], Loss: 0.5915, batch time: 0.43, accuracy:  81.25%\n",
      "Epoch [32/50], Step [417/469], Loss: 0.4900, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [418/469], Loss: 0.5689, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [32/50], Step [419/469], Loss: 0.4262, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [32/50], Step [420/469], Loss: 0.2520, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [32/50], Step [421/469], Loss: 0.4018, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [32/50], Step [422/469], Loss: 0.3408, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [32/50], Step [423/469], Loss: 0.4665, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [32/50], Step [424/469], Loss: 0.3545, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [32/50], Step [425/469], Loss: 0.3251, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [32/50], Step [426/469], Loss: 0.3552, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [32/50], Step [427/469], Loss: 0.5037, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [32/50], Step [428/469], Loss: 0.2582, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [429/469], Loss: 0.2668, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [32/50], Step [430/469], Loss: 0.4079, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [32/50], Step [431/469], Loss: 0.3574, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [32/50], Step [432/469], Loss: 0.2903, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [32/50], Step [433/469], Loss: 0.4605, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [32/50], Step [434/469], Loss: 0.4383, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [32/50], Step [435/469], Loss: 0.2713, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [32/50], Step [436/469], Loss: 0.4229, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [32/50], Step [437/469], Loss: 0.4477, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [32/50], Step [438/469], Loss: 0.5443, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [32/50], Step [439/469], Loss: 0.4405, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [32/50], Step [440/469], Loss: 0.5226, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [441/469], Loss: 0.3646, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [32/50], Step [442/469], Loss: 0.2404, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [32/50], Step [443/469], Loss: 0.4287, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [32/50], Step [444/469], Loss: 0.5072, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [32/50], Step [445/469], Loss: 0.4071, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [32/50], Step [446/469], Loss: 0.4798, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [32/50], Step [447/469], Loss: 0.2185, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [32/50], Step [448/469], Loss: 0.4773, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [32/50], Step [449/469], Loss: 0.3816, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [32/50], Step [450/469], Loss: 0.4256, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [32/50], Step [451/469], Loss: 0.3770, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [32/50], Step [452/469], Loss: 0.4467, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [32/50], Step [453/469], Loss: 0.5313, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [32/50], Step [454/469], Loss: 0.3243, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [32/50], Step [455/469], Loss: 0.3133, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [32/50], Step [456/469], Loss: 0.4097, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [32/50], Step [457/469], Loss: 0.4182, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [32/50], Step [458/469], Loss: 0.5309, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [32/50], Step [459/469], Loss: 0.3140, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [32/50], Step [460/469], Loss: 0.3971, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [32/50], Step [461/469], Loss: 0.3432, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [32/50], Step [462/469], Loss: 0.4735, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [32/50], Step [463/469], Loss: 0.3659, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [32/50], Step [464/469], Loss: 0.4451, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [32/50], Step [465/469], Loss: 0.2670, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [32/50], Step [466/469], Loss: 0.2449, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [32/50], Step [467/469], Loss: 0.2502, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [32/50], Step [468/469], Loss: 0.4294, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [32/50], Step [469/469], Loss: 0.2665, batch time: 0.45, accuracy:  91.67%\n",
      "Epoch [33/50], Step [1/469], Loss: 0.3082, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [33/50], Step [2/469], Loss: 0.3538, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [33/50], Step [3/469], Loss: 0.4944, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [33/50], Step [4/469], Loss: 0.4462, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [33/50], Step [5/469], Loss: 0.6233, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [33/50], Step [6/469], Loss: 0.3016, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [33/50], Step [7/469], Loss: 0.4221, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [33/50], Step [8/469], Loss: 0.2751, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [33/50], Step [9/469], Loss: 0.2674, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [33/50], Step [10/469], Loss: 0.3937, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [33/50], Step [11/469], Loss: 0.4201, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [33/50], Step [12/469], Loss: 0.4429, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [13/469], Loss: 0.4862, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [14/469], Loss: 0.3742, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [15/469], Loss: 0.3483, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [33/50], Step [16/469], Loss: 0.3904, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [17/469], Loss: 0.2891, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [18/469], Loss: 0.4058, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [19/469], Loss: 0.3940, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [33/50], Step [20/469], Loss: 0.2343, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [33/50], Step [21/469], Loss: 0.2649, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [33/50], Step [22/469], Loss: 0.5103, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [23/469], Loss: 0.3370, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [33/50], Step [24/469], Loss: 0.3534, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [33/50], Step [25/469], Loss: 0.4476, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [33/50], Step [26/469], Loss: 0.3004, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [33/50], Step [27/469], Loss: 0.3484, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [28/469], Loss: 0.4932, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [33/50], Step [29/469], Loss: 0.3981, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [33/50], Step [30/469], Loss: 0.3879, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [33/50], Step [31/469], Loss: 0.3574, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [33/50], Step [32/469], Loss: 0.2539, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [33/50], Step [33/469], Loss: 0.3175, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [34/469], Loss: 0.3850, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [33/50], Step [35/469], Loss: 0.4390, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [33/50], Step [36/469], Loss: 0.2789, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [33/50], Step [37/469], Loss: 0.4215, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [33/50], Step [38/469], Loss: 0.4424, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [33/50], Step [39/469], Loss: 0.3578, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [33/50], Step [40/469], Loss: 0.3478, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [33/50], Step [41/469], Loss: 0.5242, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [33/50], Step [42/469], Loss: 0.4741, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [33/50], Step [43/469], Loss: 0.3105, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [33/50], Step [44/469], Loss: 0.2175, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [33/50], Step [45/469], Loss: 0.4749, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [33/50], Step [46/469], Loss: 0.4652, batch time: 0.77, accuracy:  86.72%\n",
      "Epoch [33/50], Step [47/469], Loss: 0.3307, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [33/50], Step [48/469], Loss: 0.5053, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [33/50], Step [49/469], Loss: 0.3672, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [50/469], Loss: 0.4254, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [33/50], Step [51/469], Loss: 0.4822, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [33/50], Step [52/469], Loss: 0.3144, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [33/50], Step [53/469], Loss: 0.3785, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [33/50], Step [54/469], Loss: 0.3806, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [33/50], Step [55/469], Loss: 0.4233, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [33/50], Step [56/469], Loss: 0.5436, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [33/50], Step [57/469], Loss: 0.3864, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [33/50], Step [58/469], Loss: 0.3388, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [33/50], Step [59/469], Loss: 0.2816, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [33/50], Step [60/469], Loss: 0.4035, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [33/50], Step [61/469], Loss: 0.3614, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [62/469], Loss: 0.4542, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [63/469], Loss: 0.4880, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [64/469], Loss: 0.3326, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [33/50], Step [65/469], Loss: 0.3883, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [33/50], Step [66/469], Loss: 0.5357, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [33/50], Step [67/469], Loss: 0.5368, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [33/50], Step [68/469], Loss: 0.2561, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [33/50], Step [69/469], Loss: 0.3954, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [70/469], Loss: 0.2865, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [33/50], Step [71/469], Loss: 0.3632, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [72/469], Loss: 0.3467, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [33/50], Step [73/469], Loss: 0.4346, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [33/50], Step [74/469], Loss: 0.5488, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [33/50], Step [75/469], Loss: 0.3303, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [33/50], Step [76/469], Loss: 0.3255, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [33/50], Step [77/469], Loss: 0.3100, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [33/50], Step [78/469], Loss: 0.6822, batch time: 0.60, accuracy:  82.81%\n",
      "Epoch [33/50], Step [79/469], Loss: 0.4516, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [33/50], Step [80/469], Loss: 0.4144, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [33/50], Step [81/469], Loss: 0.4755, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [33/50], Step [82/469], Loss: 0.3689, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [33/50], Step [83/469], Loss: 0.4143, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [84/469], Loss: 0.4080, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [85/469], Loss: 0.3240, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [33/50], Step [86/469], Loss: 0.2522, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [33/50], Step [87/469], Loss: 0.3165, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [88/469], Loss: 0.2797, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [33/50], Step [89/469], Loss: 0.3034, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [90/469], Loss: 0.3332, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [91/469], Loss: 0.4598, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [33/50], Step [92/469], Loss: 0.3736, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [33/50], Step [93/469], Loss: 0.4217, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [33/50], Step [94/469], Loss: 0.4558, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [33/50], Step [95/469], Loss: 0.2671, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [33/50], Step [96/469], Loss: 0.3906, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [33/50], Step [97/469], Loss: 0.2994, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [33/50], Step [98/469], Loss: 0.2415, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [33/50], Step [99/469], Loss: 0.3240, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [33/50], Step [100/469], Loss: 0.3735, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [33/50], Step [101/469], Loss: 0.2880, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [33/50], Step [102/469], Loss: 0.3703, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [33/50], Step [103/469], Loss: 0.4000, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [104/469], Loss: 0.6484, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [33/50], Step [105/469], Loss: 0.5601, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [33/50], Step [106/469], Loss: 0.3912, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [33/50], Step [107/469], Loss: 0.3169, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [33/50], Step [108/469], Loss: 0.3549, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [33/50], Step [109/469], Loss: 0.3048, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [33/50], Step [110/469], Loss: 0.3203, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [33/50], Step [111/469], Loss: 0.3604, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [33/50], Step [112/469], Loss: 0.3738, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [113/469], Loss: 0.2993, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [33/50], Step [114/469], Loss: 0.3554, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [33/50], Step [115/469], Loss: 0.3656, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [33/50], Step [116/469], Loss: 0.3950, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [33/50], Step [117/469], Loss: 0.3405, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [33/50], Step [118/469], Loss: 0.4250, batch time: 0.63, accuracy:  89.84%\n",
      "Epoch [33/50], Step [119/469], Loss: 0.2706, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [33/50], Step [120/469], Loss: 0.2955, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [121/469], Loss: 0.3581, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [33/50], Step [122/469], Loss: 0.3814, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [123/469], Loss: 0.4438, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [33/50], Step [124/469], Loss: 0.3346, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [33/50], Step [125/469], Loss: 0.3439, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [126/469], Loss: 0.3144, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [33/50], Step [127/469], Loss: 0.2405, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [33/50], Step [128/469], Loss: 0.3247, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [33/50], Step [129/469], Loss: 0.2889, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [33/50], Step [130/469], Loss: 0.3945, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [33/50], Step [131/469], Loss: 0.2769, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [33/50], Step [132/469], Loss: 0.4905, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [33/50], Step [133/469], Loss: 0.3695, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [134/469], Loss: 0.3857, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [33/50], Step [135/469], Loss: 0.2884, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [33/50], Step [136/469], Loss: 0.4886, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [33/50], Step [137/469], Loss: 0.3052, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [33/50], Step [138/469], Loss: 0.4629, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [33/50], Step [139/469], Loss: 0.3918, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [33/50], Step [140/469], Loss: 0.2455, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [33/50], Step [141/469], Loss: 0.3839, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [33/50], Step [142/469], Loss: 0.2459, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [33/50], Step [143/469], Loss: 0.3028, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [33/50], Step [144/469], Loss: 0.4247, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [33/50], Step [145/469], Loss: 0.3463, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [33/50], Step [146/469], Loss: 0.5973, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [33/50], Step [147/469], Loss: 0.5289, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [33/50], Step [148/469], Loss: 0.3572, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [33/50], Step [149/469], Loss: 0.4520, batch time: 0.84, accuracy:  89.84%\n",
      "Epoch [33/50], Step [150/469], Loss: 0.2772, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [151/469], Loss: 0.2881, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [152/469], Loss: 0.5065, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [33/50], Step [153/469], Loss: 0.4666, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [33/50], Step [154/469], Loss: 0.5244, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [33/50], Step [155/469], Loss: 0.3965, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [156/469], Loss: 0.3473, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [33/50], Step [157/469], Loss: 0.3658, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [158/469], Loss: 0.3955, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [33/50], Step [159/469], Loss: 0.4154, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [33/50], Step [160/469], Loss: 0.4674, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [33/50], Step [161/469], Loss: 0.3849, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [33/50], Step [162/469], Loss: 0.2912, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [33/50], Step [163/469], Loss: 0.3694, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [33/50], Step [164/469], Loss: 0.4515, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [33/50], Step [165/469], Loss: 0.3973, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [33/50], Step [166/469], Loss: 0.3901, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [167/469], Loss: 0.2512, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [33/50], Step [168/469], Loss: 0.4836, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [33/50], Step [169/469], Loss: 0.4105, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [33/50], Step [170/469], Loss: 0.4420, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [171/469], Loss: 0.4465, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [172/469], Loss: 0.3868, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [33/50], Step [173/469], Loss: 0.3857, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [33/50], Step [174/469], Loss: 0.3891, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [33/50], Step [175/469], Loss: 0.3164, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [33/50], Step [176/469], Loss: 0.3875, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [177/469], Loss: 0.4311, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [33/50], Step [178/469], Loss: 0.3531, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [33/50], Step [179/469], Loss: 0.5278, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [33/50], Step [180/469], Loss: 0.4351, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [33/50], Step [181/469], Loss: 0.3918, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [33/50], Step [182/469], Loss: 0.2513, batch time: 0.60, accuracy:  94.53%\n",
      "Epoch [33/50], Step [183/469], Loss: 0.4623, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [33/50], Step [184/469], Loss: 0.3426, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [33/50], Step [185/469], Loss: 0.3572, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [33/50], Step [186/469], Loss: 0.2661, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [33/50], Step [187/469], Loss: 0.3033, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [33/50], Step [188/469], Loss: 0.4668, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [33/50], Step [189/469], Loss: 0.4375, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [33/50], Step [190/469], Loss: 0.3640, batch time: 0.62, accuracy:  85.94%\n",
      "Epoch [33/50], Step [191/469], Loss: 0.3228, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [192/469], Loss: 0.4843, batch time: 0.47, accuracy:  82.81%\n",
      "Epoch [33/50], Step [193/469], Loss: 0.3885, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [33/50], Step [194/469], Loss: 0.3096, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [33/50], Step [195/469], Loss: 0.4243, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [33/50], Step [196/469], Loss: 0.2748, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [33/50], Step [197/469], Loss: 0.3890, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [33/50], Step [198/469], Loss: 0.4553, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [33/50], Step [199/469], Loss: 0.3194, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [33/50], Step [200/469], Loss: 0.4020, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [33/50], Step [201/469], Loss: 0.4050, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [202/469], Loss: 0.4295, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [33/50], Step [203/469], Loss: 0.3041, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [33/50], Step [204/469], Loss: 0.3050, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [33/50], Step [205/469], Loss: 0.2992, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [33/50], Step [206/469], Loss: 0.2908, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [33/50], Step [207/469], Loss: 0.5470, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [208/469], Loss: 0.4289, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [33/50], Step [209/469], Loss: 0.4526, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [210/469], Loss: 0.2406, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [211/469], Loss: 0.3887, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [33/50], Step [212/469], Loss: 0.4924, batch time: 0.45, accuracy:  81.25%\n",
      "Epoch [33/50], Step [213/469], Loss: 0.3527, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [33/50], Step [214/469], Loss: 0.4808, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [33/50], Step [215/469], Loss: 0.2221, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [33/50], Step [216/469], Loss: 0.2565, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [33/50], Step [217/469], Loss: 0.3451, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [33/50], Step [218/469], Loss: 0.2445, batch time: 0.75, accuracy:  90.62%\n",
      "Epoch [33/50], Step [219/469], Loss: 0.3692, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [220/469], Loss: 0.4256, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [33/50], Step [221/469], Loss: 0.4266, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [222/469], Loss: 0.4188, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [33/50], Step [223/469], Loss: 0.2793, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [33/50], Step [224/469], Loss: 0.4113, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [33/50], Step [225/469], Loss: 0.4674, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [33/50], Step [226/469], Loss: 0.3281, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [33/50], Step [227/469], Loss: 0.2802, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [33/50], Step [228/469], Loss: 0.3913, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [33/50], Step [229/469], Loss: 0.4159, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [33/50], Step [230/469], Loss: 0.3659, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [33/50], Step [231/469], Loss: 0.4568, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [33/50], Step [232/469], Loss: 0.4645, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [33/50], Step [233/469], Loss: 0.4844, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [33/50], Step [234/469], Loss: 0.4483, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [33/50], Step [235/469], Loss: 0.2382, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [33/50], Step [236/469], Loss: 0.3123, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [33/50], Step [237/469], Loss: 0.3993, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [33/50], Step [238/469], Loss: 0.4308, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [33/50], Step [239/469], Loss: 0.3196, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [33/50], Step [240/469], Loss: 0.2897, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [33/50], Step [241/469], Loss: 0.3509, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [33/50], Step [242/469], Loss: 0.3404, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [33/50], Step [243/469], Loss: 0.4164, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [33/50], Step [244/469], Loss: 0.3030, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [33/50], Step [245/469], Loss: 0.4899, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [33/50], Step [246/469], Loss: 0.3879, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [33/50], Step [247/469], Loss: 0.3929, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [33/50], Step [248/469], Loss: 0.2278, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [33/50], Step [249/469], Loss: 0.2815, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [33/50], Step [250/469], Loss: 0.2116, batch time: 0.57, accuracy:  93.75%\n",
      "Epoch [33/50], Step [251/469], Loss: 0.5397, batch time: 0.67, accuracy:  87.50%\n",
      "Epoch [33/50], Step [252/469], Loss: 0.3891, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [33/50], Step [253/469], Loss: 0.2580, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [33/50], Step [254/469], Loss: 0.3394, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [33/50], Step [255/469], Loss: 0.2110, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [33/50], Step [256/469], Loss: 0.2295, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [33/50], Step [257/469], Loss: 0.3038, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [33/50], Step [258/469], Loss: 0.3486, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [33/50], Step [259/469], Loss: 0.3750, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [33/50], Step [260/469], Loss: 0.3805, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [33/50], Step [261/469], Loss: 0.3824, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [33/50], Step [262/469], Loss: 0.3738, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [33/50], Step [263/469], Loss: 0.3393, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [264/469], Loss: 0.4886, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [33/50], Step [265/469], Loss: 0.5283, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [33/50], Step [266/469], Loss: 0.3661, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [33/50], Step [267/469], Loss: 0.3068, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [33/50], Step [268/469], Loss: 0.5349, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [269/469], Loss: 0.4284, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [33/50], Step [270/469], Loss: 0.4462, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [33/50], Step [271/469], Loss: 0.2853, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [33/50], Step [272/469], Loss: 0.2944, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [33/50], Step [273/469], Loss: 0.4522, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [33/50], Step [274/469], Loss: 0.2656, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [33/50], Step [275/469], Loss: 0.4708, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [33/50], Step [276/469], Loss: 0.2855, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [33/50], Step [277/469], Loss: 0.2711, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [33/50], Step [278/469], Loss: 0.4266, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [33/50], Step [279/469], Loss: 0.3884, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [33/50], Step [280/469], Loss: 0.3662, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [33/50], Step [281/469], Loss: 0.4425, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [33/50], Step [282/469], Loss: 0.2252, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [33/50], Step [283/469], Loss: 0.3825, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [33/50], Step [284/469], Loss: 0.3737, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [33/50], Step [285/469], Loss: 0.1861, batch time: 0.71, accuracy:  95.31%\n",
      "Epoch [33/50], Step [286/469], Loss: 0.3104, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [287/469], Loss: 0.3512, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [33/50], Step [288/469], Loss: 0.3557, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [33/50], Step [289/469], Loss: 0.3950, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [33/50], Step [290/469], Loss: 0.4450, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [33/50], Step [291/469], Loss: 0.3762, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [292/469], Loss: 0.3999, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [33/50], Step [293/469], Loss: 0.3483, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [33/50], Step [294/469], Loss: 0.3795, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [33/50], Step [295/469], Loss: 0.2903, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [33/50], Step [296/469], Loss: 0.3818, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [33/50], Step [297/469], Loss: 0.2819, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [33/50], Step [298/469], Loss: 0.3356, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [33/50], Step [299/469], Loss: 0.3823, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [33/50], Step [300/469], Loss: 0.4157, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [33/50], Step [301/469], Loss: 0.5512, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [302/469], Loss: 0.4448, batch time: 0.43, accuracy:  82.81%\n",
      "Epoch [33/50], Step [303/469], Loss: 0.4040, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [304/469], Loss: 0.2876, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [33/50], Step [305/469], Loss: 0.3250, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [306/469], Loss: 0.5132, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [33/50], Step [307/469], Loss: 0.4434, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [33/50], Step [308/469], Loss: 0.4422, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [33/50], Step [309/469], Loss: 0.4013, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [33/50], Step [310/469], Loss: 0.3556, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [33/50], Step [311/469], Loss: 0.4699, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [33/50], Step [312/469], Loss: 0.3753, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [33/50], Step [313/469], Loss: 0.4492, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [33/50], Step [314/469], Loss: 0.3971, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [33/50], Step [315/469], Loss: 0.3873, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [33/50], Step [316/469], Loss: 0.3336, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [33/50], Step [317/469], Loss: 0.3468, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [33/50], Step [318/469], Loss: 0.3737, batch time: 0.74, accuracy:  85.16%\n",
      "Epoch [33/50], Step [319/469], Loss: 0.4581, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [33/50], Step [320/469], Loss: 0.3778, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [33/50], Step [321/469], Loss: 0.3527, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [322/469], Loss: 0.4451, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [33/50], Step [323/469], Loss: 0.3826, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [33/50], Step [324/469], Loss: 0.3815, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [325/469], Loss: 0.2686, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [33/50], Step [326/469], Loss: 0.3525, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [327/469], Loss: 0.4172, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [33/50], Step [328/469], Loss: 0.2824, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [33/50], Step [329/469], Loss: 0.3007, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [33/50], Step [330/469], Loss: 0.4243, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [33/50], Step [331/469], Loss: 0.1933, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [33/50], Step [332/469], Loss: 0.3098, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [33/50], Step [333/469], Loss: 0.3351, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [33/50], Step [334/469], Loss: 0.3187, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [335/469], Loss: 0.4285, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [33/50], Step [336/469], Loss: 0.3689, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [33/50], Step [337/469], Loss: 0.3630, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [33/50], Step [338/469], Loss: 0.3337, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [339/469], Loss: 0.2964, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [33/50], Step [340/469], Loss: 0.2282, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [33/50], Step [341/469], Loss: 0.4209, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [33/50], Step [342/469], Loss: 0.3868, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [33/50], Step [343/469], Loss: 0.4841, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [33/50], Step [344/469], Loss: 0.4468, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [33/50], Step [345/469], Loss: 0.2806, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [33/50], Step [346/469], Loss: 0.3688, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [33/50], Step [347/469], Loss: 0.2977, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [33/50], Step [348/469], Loss: 0.4509, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [33/50], Step [349/469], Loss: 0.6080, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [33/50], Step [350/469], Loss: 0.3806, batch time: 1.02, accuracy:  92.97%\n",
      "Epoch [33/50], Step [351/469], Loss: 0.5080, batch time: 0.45, accuracy:  79.69%\n",
      "Epoch [33/50], Step [352/469], Loss: 0.4155, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [33/50], Step [353/469], Loss: 0.1985, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [33/50], Step [354/469], Loss: 0.4830, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [33/50], Step [355/469], Loss: 0.4365, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [33/50], Step [356/469], Loss: 0.3486, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [33/50], Step [357/469], Loss: 0.3791, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [33/50], Step [358/469], Loss: 0.2748, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [33/50], Step [359/469], Loss: 0.2748, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [33/50], Step [360/469], Loss: 0.3620, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [361/469], Loss: 0.5512, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [33/50], Step [362/469], Loss: 0.3021, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [33/50], Step [363/469], Loss: 0.3708, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [364/469], Loss: 0.3258, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [365/469], Loss: 0.4454, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [33/50], Step [366/469], Loss: 0.3570, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [367/469], Loss: 0.2660, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [33/50], Step [368/469], Loss: 0.2491, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [33/50], Step [369/469], Loss: 0.2648, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [370/469], Loss: 0.3326, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [33/50], Step [371/469], Loss: 0.3784, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [33/50], Step [372/469], Loss: 0.4523, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [33/50], Step [373/469], Loss: 0.4939, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [33/50], Step [374/469], Loss: 0.4352, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [33/50], Step [375/469], Loss: 0.1675, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [33/50], Step [376/469], Loss: 0.2578, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [33/50], Step [377/469], Loss: 0.2787, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [33/50], Step [378/469], Loss: 0.3840, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [33/50], Step [379/469], Loss: 0.3424, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [33/50], Step [380/469], Loss: 0.4350, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [33/50], Step [381/469], Loss: 0.4250, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [33/50], Step [382/469], Loss: 0.1839, batch time: 0.51, accuracy:  96.09%\n",
      "Epoch [33/50], Step [383/469], Loss: 0.5032, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [384/469], Loss: 0.3292, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [33/50], Step [385/469], Loss: 0.3991, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [33/50], Step [386/469], Loss: 0.5123, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [33/50], Step [387/469], Loss: 0.4595, batch time: 0.60, accuracy:  83.59%\n",
      "Epoch [33/50], Step [388/469], Loss: 0.3519, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [33/50], Step [389/469], Loss: 0.2712, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [33/50], Step [390/469], Loss: 0.4341, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [33/50], Step [391/469], Loss: 0.2717, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [33/50], Step [392/469], Loss: 0.3579, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [33/50], Step [393/469], Loss: 0.3690, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [33/50], Step [394/469], Loss: 0.3760, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [33/50], Step [395/469], Loss: 0.3170, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [33/50], Step [396/469], Loss: 0.4235, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [33/50], Step [397/469], Loss: 0.4258, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [398/469], Loss: 0.5499, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [33/50], Step [399/469], Loss: 0.3284, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [33/50], Step [400/469], Loss: 0.3407, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [401/469], Loss: 0.3288, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [33/50], Step [402/469], Loss: 0.4968, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [403/469], Loss: 0.3561, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [33/50], Step [404/469], Loss: 0.2256, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [33/50], Step [405/469], Loss: 0.4141, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [33/50], Step [406/469], Loss: 0.3984, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [407/469], Loss: 0.3790, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [408/469], Loss: 0.3108, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [409/469], Loss: 0.3974, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [410/469], Loss: 0.3330, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [411/469], Loss: 0.5485, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [33/50], Step [412/469], Loss: 0.3385, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [33/50], Step [413/469], Loss: 0.1565, batch time: 0.43, accuracy:  96.88%\n",
      "Epoch [33/50], Step [414/469], Loss: 0.3474, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [33/50], Step [415/469], Loss: 0.3718, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [33/50], Step [416/469], Loss: 0.2358, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [33/50], Step [417/469], Loss: 0.2540, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [33/50], Step [418/469], Loss: 0.3279, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [33/50], Step [419/469], Loss: 0.3830, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [33/50], Step [420/469], Loss: 0.3589, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [33/50], Step [421/469], Loss: 0.5091, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [33/50], Step [422/469], Loss: 0.5029, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [33/50], Step [423/469], Loss: 0.2620, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [33/50], Step [424/469], Loss: 0.5704, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [33/50], Step [425/469], Loss: 0.3289, batch time: 0.67, accuracy:  92.97%\n",
      "Epoch [33/50], Step [426/469], Loss: 0.6329, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [33/50], Step [427/469], Loss: 0.4295, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [33/50], Step [428/469], Loss: 0.2584, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [33/50], Step [429/469], Loss: 0.1771, batch time: 0.49, accuracy:  95.31%\n",
      "Epoch [33/50], Step [430/469], Loss: 0.3342, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [33/50], Step [431/469], Loss: 0.2599, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [33/50], Step [432/469], Loss: 0.2170, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [33/50], Step [433/469], Loss: 0.4935, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [33/50], Step [434/469], Loss: 0.2865, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [33/50], Step [435/469], Loss: 0.3489, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [33/50], Step [436/469], Loss: 0.3008, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [33/50], Step [437/469], Loss: 0.2801, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [33/50], Step [438/469], Loss: 0.5333, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [33/50], Step [439/469], Loss: 0.4282, batch time: 0.64, accuracy:  87.50%\n",
      "Epoch [33/50], Step [440/469], Loss: 0.3505, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [441/469], Loss: 0.2828, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [33/50], Step [442/469], Loss: 0.2991, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [443/469], Loss: 0.3663, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [33/50], Step [444/469], Loss: 0.3559, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [33/50], Step [445/469], Loss: 0.4060, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [33/50], Step [446/469], Loss: 0.3151, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [33/50], Step [447/469], Loss: 0.3845, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [33/50], Step [448/469], Loss: 0.3450, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [33/50], Step [449/469], Loss: 0.6934, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [33/50], Step [450/469], Loss: 0.4021, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [33/50], Step [451/469], Loss: 0.2949, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [33/50], Step [452/469], Loss: 0.3736, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [33/50], Step [453/469], Loss: 0.3621, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [33/50], Step [454/469], Loss: 0.4044, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [33/50], Step [455/469], Loss: 0.3760, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [33/50], Step [456/469], Loss: 0.5167, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [33/50], Step [457/469], Loss: 0.3846, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [33/50], Step [458/469], Loss: 0.3526, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [33/50], Step [459/469], Loss: 0.6297, batch time: 0.46, accuracy:  81.25%\n",
      "Epoch [33/50], Step [460/469], Loss: 0.2361, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [33/50], Step [461/469], Loss: 0.3784, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [33/50], Step [462/469], Loss: 0.4526, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [33/50], Step [463/469], Loss: 0.2531, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [33/50], Step [464/469], Loss: 0.3054, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [465/469], Loss: 0.3298, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [33/50], Step [466/469], Loss: 0.3472, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [33/50], Step [467/469], Loss: 0.3019, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [33/50], Step [468/469], Loss: 0.4910, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [33/50], Step [469/469], Loss: 0.2570, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [34/50], Step [1/469], Loss: 0.3340, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [34/50], Step [2/469], Loss: 0.3940, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [34/50], Step [3/469], Loss: 0.3657, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [34/50], Step [4/469], Loss: 0.3850, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [34/50], Step [5/469], Loss: 0.3480, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [34/50], Step [6/469], Loss: 0.2446, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [7/469], Loss: 0.4046, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [34/50], Step [8/469], Loss: 0.4175, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [34/50], Step [9/469], Loss: 0.3715, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [34/50], Step [10/469], Loss: 0.3157, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [34/50], Step [11/469], Loss: 0.4373, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [34/50], Step [12/469], Loss: 0.3488, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [34/50], Step [13/469], Loss: 0.3267, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [14/469], Loss: 0.3763, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [34/50], Step [15/469], Loss: 0.4630, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [34/50], Step [16/469], Loss: 0.4146, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [34/50], Step [17/469], Loss: 0.2887, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [34/50], Step [18/469], Loss: 0.3835, batch time: 0.65, accuracy:  89.06%\n",
      "Epoch [34/50], Step [19/469], Loss: 0.4160, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [34/50], Step [20/469], Loss: 0.4379, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [34/50], Step [21/469], Loss: 0.3994, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [34/50], Step [22/469], Loss: 0.3185, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [23/469], Loss: 0.4412, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [34/50], Step [24/469], Loss: 0.3067, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [34/50], Step [25/469], Loss: 0.2474, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [34/50], Step [26/469], Loss: 0.3881, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [34/50], Step [27/469], Loss: 0.2973, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [34/50], Step [28/469], Loss: 0.3303, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [34/50], Step [29/469], Loss: 0.3146, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [34/50], Step [30/469], Loss: 0.3590, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [31/469], Loss: 0.3068, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [34/50], Step [32/469], Loss: 0.3884, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [34/50], Step [33/469], Loss: 0.3165, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [34/469], Loss: 0.3637, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [34/50], Step [35/469], Loss: 0.3017, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [34/50], Step [36/469], Loss: 0.2638, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [34/50], Step [37/469], Loss: 0.3104, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [34/50], Step [38/469], Loss: 0.2551, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [34/50], Step [39/469], Loss: 0.3646, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [34/50], Step [40/469], Loss: 0.3661, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [34/50], Step [41/469], Loss: 0.2848, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [42/469], Loss: 0.4761, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [34/50], Step [43/469], Loss: 0.2574, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [34/50], Step [44/469], Loss: 0.3983, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [34/50], Step [45/469], Loss: 0.3974, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [34/50], Step [46/469], Loss: 0.4833, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [34/50], Step [47/469], Loss: 0.5733, batch time: 0.53, accuracy:  81.25%\n",
      "Epoch [34/50], Step [48/469], Loss: 0.3419, batch time: 0.75, accuracy:  92.97%\n",
      "Epoch [34/50], Step [49/469], Loss: 0.2287, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [34/50], Step [50/469], Loss: 0.3308, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [34/50], Step [51/469], Loss: 0.3824, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [34/50], Step [52/469], Loss: 0.2824, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [34/50], Step [53/469], Loss: 0.4077, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [34/50], Step [54/469], Loss: 0.4189, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [34/50], Step [55/469], Loss: 0.3975, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [34/50], Step [56/469], Loss: 0.3378, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [34/50], Step [57/469], Loss: 0.2702, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [34/50], Step [58/469], Loss: 0.4250, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [34/50], Step [59/469], Loss: 0.5558, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [34/50], Step [60/469], Loss: 0.2928, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [34/50], Step [61/469], Loss: 0.3039, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [34/50], Step [62/469], Loss: 0.4281, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [34/50], Step [63/469], Loss: 0.4273, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [34/50], Step [64/469], Loss: 0.5564, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [34/50], Step [65/469], Loss: 0.4770, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [34/50], Step [66/469], Loss: 0.3720, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [34/50], Step [67/469], Loss: 0.3423, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [34/50], Step [68/469], Loss: 0.3777, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [34/50], Step [69/469], Loss: 0.3170, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [34/50], Step [70/469], Loss: 0.3555, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [34/50], Step [71/469], Loss: 0.2628, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [34/50], Step [72/469], Loss: 0.4623, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [34/50], Step [73/469], Loss: 0.2908, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [34/50], Step [74/469], Loss: 0.5042, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [34/50], Step [75/469], Loss: 0.2878, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [34/50], Step [76/469], Loss: 0.3043, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [34/50], Step [77/469], Loss: 0.3246, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [34/50], Step [78/469], Loss: 0.4417, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [34/50], Step [79/469], Loss: 0.2579, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [34/50], Step [80/469], Loss: 0.3787, batch time: 0.75, accuracy:  87.50%\n",
      "Epoch [34/50], Step [81/469], Loss: 0.3075, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [34/50], Step [82/469], Loss: 0.4307, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [83/469], Loss: 0.4054, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [34/50], Step [84/469], Loss: 0.2736, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [34/50], Step [85/469], Loss: 0.3583, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [34/50], Step [86/469], Loss: 0.3187, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [34/50], Step [87/469], Loss: 0.2449, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [34/50], Step [88/469], Loss: 0.3903, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [34/50], Step [89/469], Loss: 0.2637, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [34/50], Step [90/469], Loss: 0.3346, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [34/50], Step [91/469], Loss: 0.4727, batch time: 0.44, accuracy:  82.81%\n",
      "Epoch [34/50], Step [92/469], Loss: 0.3702, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [34/50], Step [93/469], Loss: 0.4341, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [34/50], Step [94/469], Loss: 0.3887, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [34/50], Step [95/469], Loss: 0.3198, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [34/50], Step [96/469], Loss: 0.3164, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [34/50], Step [97/469], Loss: 0.5891, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [34/50], Step [98/469], Loss: 0.3153, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [34/50], Step [99/469], Loss: 0.3475, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [34/50], Step [100/469], Loss: 0.3753, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [34/50], Step [101/469], Loss: 0.4074, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [34/50], Step [102/469], Loss: 0.3538, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [103/469], Loss: 0.4285, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [34/50], Step [104/469], Loss: 0.2780, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [34/50], Step [105/469], Loss: 0.2571, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [34/50], Step [106/469], Loss: 0.2235, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [34/50], Step [107/469], Loss: 0.4257, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [34/50], Step [108/469], Loss: 0.4274, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [34/50], Step [109/469], Loss: 0.3623, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [34/50], Step [110/469], Loss: 0.6626, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [34/50], Step [111/469], Loss: 0.5135, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [34/50], Step [112/469], Loss: 0.3044, batch time: 0.76, accuracy:  91.41%\n",
      "Epoch [34/50], Step [113/469], Loss: 0.3486, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [34/50], Step [114/469], Loss: 0.4009, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [34/50], Step [115/469], Loss: 0.4736, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [34/50], Step [116/469], Loss: 0.3951, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [117/469], Loss: 0.5574, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [34/50], Step [118/469], Loss: 0.3365, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [34/50], Step [119/469], Loss: 0.3265, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [34/50], Step [120/469], Loss: 0.5293, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [34/50], Step [121/469], Loss: 0.2991, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [34/50], Step [122/469], Loss: 0.4352, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [123/469], Loss: 0.4262, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [34/50], Step [124/469], Loss: 0.3672, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [125/469], Loss: 0.2810, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [34/50], Step [126/469], Loss: 0.4065, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [34/50], Step [127/469], Loss: 0.3603, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [34/50], Step [128/469], Loss: 0.2828, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [34/50], Step [129/469], Loss: 0.3148, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [34/50], Step [130/469], Loss: 0.2762, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [34/50], Step [131/469], Loss: 0.3053, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [34/50], Step [132/469], Loss: 0.2298, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [34/50], Step [133/469], Loss: 0.2831, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [34/50], Step [134/469], Loss: 0.2682, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [34/50], Step [135/469], Loss: 0.4023, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [34/50], Step [136/469], Loss: 0.2363, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [137/469], Loss: 0.4775, batch time: 0.46, accuracy:  82.03%\n",
      "Epoch [34/50], Step [138/469], Loss: 0.4657, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [34/50], Step [139/469], Loss: 0.3463, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [34/50], Step [140/469], Loss: 0.3532, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [34/50], Step [141/469], Loss: 0.3502, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [34/50], Step [142/469], Loss: 0.6192, batch time: 0.56, accuracy:  83.59%\n",
      "Epoch [34/50], Step [143/469], Loss: 0.3236, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [34/50], Step [144/469], Loss: 0.2677, batch time: 0.54, accuracy:  95.31%\n",
      "Epoch [34/50], Step [145/469], Loss: 0.3221, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [34/50], Step [146/469], Loss: 0.4473, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [34/50], Step [147/469], Loss: 0.4237, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [34/50], Step [148/469], Loss: 0.2936, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [149/469], Loss: 0.4812, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [34/50], Step [150/469], Loss: 0.2245, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [34/50], Step [151/469], Loss: 0.4050, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [34/50], Step [152/469], Loss: 0.4806, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [34/50], Step [153/469], Loss: 0.4440, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [34/50], Step [154/469], Loss: 0.3237, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [34/50], Step [155/469], Loss: 0.4492, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [34/50], Step [156/469], Loss: 0.4396, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [34/50], Step [157/469], Loss: 0.3655, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [158/469], Loss: 0.3655, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [34/50], Step [159/469], Loss: 0.3186, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [34/50], Step [160/469], Loss: 0.4241, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [34/50], Step [161/469], Loss: 0.4286, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [34/50], Step [162/469], Loss: 0.3477, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [34/50], Step [163/469], Loss: 0.3133, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [34/50], Step [164/469], Loss: 0.4703, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [34/50], Step [165/469], Loss: 0.3889, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [34/50], Step [166/469], Loss: 0.3268, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [34/50], Step [167/469], Loss: 0.4890, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [34/50], Step [168/469], Loss: 0.4116, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [34/50], Step [169/469], Loss: 0.2055, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [34/50], Step [170/469], Loss: 0.3852, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [34/50], Step [171/469], Loss: 0.4765, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [34/50], Step [172/469], Loss: 0.3524, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [34/50], Step [173/469], Loss: 0.4132, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [34/50], Step [174/469], Loss: 0.4679, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [34/50], Step [175/469], Loss: 0.4713, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [34/50], Step [176/469], Loss: 0.2255, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [34/50], Step [177/469], Loss: 0.5150, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [34/50], Step [178/469], Loss: 0.3015, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [34/50], Step [179/469], Loss: 0.3320, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [34/50], Step [180/469], Loss: 0.5028, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [34/50], Step [181/469], Loss: 0.3926, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [34/50], Step [182/469], Loss: 0.4084, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [34/50], Step [183/469], Loss: 0.4471, batch time: 0.55, accuracy:  82.81%\n",
      "Epoch [34/50], Step [184/469], Loss: 0.3387, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [34/50], Step [185/469], Loss: 0.4064, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [34/50], Step [186/469], Loss: 0.6021, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [34/50], Step [187/469], Loss: 0.3045, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [34/50], Step [188/469], Loss: 0.3358, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [189/469], Loss: 0.3723, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [34/50], Step [190/469], Loss: 0.2830, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [34/50], Step [191/469], Loss: 0.4047, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [34/50], Step [192/469], Loss: 0.2560, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [34/50], Step [193/469], Loss: 0.4054, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [34/50], Step [194/469], Loss: 0.3272, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [34/50], Step [195/469], Loss: 0.3807, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [34/50], Step [196/469], Loss: 0.2935, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [34/50], Step [197/469], Loss: 0.3560, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [34/50], Step [198/469], Loss: 0.4557, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [34/50], Step [199/469], Loss: 0.2668, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [34/50], Step [200/469], Loss: 0.3225, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [201/469], Loss: 0.2210, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [34/50], Step [202/469], Loss: 0.4815, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [34/50], Step [203/469], Loss: 0.2865, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [34/50], Step [204/469], Loss: 0.3780, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [34/50], Step [205/469], Loss: 0.2609, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [34/50], Step [206/469], Loss: 0.3685, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [34/50], Step [207/469], Loss: 0.3576, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [34/50], Step [208/469], Loss: 0.3424, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [34/50], Step [209/469], Loss: 0.4420, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [34/50], Step [210/469], Loss: 0.2711, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [34/50], Step [211/469], Loss: 0.2351, batch time: 0.93, accuracy:  92.19%\n",
      "Epoch [34/50], Step [212/469], Loss: 0.3309, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [34/50], Step [213/469], Loss: 0.3086, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [34/50], Step [214/469], Loss: 0.4760, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [34/50], Step [215/469], Loss: 0.3505, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [34/50], Step [216/469], Loss: 0.2086, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [34/50], Step [217/469], Loss: 0.3695, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [34/50], Step [218/469], Loss: 0.3060, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [34/50], Step [219/469], Loss: 0.4420, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [34/50], Step [220/469], Loss: 0.3843, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [34/50], Step [221/469], Loss: 0.3030, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [34/50], Step [222/469], Loss: 0.3992, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [34/50], Step [223/469], Loss: 0.3484, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [34/50], Step [224/469], Loss: 0.3661, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [34/50], Step [225/469], Loss: 0.2607, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [34/50], Step [226/469], Loss: 0.3784, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [34/50], Step [227/469], Loss: 0.4955, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [34/50], Step [228/469], Loss: 0.3832, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [34/50], Step [229/469], Loss: 0.3976, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [34/50], Step [230/469], Loss: 0.4667, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [34/50], Step [231/469], Loss: 0.5567, batch time: 0.63, accuracy:  82.03%\n",
      "Epoch [34/50], Step [232/469], Loss: 0.3680, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [34/50], Step [233/469], Loss: 0.2524, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [34/50], Step [234/469], Loss: 0.3311, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [235/469], Loss: 0.5808, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [34/50], Step [236/469], Loss: 0.3755, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [34/50], Step [237/469], Loss: 0.3132, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [34/50], Step [238/469], Loss: 0.3817, batch time: 0.67, accuracy:  87.50%\n",
      "Epoch [34/50], Step [239/469], Loss: 0.3926, batch time: 0.78, accuracy:  89.06%\n",
      "Epoch [34/50], Step [240/469], Loss: 0.4597, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [34/50], Step [241/469], Loss: 0.3061, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [242/469], Loss: 0.3433, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [34/50], Step [243/469], Loss: 0.3818, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [34/50], Step [244/469], Loss: 0.4196, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [34/50], Step [245/469], Loss: 0.3368, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [34/50], Step [246/469], Loss: 0.3108, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [34/50], Step [247/469], Loss: 0.5180, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [34/50], Step [248/469], Loss: 0.3113, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [34/50], Step [249/469], Loss: 0.2232, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [34/50], Step [250/469], Loss: 0.4617, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [251/469], Loss: 0.3217, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [34/50], Step [252/469], Loss: 0.3247, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [34/50], Step [253/469], Loss: 0.3374, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [34/50], Step [254/469], Loss: 0.5696, batch time: 0.56, accuracy:  83.59%\n",
      "Epoch [34/50], Step [255/469], Loss: 0.3726, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [34/50], Step [256/469], Loss: 0.1489, batch time: 0.48, accuracy:  96.09%\n",
      "Epoch [34/50], Step [257/469], Loss: 0.2676, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [34/50], Step [258/469], Loss: 0.3226, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [34/50], Step [259/469], Loss: 0.4439, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [34/50], Step [260/469], Loss: 0.4974, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [34/50], Step [261/469], Loss: 0.2248, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [34/50], Step [262/469], Loss: 0.5324, batch time: 0.56, accuracy:  83.59%\n",
      "Epoch [34/50], Step [263/469], Loss: 0.3261, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [34/50], Step [264/469], Loss: 0.3997, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [34/50], Step [265/469], Loss: 0.3093, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [34/50], Step [266/469], Loss: 0.3629, batch time: 0.61, accuracy:  92.97%\n",
      "Epoch [34/50], Step [267/469], Loss: 0.4828, batch time: 0.61, accuracy:  85.94%\n",
      "Epoch [34/50], Step [268/469], Loss: 0.3413, batch time: 0.73, accuracy:  89.84%\n",
      "Epoch [34/50], Step [269/469], Loss: 0.3844, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [34/50], Step [270/469], Loss: 0.3403, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [34/50], Step [271/469], Loss: 0.3865, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [34/50], Step [272/469], Loss: 0.3063, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [34/50], Step [273/469], Loss: 0.3262, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [34/50], Step [274/469], Loss: 0.5064, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [34/50], Step [275/469], Loss: 0.4089, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [276/469], Loss: 0.2477, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [34/50], Step [277/469], Loss: 0.4281, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [34/50], Step [278/469], Loss: 0.5082, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [34/50], Step [279/469], Loss: 0.2865, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [34/50], Step [280/469], Loss: 0.3638, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [34/50], Step [281/469], Loss: 0.4671, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [34/50], Step [282/469], Loss: 0.3488, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [34/50], Step [283/469], Loss: 0.3456, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [34/50], Step [284/469], Loss: 0.4809, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [34/50], Step [285/469], Loss: 0.2131, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [34/50], Step [286/469], Loss: 0.4199, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [34/50], Step [287/469], Loss: 0.4408, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [34/50], Step [288/469], Loss: 0.2715, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [34/50], Step [289/469], Loss: 0.4622, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [34/50], Step [290/469], Loss: 0.3104, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [34/50], Step [291/469], Loss: 0.4709, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [34/50], Step [292/469], Loss: 0.3390, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [34/50], Step [293/469], Loss: 0.2307, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [34/50], Step [294/469], Loss: 0.3453, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [34/50], Step [295/469], Loss: 0.4336, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [34/50], Step [296/469], Loss: 0.4006, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [34/50], Step [297/469], Loss: 0.3814, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [34/50], Step [298/469], Loss: 0.2890, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [34/50], Step [299/469], Loss: 0.4630, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [34/50], Step [300/469], Loss: 0.4989, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [34/50], Step [301/469], Loss: 0.3790, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [34/50], Step [302/469], Loss: 0.2882, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [34/50], Step [303/469], Loss: 0.2753, batch time: 0.67, accuracy:  92.19%\n",
      "Epoch [34/50], Step [304/469], Loss: 0.4271, batch time: 0.68, accuracy:  85.94%\n",
      "Epoch [34/50], Step [305/469], Loss: 0.3738, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [34/50], Step [306/469], Loss: 0.3152, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [34/50], Step [307/469], Loss: 0.3428, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [34/50], Step [308/469], Loss: 0.2064, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [34/50], Step [309/469], Loss: 0.3903, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [34/50], Step [310/469], Loss: 0.4230, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [34/50], Step [311/469], Loss: 0.3220, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [34/50], Step [312/469], Loss: 0.3693, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [34/50], Step [313/469], Loss: 0.3450, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [34/50], Step [314/469], Loss: 0.2366, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [34/50], Step [315/469], Loss: 0.1956, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [34/50], Step [316/469], Loss: 0.3590, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [34/50], Step [317/469], Loss: 0.2571, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [34/50], Step [318/469], Loss: 0.2552, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [34/50], Step [319/469], Loss: 0.3586, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [34/50], Step [320/469], Loss: 0.2982, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [34/50], Step [321/469], Loss: 0.2826, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [34/50], Step [322/469], Loss: 0.3171, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [34/50], Step [323/469], Loss: 0.3063, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [34/50], Step [324/469], Loss: 0.3716, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [34/50], Step [325/469], Loss: 0.4956, batch time: 0.70, accuracy:  85.16%\n",
      "Epoch [34/50], Step [326/469], Loss: 0.3071, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [34/50], Step [327/469], Loss: 0.4146, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [34/50], Step [328/469], Loss: 0.4678, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [34/50], Step [329/469], Loss: 0.3994, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [34/50], Step [330/469], Loss: 0.4424, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [34/50], Step [331/469], Loss: 0.2923, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [34/50], Step [332/469], Loss: 0.3617, batch time: 0.62, accuracy:  86.72%\n",
      "Epoch [34/50], Step [333/469], Loss: 0.3968, batch time: 0.75, accuracy:  89.84%\n",
      "Epoch [34/50], Step [334/469], Loss: 0.4337, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [34/50], Step [335/469], Loss: 0.3441, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [34/50], Step [336/469], Loss: 0.2975, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [34/50], Step [337/469], Loss: 0.4354, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [34/50], Step [338/469], Loss: 0.5467, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [34/50], Step [339/469], Loss: 0.6090, batch time: 0.49, accuracy:  78.91%\n",
      "Epoch [34/50], Step [340/469], Loss: 0.4964, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [34/50], Step [341/469], Loss: 0.3600, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [34/50], Step [342/469], Loss: 0.2902, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [34/50], Step [343/469], Loss: 0.3411, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [34/50], Step [344/469], Loss: 0.4569, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [34/50], Step [345/469], Loss: 0.4044, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [34/50], Step [346/469], Loss: 0.4313, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [34/50], Step [347/469], Loss: 0.2916, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [34/50], Step [348/469], Loss: 0.2161, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [34/50], Step [349/469], Loss: 0.3130, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [34/50], Step [350/469], Loss: 0.3186, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [34/50], Step [351/469], Loss: 0.5660, batch time: 0.56, accuracy:  83.59%\n",
      "Epoch [34/50], Step [352/469], Loss: 0.4601, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [34/50], Step [353/469], Loss: 0.3905, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [34/50], Step [354/469], Loss: 0.2894, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [34/50], Step [355/469], Loss: 0.3490, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [34/50], Step [356/469], Loss: 0.3900, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [34/50], Step [357/469], Loss: 0.3509, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [34/50], Step [358/469], Loss: 0.2930, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [34/50], Step [359/469], Loss: 0.2920, batch time: 0.67, accuracy:  88.28%\n",
      "Epoch [34/50], Step [360/469], Loss: 0.2582, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [34/50], Step [361/469], Loss: 0.3616, batch time: 0.68, accuracy:  88.28%\n",
      "Epoch [34/50], Step [362/469], Loss: 0.3139, batch time: 0.70, accuracy:  92.97%\n",
      "Epoch [34/50], Step [363/469], Loss: 0.3996, batch time: 0.64, accuracy:  85.16%\n",
      "Epoch [34/50], Step [364/469], Loss: 0.4270, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [34/50], Step [365/469], Loss: 0.3110, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [34/50], Step [366/469], Loss: 0.4794, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [34/50], Step [367/469], Loss: 0.4469, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [34/50], Step [368/469], Loss: 0.4147, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [34/50], Step [369/469], Loss: 0.3265, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [34/50], Step [370/469], Loss: 0.3990, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [371/469], Loss: 0.3080, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [34/50], Step [372/469], Loss: 0.2991, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [34/50], Step [373/469], Loss: 0.3517, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [34/50], Step [374/469], Loss: 0.2659, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [34/50], Step [375/469], Loss: 0.2919, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [34/50], Step [376/469], Loss: 0.3233, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [34/50], Step [377/469], Loss: 0.5045, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [378/469], Loss: 0.1851, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [34/50], Step [379/469], Loss: 0.2395, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [34/50], Step [380/469], Loss: 0.3941, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [34/50], Step [381/469], Loss: 0.2931, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [34/50], Step [382/469], Loss: 0.3375, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [34/50], Step [383/469], Loss: 0.4168, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [34/50], Step [384/469], Loss: 0.4690, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [34/50], Step [385/469], Loss: 0.3053, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [34/50], Step [386/469], Loss: 0.3553, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [34/50], Step [387/469], Loss: 0.2767, batch time: 0.63, accuracy:  90.62%\n",
      "Epoch [34/50], Step [388/469], Loss: 0.6456, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [34/50], Step [389/469], Loss: 0.4663, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [34/50], Step [390/469], Loss: 0.4315, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [34/50], Step [391/469], Loss: 0.3573, batch time: 0.67, accuracy:  90.62%\n",
      "Epoch [34/50], Step [392/469], Loss: 0.4555, batch time: 0.64, accuracy:  85.16%\n",
      "Epoch [34/50], Step [393/469], Loss: 0.4059, batch time: 0.65, accuracy:  86.72%\n",
      "Epoch [34/50], Step [394/469], Loss: 0.3093, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [34/50], Step [395/469], Loss: 0.3829, batch time: 0.68, accuracy:  89.84%\n",
      "Epoch [34/50], Step [396/469], Loss: 0.3715, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [34/50], Step [397/469], Loss: 0.3795, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [34/50], Step [398/469], Loss: 0.6332, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [34/50], Step [399/469], Loss: 0.4073, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [34/50], Step [400/469], Loss: 0.4419, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [34/50], Step [401/469], Loss: 0.3297, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [34/50], Step [402/469], Loss: 0.3827, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [34/50], Step [403/469], Loss: 0.3759, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [34/50], Step [404/469], Loss: 0.2318, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [34/50], Step [405/469], Loss: 0.4339, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [34/50], Step [406/469], Loss: 0.2517, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [34/50], Step [407/469], Loss: 0.3716, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [34/50], Step [408/469], Loss: 0.4939, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [34/50], Step [409/469], Loss: 0.3017, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [34/50], Step [410/469], Loss: 0.3834, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [34/50], Step [411/469], Loss: 0.3269, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [34/50], Step [412/469], Loss: 0.4738, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [34/50], Step [413/469], Loss: 0.4667, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [34/50], Step [414/469], Loss: 0.3799, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [34/50], Step [415/469], Loss: 0.5194, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [34/50], Step [416/469], Loss: 0.3796, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [34/50], Step [417/469], Loss: 0.3982, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [34/50], Step [418/469], Loss: 0.4778, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [34/50], Step [419/469], Loss: 0.4788, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [34/50], Step [420/469], Loss: 0.3811, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [34/50], Step [421/469], Loss: 0.6021, batch time: 0.56, accuracy:  85.16%\n",
      "Epoch [34/50], Step [422/469], Loss: 0.2620, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [34/50], Step [423/469], Loss: 0.2269, batch time: 0.95, accuracy:  92.97%\n",
      "Epoch [34/50], Step [424/469], Loss: 0.3942, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [34/50], Step [425/469], Loss: 0.2848, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [34/50], Step [426/469], Loss: 0.2968, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [34/50], Step [427/469], Loss: 0.3413, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [34/50], Step [428/469], Loss: 0.3345, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [34/50], Step [429/469], Loss: 0.3768, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [34/50], Step [430/469], Loss: 0.2548, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [34/50], Step [431/469], Loss: 0.5125, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [34/50], Step [432/469], Loss: 0.3713, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [34/50], Step [433/469], Loss: 0.4162, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [34/50], Step [434/469], Loss: 0.2514, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [34/50], Step [435/469], Loss: 0.3224, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [34/50], Step [436/469], Loss: 0.2910, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [34/50], Step [437/469], Loss: 0.5030, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [34/50], Step [438/469], Loss: 0.4059, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [34/50], Step [439/469], Loss: 0.2912, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [34/50], Step [440/469], Loss: 0.2825, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [34/50], Step [441/469], Loss: 0.2889, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [34/50], Step [442/469], Loss: 0.2512, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [34/50], Step [443/469], Loss: 0.3263, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [34/50], Step [444/469], Loss: 0.5772, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [34/50], Step [445/469], Loss: 0.4600, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [34/50], Step [446/469], Loss: 0.4924, batch time: 0.57, accuracy:  84.38%\n",
      "Epoch [34/50], Step [447/469], Loss: 0.3425, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [34/50], Step [448/469], Loss: 0.4583, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [34/50], Step [449/469], Loss: 0.3899, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [34/50], Step [450/469], Loss: 0.3397, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [34/50], Step [451/469], Loss: 0.3458, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [34/50], Step [452/469], Loss: 0.2746, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [34/50], Step [453/469], Loss: 0.2892, batch time: 0.74, accuracy:  90.62%\n",
      "Epoch [34/50], Step [454/469], Loss: 0.3952, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [34/50], Step [455/469], Loss: 0.2903, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [34/50], Step [456/469], Loss: 0.3078, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [34/50], Step [457/469], Loss: 0.4282, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [34/50], Step [458/469], Loss: 0.3006, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [34/50], Step [459/469], Loss: 0.2797, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [34/50], Step [460/469], Loss: 0.3643, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [34/50], Step [461/469], Loss: 0.3349, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [34/50], Step [462/469], Loss: 0.3602, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [34/50], Step [463/469], Loss: 0.4006, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [34/50], Step [464/469], Loss: 0.3531, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [34/50], Step [465/469], Loss: 0.2409, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [34/50], Step [466/469], Loss: 0.3089, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [34/50], Step [467/469], Loss: 0.4136, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [34/50], Step [468/469], Loss: 0.3624, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [34/50], Step [469/469], Loss: 0.3360, batch time: 0.50, accuracy:  89.58%\n",
      "Epoch [35/50], Step [1/469], Loss: 0.3057, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [35/50], Step [2/469], Loss: 0.4015, batch time: 0.48, accuracy:  82.03%\n",
      "Epoch [35/50], Step [3/469], Loss: 0.2032, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [35/50], Step [4/469], Loss: 0.5252, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [5/469], Loss: 0.2182, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [35/50], Step [6/469], Loss: 0.3411, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [35/50], Step [7/469], Loss: 0.4331, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [35/50], Step [8/469], Loss: 0.3128, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [9/469], Loss: 0.3103, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [35/50], Step [10/469], Loss: 0.3708, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [35/50], Step [11/469], Loss: 0.2927, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [35/50], Step [12/469], Loss: 0.3805, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [35/50], Step [13/469], Loss: 0.3018, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [35/50], Step [14/469], Loss: 0.3114, batch time: 0.68, accuracy:  92.19%\n",
      "Epoch [35/50], Step [15/469], Loss: 0.3427, batch time: 0.73, accuracy:  92.19%\n",
      "Epoch [35/50], Step [16/469], Loss: 0.4132, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [35/50], Step [17/469], Loss: 0.1777, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [35/50], Step [18/469], Loss: 0.4851, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [35/50], Step [19/469], Loss: 0.3742, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [35/50], Step [20/469], Loss: 0.3397, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [35/50], Step [21/469], Loss: 0.3245, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [35/50], Step [22/469], Loss: 0.3969, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [35/50], Step [23/469], Loss: 0.2749, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [35/50], Step [24/469], Loss: 0.4215, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [35/50], Step [25/469], Loss: 0.3942, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [26/469], Loss: 0.4665, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [35/50], Step [27/469], Loss: 0.4535, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [35/50], Step [28/469], Loss: 0.5388, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [35/50], Step [29/469], Loss: 0.4610, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [35/50], Step [30/469], Loss: 0.2274, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [35/50], Step [31/469], Loss: 0.3088, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [35/50], Step [32/469], Loss: 0.4824, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [35/50], Step [33/469], Loss: 0.3801, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [34/469], Loss: 0.3350, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [35/50], Step [35/469], Loss: 0.3086, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [35/50], Step [36/469], Loss: 0.2171, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [35/50], Step [37/469], Loss: 0.5074, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [35/50], Step [38/469], Loss: 0.3200, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [39/469], Loss: 0.3371, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [35/50], Step [40/469], Loss: 0.4400, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [35/50], Step [41/469], Loss: 0.2213, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [35/50], Step [42/469], Loss: 0.5724, batch time: 0.61, accuracy:  82.03%\n",
      "Epoch [35/50], Step [43/469], Loss: 0.2851, batch time: 0.73, accuracy:  89.06%\n",
      "Epoch [35/50], Step [44/469], Loss: 0.3159, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [35/50], Step [45/469], Loss: 0.2208, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [35/50], Step [46/469], Loss: 0.4657, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [35/50], Step [47/469], Loss: 0.4569, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [35/50], Step [48/469], Loss: 0.5610, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [35/50], Step [49/469], Loss: 0.2637, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [35/50], Step [50/469], Loss: 0.2758, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [35/50], Step [51/469], Loss: 0.4351, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [35/50], Step [52/469], Loss: 0.3385, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [35/50], Step [53/469], Loss: 0.3675, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [35/50], Step [54/469], Loss: 0.3755, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [35/50], Step [55/469], Loss: 0.4076, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [35/50], Step [56/469], Loss: 0.3075, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [57/469], Loss: 0.4076, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [35/50], Step [58/469], Loss: 0.3271, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [35/50], Step [59/469], Loss: 0.4126, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [35/50], Step [60/469], Loss: 0.2761, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [61/469], Loss: 0.3272, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [35/50], Step [62/469], Loss: 0.3520, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [35/50], Step [63/469], Loss: 0.3545, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [64/469], Loss: 0.2798, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [35/50], Step [65/469], Loss: 0.3084, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [35/50], Step [66/469], Loss: 0.4772, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [35/50], Step [67/469], Loss: 0.3025, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [35/50], Step [68/469], Loss: 0.5413, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [35/50], Step [69/469], Loss: 0.2165, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [35/50], Step [70/469], Loss: 0.3635, batch time: 0.62, accuracy:  86.72%\n",
      "Epoch [35/50], Step [71/469], Loss: 0.4499, batch time: 0.67, accuracy:  86.72%\n",
      "Epoch [35/50], Step [72/469], Loss: 0.2829, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [35/50], Step [73/469], Loss: 0.4880, batch time: 0.86, accuracy:  85.94%\n",
      "Epoch [35/50], Step [74/469], Loss: 0.4136, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [35/50], Step [75/469], Loss: 0.5152, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [35/50], Step [76/469], Loss: 0.4457, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [35/50], Step [77/469], Loss: 0.3588, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [35/50], Step [78/469], Loss: 0.3555, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [35/50], Step [79/469], Loss: 0.2379, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [35/50], Step [80/469], Loss: 0.3467, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [35/50], Step [81/469], Loss: 0.2926, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [82/469], Loss: 0.2152, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [35/50], Step [83/469], Loss: 0.3017, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [35/50], Step [84/469], Loss: 0.3381, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [35/50], Step [85/469], Loss: 0.3232, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [35/50], Step [86/469], Loss: 0.3077, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [35/50], Step [87/469], Loss: 0.3366, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [35/50], Step [88/469], Loss: 0.3010, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [89/469], Loss: 0.3650, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [35/50], Step [90/469], Loss: 0.2120, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [35/50], Step [91/469], Loss: 0.3180, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [92/469], Loss: 0.3675, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [35/50], Step [93/469], Loss: 0.3120, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [35/50], Step [94/469], Loss: 0.3370, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [35/50], Step [95/469], Loss: 0.4119, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [35/50], Step [96/469], Loss: 0.3280, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [35/50], Step [97/469], Loss: 0.4109, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [35/50], Step [98/469], Loss: 0.2537, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [99/469], Loss: 0.3044, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [35/50], Step [100/469], Loss: 0.4133, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [101/469], Loss: 0.4890, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [35/50], Step [102/469], Loss: 0.3108, batch time: 0.74, accuracy:  89.84%\n",
      "Epoch [35/50], Step [103/469], Loss: 0.5097, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [35/50], Step [104/469], Loss: 0.4484, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [35/50], Step [105/469], Loss: 0.3932, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [35/50], Step [106/469], Loss: 0.5187, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [35/50], Step [107/469], Loss: 0.4746, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [108/469], Loss: 0.2401, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [35/50], Step [109/469], Loss: 0.3889, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [35/50], Step [110/469], Loss: 0.2354, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [35/50], Step [111/469], Loss: 0.2991, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [35/50], Step [112/469], Loss: 0.3339, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [35/50], Step [113/469], Loss: 0.3675, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [35/50], Step [114/469], Loss: 0.3493, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [35/50], Step [115/469], Loss: 0.2171, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [35/50], Step [116/469], Loss: 0.4447, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [117/469], Loss: 0.5115, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [35/50], Step [118/469], Loss: 0.4115, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [35/50], Step [119/469], Loss: 0.2441, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [35/50], Step [120/469], Loss: 0.4429, batch time: 0.61, accuracy:  84.38%\n",
      "Epoch [35/50], Step [121/469], Loss: 0.2787, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [35/50], Step [122/469], Loss: 0.2986, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [35/50], Step [123/469], Loss: 0.2591, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [35/50], Step [124/469], Loss: 0.3013, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [35/50], Step [125/469], Loss: 0.3545, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [35/50], Step [126/469], Loss: 0.3624, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [35/50], Step [127/469], Loss: 0.2928, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [35/50], Step [128/469], Loss: 0.2464, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [129/469], Loss: 0.4771, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [35/50], Step [130/469], Loss: 0.4528, batch time: 0.56, accuracy:  81.25%\n",
      "Epoch [35/50], Step [131/469], Loss: 0.2961, batch time: 0.67, accuracy:  90.62%\n",
      "Epoch [35/50], Step [132/469], Loss: 0.3087, batch time: 0.68, accuracy:  89.84%\n",
      "Epoch [35/50], Step [133/469], Loss: 0.2418, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [35/50], Step [134/469], Loss: 0.2375, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [35/50], Step [135/469], Loss: 0.3710, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [35/50], Step [136/469], Loss: 0.3116, batch time: 0.66, accuracy:  89.06%\n",
      "Epoch [35/50], Step [137/469], Loss: 0.3694, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [35/50], Step [138/469], Loss: 0.4078, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [35/50], Step [139/469], Loss: 0.3313, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [35/50], Step [140/469], Loss: 0.4388, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [35/50], Step [141/469], Loss: 0.3504, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [35/50], Step [142/469], Loss: 0.3966, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [35/50], Step [143/469], Loss: 0.2216, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [35/50], Step [144/469], Loss: 0.4454, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [35/50], Step [145/469], Loss: 0.4060, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [35/50], Step [146/469], Loss: 0.4029, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [35/50], Step [147/469], Loss: 0.5031, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [35/50], Step [148/469], Loss: 0.3981, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [35/50], Step [149/469], Loss: 0.4272, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [35/50], Step [150/469], Loss: 0.4148, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [35/50], Step [151/469], Loss: 0.3682, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [35/50], Step [152/469], Loss: 0.3748, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [35/50], Step [153/469], Loss: 0.3404, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [35/50], Step [154/469], Loss: 0.3598, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [155/469], Loss: 0.4200, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [35/50], Step [156/469], Loss: 0.2750, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [35/50], Step [157/469], Loss: 0.3134, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [35/50], Step [158/469], Loss: 0.3200, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [159/469], Loss: 0.3631, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [35/50], Step [160/469], Loss: 0.2603, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [35/50], Step [161/469], Loss: 0.4637, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [35/50], Step [162/469], Loss: 0.2905, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [35/50], Step [163/469], Loss: 0.3165, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [35/50], Step [164/469], Loss: 0.3041, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [35/50], Step [165/469], Loss: 0.3448, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [35/50], Step [166/469], Loss: 0.2872, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [35/50], Step [167/469], Loss: 0.3544, batch time: 0.63, accuracy:  90.62%\n",
      "Epoch [35/50], Step [168/469], Loss: 0.3058, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [35/50], Step [169/469], Loss: 0.6132, batch time: 0.59, accuracy:  80.47%\n",
      "Epoch [35/50], Step [170/469], Loss: 0.3265, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [35/50], Step [171/469], Loss: 0.4296, batch time: 0.66, accuracy:  85.16%\n",
      "Epoch [35/50], Step [172/469], Loss: 0.2982, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [35/50], Step [173/469], Loss: 0.4449, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [174/469], Loss: 0.3252, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [35/50], Step [175/469], Loss: 0.4581, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [35/50], Step [176/469], Loss: 0.4299, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [35/50], Step [177/469], Loss: 0.2163, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [35/50], Step [178/469], Loss: 0.2528, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [35/50], Step [179/469], Loss: 0.3143, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [35/50], Step [180/469], Loss: 0.2942, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [35/50], Step [181/469], Loss: 0.3162, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [35/50], Step [182/469], Loss: 0.3443, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [35/50], Step [183/469], Loss: 0.3972, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [35/50], Step [184/469], Loss: 0.3979, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [35/50], Step [185/469], Loss: 0.6854, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [35/50], Step [186/469], Loss: 0.4837, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [35/50], Step [187/469], Loss: 0.4711, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [35/50], Step [188/469], Loss: 0.3676, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [35/50], Step [189/469], Loss: 0.3788, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [35/50], Step [190/469], Loss: 0.4086, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [35/50], Step [191/469], Loss: 0.3522, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [35/50], Step [192/469], Loss: 0.5901, batch time: 0.50, accuracy:  81.25%\n",
      "Epoch [35/50], Step [193/469], Loss: 0.2368, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [35/50], Step [194/469], Loss: 0.2687, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [35/50], Step [195/469], Loss: 0.3690, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [196/469], Loss: 0.1797, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [35/50], Step [197/469], Loss: 0.3870, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [198/469], Loss: 0.5083, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [35/50], Step [199/469], Loss: 0.3762, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [200/469], Loss: 0.2598, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [35/50], Step [201/469], Loss: 0.2258, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [35/50], Step [202/469], Loss: 0.3316, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [35/50], Step [203/469], Loss: 0.2576, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [35/50], Step [204/469], Loss: 0.4213, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [35/50], Step [205/469], Loss: 0.3409, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [35/50], Step [206/469], Loss: 0.3192, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [35/50], Step [207/469], Loss: 0.2942, batch time: 0.66, accuracy:  93.75%\n",
      "Epoch [35/50], Step [208/469], Loss: 0.2639, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [35/50], Step [209/469], Loss: 0.3833, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [35/50], Step [210/469], Loss: 0.2992, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [35/50], Step [211/469], Loss: 0.2628, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [35/50], Step [212/469], Loss: 0.2987, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [35/50], Step [213/469], Loss: 0.3634, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [35/50], Step [214/469], Loss: 0.3935, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [35/50], Step [215/469], Loss: 0.2103, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [35/50], Step [216/469], Loss: 0.4354, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [35/50], Step [217/469], Loss: 0.2437, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [35/50], Step [218/469], Loss: 0.3787, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [35/50], Step [219/469], Loss: 0.3666, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [35/50], Step [220/469], Loss: 0.3182, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [221/469], Loss: 0.3672, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [35/50], Step [222/469], Loss: 0.3153, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [35/50], Step [223/469], Loss: 0.3456, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [35/50], Step [224/469], Loss: 0.3198, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [35/50], Step [225/469], Loss: 0.4312, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [35/50], Step [226/469], Loss: 0.3264, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [35/50], Step [227/469], Loss: 0.4452, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [35/50], Step [228/469], Loss: 0.2721, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [35/50], Step [229/469], Loss: 0.2435, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [35/50], Step [230/469], Loss: 0.3335, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [35/50], Step [231/469], Loss: 0.2663, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [35/50], Step [232/469], Loss: 0.2576, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [35/50], Step [233/469], Loss: 0.3777, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [35/50], Step [234/469], Loss: 0.6704, batch time: 0.70, accuracy:  83.59%\n",
      "Epoch [35/50], Step [235/469], Loss: 0.6084, batch time: 0.68, accuracy:  87.50%\n",
      "Epoch [35/50], Step [236/469], Loss: 0.5467, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [35/50], Step [237/469], Loss: 0.3856, batch time: 0.64, accuracy:  89.06%\n",
      "Epoch [35/50], Step [238/469], Loss: 0.3333, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [35/50], Step [239/469], Loss: 0.3660, batch time: 0.62, accuracy:  86.72%\n",
      "Epoch [35/50], Step [240/469], Loss: 0.3543, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [35/50], Step [241/469], Loss: 0.3923, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [35/50], Step [242/469], Loss: 0.2891, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [35/50], Step [243/469], Loss: 0.4108, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [35/50], Step [244/469], Loss: 0.3398, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [35/50], Step [245/469], Loss: 0.3495, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [35/50], Step [246/469], Loss: 0.3952, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [35/50], Step [247/469], Loss: 0.3510, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [35/50], Step [248/469], Loss: 0.3981, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [35/50], Step [249/469], Loss: 0.2888, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [35/50], Step [250/469], Loss: 0.4436, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [35/50], Step [251/469], Loss: 0.4134, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [35/50], Step [252/469], Loss: 0.2410, batch time: 0.61, accuracy:  95.31%\n",
      "Epoch [35/50], Step [253/469], Loss: 0.2906, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [35/50], Step [254/469], Loss: 0.4255, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [35/50], Step [255/469], Loss: 0.2175, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [35/50], Step [256/469], Loss: 0.2718, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [35/50], Step [257/469], Loss: 0.4373, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [35/50], Step [258/469], Loss: 0.4670, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [35/50], Step [259/469], Loss: 0.4079, batch time: 0.64, accuracy:  85.94%\n",
      "Epoch [35/50], Step [260/469], Loss: 0.2394, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [35/50], Step [261/469], Loss: 0.2712, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [35/50], Step [262/469], Loss: 0.5828, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [35/50], Step [263/469], Loss: 0.3295, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [35/50], Step [264/469], Loss: 0.2347, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [35/50], Step [265/469], Loss: 0.4845, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [35/50], Step [266/469], Loss: 0.4282, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [35/50], Step [267/469], Loss: 0.2449, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [35/50], Step [268/469], Loss: 0.3561, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [35/50], Step [269/469], Loss: 0.3184, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [35/50], Step [270/469], Loss: 0.4319, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [35/50], Step [271/469], Loss: 0.3207, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [35/50], Step [272/469], Loss: 0.2402, batch time: 0.68, accuracy:  93.75%\n",
      "Epoch [35/50], Step [273/469], Loss: 0.2952, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [35/50], Step [274/469], Loss: 0.3837, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [35/50], Step [275/469], Loss: 0.2843, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [35/50], Step [276/469], Loss: 0.4839, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [35/50], Step [277/469], Loss: 0.2579, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [35/50], Step [278/469], Loss: 0.3144, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [279/469], Loss: 0.4369, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [35/50], Step [280/469], Loss: 0.3095, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [35/50], Step [281/469], Loss: 0.2536, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [35/50], Step [282/469], Loss: 0.3294, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [35/50], Step [283/469], Loss: 0.2437, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [35/50], Step [284/469], Loss: 0.2468, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [35/50], Step [285/469], Loss: 0.2570, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [35/50], Step [286/469], Loss: 0.2747, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [35/50], Step [287/469], Loss: 0.4077, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [35/50], Step [288/469], Loss: 0.2822, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [35/50], Step [289/469], Loss: 0.4155, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [35/50], Step [290/469], Loss: 0.4537, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [35/50], Step [291/469], Loss: 0.3484, batch time: 0.72, accuracy:  89.06%\n",
      "Epoch [35/50], Step [292/469], Loss: 0.3013, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [35/50], Step [293/469], Loss: 0.1674, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [35/50], Step [294/469], Loss: 0.2866, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [35/50], Step [295/469], Loss: 0.3803, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [35/50], Step [296/469], Loss: 0.3173, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [35/50], Step [297/469], Loss: 0.3937, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [298/469], Loss: 0.3714, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [35/50], Step [299/469], Loss: 0.3374, batch time: 0.70, accuracy:  90.62%\n",
      "Epoch [35/50], Step [300/469], Loss: 0.3560, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [35/50], Step [301/469], Loss: 0.5791, batch time: 0.61, accuracy:  85.94%\n",
      "Epoch [35/50], Step [302/469], Loss: 0.4032, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [35/50], Step [303/469], Loss: 0.4081, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [35/50], Step [304/469], Loss: 0.4169, batch time: 0.64, accuracy:  87.50%\n",
      "Epoch [35/50], Step [305/469], Loss: 0.3648, batch time: 0.70, accuracy:  89.06%\n",
      "Epoch [35/50], Step [306/469], Loss: 0.5628, batch time: 0.65, accuracy:  84.38%\n",
      "Epoch [35/50], Step [307/469], Loss: 0.2694, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [35/50], Step [308/469], Loss: 0.4033, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [35/50], Step [309/469], Loss: 0.2998, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [35/50], Step [310/469], Loss: 0.2345, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [35/50], Step [311/469], Loss: 0.3802, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [35/50], Step [312/469], Loss: 0.4491, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [313/469], Loss: 0.2929, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [35/50], Step [314/469], Loss: 0.3425, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [35/50], Step [315/469], Loss: 0.3665, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [35/50], Step [316/469], Loss: 0.4091, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [35/50], Step [317/469], Loss: 0.4243, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [35/50], Step [318/469], Loss: 0.3303, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [35/50], Step [319/469], Loss: 0.3394, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [35/50], Step [320/469], Loss: 0.4359, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [35/50], Step [321/469], Loss: 0.2511, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [35/50], Step [322/469], Loss: 0.2857, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [323/469], Loss: 0.5179, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [324/469], Loss: 0.3611, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [35/50], Step [325/469], Loss: 0.3708, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [35/50], Step [326/469], Loss: 0.4720, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [35/50], Step [327/469], Loss: 0.3059, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [35/50], Step [328/469], Loss: 0.3923, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [35/50], Step [329/469], Loss: 0.3841, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [35/50], Step [330/469], Loss: 0.3945, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [35/50], Step [331/469], Loss: 0.2840, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [35/50], Step [332/469], Loss: 0.4426, batch time: 0.51, accuracy:  81.25%\n",
      "Epoch [35/50], Step [333/469], Loss: 0.4623, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [35/50], Step [334/469], Loss: 0.4220, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [35/50], Step [335/469], Loss: 0.3839, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [35/50], Step [336/469], Loss: 0.2801, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [35/50], Step [337/469], Loss: 0.3276, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [35/50], Step [338/469], Loss: 0.5370, batch time: 0.70, accuracy:  84.38%\n",
      "Epoch [35/50], Step [339/469], Loss: 0.4874, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [35/50], Step [340/469], Loss: 0.4665, batch time: 0.65, accuracy:  84.38%\n",
      "Epoch [35/50], Step [341/469], Loss: 0.3196, batch time: 0.62, accuracy:  91.41%\n",
      "Epoch [35/50], Step [342/469], Loss: 0.3359, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [35/50], Step [343/469], Loss: 0.4422, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [35/50], Step [344/469], Loss: 0.3188, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [35/50], Step [345/469], Loss: 0.3944, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [346/469], Loss: 0.4115, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [347/469], Loss: 0.4355, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [35/50], Step [348/469], Loss: 0.3743, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [35/50], Step [349/469], Loss: 0.4118, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [35/50], Step [350/469], Loss: 0.3866, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [351/469], Loss: 0.2857, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [35/50], Step [352/469], Loss: 0.3051, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [353/469], Loss: 0.3115, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [35/50], Step [354/469], Loss: 0.3626, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [35/50], Step [355/469], Loss: 0.2559, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [35/50], Step [356/469], Loss: 0.3717, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [35/50], Step [357/469], Loss: 0.4149, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [35/50], Step [358/469], Loss: 0.3874, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [35/50], Step [359/469], Loss: 0.3656, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [35/50], Step [360/469], Loss: 0.3298, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [35/50], Step [361/469], Loss: 0.2352, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [35/50], Step [362/469], Loss: 0.4223, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [35/50], Step [363/469], Loss: 0.3658, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [35/50], Step [364/469], Loss: 0.4668, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [35/50], Step [365/469], Loss: 0.3696, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [366/469], Loss: 0.3058, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [367/469], Loss: 0.3612, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [35/50], Step [368/469], Loss: 0.4119, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [35/50], Step [369/469], Loss: 0.4817, batch time: 0.71, accuracy:  86.72%\n",
      "Epoch [35/50], Step [370/469], Loss: 0.2614, batch time: 0.65, accuracy:  93.75%\n",
      "Epoch [35/50], Step [371/469], Loss: 0.2723, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [35/50], Step [372/469], Loss: 0.2903, batch time: 0.67, accuracy:  92.19%\n",
      "Epoch [35/50], Step [373/469], Loss: 0.3369, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [374/469], Loss: 0.4176, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [35/50], Step [375/469], Loss: 0.3746, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [35/50], Step [376/469], Loss: 0.3346, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [35/50], Step [377/469], Loss: 0.3142, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [35/50], Step [378/469], Loss: 0.3753, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [379/469], Loss: 0.4387, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [35/50], Step [380/469], Loss: 0.3918, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [35/50], Step [381/469], Loss: 0.3726, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [382/469], Loss: 0.3171, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [35/50], Step [383/469], Loss: 0.4181, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [35/50], Step [384/469], Loss: 0.3803, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [35/50], Step [385/469], Loss: 0.3068, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [35/50], Step [386/469], Loss: 0.4951, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [35/50], Step [387/469], Loss: 0.2874, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [35/50], Step [388/469], Loss: 0.3605, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [35/50], Step [389/469], Loss: 0.3972, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [35/50], Step [390/469], Loss: 0.3790, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [35/50], Step [391/469], Loss: 0.3186, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [35/50], Step [392/469], Loss: 0.4378, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [35/50], Step [393/469], Loss: 0.3997, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [35/50], Step [394/469], Loss: 0.2861, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [35/50], Step [395/469], Loss: 0.2901, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [35/50], Step [396/469], Loss: 0.2914, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [35/50], Step [397/469], Loss: 0.3952, batch time: 0.69, accuracy:  88.28%\n",
      "Epoch [35/50], Step [398/469], Loss: 0.3172, batch time: 0.83, accuracy:  90.62%\n",
      "Epoch [35/50], Step [399/469], Loss: 0.2850, batch time: 0.66, accuracy:  90.62%\n",
      "Epoch [35/50], Step [400/469], Loss: 0.4076, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [35/50], Step [401/469], Loss: 0.3259, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [35/50], Step [402/469], Loss: 0.4055, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [35/50], Step [403/469], Loss: 0.2274, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [35/50], Step [404/469], Loss: 0.3991, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [35/50], Step [405/469], Loss: 0.4056, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [35/50], Step [406/469], Loss: 0.4425, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [35/50], Step [407/469], Loss: 0.3458, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [35/50], Step [408/469], Loss: 0.3334, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [35/50], Step [409/469], Loss: 0.3311, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [35/50], Step [410/469], Loss: 0.3762, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [35/50], Step [411/469], Loss: 0.4667, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [35/50], Step [412/469], Loss: 0.3599, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [35/50], Step [413/469], Loss: 0.3748, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [35/50], Step [414/469], Loss: 0.3550, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [35/50], Step [415/469], Loss: 0.3714, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [35/50], Step [416/469], Loss: 0.2942, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [35/50], Step [417/469], Loss: 0.3512, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [35/50], Step [418/469], Loss: 0.2470, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [35/50], Step [419/469], Loss: 0.2916, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [35/50], Step [420/469], Loss: 0.3163, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [35/50], Step [421/469], Loss: 0.4149, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [35/50], Step [422/469], Loss: 0.4651, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [35/50], Step [423/469], Loss: 0.5587, batch time: 0.59, accuracy:  82.81%\n",
      "Epoch [35/50], Step [424/469], Loss: 0.4866, batch time: 0.60, accuracy:  84.38%\n",
      "Epoch [35/50], Step [425/469], Loss: 0.3785, batch time: 0.78, accuracy:  91.41%\n",
      "Epoch [35/50], Step [426/469], Loss: 0.3508, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [35/50], Step [427/469], Loss: 0.4028, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [35/50], Step [428/469], Loss: 0.2481, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [35/50], Step [429/469], Loss: 0.2156, batch time: 0.61, accuracy:  95.31%\n",
      "Epoch [35/50], Step [430/469], Loss: 0.3267, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [35/50], Step [431/469], Loss: 0.3045, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [35/50], Step [432/469], Loss: 0.3219, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [35/50], Step [433/469], Loss: 0.3180, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [35/50], Step [434/469], Loss: 0.3663, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [35/50], Step [435/469], Loss: 0.4184, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [35/50], Step [436/469], Loss: 0.3529, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [35/50], Step [437/469], Loss: 0.2520, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [35/50], Step [438/469], Loss: 0.3681, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [35/50], Step [439/469], Loss: 0.3331, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [35/50], Step [440/469], Loss: 0.4349, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [35/50], Step [441/469], Loss: 0.3733, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [35/50], Step [442/469], Loss: 0.3225, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [35/50], Step [443/469], Loss: 0.2915, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [35/50], Step [444/469], Loss: 0.3703, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [35/50], Step [445/469], Loss: 0.4364, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [35/50], Step [446/469], Loss: 0.4683, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [35/50], Step [447/469], Loss: 0.3959, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [35/50], Step [448/469], Loss: 0.5008, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [35/50], Step [449/469], Loss: 0.4316, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [35/50], Step [450/469], Loss: 0.3985, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [35/50], Step [451/469], Loss: 0.3733, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [35/50], Step [452/469], Loss: 0.4202, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [35/50], Step [453/469], Loss: 0.2223, batch time: 0.66, accuracy:  92.19%\n",
      "Epoch [35/50], Step [454/469], Loss: 0.4058, batch time: 0.70, accuracy:  87.50%\n",
      "Epoch [35/50], Step [455/469], Loss: 0.2422, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [35/50], Step [456/469], Loss: 0.4792, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [35/50], Step [457/469], Loss: 0.2714, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [35/50], Step [458/469], Loss: 0.3497, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [35/50], Step [459/469], Loss: 0.3702, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [35/50], Step [460/469], Loss: 0.3586, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [35/50], Step [461/469], Loss: 0.2944, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [35/50], Step [462/469], Loss: 0.2904, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [35/50], Step [463/469], Loss: 0.3693, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [35/50], Step [464/469], Loss: 0.3837, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [35/50], Step [465/469], Loss: 0.3292, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [35/50], Step [466/469], Loss: 0.3015, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [35/50], Step [467/469], Loss: 0.3378, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [35/50], Step [468/469], Loss: 0.3145, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [35/50], Step [469/469], Loss: 0.3521, batch time: 0.53, accuracy:  89.58%\n",
      "Epoch [36/50], Step [1/469], Loss: 0.3617, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [36/50], Step [2/469], Loss: 0.4566, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [36/50], Step [3/469], Loss: 0.3539, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [36/50], Step [4/469], Loss: 0.2471, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [5/469], Loss: 0.4165, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [36/50], Step [6/469], Loss: 0.4305, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [36/50], Step [7/469], Loss: 0.3555, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [36/50], Step [8/469], Loss: 0.2890, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [36/50], Step [9/469], Loss: 0.3013, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [36/50], Step [10/469], Loss: 0.3253, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [36/50], Step [11/469], Loss: 0.3518, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [36/50], Step [12/469], Loss: 0.3249, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [36/50], Step [13/469], Loss: 0.3085, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [36/50], Step [14/469], Loss: 0.3544, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [36/50], Step [15/469], Loss: 0.3066, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [36/50], Step [16/469], Loss: 0.3229, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [36/50], Step [17/469], Loss: 0.3683, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [36/50], Step [18/469], Loss: 0.3361, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [36/50], Step [19/469], Loss: 0.2863, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [36/50], Step [20/469], Loss: 0.3067, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [36/50], Step [21/469], Loss: 0.3486, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [36/50], Step [22/469], Loss: 0.2198, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [36/50], Step [23/469], Loss: 0.4762, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [36/50], Step [24/469], Loss: 0.5299, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [36/50], Step [25/469], Loss: 0.3147, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [36/50], Step [26/469], Loss: 0.2952, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [36/50], Step [27/469], Loss: 0.4128, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [36/50], Step [28/469], Loss: 0.3765, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [36/50], Step [29/469], Loss: 0.5121, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [36/50], Step [30/469], Loss: 0.3515, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [36/50], Step [31/469], Loss: 0.2202, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [36/50], Step [32/469], Loss: 0.5007, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [36/50], Step [33/469], Loss: 0.3163, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [36/50], Step [34/469], Loss: 0.2650, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [36/50], Step [35/469], Loss: 0.3632, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [36/50], Step [36/469], Loss: 0.3539, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [36/50], Step [37/469], Loss: 0.2820, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [36/50], Step [38/469], Loss: 0.3229, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [36/50], Step [39/469], Loss: 0.2243, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [36/50], Step [40/469], Loss: 0.2485, batch time: 0.74, accuracy:  94.53%\n",
      "Epoch [36/50], Step [41/469], Loss: 0.3299, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [36/50], Step [42/469], Loss: 0.4613, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [36/50], Step [43/469], Loss: 0.3573, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [36/50], Step [44/469], Loss: 0.4542, batch time: 0.62, accuracy:  83.59%\n",
      "Epoch [36/50], Step [45/469], Loss: 0.3815, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [36/50], Step [46/469], Loss: 0.3238, batch time: 0.62, accuracy:  93.75%\n",
      "Epoch [36/50], Step [47/469], Loss: 0.3260, batch time: 0.68, accuracy:  88.28%\n",
      "Epoch [36/50], Step [48/469], Loss: 0.5300, batch time: 0.68, accuracy:  89.84%\n",
      "Epoch [36/50], Step [49/469], Loss: 0.3898, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [36/50], Step [50/469], Loss: 0.3901, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [36/50], Step [51/469], Loss: 0.5416, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [36/50], Step [52/469], Loss: 0.2715, batch time: 0.57, accuracy:  93.75%\n",
      "Epoch [36/50], Step [53/469], Loss: 0.3518, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [36/50], Step [54/469], Loss: 0.2489, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [36/50], Step [55/469], Loss: 0.3861, batch time: 0.57, accuracy:  82.03%\n",
      "Epoch [36/50], Step [56/469], Loss: 0.3538, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [36/50], Step [57/469], Loss: 0.2218, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [36/50], Step [58/469], Loss: 0.4402, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [36/50], Step [59/469], Loss: 0.4311, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [60/469], Loss: 0.4581, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [36/50], Step [61/469], Loss: 0.5863, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [36/50], Step [62/469], Loss: 0.3825, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [36/50], Step [63/469], Loss: 0.3829, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [36/50], Step [64/469], Loss: 0.3501, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [36/50], Step [65/469], Loss: 0.3912, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [36/50], Step [66/469], Loss: 0.3425, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [67/469], Loss: 0.3831, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [68/469], Loss: 0.4625, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [36/50], Step [69/469], Loss: 0.3895, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [36/50], Step [70/469], Loss: 0.3897, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [36/50], Step [71/469], Loss: 0.4467, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [36/50], Step [72/469], Loss: 0.2598, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [36/50], Step [73/469], Loss: 0.3697, batch time: 0.75, accuracy:  85.16%\n",
      "Epoch [36/50], Step [74/469], Loss: 0.3845, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [36/50], Step [75/469], Loss: 0.2781, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [36/50], Step [76/469], Loss: 0.6079, batch time: 0.55, accuracy:  83.59%\n",
      "Epoch [36/50], Step [77/469], Loss: 0.3581, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [78/469], Loss: 0.3795, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [36/50], Step [79/469], Loss: 0.3036, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [36/50], Step [80/469], Loss: 0.3413, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [36/50], Step [81/469], Loss: 0.2848, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [36/50], Step [82/469], Loss: 0.3785, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [36/50], Step [83/469], Loss: 0.2805, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [36/50], Step [84/469], Loss: 0.4039, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [36/50], Step [85/469], Loss: 0.3323, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [36/50], Step [86/469], Loss: 0.4531, batch time: 0.63, accuracy:  85.94%\n",
      "Epoch [36/50], Step [87/469], Loss: 0.2770, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [36/50], Step [88/469], Loss: 0.2929, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [36/50], Step [89/469], Loss: 0.2909, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [36/50], Step [90/469], Loss: 0.5211, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [36/50], Step [91/469], Loss: 0.3801, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [36/50], Step [92/469], Loss: 0.2904, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [36/50], Step [93/469], Loss: 0.3824, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [36/50], Step [94/469], Loss: 0.4339, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [36/50], Step [95/469], Loss: 0.4805, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [36/50], Step [96/469], Loss: 0.2901, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [97/469], Loss: 0.4537, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [36/50], Step [98/469], Loss: 0.3607, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [36/50], Step [99/469], Loss: 0.3625, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [36/50], Step [100/469], Loss: 0.3382, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [36/50], Step [101/469], Loss: 0.2723, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [36/50], Step [102/469], Loss: 0.3469, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [36/50], Step [103/469], Loss: 0.4010, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [36/50], Step [104/469], Loss: 0.3279, batch time: 0.63, accuracy:  86.72%\n",
      "Epoch [36/50], Step [105/469], Loss: 0.2192, batch time: 0.65, accuracy:  95.31%\n",
      "Epoch [36/50], Step [106/469], Loss: 0.2861, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [36/50], Step [107/469], Loss: 0.5036, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [36/50], Step [108/469], Loss: 0.3742, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [36/50], Step [109/469], Loss: 0.2826, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [110/469], Loss: 0.2318, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [36/50], Step [111/469], Loss: 0.3498, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [36/50], Step [112/469], Loss: 0.4320, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [36/50], Step [113/469], Loss: 0.3728, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [36/50], Step [114/469], Loss: 0.2333, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [36/50], Step [115/469], Loss: 0.4184, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [36/50], Step [116/469], Loss: 0.2534, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [36/50], Step [117/469], Loss: 0.3578, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [36/50], Step [118/469], Loss: 0.4690, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [36/50], Step [119/469], Loss: 0.3288, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [36/50], Step [120/469], Loss: 0.3715, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [36/50], Step [121/469], Loss: 0.4449, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [36/50], Step [122/469], Loss: 0.3696, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [36/50], Step [123/469], Loss: 0.2804, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [36/50], Step [124/469], Loss: 0.3539, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [36/50], Step [125/469], Loss: 0.2556, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [36/50], Step [126/469], Loss: 0.4325, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [36/50], Step [127/469], Loss: 0.3499, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [36/50], Step [128/469], Loss: 0.4950, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [36/50], Step [129/469], Loss: 0.3470, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [36/50], Step [130/469], Loss: 0.3006, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [36/50], Step [131/469], Loss: 0.3154, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [36/50], Step [132/469], Loss: 0.4649, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [36/50], Step [133/469], Loss: 0.2394, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [36/50], Step [134/469], Loss: 0.3873, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [36/50], Step [135/469], Loss: 0.2514, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [36/50], Step [136/469], Loss: 0.5272, batch time: 0.67, accuracy:  85.94%\n",
      "Epoch [36/50], Step [137/469], Loss: 0.4466, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [36/50], Step [138/469], Loss: 0.4643, batch time: 0.65, accuracy:  89.06%\n",
      "Epoch [36/50], Step [139/469], Loss: 0.3258, batch time: 0.65, accuracy:  89.84%\n",
      "Epoch [36/50], Step [140/469], Loss: 0.2917, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [36/50], Step [141/469], Loss: 0.4104, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [36/50], Step [142/469], Loss: 0.3944, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [36/50], Step [143/469], Loss: 0.4117, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [36/50], Step [144/469], Loss: 0.2902, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [36/50], Step [145/469], Loss: 0.3966, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [36/50], Step [146/469], Loss: 0.2966, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [36/50], Step [147/469], Loss: 0.3207, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [148/469], Loss: 0.2917, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [36/50], Step [149/469], Loss: 0.4240, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [36/50], Step [150/469], Loss: 0.2302, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [36/50], Step [151/469], Loss: 0.4783, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [36/50], Step [152/469], Loss: 0.4693, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [36/50], Step [153/469], Loss: 0.3466, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [36/50], Step [154/469], Loss: 0.4149, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [36/50], Step [155/469], Loss: 0.3752, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [36/50], Step [156/469], Loss: 0.3194, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [36/50], Step [157/469], Loss: 0.3125, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [36/50], Step [158/469], Loss: 0.2225, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [36/50], Step [159/469], Loss: 0.3188, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [36/50], Step [160/469], Loss: 0.3643, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [161/469], Loss: 0.2581, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [36/50], Step [162/469], Loss: 0.2880, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [36/50], Step [163/469], Loss: 0.3815, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [164/469], Loss: 0.2826, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [36/50], Step [165/469], Loss: 0.2655, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [36/50], Step [166/469], Loss: 0.2785, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [36/50], Step [167/469], Loss: 0.3353, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [36/50], Step [168/469], Loss: 0.3460, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [36/50], Step [169/469], Loss: 0.4073, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [36/50], Step [170/469], Loss: 0.3873, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [36/50], Step [171/469], Loss: 0.4015, batch time: 0.68, accuracy:  92.97%\n",
      "Epoch [36/50], Step [172/469], Loss: 0.3569, batch time: 0.66, accuracy:  86.72%\n",
      "Epoch [36/50], Step [173/469], Loss: 0.4406, batch time: 0.67, accuracy:  87.50%\n",
      "Epoch [36/50], Step [174/469], Loss: 0.3274, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [36/50], Step [175/469], Loss: 0.4758, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [36/50], Step [176/469], Loss: 0.3838, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [177/469], Loss: 0.4682, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [36/50], Step [178/469], Loss: 0.6059, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [36/50], Step [179/469], Loss: 0.2353, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [36/50], Step [180/469], Loss: 0.3278, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [36/50], Step [181/469], Loss: 0.3024, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [36/50], Step [182/469], Loss: 0.2920, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [36/50], Step [183/469], Loss: 0.2033, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [36/50], Step [184/469], Loss: 0.3576, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [36/50], Step [185/469], Loss: 0.3731, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [36/50], Step [186/469], Loss: 0.4170, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [36/50], Step [187/469], Loss: 0.4114, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [36/50], Step [188/469], Loss: 0.3631, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [36/50], Step [189/469], Loss: 0.3712, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [36/50], Step [190/469], Loss: 0.4574, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [36/50], Step [191/469], Loss: 0.5396, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [36/50], Step [192/469], Loss: 0.4869, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [36/50], Step [193/469], Loss: 0.3058, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [36/50], Step [194/469], Loss: 0.2654, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [36/50], Step [195/469], Loss: 0.4841, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [36/50], Step [196/469], Loss: 0.3831, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [36/50], Step [197/469], Loss: 0.4136, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [36/50], Step [198/469], Loss: 0.4680, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [36/50], Step [199/469], Loss: 0.3732, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [36/50], Step [200/469], Loss: 0.2687, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [36/50], Step [201/469], Loss: 0.3362, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [36/50], Step [202/469], Loss: 0.4664, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [36/50], Step [203/469], Loss: 0.3150, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [36/50], Step [204/469], Loss: 0.3363, batch time: 0.66, accuracy:  90.62%\n",
      "Epoch [36/50], Step [205/469], Loss: 0.4116, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [36/50], Step [206/469], Loss: 0.3484, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [36/50], Step [207/469], Loss: 0.6129, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [36/50], Step [208/469], Loss: 0.3488, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [36/50], Step [209/469], Loss: 0.7739, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [36/50], Step [210/469], Loss: 0.3043, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [36/50], Step [211/469], Loss: 0.3091, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [36/50], Step [212/469], Loss: 0.4375, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [36/50], Step [213/469], Loss: 0.3834, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [36/50], Step [214/469], Loss: 0.3144, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [36/50], Step [215/469], Loss: 0.2772, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [36/50], Step [216/469], Loss: 0.5066, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [36/50], Step [217/469], Loss: 0.3448, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [36/50], Step [218/469], Loss: 0.3912, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [36/50], Step [219/469], Loss: 0.3259, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [220/469], Loss: 0.3904, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [36/50], Step [221/469], Loss: 0.3512, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [36/50], Step [222/469], Loss: 0.3366, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [36/50], Step [223/469], Loss: 0.3922, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [36/50], Step [224/469], Loss: 0.3504, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [36/50], Step [225/469], Loss: 0.4754, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [36/50], Step [226/469], Loss: 0.3867, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [227/469], Loss: 0.2885, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [36/50], Step [228/469], Loss: 0.3298, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [36/50], Step [229/469], Loss: 0.3208, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [36/50], Step [230/469], Loss: 0.2824, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [36/50], Step [231/469], Loss: 0.3702, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [36/50], Step [232/469], Loss: 0.3210, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [36/50], Step [233/469], Loss: 0.3692, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [36/50], Step [234/469], Loss: 0.4865, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [36/50], Step [235/469], Loss: 0.3457, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [36/50], Step [236/469], Loss: 0.2976, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [36/50], Step [237/469], Loss: 0.4208, batch time: 0.90, accuracy:  89.84%\n",
      "Epoch [36/50], Step [238/469], Loss: 0.3758, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [36/50], Step [239/469], Loss: 0.2884, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [36/50], Step [240/469], Loss: 0.3809, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [36/50], Step [241/469], Loss: 0.2090, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [36/50], Step [242/469], Loss: 0.3199, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [36/50], Step [243/469], Loss: 0.3571, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [36/50], Step [244/469], Loss: 0.3108, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [36/50], Step [245/469], Loss: 0.5447, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [246/469], Loss: 0.2639, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [36/50], Step [247/469], Loss: 0.3112, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [36/50], Step [248/469], Loss: 0.3202, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [36/50], Step [249/469], Loss: 0.3623, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [36/50], Step [250/469], Loss: 0.4113, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [36/50], Step [251/469], Loss: 0.4702, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [36/50], Step [252/469], Loss: 0.3363, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [36/50], Step [253/469], Loss: 0.3999, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [36/50], Step [254/469], Loss: 0.5142, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [36/50], Step [255/469], Loss: 0.3334, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [36/50], Step [256/469], Loss: 0.3892, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [36/50], Step [257/469], Loss: 0.3650, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [36/50], Step [258/469], Loss: 0.3453, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [36/50], Step [259/469], Loss: 0.4159, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [36/50], Step [260/469], Loss: 0.2364, batch time: 0.52, accuracy:  96.09%\n",
      "Epoch [36/50], Step [261/469], Loss: 0.3535, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [36/50], Step [262/469], Loss: 0.2760, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [36/50], Step [263/469], Loss: 0.3399, batch time: 0.65, accuracy:  89.84%\n",
      "Epoch [36/50], Step [264/469], Loss: 0.1838, batch time: 0.74, accuracy:  92.97%\n",
      "Epoch [36/50], Step [265/469], Loss: 0.3261, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [36/50], Step [266/469], Loss: 0.3293, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [36/50], Step [267/469], Loss: 0.3592, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [36/50], Step [268/469], Loss: 0.4216, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [36/50], Step [269/469], Loss: 0.3455, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [36/50], Step [270/469], Loss: 0.3057, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [271/469], Loss: 0.3919, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [36/50], Step [272/469], Loss: 0.3171, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [36/50], Step [273/469], Loss: 0.3326, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [36/50], Step [274/469], Loss: 0.3412, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [36/50], Step [275/469], Loss: 0.3123, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [36/50], Step [276/469], Loss: 0.2738, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [36/50], Step [277/469], Loss: 0.3580, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [36/50], Step [278/469], Loss: 0.3646, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [36/50], Step [279/469], Loss: 0.3683, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [36/50], Step [280/469], Loss: 0.3512, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [36/50], Step [281/469], Loss: 0.3605, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [36/50], Step [282/469], Loss: 0.3410, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [36/50], Step [283/469], Loss: 0.2705, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [36/50], Step [284/469], Loss: 0.2894, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [36/50], Step [285/469], Loss: 0.3819, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [36/50], Step [286/469], Loss: 0.3979, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [36/50], Step [287/469], Loss: 0.3025, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [36/50], Step [288/469], Loss: 0.3413, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [36/50], Step [289/469], Loss: 0.5267, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [36/50], Step [290/469], Loss: 0.3511, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [36/50], Step [291/469], Loss: 0.3322, batch time: 0.60, accuracy:  85.16%\n",
      "Epoch [36/50], Step [292/469], Loss: 0.4462, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [36/50], Step [293/469], Loss: 0.3265, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [36/50], Step [294/469], Loss: 0.2272, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [36/50], Step [295/469], Loss: 0.2465, batch time: 0.73, accuracy:  91.41%\n",
      "Epoch [36/50], Step [296/469], Loss: 0.3854, batch time: 0.60, accuracy:  87.50%\n",
      "Epoch [36/50], Step [297/469], Loss: 0.3161, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [36/50], Step [298/469], Loss: 0.3739, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [36/50], Step [299/469], Loss: 0.2468, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [36/50], Step [300/469], Loss: 0.3919, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [36/50], Step [301/469], Loss: 0.3705, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [36/50], Step [302/469], Loss: 0.3338, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [36/50], Step [303/469], Loss: 0.3832, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [36/50], Step [304/469], Loss: 0.4102, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [36/50], Step [305/469], Loss: 0.3575, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [36/50], Step [306/469], Loss: 0.2565, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [36/50], Step [307/469], Loss: 0.3969, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [36/50], Step [308/469], Loss: 0.2524, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [36/50], Step [309/469], Loss: 0.2858, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [36/50], Step [310/469], Loss: 0.3519, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [36/50], Step [311/469], Loss: 0.2870, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [36/50], Step [312/469], Loss: 0.3521, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [36/50], Step [313/469], Loss: 0.4578, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [314/469], Loss: 0.4811, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [36/50], Step [315/469], Loss: 0.3715, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [36/50], Step [316/469], Loss: 0.3434, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [317/469], Loss: 0.2630, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [36/50], Step [318/469], Loss: 0.3242, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [36/50], Step [319/469], Loss: 0.3385, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [36/50], Step [320/469], Loss: 0.2916, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [36/50], Step [321/469], Loss: 0.3493, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [36/50], Step [322/469], Loss: 0.4080, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [36/50], Step [323/469], Loss: 0.2459, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [36/50], Step [324/469], Loss: 0.3538, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [36/50], Step [325/469], Loss: 0.1818, batch time: 0.60, accuracy:  94.53%\n",
      "Epoch [36/50], Step [326/469], Loss: 0.2417, batch time: 0.75, accuracy:  91.41%\n",
      "Epoch [36/50], Step [327/469], Loss: 0.3100, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [36/50], Step [328/469], Loss: 0.2152, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [36/50], Step [329/469], Loss: 0.4267, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [36/50], Step [330/469], Loss: 0.3300, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [36/50], Step [331/469], Loss: 0.3185, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [36/50], Step [332/469], Loss: 0.2191, batch time: 0.48, accuracy:  96.09%\n",
      "Epoch [36/50], Step [333/469], Loss: 0.2684, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [36/50], Step [334/469], Loss: 0.5357, batch time: 0.49, accuracy:  81.25%\n",
      "Epoch [36/50], Step [335/469], Loss: 0.3207, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [36/50], Step [336/469], Loss: 0.2675, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [36/50], Step [337/469], Loss: 0.3304, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [36/50], Step [338/469], Loss: 0.2986, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [36/50], Step [339/469], Loss: 0.2668, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [36/50], Step [340/469], Loss: 0.3452, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [36/50], Step [341/469], Loss: 0.3983, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [342/469], Loss: 0.2584, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [36/50], Step [343/469], Loss: 0.3782, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [36/50], Step [344/469], Loss: 0.2996, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [36/50], Step [345/469], Loss: 0.4201, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [36/50], Step [346/469], Loss: 0.2635, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [36/50], Step [347/469], Loss: 0.3339, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [36/50], Step [348/469], Loss: 0.2710, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [36/50], Step [349/469], Loss: 0.2879, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [36/50], Step [350/469], Loss: 0.4335, batch time: 0.53, accuracy:  83.59%\n",
      "Epoch [36/50], Step [351/469], Loss: 0.3503, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [36/50], Step [352/469], Loss: 0.2774, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [36/50], Step [353/469], Loss: 0.4345, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [36/50], Step [354/469], Loss: 0.2350, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [36/50], Step [355/469], Loss: 0.3892, batch time: 0.72, accuracy:  92.97%\n",
      "Epoch [36/50], Step [356/469], Loss: 0.2856, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [36/50], Step [357/469], Loss: 0.3503, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [36/50], Step [358/469], Loss: 0.2464, batch time: 0.61, accuracy:  92.97%\n",
      "Epoch [36/50], Step [359/469], Loss: 0.2424, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [36/50], Step [360/469], Loss: 0.4062, batch time: 0.69, accuracy:  90.62%\n",
      "Epoch [36/50], Step [361/469], Loss: 0.3117, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [36/50], Step [362/469], Loss: 0.4042, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [36/50], Step [363/469], Loss: 0.5119, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [36/50], Step [364/469], Loss: 0.4133, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [36/50], Step [365/469], Loss: 0.3230, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [36/50], Step [366/469], Loss: 0.5225, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [36/50], Step [367/469], Loss: 0.5113, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [36/50], Step [368/469], Loss: 0.2838, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [36/50], Step [369/469], Loss: 0.3231, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [36/50], Step [370/469], Loss: 0.4774, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [36/50], Step [371/469], Loss: 0.3905, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [36/50], Step [372/469], Loss: 0.2886, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [36/50], Step [373/469], Loss: 0.3270, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [36/50], Step [374/469], Loss: 0.3774, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [36/50], Step [375/469], Loss: 0.2744, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [36/50], Step [376/469], Loss: 0.3144, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [36/50], Step [377/469], Loss: 0.3153, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [36/50], Step [378/469], Loss: 0.3457, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [36/50], Step [379/469], Loss: 0.4415, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [36/50], Step [380/469], Loss: 0.2826, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [36/50], Step [381/469], Loss: 0.2529, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [36/50], Step [382/469], Loss: 0.3982, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [36/50], Step [383/469], Loss: 0.4018, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [36/50], Step [384/469], Loss: 0.4659, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [36/50], Step [385/469], Loss: 0.4385, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [36/50], Step [386/469], Loss: 0.3410, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [36/50], Step [387/469], Loss: 0.3011, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [36/50], Step [388/469], Loss: 0.2859, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [36/50], Step [389/469], Loss: 0.2936, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [36/50], Step [390/469], Loss: 0.5011, batch time: 0.57, accuracy:  82.81%\n",
      "Epoch [36/50], Step [391/469], Loss: 0.3240, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [36/50], Step [392/469], Loss: 0.3772, batch time: 0.65, accuracy:  89.06%\n",
      "Epoch [36/50], Step [393/469], Loss: 0.2664, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [36/50], Step [394/469], Loss: 0.4588, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [36/50], Step [395/469], Loss: 0.2873, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [36/50], Step [396/469], Loss: 0.5852, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [36/50], Step [397/469], Loss: 0.4593, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [36/50], Step [398/469], Loss: 0.3116, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [36/50], Step [399/469], Loss: 0.3480, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [36/50], Step [400/469], Loss: 0.2546, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [36/50], Step [401/469], Loss: 0.2929, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [36/50], Step [402/469], Loss: 0.2826, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [36/50], Step [403/469], Loss: 0.3261, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [36/50], Step [404/469], Loss: 0.3514, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [36/50], Step [405/469], Loss: 0.2687, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [36/50], Step [406/469], Loss: 0.3069, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [36/50], Step [407/469], Loss: 0.2865, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [36/50], Step [408/469], Loss: 0.4085, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [36/50], Step [409/469], Loss: 0.2451, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [36/50], Step [410/469], Loss: 0.4679, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [36/50], Step [411/469], Loss: 0.3735, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [36/50], Step [412/469], Loss: 0.4250, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [36/50], Step [413/469], Loss: 0.3479, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [36/50], Step [414/469], Loss: 0.4252, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [36/50], Step [415/469], Loss: 0.2292, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [36/50], Step [416/469], Loss: 0.2912, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [36/50], Step [417/469], Loss: 0.3630, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [36/50], Step [418/469], Loss: 0.2697, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [36/50], Step [419/469], Loss: 0.4374, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [36/50], Step [420/469], Loss: 0.4598, batch time: 0.64, accuracy:  86.72%\n",
      "Epoch [36/50], Step [421/469], Loss: 0.2622, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [36/50], Step [422/469], Loss: 0.4141, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [36/50], Step [423/469], Loss: 0.1983, batch time: 0.63, accuracy:  92.97%\n",
      "Epoch [36/50], Step [424/469], Loss: 0.2457, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [36/50], Step [425/469], Loss: 0.4430, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [36/50], Step [426/469], Loss: 0.3746, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [36/50], Step [427/469], Loss: 0.2677, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [36/50], Step [428/469], Loss: 0.2226, batch time: 0.56, accuracy:  94.53%\n",
      "Epoch [36/50], Step [429/469], Loss: 0.3486, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [36/50], Step [430/469], Loss: 0.2867, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [36/50], Step [431/469], Loss: 0.1675, batch time: 0.52, accuracy:  95.31%\n",
      "Epoch [36/50], Step [432/469], Loss: 0.2966, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [36/50], Step [433/469], Loss: 0.3315, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [36/50], Step [434/469], Loss: 0.3728, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [36/50], Step [435/469], Loss: 0.3706, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [36/50], Step [436/469], Loss: 0.3031, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [36/50], Step [437/469], Loss: 0.3493, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [36/50], Step [438/469], Loss: 0.2040, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [36/50], Step [439/469], Loss: 0.2923, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [36/50], Step [440/469], Loss: 0.2392, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [36/50], Step [441/469], Loss: 0.2662, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [36/50], Step [442/469], Loss: 0.3338, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [36/50], Step [443/469], Loss: 0.4658, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [36/50], Step [444/469], Loss: 0.3430, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [36/50], Step [445/469], Loss: 0.3102, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [36/50], Step [446/469], Loss: 0.3757, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [36/50], Step [447/469], Loss: 0.3085, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [448/469], Loss: 0.2158, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [36/50], Step [449/469], Loss: 0.3355, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [36/50], Step [450/469], Loss: 0.2492, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [36/50], Step [451/469], Loss: 0.2114, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [36/50], Step [452/469], Loss: 0.3824, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [36/50], Step [453/469], Loss: 0.3367, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [36/50], Step [454/469], Loss: 0.3086, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [36/50], Step [455/469], Loss: 0.2410, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [36/50], Step [456/469], Loss: 0.3523, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [36/50], Step [457/469], Loss: 0.2372, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [36/50], Step [458/469], Loss: 0.3233, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [36/50], Step [459/469], Loss: 0.3897, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [36/50], Step [460/469], Loss: 0.3747, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [36/50], Step [461/469], Loss: 0.3867, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [36/50], Step [462/469], Loss: 0.3820, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [36/50], Step [463/469], Loss: 0.3982, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [36/50], Step [464/469], Loss: 0.2550, batch time: 0.58, accuracy:  92.97%\n",
      "Epoch [36/50], Step [465/469], Loss: 0.2797, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [36/50], Step [466/469], Loss: 0.4317, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [36/50], Step [467/469], Loss: 0.2663, batch time: 0.64, accuracy:  89.06%\n",
      "Epoch [36/50], Step [468/469], Loss: 0.3280, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [36/50], Step [469/469], Loss: 0.1989, batch time: 0.59, accuracy:  96.88%\n",
      "Epoch [37/50], Step [1/469], Loss: 0.3433, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [37/50], Step [2/469], Loss: 0.1940, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [37/50], Step [3/469], Loss: 0.3182, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [37/50], Step [4/469], Loss: 0.3436, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [37/50], Step [5/469], Loss: 0.3695, batch time: 0.63, accuracy:  85.16%\n",
      "Epoch [37/50], Step [6/469], Loss: 0.2575, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [37/50], Step [7/469], Loss: 0.2020, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [37/50], Step [8/469], Loss: 0.4421, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [9/469], Loss: 0.3770, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [37/50], Step [10/469], Loss: 0.4093, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [37/50], Step [11/469], Loss: 0.2586, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [37/50], Step [12/469], Loss: 0.4940, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [37/50], Step [13/469], Loss: 0.3375, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [37/50], Step [14/469], Loss: 0.3493, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [37/50], Step [15/469], Loss: 0.3142, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [37/50], Step [16/469], Loss: 0.4088, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [37/50], Step [17/469], Loss: 0.3310, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [37/50], Step [18/469], Loss: 0.4191, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [37/50], Step [19/469], Loss: 0.2671, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [37/50], Step [20/469], Loss: 0.3305, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [37/50], Step [21/469], Loss: 0.3195, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [37/50], Step [22/469], Loss: 0.4066, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [37/50], Step [23/469], Loss: 0.3954, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [37/50], Step [24/469], Loss: 0.3202, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [37/50], Step [25/469], Loss: 0.3784, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [37/50], Step [26/469], Loss: 0.2785, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [27/469], Loss: 0.2198, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [37/50], Step [28/469], Loss: 0.4769, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [37/50], Step [29/469], Loss: 0.3854, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [37/50], Step [30/469], Loss: 0.3535, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [37/50], Step [31/469], Loss: 0.3047, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [37/50], Step [32/469], Loss: 0.3078, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [37/50], Step [33/469], Loss: 0.3407, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [37/50], Step [34/469], Loss: 0.4035, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [37/50], Step [35/469], Loss: 0.2854, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [37/50], Step [36/469], Loss: 0.2631, batch time: 0.84, accuracy:  93.75%\n",
      "Epoch [37/50], Step [37/469], Loss: 0.2129, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [37/50], Step [38/469], Loss: 0.4477, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [37/50], Step [39/469], Loss: 0.3278, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [37/50], Step [40/469], Loss: 0.3577, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [37/50], Step [41/469], Loss: 0.2392, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [37/50], Step [42/469], Loss: 0.2541, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [43/469], Loss: 0.2828, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [37/50], Step [44/469], Loss: 0.4943, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [37/50], Step [45/469], Loss: 0.2739, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [37/50], Step [46/469], Loss: 0.3885, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [37/50], Step [47/469], Loss: 0.2532, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [37/50], Step [48/469], Loss: 0.2572, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [49/469], Loss: 0.5124, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [37/50], Step [50/469], Loss: 0.2973, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [51/469], Loss: 0.2934, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [37/50], Step [52/469], Loss: 0.3155, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [37/50], Step [53/469], Loss: 0.2762, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [54/469], Loss: 0.3961, batch time: 0.64, accuracy:  89.06%\n",
      "Epoch [37/50], Step [55/469], Loss: 0.3256, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [37/50], Step [56/469], Loss: 0.2404, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [37/50], Step [57/469], Loss: 0.4774, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [37/50], Step [58/469], Loss: 0.5381, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [37/50], Step [59/469], Loss: 0.2247, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [37/50], Step [60/469], Loss: 0.2775, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [37/50], Step [61/469], Loss: 0.4742, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [37/50], Step [62/469], Loss: 0.4613, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [37/50], Step [63/469], Loss: 0.3789, batch time: 0.81, accuracy:  88.28%\n",
      "Epoch [37/50], Step [64/469], Loss: 0.2840, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [37/50], Step [65/469], Loss: 0.5442, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [37/50], Step [66/469], Loss: 0.3073, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [37/50], Step [67/469], Loss: 0.3462, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [37/50], Step [68/469], Loss: 0.3474, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [37/50], Step [69/469], Loss: 0.2488, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [37/50], Step [70/469], Loss: 0.3735, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [37/50], Step [71/469], Loss: 0.3748, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [72/469], Loss: 0.3234, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [37/50], Step [73/469], Loss: 0.2092, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [37/50], Step [74/469], Loss: 0.4336, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [37/50], Step [75/469], Loss: 0.3829, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [37/50], Step [76/469], Loss: 0.3009, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [37/50], Step [77/469], Loss: 0.2955, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [37/50], Step [78/469], Loss: 0.2595, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [37/50], Step [79/469], Loss: 0.3308, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [37/50], Step [80/469], Loss: 0.4395, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [37/50], Step [81/469], Loss: 0.3630, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [37/50], Step [82/469], Loss: 0.2810, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [37/50], Step [83/469], Loss: 0.5476, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [37/50], Step [84/469], Loss: 0.2306, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [37/50], Step [85/469], Loss: 0.3051, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [37/50], Step [86/469], Loss: 0.3075, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [37/50], Step [87/469], Loss: 0.2731, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [37/50], Step [88/469], Loss: 0.2794, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [37/50], Step [89/469], Loss: 0.2443, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [37/50], Step [90/469], Loss: 0.4649, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [37/50], Step [91/469], Loss: 0.3902, batch time: 1.00, accuracy:  86.72%\n",
      "Epoch [37/50], Step [92/469], Loss: 0.3439, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [37/50], Step [93/469], Loss: 0.4232, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [37/50], Step [94/469], Loss: 0.2986, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [37/50], Step [95/469], Loss: 0.3971, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [37/50], Step [96/469], Loss: 0.2510, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [37/50], Step [97/469], Loss: 0.4904, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [37/50], Step [98/469], Loss: 0.2367, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [37/50], Step [99/469], Loss: 0.3312, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [37/50], Step [100/469], Loss: 0.4913, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [37/50], Step [101/469], Loss: 0.2402, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [37/50], Step [102/469], Loss: 0.2517, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [37/50], Step [103/469], Loss: 0.4120, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [37/50], Step [104/469], Loss: 0.3091, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [37/50], Step [105/469], Loss: 0.4245, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [37/50], Step [106/469], Loss: 0.4687, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [37/50], Step [107/469], Loss: 0.2717, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [37/50], Step [108/469], Loss: 0.3103, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [37/50], Step [109/469], Loss: 0.3282, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [37/50], Step [110/469], Loss: 0.4873, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [37/50], Step [111/469], Loss: 0.3688, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [37/50], Step [112/469], Loss: 0.3181, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [37/50], Step [113/469], Loss: 0.3424, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [37/50], Step [114/469], Loss: 0.3289, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [37/50], Step [115/469], Loss: 0.3228, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [37/50], Step [116/469], Loss: 0.4735, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [37/50], Step [117/469], Loss: 0.4031, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [37/50], Step [118/469], Loss: 0.3225, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [37/50], Step [119/469], Loss: 0.4058, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [37/50], Step [120/469], Loss: 0.3740, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [37/50], Step [121/469], Loss: 0.3440, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [37/50], Step [122/469], Loss: 0.4938, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [37/50], Step [123/469], Loss: 0.2935, batch time: 0.75, accuracy:  91.41%\n",
      "Epoch [37/50], Step [124/469], Loss: 0.3195, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [37/50], Step [125/469], Loss: 0.3397, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [37/50], Step [126/469], Loss: 0.2594, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [37/50], Step [127/469], Loss: 0.4338, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [37/50], Step [128/469], Loss: 0.2493, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [37/50], Step [129/469], Loss: 0.4023, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [37/50], Step [130/469], Loss: 0.2017, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [37/50], Step [131/469], Loss: 0.3011, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [37/50], Step [132/469], Loss: 0.5848, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [37/50], Step [133/469], Loss: 0.4727, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [37/50], Step [134/469], Loss: 0.4388, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [37/50], Step [135/469], Loss: 0.3806, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [37/50], Step [136/469], Loss: 0.3630, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [37/50], Step [137/469], Loss: 0.4005, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [37/50], Step [138/469], Loss: 0.3790, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [37/50], Step [139/469], Loss: 0.3735, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [37/50], Step [140/469], Loss: 0.3430, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [37/50], Step [141/469], Loss: 0.3045, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [37/50], Step [142/469], Loss: 0.2805, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [37/50], Step [143/469], Loss: 0.2672, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [37/50], Step [144/469], Loss: 0.4678, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [37/50], Step [145/469], Loss: 0.4510, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [37/50], Step [146/469], Loss: 0.3600, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [37/50], Step [147/469], Loss: 0.2902, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [37/50], Step [148/469], Loss: 0.3044, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [37/50], Step [149/469], Loss: 0.1785, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [37/50], Step [150/469], Loss: 0.4300, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [37/50], Step [151/469], Loss: 0.2012, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [37/50], Step [152/469], Loss: 0.2731, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [153/469], Loss: 0.4002, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [37/50], Step [154/469], Loss: 0.2900, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [155/469], Loss: 0.3902, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [37/50], Step [156/469], Loss: 0.3650, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [37/50], Step [157/469], Loss: 0.2473, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [37/50], Step [158/469], Loss: 0.3292, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [37/50], Step [159/469], Loss: 0.2955, batch time: 0.70, accuracy:  89.84%\n",
      "Epoch [37/50], Step [160/469], Loss: 0.3429, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [37/50], Step [161/469], Loss: 0.4726, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [37/50], Step [162/469], Loss: 0.2557, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [37/50], Step [163/469], Loss: 0.3698, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [37/50], Step [164/469], Loss: 0.3188, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [37/50], Step [165/469], Loss: 0.3726, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [37/50], Step [166/469], Loss: 0.3499, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [37/50], Step [167/469], Loss: 0.3103, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [37/50], Step [168/469], Loss: 0.3553, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [37/50], Step [169/469], Loss: 0.5165, batch time: 0.51, accuracy:  82.03%\n",
      "Epoch [37/50], Step [170/469], Loss: 0.1702, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [37/50], Step [171/469], Loss: 0.3354, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [37/50], Step [172/469], Loss: 0.2156, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [37/50], Step [173/469], Loss: 0.4025, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [37/50], Step [174/469], Loss: 0.2106, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [37/50], Step [175/469], Loss: 0.2863, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [37/50], Step [176/469], Loss: 0.4039, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [177/469], Loss: 0.3306, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [37/50], Step [178/469], Loss: 0.2638, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [37/50], Step [179/469], Loss: 0.2801, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [37/50], Step [180/469], Loss: 0.4253, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [37/50], Step [181/469], Loss: 0.2299, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [37/50], Step [182/469], Loss: 0.3972, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [37/50], Step [183/469], Loss: 0.4360, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [37/50], Step [184/469], Loss: 0.5289, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [37/50], Step [185/469], Loss: 0.3719, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [37/50], Step [186/469], Loss: 0.2746, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [37/50], Step [187/469], Loss: 0.3897, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [37/50], Step [188/469], Loss: 0.3354, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [37/50], Step [189/469], Loss: 0.3441, batch time: 0.63, accuracy:  86.72%\n",
      "Epoch [37/50], Step [190/469], Loss: 0.1302, batch time: 0.57, accuracy:  96.09%\n",
      "Epoch [37/50], Step [191/469], Loss: 0.3222, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [37/50], Step [192/469], Loss: 0.2788, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [37/50], Step [193/469], Loss: 0.3684, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [37/50], Step [194/469], Loss: 0.3116, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [37/50], Step [195/469], Loss: 0.2861, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [37/50], Step [196/469], Loss: 0.3131, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [37/50], Step [197/469], Loss: 0.3814, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [37/50], Step [198/469], Loss: 0.3144, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [199/469], Loss: 0.2752, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [37/50], Step [200/469], Loss: 0.2809, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [37/50], Step [201/469], Loss: 0.2169, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [37/50], Step [202/469], Loss: 0.4995, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [37/50], Step [203/469], Loss: 0.3315, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [37/50], Step [204/469], Loss: 0.3589, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [37/50], Step [205/469], Loss: 0.2870, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [37/50], Step [206/469], Loss: 0.3537, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [37/50], Step [207/469], Loss: 0.3107, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [37/50], Step [208/469], Loss: 0.2865, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [209/469], Loss: 0.3678, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [37/50], Step [210/469], Loss: 0.3683, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [37/50], Step [211/469], Loss: 0.3750, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [37/50], Step [212/469], Loss: 0.3636, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [37/50], Step [213/469], Loss: 0.3498, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [37/50], Step [214/469], Loss: 0.2570, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [37/50], Step [215/469], Loss: 0.4103, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [37/50], Step [216/469], Loss: 0.3088, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [37/50], Step [217/469], Loss: 0.2533, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [37/50], Step [218/469], Loss: 0.3410, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [37/50], Step [219/469], Loss: 0.3245, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [37/50], Step [220/469], Loss: 0.3344, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [37/50], Step [221/469], Loss: 0.4498, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [37/50], Step [222/469], Loss: 0.2549, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [37/50], Step [223/469], Loss: 0.2549, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [37/50], Step [224/469], Loss: 0.2670, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [37/50], Step [225/469], Loss: 0.5273, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [37/50], Step [226/469], Loss: 0.2718, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [227/469], Loss: 0.2206, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [37/50], Step [228/469], Loss: 0.3026, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [229/469], Loss: 0.3187, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [37/50], Step [230/469], Loss: 0.3324, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [37/50], Step [231/469], Loss: 0.3659, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [37/50], Step [232/469], Loss: 0.4718, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [37/50], Step [233/469], Loss: 0.3957, batch time: 0.64, accuracy:  85.94%\n",
      "Epoch [37/50], Step [234/469], Loss: 0.2582, batch time: 0.64, accuracy:  92.97%\n",
      "Epoch [37/50], Step [235/469], Loss: 0.3258, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [37/50], Step [236/469], Loss: 0.4118, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [37/50], Step [237/469], Loss: 0.4415, batch time: 0.60, accuracy:  85.94%\n",
      "Epoch [37/50], Step [238/469], Loss: 0.1987, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [37/50], Step [239/469], Loss: 0.3637, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [37/50], Step [240/469], Loss: 0.4478, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [37/50], Step [241/469], Loss: 0.3327, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [37/50], Step [242/469], Loss: 0.2995, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [37/50], Step [243/469], Loss: 0.4263, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [37/50], Step [244/469], Loss: 0.4756, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [37/50], Step [245/469], Loss: 0.3827, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [37/50], Step [246/469], Loss: 0.3762, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [37/50], Step [247/469], Loss: 0.3517, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [37/50], Step [248/469], Loss: 0.2711, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [37/50], Step [249/469], Loss: 0.2596, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [37/50], Step [250/469], Loss: 0.3233, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [37/50], Step [251/469], Loss: 0.3951, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [37/50], Step [252/469], Loss: 0.3748, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [37/50], Step [253/469], Loss: 0.2143, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [37/50], Step [254/469], Loss: 0.2325, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [37/50], Step [255/469], Loss: 0.4531, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [37/50], Step [256/469], Loss: 0.3926, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [37/50], Step [257/469], Loss: 0.4390, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [37/50], Step [258/469], Loss: 0.3116, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [37/50], Step [259/469], Loss: 0.3403, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [37/50], Step [260/469], Loss: 0.2928, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [37/50], Step [261/469], Loss: 0.3871, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [37/50], Step [262/469], Loss: 0.2984, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [37/50], Step [263/469], Loss: 0.1902, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [37/50], Step [264/469], Loss: 0.4014, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [37/50], Step [265/469], Loss: 0.4057, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [37/50], Step [266/469], Loss: 0.3494, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [37/50], Step [267/469], Loss: 0.4095, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [37/50], Step [268/469], Loss: 0.3817, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [37/50], Step [269/469], Loss: 0.2329, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [37/50], Step [270/469], Loss: 0.4332, batch time: 0.64, accuracy:  86.72%\n",
      "Epoch [37/50], Step [271/469], Loss: 0.3346, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [37/50], Step [272/469], Loss: 0.3032, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [37/50], Step [273/469], Loss: 0.3130, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [37/50], Step [274/469], Loss: 0.3445, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [37/50], Step [275/469], Loss: 0.3546, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [37/50], Step [276/469], Loss: 0.2206, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [37/50], Step [277/469], Loss: 0.3020, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [37/50], Step [278/469], Loss: 0.3358, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [279/469], Loss: 0.2508, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [37/50], Step [280/469], Loss: 0.4269, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [37/50], Step [281/469], Loss: 0.2176, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [37/50], Step [282/469], Loss: 0.3130, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [37/50], Step [283/469], Loss: 0.2955, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [37/50], Step [284/469], Loss: 0.3814, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [37/50], Step [285/469], Loss: 0.3225, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [37/50], Step [286/469], Loss: 0.3072, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [37/50], Step [287/469], Loss: 0.3933, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [37/50], Step [288/469], Loss: 0.2986, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [37/50], Step [289/469], Loss: 0.2292, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [37/50], Step [290/469], Loss: 0.2750, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [37/50], Step [291/469], Loss: 0.4593, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [292/469], Loss: 0.2947, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [37/50], Step [293/469], Loss: 0.2389, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [37/50], Step [294/469], Loss: 0.3379, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [37/50], Step [295/469], Loss: 0.2493, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [37/50], Step [296/469], Loss: 0.1943, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [297/469], Loss: 0.2865, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [37/50], Step [298/469], Loss: 0.2580, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [37/50], Step [299/469], Loss: 0.5098, batch time: 0.63, accuracy:  86.72%\n",
      "Epoch [37/50], Step [300/469], Loss: 0.3273, batch time: 0.99, accuracy:  89.06%\n",
      "Epoch [37/50], Step [301/469], Loss: 0.2059, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [37/50], Step [302/469], Loss: 0.3516, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [37/50], Step [303/469], Loss: 0.2668, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [37/50], Step [304/469], Loss: 0.6713, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [37/50], Step [305/469], Loss: 0.3704, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [37/50], Step [306/469], Loss: 0.3527, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [37/50], Step [307/469], Loss: 0.3129, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [37/50], Step [308/469], Loss: 0.3585, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [37/50], Step [309/469], Loss: 0.2968, batch time: 0.60, accuracy:  87.50%\n",
      "Epoch [37/50], Step [310/469], Loss: 0.5310, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [37/50], Step [311/469], Loss: 0.4598, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [37/50], Step [312/469], Loss: 0.4099, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [37/50], Step [313/469], Loss: 0.4309, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [37/50], Step [314/469], Loss: 0.3818, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [37/50], Step [315/469], Loss: 0.4069, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [316/469], Loss: 0.3579, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [317/469], Loss: 0.3499, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [37/50], Step [318/469], Loss: 0.4400, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [37/50], Step [319/469], Loss: 0.3964, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [37/50], Step [320/469], Loss: 0.2325, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [37/50], Step [321/469], Loss: 0.3193, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [322/469], Loss: 0.4125, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [37/50], Step [323/469], Loss: 0.3815, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [37/50], Step [324/469], Loss: 0.4187, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [37/50], Step [325/469], Loss: 0.3266, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [37/50], Step [326/469], Loss: 0.4190, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [37/50], Step [327/469], Loss: 0.2635, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [37/50], Step [328/469], Loss: 0.2463, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [37/50], Step [329/469], Loss: 0.2883, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [37/50], Step [330/469], Loss: 0.2385, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [37/50], Step [331/469], Loss: 0.3202, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [37/50], Step [332/469], Loss: 0.5424, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [37/50], Step [333/469], Loss: 0.3425, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [37/50], Step [334/469], Loss: 0.3110, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [37/50], Step [335/469], Loss: 0.2310, batch time: 0.71, accuracy:  92.97%\n",
      "Epoch [37/50], Step [336/469], Loss: 0.2041, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [37/50], Step [337/469], Loss: 0.3076, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [37/50], Step [338/469], Loss: 0.3064, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [37/50], Step [339/469], Loss: 0.5091, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [37/50], Step [340/469], Loss: 0.2882, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [341/469], Loss: 0.4042, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [37/50], Step [342/469], Loss: 0.3204, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [37/50], Step [343/469], Loss: 0.4113, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [37/50], Step [344/469], Loss: 0.3793, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [37/50], Step [345/469], Loss: 0.3532, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [37/50], Step [346/469], Loss: 0.4386, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [37/50], Step [347/469], Loss: 0.4641, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [37/50], Step [348/469], Loss: 0.3471, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [37/50], Step [349/469], Loss: 0.4262, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [37/50], Step [350/469], Loss: 0.3307, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [37/50], Step [351/469], Loss: 0.3881, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [37/50], Step [352/469], Loss: 0.3249, batch time: 0.70, accuracy:  88.28%\n",
      "Epoch [37/50], Step [353/469], Loss: 0.2724, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [37/50], Step [354/469], Loss: 0.3754, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [37/50], Step [355/469], Loss: 0.3828, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [37/50], Step [356/469], Loss: 0.2752, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [37/50], Step [357/469], Loss: 0.3300, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [37/50], Step [358/469], Loss: 0.2870, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [37/50], Step [359/469], Loss: 0.4331, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [360/469], Loss: 0.3401, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [37/50], Step [361/469], Loss: 0.2537, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [37/50], Step [362/469], Loss: 0.3847, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [37/50], Step [363/469], Loss: 0.3674, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [37/50], Step [364/469], Loss: 0.2985, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [37/50], Step [365/469], Loss: 0.3355, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [37/50], Step [366/469], Loss: 0.3371, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [37/50], Step [367/469], Loss: 0.4092, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [37/50], Step [368/469], Loss: 0.5397, batch time: 0.67, accuracy:  87.50%\n",
      "Epoch [37/50], Step [369/469], Loss: 0.2690, batch time: 0.62, accuracy:  92.97%\n",
      "Epoch [37/50], Step [370/469], Loss: 0.3073, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [37/50], Step [371/469], Loss: 0.2863, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [37/50], Step [372/469], Loss: 0.5786, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [37/50], Step [373/469], Loss: 0.3860, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [37/50], Step [374/469], Loss: 0.2620, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [375/469], Loss: 0.2797, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [376/469], Loss: 0.3771, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [37/50], Step [377/469], Loss: 0.4445, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [37/50], Step [378/469], Loss: 0.3818, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [37/50], Step [379/469], Loss: 0.4635, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [37/50], Step [380/469], Loss: 0.5025, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [37/50], Step [381/469], Loss: 0.3478, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [37/50], Step [382/469], Loss: 0.3066, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [37/50], Step [383/469], Loss: 0.4155, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [37/50], Step [384/469], Loss: 0.3399, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [37/50], Step [385/469], Loss: 0.2522, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [37/50], Step [386/469], Loss: 0.3978, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [37/50], Step [387/469], Loss: 0.4046, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [37/50], Step [388/469], Loss: 0.3985, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [37/50], Step [389/469], Loss: 0.2985, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [37/50], Step [390/469], Loss: 0.2181, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [37/50], Step [391/469], Loss: 0.3310, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [37/50], Step [392/469], Loss: 0.3014, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [37/50], Step [393/469], Loss: 0.3629, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [37/50], Step [394/469], Loss: 0.3343, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [37/50], Step [395/469], Loss: 0.3884, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [37/50], Step [396/469], Loss: 0.4693, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [37/50], Step [397/469], Loss: 0.2631, batch time: 0.62, accuracy:  93.75%\n",
      "Epoch [37/50], Step [398/469], Loss: 0.2707, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [37/50], Step [399/469], Loss: 0.2785, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [37/50], Step [400/469], Loss: 0.2816, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [37/50], Step [401/469], Loss: 0.2300, batch time: 0.57, accuracy:  95.31%\n",
      "Epoch [37/50], Step [402/469], Loss: 0.3695, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [37/50], Step [403/469], Loss: 0.3330, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [37/50], Step [404/469], Loss: 0.5246, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [37/50], Step [405/469], Loss: 0.3936, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [37/50], Step [406/469], Loss: 0.2851, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [37/50], Step [407/469], Loss: 0.2713, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [37/50], Step [408/469], Loss: 0.4431, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [37/50], Step [409/469], Loss: 0.2925, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [37/50], Step [410/469], Loss: 0.2499, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [37/50], Step [411/469], Loss: 0.4278, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [37/50], Step [412/469], Loss: 0.2552, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [37/50], Step [413/469], Loss: 0.4570, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [37/50], Step [414/469], Loss: 0.4894, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [37/50], Step [415/469], Loss: 0.4217, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [37/50], Step [416/469], Loss: 0.3982, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [37/50], Step [417/469], Loss: 0.4078, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [37/50], Step [418/469], Loss: 0.3110, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [419/469], Loss: 0.3036, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [37/50], Step [420/469], Loss: 0.3599, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [37/50], Step [421/469], Loss: 0.2768, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [37/50], Step [422/469], Loss: 0.4346, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [37/50], Step [423/469], Loss: 0.2860, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [37/50], Step [424/469], Loss: 0.4002, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [37/50], Step [425/469], Loss: 0.2526, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [37/50], Step [426/469], Loss: 0.4055, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [37/50], Step [427/469], Loss: 0.3024, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [37/50], Step [428/469], Loss: 0.4899, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [37/50], Step [429/469], Loss: 0.6155, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [37/50], Step [430/469], Loss: 0.3754, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [37/50], Step [431/469], Loss: 0.4319, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [37/50], Step [432/469], Loss: 0.2110, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [37/50], Step [433/469], Loss: 0.4016, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [37/50], Step [434/469], Loss: 0.3549, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [37/50], Step [435/469], Loss: 0.3766, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [37/50], Step [436/469], Loss: 0.3982, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [37/50], Step [437/469], Loss: 0.2854, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [37/50], Step [438/469], Loss: 0.3579, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [37/50], Step [439/469], Loss: 0.2939, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [37/50], Step [440/469], Loss: 0.2830, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [37/50], Step [441/469], Loss: 0.2603, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [37/50], Step [442/469], Loss: 0.3533, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [37/50], Step [443/469], Loss: 0.2416, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [37/50], Step [444/469], Loss: 0.4001, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [37/50], Step [445/469], Loss: 0.3966, batch time: 0.54, accuracy:  83.59%\n",
      "Epoch [37/50], Step [446/469], Loss: 0.3332, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [37/50], Step [447/469], Loss: 0.4915, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [37/50], Step [448/469], Loss: 0.5275, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [37/50], Step [449/469], Loss: 0.2427, batch time: 0.47, accuracy:  96.88%\n",
      "Epoch [37/50], Step [450/469], Loss: 0.2993, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [37/50], Step [451/469], Loss: 0.2173, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [37/50], Step [452/469], Loss: 0.2842, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [37/50], Step [453/469], Loss: 0.2348, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [37/50], Step [454/469], Loss: 0.3377, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [37/50], Step [455/469], Loss: 0.3506, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [37/50], Step [456/469], Loss: 0.3445, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [37/50], Step [457/469], Loss: 0.1841, batch time: 0.56, accuracy:  96.09%\n",
      "Epoch [37/50], Step [458/469], Loss: 0.3332, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [37/50], Step [459/469], Loss: 0.2448, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [37/50], Step [460/469], Loss: 0.3417, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [37/50], Step [461/469], Loss: 0.3871, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [37/50], Step [462/469], Loss: 0.2836, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [37/50], Step [463/469], Loss: 0.2171, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [37/50], Step [464/469], Loss: 0.3684, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [37/50], Step [465/469], Loss: 0.3368, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [37/50], Step [466/469], Loss: 0.3073, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [37/50], Step [467/469], Loss: 0.4696, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [37/50], Step [468/469], Loss: 0.2547, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [37/50], Step [469/469], Loss: 0.5553, batch time: 0.49, accuracy:  85.42%\n",
      "Epoch [38/50], Step [1/469], Loss: 0.2705, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [38/50], Step [2/469], Loss: 0.2720, batch time: 0.63, accuracy:  92.19%\n",
      "Epoch [38/50], Step [3/469], Loss: 0.1616, batch time: 0.62, accuracy:  95.31%\n",
      "Epoch [38/50], Step [4/469], Loss: 0.4560, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [38/50], Step [5/469], Loss: 0.3597, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [38/50], Step [6/469], Loss: 0.4126, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [38/50], Step [7/469], Loss: 0.3533, batch time: 0.60, accuracy:  87.50%\n",
      "Epoch [38/50], Step [8/469], Loss: 0.3001, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [38/50], Step [9/469], Loss: 0.3382, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [38/50], Step [10/469], Loss: 0.5031, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [38/50], Step [11/469], Loss: 0.3820, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [38/50], Step [12/469], Loss: 0.2653, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [13/469], Loss: 0.2185, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [38/50], Step [14/469], Loss: 0.2421, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [15/469], Loss: 0.2582, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [38/50], Step [16/469], Loss: 0.3217, batch time: 0.48, accuracy:  96.09%\n",
      "Epoch [38/50], Step [17/469], Loss: 0.2635, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [38/50], Step [18/469], Loss: 0.3792, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [38/50], Step [19/469], Loss: 0.4682, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [38/50], Step [20/469], Loss: 0.4143, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [38/50], Step [21/469], Loss: 0.4074, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [38/50], Step [22/469], Loss: 0.2306, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [38/50], Step [23/469], Loss: 0.3833, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [38/50], Step [24/469], Loss: 0.3596, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [38/50], Step [25/469], Loss: 0.3328, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [38/50], Step [26/469], Loss: 0.3599, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [38/50], Step [27/469], Loss: 0.1998, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [38/50], Step [28/469], Loss: 0.1724, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [38/50], Step [29/469], Loss: 0.2961, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [38/50], Step [30/469], Loss: 0.2644, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [38/50], Step [31/469], Loss: 0.4269, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [38/50], Step [32/469], Loss: 0.3448, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [38/50], Step [33/469], Loss: 0.2968, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [38/50], Step [34/469], Loss: 0.2348, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [38/50], Step [35/469], Loss: 0.3747, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [38/50], Step [36/469], Loss: 0.3073, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [38/50], Step [37/469], Loss: 0.3971, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [38/50], Step [38/469], Loss: 0.3126, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [38/50], Step [39/469], Loss: 0.3124, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [38/50], Step [40/469], Loss: 0.3699, batch time: 0.61, accuracy:  83.59%\n",
      "Epoch [38/50], Step [41/469], Loss: 0.2790, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [38/50], Step [42/469], Loss: 0.2502, batch time: 0.65, accuracy:  90.62%\n",
      "Epoch [38/50], Step [43/469], Loss: 0.3675, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [38/50], Step [44/469], Loss: 0.4313, batch time: 0.65, accuracy:  86.72%\n",
      "Epoch [38/50], Step [45/469], Loss: 0.3795, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [38/50], Step [46/469], Loss: 0.3480, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [38/50], Step [47/469], Loss: 0.2622, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [38/50], Step [48/469], Loss: 0.3690, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [38/50], Step [49/469], Loss: 0.3204, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [38/50], Step [50/469], Loss: 0.4071, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [38/50], Step [51/469], Loss: 0.2875, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [52/469], Loss: 0.3458, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [38/50], Step [53/469], Loss: 0.3613, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [38/50], Step [54/469], Loss: 0.2921, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [38/50], Step [55/469], Loss: 0.4342, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [38/50], Step [56/469], Loss: 0.2682, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [38/50], Step [57/469], Loss: 0.3220, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [38/50], Step [58/469], Loss: 0.3399, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [38/50], Step [59/469], Loss: 0.4600, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [38/50], Step [60/469], Loss: 0.3761, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [38/50], Step [61/469], Loss: 0.3714, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [38/50], Step [62/469], Loss: 0.3278, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [38/50], Step [63/469], Loss: 0.3558, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [64/469], Loss: 0.2804, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [38/50], Step [65/469], Loss: 0.4668, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [38/50], Step [66/469], Loss: 0.4574, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [38/50], Step [67/469], Loss: 0.2334, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [38/50], Step [68/469], Loss: 0.3606, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [38/50], Step [69/469], Loss: 0.3002, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [38/50], Step [70/469], Loss: 0.4244, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [38/50], Step [71/469], Loss: 0.3048, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [38/50], Step [72/469], Loss: 0.3458, batch time: 1.20, accuracy:  89.84%\n",
      "Epoch [38/50], Step [73/469], Loss: 0.3370, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [38/50], Step [74/469], Loss: 0.2174, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [38/50], Step [75/469], Loss: 0.2888, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [38/50], Step [76/469], Loss: 0.4154, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [38/50], Step [77/469], Loss: 0.2495, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [38/50], Step [78/469], Loss: 0.2634, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [79/469], Loss: 0.2499, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [38/50], Step [80/469], Loss: 0.4130, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [38/50], Step [81/469], Loss: 0.2985, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [38/50], Step [82/469], Loss: 0.3622, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [38/50], Step [83/469], Loss: 0.2872, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [38/50], Step [84/469], Loss: 0.4836, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [38/50], Step [85/469], Loss: 0.3458, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [38/50], Step [86/469], Loss: 0.2890, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [38/50], Step [87/469], Loss: 0.1934, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [38/50], Step [88/469], Loss: 0.5411, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [38/50], Step [89/469], Loss: 0.4213, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [38/50], Step [90/469], Loss: 0.2840, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [38/50], Step [91/469], Loss: 0.2915, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [38/50], Step [92/469], Loss: 0.3692, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [38/50], Step [93/469], Loss: 0.4118, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [38/50], Step [94/469], Loss: 0.3349, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [38/50], Step [95/469], Loss: 0.2950, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [38/50], Step [96/469], Loss: 0.3630, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [38/50], Step [97/469], Loss: 0.2825, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [38/50], Step [98/469], Loss: 0.4271, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [38/50], Step [99/469], Loss: 0.3261, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [38/50], Step [100/469], Loss: 0.3461, batch time: 0.67, accuracy:  90.62%\n",
      "Epoch [38/50], Step [101/469], Loss: 0.3404, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [38/50], Step [102/469], Loss: 0.4419, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [103/469], Loss: 0.2661, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [38/50], Step [104/469], Loss: 0.2316, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [38/50], Step [105/469], Loss: 0.2354, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [38/50], Step [106/469], Loss: 0.6871, batch time: 0.48, accuracy:  82.81%\n",
      "Epoch [38/50], Step [107/469], Loss: 0.2348, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [38/50], Step [108/469], Loss: 0.2691, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [38/50], Step [109/469], Loss: 0.2547, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [110/469], Loss: 0.2885, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [38/50], Step [111/469], Loss: 0.3475, batch time: 0.64, accuracy:  88.28%\n",
      "Epoch [38/50], Step [112/469], Loss: 0.3282, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [38/50], Step [113/469], Loss: 0.2370, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [38/50], Step [114/469], Loss: 0.2776, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [38/50], Step [115/469], Loss: 0.3615, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [38/50], Step [116/469], Loss: 0.3267, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [38/50], Step [117/469], Loss: 0.3336, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [38/50], Step [118/469], Loss: 0.3074, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [38/50], Step [119/469], Loss: 0.2894, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [38/50], Step [120/469], Loss: 0.3854, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [38/50], Step [121/469], Loss: 0.3881, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [38/50], Step [122/469], Loss: 0.2696, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [38/50], Step [123/469], Loss: 0.3472, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [38/50], Step [124/469], Loss: 0.4981, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [38/50], Step [125/469], Loss: 0.5256, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [38/50], Step [126/469], Loss: 0.3049, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [38/50], Step [127/469], Loss: 0.2661, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [38/50], Step [128/469], Loss: 0.3283, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [38/50], Step [129/469], Loss: 0.2827, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [130/469], Loss: 0.2690, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [38/50], Step [131/469], Loss: 0.3799, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [38/50], Step [132/469], Loss: 0.3819, batch time: 0.79, accuracy:  89.84%\n",
      "Epoch [38/50], Step [133/469], Loss: 0.2866, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [38/50], Step [134/469], Loss: 0.3091, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [38/50], Step [135/469], Loss: 0.4201, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [38/50], Step [136/469], Loss: 0.2798, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [38/50], Step [137/469], Loss: 0.2460, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [38/50], Step [138/469], Loss: 0.4092, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [38/50], Step [139/469], Loss: 0.2406, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [140/469], Loss: 0.3190, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [38/50], Step [141/469], Loss: 0.2239, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [38/50], Step [142/469], Loss: 0.5537, batch time: 0.52, accuracy:  83.59%\n",
      "Epoch [38/50], Step [143/469], Loss: 0.2914, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [38/50], Step [144/469], Loss: 0.2738, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [145/469], Loss: 0.3684, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [38/50], Step [146/469], Loss: 0.4075, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [38/50], Step [147/469], Loss: 0.2993, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [38/50], Step [148/469], Loss: 0.3031, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [38/50], Step [149/469], Loss: 0.3543, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [38/50], Step [150/469], Loss: 0.3955, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [38/50], Step [151/469], Loss: 0.4868, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [38/50], Step [152/469], Loss: 0.3471, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [38/50], Step [153/469], Loss: 0.3174, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [38/50], Step [154/469], Loss: 0.3972, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [38/50], Step [155/469], Loss: 0.2015, batch time: 0.46, accuracy:  96.09%\n",
      "Epoch [38/50], Step [156/469], Loss: 0.3789, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [38/50], Step [157/469], Loss: 0.3553, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [38/50], Step [158/469], Loss: 0.2472, batch time: 0.54, accuracy:  95.31%\n",
      "Epoch [38/50], Step [159/469], Loss: 0.4163, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [38/50], Step [160/469], Loss: 0.3518, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [38/50], Step [161/469], Loss: 0.3980, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [38/50], Step [162/469], Loss: 0.3824, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [38/50], Step [163/469], Loss: 0.3352, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [38/50], Step [164/469], Loss: 0.2546, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [38/50], Step [165/469], Loss: 0.4522, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [38/50], Step [166/469], Loss: 0.2970, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [38/50], Step [167/469], Loss: 0.3146, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [38/50], Step [168/469], Loss: 0.3016, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [38/50], Step [169/469], Loss: 0.4918, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [38/50], Step [170/469], Loss: 0.3188, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [38/50], Step [171/469], Loss: 0.2073, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [38/50], Step [172/469], Loss: 0.3681, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [38/50], Step [173/469], Loss: 0.3783, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [38/50], Step [174/469], Loss: 0.2857, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [38/50], Step [175/469], Loss: 0.2673, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [38/50], Step [176/469], Loss: 0.3076, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [38/50], Step [177/469], Loss: 0.2898, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [38/50], Step [178/469], Loss: 0.3023, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [38/50], Step [179/469], Loss: 0.3025, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [38/50], Step [180/469], Loss: 0.2979, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [38/50], Step [181/469], Loss: 0.3642, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [38/50], Step [182/469], Loss: 0.3303, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [38/50], Step [183/469], Loss: 0.4646, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [38/50], Step [184/469], Loss: 0.2677, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [38/50], Step [185/469], Loss: 0.3583, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [38/50], Step [186/469], Loss: 0.3463, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [38/50], Step [187/469], Loss: 0.3565, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [38/50], Step [188/469], Loss: 0.3366, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [38/50], Step [189/469], Loss: 0.3109, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [38/50], Step [190/469], Loss: 0.2484, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [38/50], Step [191/469], Loss: 0.2718, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [38/50], Step [192/469], Loss: 0.3455, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [38/50], Step [193/469], Loss: 0.3756, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [38/50], Step [194/469], Loss: 0.3607, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [38/50], Step [195/469], Loss: 0.4048, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [38/50], Step [196/469], Loss: 0.3138, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [38/50], Step [197/469], Loss: 0.2568, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [38/50], Step [198/469], Loss: 0.4268, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [38/50], Step [199/469], Loss: 0.3613, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [38/50], Step [200/469], Loss: 0.2144, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [38/50], Step [201/469], Loss: 0.2891, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [38/50], Step [202/469], Loss: 0.4091, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [38/50], Step [203/469], Loss: 0.2498, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [204/469], Loss: 0.6285, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [38/50], Step [205/469], Loss: 0.2969, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [38/50], Step [206/469], Loss: 0.4062, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [38/50], Step [207/469], Loss: 0.2626, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [38/50], Step [208/469], Loss: 0.3314, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [38/50], Step [209/469], Loss: 0.2589, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [38/50], Step [210/469], Loss: 0.4124, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [38/50], Step [211/469], Loss: 0.2622, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [38/50], Step [212/469], Loss: 0.4775, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [38/50], Step [213/469], Loss: 0.2551, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [38/50], Step [214/469], Loss: 0.2664, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [38/50], Step [215/469], Loss: 0.2133, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [38/50], Step [216/469], Loss: 0.3181, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [38/50], Step [217/469], Loss: 0.4982, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [38/50], Step [218/469], Loss: 0.5485, batch time: 0.62, accuracy:  85.94%\n",
      "Epoch [38/50], Step [219/469], Loss: 0.3583, batch time: 1.17, accuracy:  87.50%\n",
      "Epoch [38/50], Step [220/469], Loss: 0.4669, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [38/50], Step [221/469], Loss: 0.3101, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [38/50], Step [222/469], Loss: 0.3230, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [38/50], Step [223/469], Loss: 0.4204, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [38/50], Step [224/469], Loss: 0.4071, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [38/50], Step [225/469], Loss: 0.4395, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [38/50], Step [226/469], Loss: 0.2871, batch time: 0.63, accuracy:  89.84%\n",
      "Epoch [38/50], Step [227/469], Loss: 0.3603, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [38/50], Step [228/469], Loss: 0.3536, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [38/50], Step [229/469], Loss: 0.4027, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [38/50], Step [230/469], Loss: 0.3252, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [38/50], Step [231/469], Loss: 0.3537, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [38/50], Step [232/469], Loss: 0.2058, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [38/50], Step [233/469], Loss: 0.5050, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [38/50], Step [234/469], Loss: 0.2227, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [38/50], Step [235/469], Loss: 0.2467, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [38/50], Step [236/469], Loss: 0.2720, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [38/50], Step [237/469], Loss: 0.2468, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [38/50], Step [238/469], Loss: 0.3329, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [38/50], Step [239/469], Loss: 0.2027, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [38/50], Step [240/469], Loss: 0.3289, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [38/50], Step [241/469], Loss: 0.1773, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [38/50], Step [242/469], Loss: 0.2942, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [38/50], Step [243/469], Loss: 0.3637, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [38/50], Step [244/469], Loss: 0.2904, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [38/50], Step [245/469], Loss: 0.3054, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [38/50], Step [246/469], Loss: 0.4223, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [38/50], Step [247/469], Loss: 0.4749, batch time: 0.62, accuracy:  84.38%\n",
      "Epoch [38/50], Step [248/469], Loss: 0.2626, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [38/50], Step [249/469], Loss: 0.3479, batch time: 0.64, accuracy:  88.28%\n",
      "Epoch [38/50], Step [250/469], Loss: 0.2531, batch time: 0.69, accuracy:  89.84%\n",
      "Epoch [38/50], Step [251/469], Loss: 0.2258, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [38/50], Step [252/469], Loss: 0.1655, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [38/50], Step [253/469], Loss: 0.1938, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [38/50], Step [254/469], Loss: 0.3741, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [38/50], Step [255/469], Loss: 0.1942, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [38/50], Step [256/469], Loss: 0.4617, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [38/50], Step [257/469], Loss: 0.2546, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [38/50], Step [258/469], Loss: 0.2692, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [38/50], Step [259/469], Loss: 0.2859, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [38/50], Step [260/469], Loss: 0.2537, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [38/50], Step [261/469], Loss: 0.3160, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [38/50], Step [262/469], Loss: 0.3303, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [38/50], Step [263/469], Loss: 0.2718, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [38/50], Step [264/469], Loss: 0.4908, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [38/50], Step [265/469], Loss: 0.3058, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [38/50], Step [266/469], Loss: 0.4190, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [38/50], Step [267/469], Loss: 0.4533, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [38/50], Step [268/469], Loss: 0.2698, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [38/50], Step [269/469], Loss: 0.3202, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [38/50], Step [270/469], Loss: 0.1098, batch time: 0.51, accuracy:  97.66%\n",
      "Epoch [38/50], Step [271/469], Loss: 0.3538, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [38/50], Step [272/469], Loss: 0.2950, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [38/50], Step [273/469], Loss: 0.1627, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [38/50], Step [274/469], Loss: 0.3347, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [38/50], Step [275/469], Loss: 0.2225, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [38/50], Step [276/469], Loss: 0.2519, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [38/50], Step [277/469], Loss: 0.2839, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [278/469], Loss: 0.2007, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [38/50], Step [279/469], Loss: 0.3564, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [38/50], Step [280/469], Loss: 0.1900, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [281/469], Loss: 0.3490, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [38/50], Step [282/469], Loss: 0.2560, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [38/50], Step [283/469], Loss: 0.3460, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [38/50], Step [284/469], Loss: 0.2926, batch time: 0.65, accuracy:  92.19%\n",
      "Epoch [38/50], Step [285/469], Loss: 0.3897, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [38/50], Step [286/469], Loss: 0.4010, batch time: 0.64, accuracy:  87.50%\n",
      "Epoch [38/50], Step [287/469], Loss: 0.3244, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [38/50], Step [288/469], Loss: 0.3346, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [38/50], Step [289/469], Loss: 0.2529, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [38/50], Step [290/469], Loss: 0.2562, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [38/50], Step [291/469], Loss: 0.4041, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [38/50], Step [292/469], Loss: 0.3115, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [38/50], Step [293/469], Loss: 0.2314, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [294/469], Loss: 0.2967, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [38/50], Step [295/469], Loss: 0.4380, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [38/50], Step [296/469], Loss: 0.2390, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [38/50], Step [297/469], Loss: 0.4888, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [38/50], Step [298/469], Loss: 0.3978, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [38/50], Step [299/469], Loss: 0.2219, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [38/50], Step [300/469], Loss: 0.4287, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [38/50], Step [301/469], Loss: 0.2696, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [38/50], Step [302/469], Loss: 0.2395, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [38/50], Step [303/469], Loss: 0.3705, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [38/50], Step [304/469], Loss: 0.2271, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [38/50], Step [305/469], Loss: 0.3277, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [38/50], Step [306/469], Loss: 0.2904, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [38/50], Step [307/469], Loss: 0.4573, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [38/50], Step [308/469], Loss: 0.2765, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [38/50], Step [309/469], Loss: 0.2759, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [38/50], Step [310/469], Loss: 0.2903, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [38/50], Step [311/469], Loss: 0.3757, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [38/50], Step [312/469], Loss: 0.2608, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [38/50], Step [313/469], Loss: 0.2847, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [38/50], Step [314/469], Loss: 0.2526, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [38/50], Step [315/469], Loss: 0.4838, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [38/50], Step [316/469], Loss: 0.5443, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [38/50], Step [317/469], Loss: 0.3429, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [38/50], Step [318/469], Loss: 0.3461, batch time: 0.67, accuracy:  92.19%\n",
      "Epoch [38/50], Step [319/469], Loss: 0.2447, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [38/50], Step [320/469], Loss: 0.2632, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [38/50], Step [321/469], Loss: 0.4125, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [38/50], Step [322/469], Loss: 0.3589, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [38/50], Step [323/469], Loss: 0.4419, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [38/50], Step [324/469], Loss: 0.2870, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [38/50], Step [325/469], Loss: 0.2635, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [38/50], Step [326/469], Loss: 0.4270, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [38/50], Step [327/469], Loss: 0.2805, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [38/50], Step [328/469], Loss: 0.4060, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [38/50], Step [329/469], Loss: 0.3318, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [38/50], Step [330/469], Loss: 0.3274, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [38/50], Step [331/469], Loss: 0.2274, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [38/50], Step [332/469], Loss: 0.5223, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [38/50], Step [333/469], Loss: 0.4264, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [38/50], Step [334/469], Loss: 0.4193, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [38/50], Step [335/469], Loss: 0.3549, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [38/50], Step [336/469], Loss: 0.3789, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [38/50], Step [337/469], Loss: 0.3550, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [38/50], Step [338/469], Loss: 0.3719, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [38/50], Step [339/469], Loss: 0.3498, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [38/50], Step [340/469], Loss: 0.4527, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [38/50], Step [341/469], Loss: 0.4264, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [38/50], Step [342/469], Loss: 0.5123, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [38/50], Step [343/469], Loss: 0.2983, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [38/50], Step [344/469], Loss: 0.2791, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [38/50], Step [345/469], Loss: 0.2447, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [38/50], Step [346/469], Loss: 0.1815, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [38/50], Step [347/469], Loss: 0.2237, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [38/50], Step [348/469], Loss: 0.3040, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [38/50], Step [349/469], Loss: 0.3230, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [38/50], Step [350/469], Loss: 0.2885, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [38/50], Step [351/469], Loss: 0.3735, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [38/50], Step [352/469], Loss: 0.3867, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [38/50], Step [353/469], Loss: 0.5044, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [38/50], Step [354/469], Loss: 0.3649, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [38/50], Step [355/469], Loss: 0.3450, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [38/50], Step [356/469], Loss: 0.2247, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [38/50], Step [357/469], Loss: 0.3820, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [38/50], Step [358/469], Loss: 0.4447, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [38/50], Step [359/469], Loss: 0.3874, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [38/50], Step [360/469], Loss: 0.2067, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [38/50], Step [361/469], Loss: 0.3708, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [38/50], Step [362/469], Loss: 0.4879, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [38/50], Step [363/469], Loss: 0.3807, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [38/50], Step [364/469], Loss: 0.2218, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [38/50], Step [365/469], Loss: 0.3281, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [38/50], Step [366/469], Loss: 0.4418, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [38/50], Step [367/469], Loss: 0.3002, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [38/50], Step [368/469], Loss: 0.4163, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [38/50], Step [369/469], Loss: 0.3425, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [38/50], Step [370/469], Loss: 0.5048, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [38/50], Step [371/469], Loss: 0.2735, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [38/50], Step [372/469], Loss: 0.4405, batch time: 0.50, accuracy:  83.59%\n",
      "Epoch [38/50], Step [373/469], Loss: 0.4213, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [38/50], Step [374/469], Loss: 0.4036, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [38/50], Step [375/469], Loss: 0.2856, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [38/50], Step [376/469], Loss: 0.2738, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [38/50], Step [377/469], Loss: 0.2751, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [38/50], Step [378/469], Loss: 0.3226, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [38/50], Step [379/469], Loss: 0.2631, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [38/50], Step [380/469], Loss: 0.3568, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [38/50], Step [381/469], Loss: 0.2745, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [38/50], Step [382/469], Loss: 0.3284, batch time: 0.88, accuracy:  89.84%\n",
      "Epoch [38/50], Step [383/469], Loss: 0.4360, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [38/50], Step [384/469], Loss: 0.4002, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [38/50], Step [385/469], Loss: 0.2409, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [38/50], Step [386/469], Loss: 0.3470, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [38/50], Step [387/469], Loss: 0.4661, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [38/50], Step [388/469], Loss: 0.3833, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [38/50], Step [389/469], Loss: 0.3098, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [38/50], Step [390/469], Loss: 0.4922, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [38/50], Step [391/469], Loss: 0.4243, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [38/50], Step [392/469], Loss: 0.3721, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [38/50], Step [393/469], Loss: 0.4822, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [38/50], Step [394/469], Loss: 0.2972, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [38/50], Step [395/469], Loss: 0.4754, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [38/50], Step [396/469], Loss: 0.2894, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [38/50], Step [397/469], Loss: 0.3969, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [38/50], Step [398/469], Loss: 0.4618, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [38/50], Step [399/469], Loss: 0.3157, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [38/50], Step [400/469], Loss: 0.2718, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [38/50], Step [401/469], Loss: 0.2951, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [38/50], Step [402/469], Loss: 0.2891, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [38/50], Step [403/469], Loss: 0.3342, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [38/50], Step [404/469], Loss: 0.3979, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [38/50], Step [405/469], Loss: 0.4088, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [38/50], Step [406/469], Loss: 0.2498, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [38/50], Step [407/469], Loss: 0.3661, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [38/50], Step [408/469], Loss: 0.4861, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [38/50], Step [409/469], Loss: 0.2118, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [38/50], Step [410/469], Loss: 0.2555, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [38/50], Step [411/469], Loss: 0.5233, batch time: 0.44, accuracy:  81.25%\n",
      "Epoch [38/50], Step [412/469], Loss: 0.2232, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [38/50], Step [413/469], Loss: 0.4322, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [38/50], Step [414/469], Loss: 0.3898, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [38/50], Step [415/469], Loss: 0.3642, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [38/50], Step [416/469], Loss: 0.4254, batch time: 0.63, accuracy:  85.16%\n",
      "Epoch [38/50], Step [417/469], Loss: 0.3393, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [38/50], Step [418/469], Loss: 0.2677, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [38/50], Step [419/469], Loss: 0.2141, batch time: 0.65, accuracy:  93.75%\n",
      "Epoch [38/50], Step [420/469], Loss: 0.3121, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [38/50], Step [421/469], Loss: 0.3437, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [38/50], Step [422/469], Loss: 0.5997, batch time: 0.63, accuracy:  83.59%\n",
      "Epoch [38/50], Step [423/469], Loss: 0.4296, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [38/50], Step [424/469], Loss: 0.3688, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [38/50], Step [425/469], Loss: 0.3112, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [38/50], Step [426/469], Loss: 0.3843, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [38/50], Step [427/469], Loss: 0.2702, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [38/50], Step [428/469], Loss: 0.3171, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [38/50], Step [429/469], Loss: 0.4888, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [38/50], Step [430/469], Loss: 0.4449, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [38/50], Step [431/469], Loss: 0.2828, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [38/50], Step [432/469], Loss: 0.2394, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [38/50], Step [433/469], Loss: 0.5335, batch time: 0.47, accuracy:  79.69%\n",
      "Epoch [38/50], Step [434/469], Loss: 0.4446, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [38/50], Step [435/469], Loss: 0.3663, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [38/50], Step [436/469], Loss: 0.4715, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [38/50], Step [437/469], Loss: 0.3039, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [38/50], Step [438/469], Loss: 0.2816, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [38/50], Step [439/469], Loss: 0.3362, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [38/50], Step [440/469], Loss: 0.2743, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [38/50], Step [441/469], Loss: 0.3410, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [38/50], Step [442/469], Loss: 0.3939, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [38/50], Step [443/469], Loss: 0.4285, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [38/50], Step [444/469], Loss: 0.4321, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [38/50], Step [445/469], Loss: 0.4357, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [38/50], Step [446/469], Loss: 0.3242, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [38/50], Step [447/469], Loss: 0.2053, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [448/469], Loss: 0.2967, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [38/50], Step [449/469], Loss: 0.4149, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [38/50], Step [450/469], Loss: 0.3957, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [38/50], Step [451/469], Loss: 0.2400, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [38/50], Step [452/469], Loss: 0.4560, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [38/50], Step [453/469], Loss: 0.2930, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [38/50], Step [454/469], Loss: 0.4380, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [38/50], Step [455/469], Loss: 0.3660, batch time: 0.74, accuracy:  86.72%\n",
      "Epoch [38/50], Step [456/469], Loss: 0.2466, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [38/50], Step [457/469], Loss: 0.4098, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [38/50], Step [458/469], Loss: 0.3440, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [38/50], Step [459/469], Loss: 0.2417, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [38/50], Step [460/469], Loss: 0.2607, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [38/50], Step [461/469], Loss: 0.2407, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [38/50], Step [462/469], Loss: 0.3832, batch time: 0.65, accuracy:  91.41%\n",
      "Epoch [38/50], Step [463/469], Loss: 0.3875, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [38/50], Step [464/469], Loss: 0.1983, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [38/50], Step [465/469], Loss: 0.4138, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [38/50], Step [466/469], Loss: 0.3481, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [38/50], Step [467/469], Loss: 0.1822, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [38/50], Step [468/469], Loss: 0.4017, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [38/50], Step [469/469], Loss: 0.2961, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [39/50], Step [1/469], Loss: 0.5045, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [39/50], Step [2/469], Loss: 0.4066, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [39/50], Step [3/469], Loss: 0.3691, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [39/50], Step [4/469], Loss: 0.4502, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [39/50], Step [5/469], Loss: 0.3786, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [39/50], Step [6/469], Loss: 0.4255, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [39/50], Step [7/469], Loss: 0.2019, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [39/50], Step [8/469], Loss: 0.1950, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [39/50], Step [9/469], Loss: 0.3038, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [39/50], Step [10/469], Loss: 0.2124, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [39/50], Step [11/469], Loss: 0.2785, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [39/50], Step [12/469], Loss: 0.3007, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [39/50], Step [13/469], Loss: 0.3027, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [39/50], Step [14/469], Loss: 0.3777, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [39/50], Step [15/469], Loss: 0.3616, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [39/50], Step [16/469], Loss: 0.3080, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [39/50], Step [17/469], Loss: 0.3281, batch time: 0.66, accuracy:  89.06%\n",
      "Epoch [39/50], Step [18/469], Loss: 0.3341, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [39/50], Step [19/469], Loss: 0.3839, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [39/50], Step [20/469], Loss: 0.1791, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [39/50], Step [21/469], Loss: 0.3329, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [39/50], Step [22/469], Loss: 0.2936, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [39/50], Step [23/469], Loss: 0.3219, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [39/50], Step [24/469], Loss: 0.3640, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [39/50], Step [25/469], Loss: 0.3169, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [39/50], Step [26/469], Loss: 0.3929, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [39/50], Step [27/469], Loss: 0.3045, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [39/50], Step [28/469], Loss: 0.3821, batch time: 0.68, accuracy:  86.72%\n",
      "Epoch [39/50], Step [29/469], Loss: 0.2658, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [39/50], Step [30/469], Loss: 0.3338, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [39/50], Step [31/469], Loss: 0.2716, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [39/50], Step [32/469], Loss: 0.2850, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [39/50], Step [33/469], Loss: 0.2421, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [39/50], Step [34/469], Loss: 0.3269, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [39/50], Step [35/469], Loss: 0.2735, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [39/50], Step [36/469], Loss: 0.1647, batch time: 0.52, accuracy:  96.88%\n",
      "Epoch [39/50], Step [37/469], Loss: 0.3572, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [39/50], Step [38/469], Loss: 0.3486, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [39/50], Step [39/469], Loss: 0.2998, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [39/50], Step [40/469], Loss: 0.4704, batch time: 0.45, accuracy:  83.59%\n",
      "Epoch [39/50], Step [41/469], Loss: 0.2945, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [39/50], Step [42/469], Loss: 0.3139, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [39/50], Step [43/469], Loss: 0.5858, batch time: 0.47, accuracy:  84.38%\n",
      "Epoch [39/50], Step [44/469], Loss: 0.3484, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [39/50], Step [45/469], Loss: 0.3595, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [39/50], Step [46/469], Loss: 0.2455, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [39/50], Step [47/469], Loss: 0.2560, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [39/50], Step [48/469], Loss: 0.3455, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [39/50], Step [49/469], Loss: 0.4034, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [39/50], Step [50/469], Loss: 0.3072, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [39/50], Step [51/469], Loss: 0.3439, batch time: 0.80, accuracy:  88.28%\n",
      "Epoch [39/50], Step [52/469], Loss: 0.3412, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [39/50], Step [53/469], Loss: 0.3623, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [39/50], Step [54/469], Loss: 0.3714, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [39/50], Step [55/469], Loss: 0.3849, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [39/50], Step [56/469], Loss: 0.4290, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [39/50], Step [57/469], Loss: 0.4217, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [39/50], Step [58/469], Loss: 0.3359, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [39/50], Step [59/469], Loss: 0.4001, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [39/50], Step [60/469], Loss: 0.5077, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [39/50], Step [61/469], Loss: 0.2504, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [39/50], Step [62/469], Loss: 0.3022, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [39/50], Step [63/469], Loss: 0.3862, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [64/469], Loss: 0.3877, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [39/50], Step [65/469], Loss: 0.2358, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [39/50], Step [66/469], Loss: 0.3170, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [39/50], Step [67/469], Loss: 0.2780, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [39/50], Step [68/469], Loss: 0.2606, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [39/50], Step [69/469], Loss: 0.3697, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [39/50], Step [70/469], Loss: 0.2927, batch time: 0.53, accuracy:  96.09%\n",
      "Epoch [39/50], Step [71/469], Loss: 0.3759, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [39/50], Step [72/469], Loss: 0.3858, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [39/50], Step [73/469], Loss: 0.3144, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [74/469], Loss: 0.3232, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [39/50], Step [75/469], Loss: 0.2013, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [39/50], Step [76/469], Loss: 0.3404, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [39/50], Step [77/469], Loss: 0.3715, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [39/50], Step [78/469], Loss: 0.3797, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [79/469], Loss: 0.2506, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [39/50], Step [80/469], Loss: 0.3108, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [39/50], Step [81/469], Loss: 0.3557, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [39/50], Step [82/469], Loss: 0.2619, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [39/50], Step [83/469], Loss: 0.1883, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [39/50], Step [84/469], Loss: 0.3990, batch time: 0.61, accuracy:  85.94%\n",
      "Epoch [39/50], Step [85/469], Loss: 0.2573, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [39/50], Step [86/469], Loss: 0.2332, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [39/50], Step [87/469], Loss: 0.3341, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [88/469], Loss: 0.4128, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [39/50], Step [89/469], Loss: 0.3248, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [39/50], Step [90/469], Loss: 0.2665, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [39/50], Step [91/469], Loss: 0.3097, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [39/50], Step [92/469], Loss: 0.2192, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [39/50], Step [93/469], Loss: 0.2342, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [39/50], Step [94/469], Loss: 0.3729, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [39/50], Step [95/469], Loss: 0.3435, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [39/50], Step [96/469], Loss: 0.3834, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [39/50], Step [97/469], Loss: 0.2333, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [39/50], Step [98/469], Loss: 0.3102, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [39/50], Step [99/469], Loss: 0.3459, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [39/50], Step [100/469], Loss: 0.4785, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [39/50], Step [101/469], Loss: 0.3009, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [39/50], Step [102/469], Loss: 0.2657, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [39/50], Step [103/469], Loss: 0.3939, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [39/50], Step [104/469], Loss: 0.2130, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [39/50], Step [105/469], Loss: 0.3204, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [39/50], Step [106/469], Loss: 0.3433, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [39/50], Step [107/469], Loss: 0.2456, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [39/50], Step [108/469], Loss: 0.3812, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [39/50], Step [109/469], Loss: 0.3153, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [39/50], Step [110/469], Loss: 0.4449, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [39/50], Step [111/469], Loss: 0.3469, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [39/50], Step [112/469], Loss: 0.2641, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [39/50], Step [113/469], Loss: 0.3322, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [39/50], Step [114/469], Loss: 0.2995, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [39/50], Step [115/469], Loss: 0.6812, batch time: 0.57, accuracy:  79.69%\n",
      "Epoch [39/50], Step [116/469], Loss: 0.5854, batch time: 0.61, accuracy:  84.38%\n",
      "Epoch [39/50], Step [117/469], Loss: 0.3969, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [39/50], Step [118/469], Loss: 0.2290, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [39/50], Step [119/469], Loss: 0.3983, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [39/50], Step [120/469], Loss: 0.5863, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [39/50], Step [121/469], Loss: 0.3747, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [39/50], Step [122/469], Loss: 0.2486, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [39/50], Step [123/469], Loss: 0.3466, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [39/50], Step [124/469], Loss: 0.2500, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [39/50], Step [125/469], Loss: 0.3139, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [39/50], Step [126/469], Loss: 0.3504, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [39/50], Step [127/469], Loss: 0.4734, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [39/50], Step [128/469], Loss: 0.3592, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [39/50], Step [129/469], Loss: 0.3065, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [39/50], Step [130/469], Loss: 0.3656, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [39/50], Step [131/469], Loss: 0.2922, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [39/50], Step [132/469], Loss: 0.4411, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [39/50], Step [133/469], Loss: 0.2532, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [39/50], Step [134/469], Loss: 0.3259, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [39/50], Step [135/469], Loss: 0.3358, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [39/50], Step [136/469], Loss: 0.3767, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [39/50], Step [137/469], Loss: 0.2708, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [39/50], Step [138/469], Loss: 0.4800, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [39/50], Step [139/469], Loss: 0.4255, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [39/50], Step [140/469], Loss: 0.3722, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [141/469], Loss: 0.3869, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [39/50], Step [142/469], Loss: 0.3420, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [39/50], Step [143/469], Loss: 0.4184, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [39/50], Step [144/469], Loss: 0.2949, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [39/50], Step [145/469], Loss: 0.4295, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [39/50], Step [146/469], Loss: 0.2990, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [39/50], Step [147/469], Loss: 0.2720, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [39/50], Step [148/469], Loss: 0.3006, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [39/50], Step [149/469], Loss: 0.4686, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [39/50], Step [150/469], Loss: 0.2402, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [39/50], Step [151/469], Loss: 0.3359, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [39/50], Step [152/469], Loss: 0.3102, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [153/469], Loss: 0.3896, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [39/50], Step [154/469], Loss: 0.4210, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [155/469], Loss: 0.3566, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [39/50], Step [156/469], Loss: 0.4242, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [39/50], Step [157/469], Loss: 0.3941, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [39/50], Step [158/469], Loss: 0.2070, batch time: 0.56, accuracy:  94.53%\n",
      "Epoch [39/50], Step [159/469], Loss: 0.5295, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [39/50], Step [160/469], Loss: 0.4636, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [39/50], Step [161/469], Loss: 0.2692, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [39/50], Step [162/469], Loss: 0.2873, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [39/50], Step [163/469], Loss: 0.3304, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [39/50], Step [164/469], Loss: 0.3175, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [165/469], Loss: 0.2807, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [39/50], Step [166/469], Loss: 0.1682, batch time: 0.53, accuracy:  96.09%\n",
      "Epoch [39/50], Step [167/469], Loss: 0.2945, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [39/50], Step [168/469], Loss: 0.2508, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [39/50], Step [169/469], Loss: 0.4736, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [39/50], Step [170/469], Loss: 0.4513, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [39/50], Step [171/469], Loss: 0.2846, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [39/50], Step [172/469], Loss: 0.4701, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [39/50], Step [173/469], Loss: 0.3330, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [39/50], Step [174/469], Loss: 0.3080, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [39/50], Step [175/469], Loss: 0.2002, batch time: 0.48, accuracy:  96.09%\n",
      "Epoch [39/50], Step [176/469], Loss: 0.2634, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [39/50], Step [177/469], Loss: 0.2870, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [39/50], Step [178/469], Loss: 0.2800, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [39/50], Step [179/469], Loss: 0.3594, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [39/50], Step [180/469], Loss: 0.2158, batch time: 0.65, accuracy:  92.97%\n",
      "Epoch [39/50], Step [181/469], Loss: 0.2934, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [39/50], Step [182/469], Loss: 0.1887, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [39/50], Step [183/469], Loss: 0.2989, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [39/50], Step [184/469], Loss: 0.2114, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [39/50], Step [185/469], Loss: 0.2937, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [39/50], Step [186/469], Loss: 0.3157, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [187/469], Loss: 0.3109, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [39/50], Step [188/469], Loss: 0.2767, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [39/50], Step [189/469], Loss: 0.3486, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [39/50], Step [190/469], Loss: 0.2849, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [39/50], Step [191/469], Loss: 0.3391, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [39/50], Step [192/469], Loss: 0.5739, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [39/50], Step [193/469], Loss: 0.4100, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [39/50], Step [194/469], Loss: 0.4044, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [39/50], Step [195/469], Loss: 0.1660, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [39/50], Step [196/469], Loss: 0.5428, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [39/50], Step [197/469], Loss: 0.4245, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [39/50], Step [198/469], Loss: 0.3798, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [39/50], Step [199/469], Loss: 0.2836, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [39/50], Step [200/469], Loss: 0.3024, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [39/50], Step [201/469], Loss: 0.3209, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [39/50], Step [202/469], Loss: 0.3214, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [39/50], Step [203/469], Loss: 0.3214, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [204/469], Loss: 0.1909, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [39/50], Step [205/469], Loss: 0.2349, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [39/50], Step [206/469], Loss: 0.3527, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [39/50], Step [207/469], Loss: 0.2690, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [39/50], Step [208/469], Loss: 0.2648, batch time: 0.91, accuracy:  91.41%\n",
      "Epoch [39/50], Step [209/469], Loss: 0.4028, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [39/50], Step [210/469], Loss: 0.1985, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [39/50], Step [211/469], Loss: 0.3817, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [39/50], Step [212/469], Loss: 0.2646, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [39/50], Step [213/469], Loss: 0.3467, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [39/50], Step [214/469], Loss: 0.1954, batch time: 0.53, accuracy:  95.31%\n",
      "Epoch [39/50], Step [215/469], Loss: 0.3268, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [39/50], Step [216/469], Loss: 0.3060, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [39/50], Step [217/469], Loss: 0.4308, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [39/50], Step [218/469], Loss: 0.4617, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [39/50], Step [219/469], Loss: 0.3908, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [39/50], Step [220/469], Loss: 0.2204, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [39/50], Step [221/469], Loss: 0.4238, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [39/50], Step [222/469], Loss: 0.3591, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [39/50], Step [223/469], Loss: 0.2503, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [39/50], Step [224/469], Loss: 0.4204, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [39/50], Step [225/469], Loss: 0.1875, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [39/50], Step [226/469], Loss: 0.2064, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [39/50], Step [227/469], Loss: 0.3309, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [39/50], Step [228/469], Loss: 0.4925, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [39/50], Step [229/469], Loss: 0.2896, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [39/50], Step [230/469], Loss: 0.4169, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [39/50], Step [231/469], Loss: 0.2769, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [39/50], Step [232/469], Loss: 0.3576, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [233/469], Loss: 0.2764, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [39/50], Step [234/469], Loss: 0.4733, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [39/50], Step [235/469], Loss: 0.2596, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [39/50], Step [236/469], Loss: 0.2206, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [39/50], Step [237/469], Loss: 0.2272, batch time: 0.49, accuracy:  95.31%\n",
      "Epoch [39/50], Step [238/469], Loss: 0.3767, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [39/50], Step [239/469], Loss: 0.3217, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [39/50], Step [240/469], Loss: 0.2687, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [39/50], Step [241/469], Loss: 0.4119, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [39/50], Step [242/469], Loss: 0.2386, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [39/50], Step [243/469], Loss: 0.2332, batch time: 0.58, accuracy:  92.97%\n",
      "Epoch [39/50], Step [244/469], Loss: 0.4725, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [39/50], Step [245/469], Loss: 0.2552, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [39/50], Step [246/469], Loss: 0.2651, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [39/50], Step [247/469], Loss: 0.2975, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [39/50], Step [248/469], Loss: 0.4478, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [39/50], Step [249/469], Loss: 0.3167, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [39/50], Step [250/469], Loss: 0.3305, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [251/469], Loss: 0.2495, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [39/50], Step [252/469], Loss: 0.3130, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [39/50], Step [253/469], Loss: 0.2276, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [39/50], Step [254/469], Loss: 0.2868, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [39/50], Step [255/469], Loss: 0.4787, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [39/50], Step [256/469], Loss: 0.4261, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [39/50], Step [257/469], Loss: 0.4738, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [39/50], Step [258/469], Loss: 0.3826, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [39/50], Step [259/469], Loss: 0.3165, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [39/50], Step [260/469], Loss: 0.3959, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [39/50], Step [261/469], Loss: 0.3909, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [39/50], Step [262/469], Loss: 0.2983, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [39/50], Step [263/469], Loss: 0.3154, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [39/50], Step [264/469], Loss: 0.4654, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [39/50], Step [265/469], Loss: 0.3257, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [39/50], Step [266/469], Loss: 0.2865, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [39/50], Step [267/469], Loss: 0.4726, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [39/50], Step [268/469], Loss: 0.4543, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [39/50], Step [269/469], Loss: 0.4287, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [39/50], Step [270/469], Loss: 0.3347, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [271/469], Loss: 0.4069, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [39/50], Step [272/469], Loss: 0.2889, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [39/50], Step [273/469], Loss: 0.2846, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [39/50], Step [274/469], Loss: 0.5001, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [39/50], Step [275/469], Loss: 0.3569, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [39/50], Step [276/469], Loss: 0.2775, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [39/50], Step [277/469], Loss: 0.2987, batch time: 0.70, accuracy:  91.41%\n",
      "Epoch [39/50], Step [278/469], Loss: 0.2579, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [39/50], Step [279/469], Loss: 0.3761, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [39/50], Step [280/469], Loss: 0.2727, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [39/50], Step [281/469], Loss: 0.2654, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [39/50], Step [282/469], Loss: 0.2570, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [39/50], Step [283/469], Loss: 0.3714, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [39/50], Step [284/469], Loss: 0.3137, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [39/50], Step [285/469], Loss: 0.3193, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [39/50], Step [286/469], Loss: 0.4372, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [39/50], Step [287/469], Loss: 0.5372, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [39/50], Step [288/469], Loss: 0.3496, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [39/50], Step [289/469], Loss: 0.2955, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [39/50], Step [290/469], Loss: 0.3298, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [39/50], Step [291/469], Loss: 0.3530, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [39/50], Step [292/469], Loss: 0.2026, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [39/50], Step [293/469], Loss: 0.3112, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [39/50], Step [294/469], Loss: 0.3648, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [39/50], Step [295/469], Loss: 0.2813, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [39/50], Step [296/469], Loss: 0.2886, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [39/50], Step [297/469], Loss: 0.2766, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [39/50], Step [298/469], Loss: 0.3630, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [39/50], Step [299/469], Loss: 0.3276, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [39/50], Step [300/469], Loss: 0.3653, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [39/50], Step [301/469], Loss: 0.4007, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [39/50], Step [302/469], Loss: 0.2845, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [39/50], Step [303/469], Loss: 0.2788, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [39/50], Step [304/469], Loss: 0.4677, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [39/50], Step [305/469], Loss: 0.3556, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [306/469], Loss: 0.3283, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [39/50], Step [307/469], Loss: 0.3158, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [39/50], Step [308/469], Loss: 0.3452, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [39/50], Step [309/469], Loss: 0.2703, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [39/50], Step [310/469], Loss: 0.3269, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [39/50], Step [311/469], Loss: 0.2127, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [39/50], Step [312/469], Loss: 0.3804, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [39/50], Step [313/469], Loss: 0.3892, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [39/50], Step [314/469], Loss: 0.2472, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [39/50], Step [315/469], Loss: 0.3302, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [316/469], Loss: 0.4126, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [39/50], Step [317/469], Loss: 0.4465, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [39/50], Step [318/469], Loss: 0.2013, batch time: 0.54, accuracy:  95.31%\n",
      "Epoch [39/50], Step [319/469], Loss: 0.4301, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [39/50], Step [320/469], Loss: 0.4194, batch time: 0.58, accuracy:  83.59%\n",
      "Epoch [39/50], Step [321/469], Loss: 0.3065, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [39/50], Step [322/469], Loss: 0.3451, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [39/50], Step [323/469], Loss: 0.4378, batch time: 0.62, accuracy:  85.94%\n",
      "Epoch [39/50], Step [324/469], Loss: 0.3475, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [39/50], Step [325/469], Loss: 0.3583, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [39/50], Step [326/469], Loss: 0.3524, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [39/50], Step [327/469], Loss: 0.4373, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [39/50], Step [328/469], Loss: 0.2772, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [39/50], Step [329/469], Loss: 0.2714, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [39/50], Step [330/469], Loss: 0.2766, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [39/50], Step [331/469], Loss: 0.1973, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [39/50], Step [332/469], Loss: 0.2471, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [39/50], Step [333/469], Loss: 0.3414, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [39/50], Step [334/469], Loss: 0.3336, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [39/50], Step [335/469], Loss: 0.3635, batch time: 0.63, accuracy:  90.62%\n",
      "Epoch [39/50], Step [336/469], Loss: 0.3458, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [39/50], Step [337/469], Loss: 0.3034, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [39/50], Step [338/469], Loss: 0.3057, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [39/50], Step [339/469], Loss: 0.2245, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [39/50], Step [340/469], Loss: 0.2797, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [39/50], Step [341/469], Loss: 0.2938, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [342/469], Loss: 0.2760, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [39/50], Step [343/469], Loss: 0.3390, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [39/50], Step [344/469], Loss: 0.2812, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [345/469], Loss: 0.3841, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [346/469], Loss: 0.3707, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [39/50], Step [347/469], Loss: 0.2112, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [39/50], Step [348/469], Loss: 0.2293, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [39/50], Step [349/469], Loss: 0.3278, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [39/50], Step [350/469], Loss: 0.2161, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [39/50], Step [351/469], Loss: 0.3061, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [39/50], Step [352/469], Loss: 0.2319, batch time: 0.90, accuracy:  89.84%\n",
      "Epoch [39/50], Step [353/469], Loss: 0.2776, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [39/50], Step [354/469], Loss: 0.2405, batch time: 0.62, accuracy:  92.97%\n",
      "Epoch [39/50], Step [355/469], Loss: 0.3331, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [39/50], Step [356/469], Loss: 0.2567, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [39/50], Step [357/469], Loss: 0.2172, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [39/50], Step [358/469], Loss: 0.3760, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [39/50], Step [359/469], Loss: 0.2598, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [39/50], Step [360/469], Loss: 0.3578, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [39/50], Step [361/469], Loss: 0.4713, batch time: 0.59, accuracy:  85.94%\n",
      "Epoch [39/50], Step [362/469], Loss: 0.3321, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [39/50], Step [363/469], Loss: 0.2673, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [39/50], Step [364/469], Loss: 0.3516, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [39/50], Step [365/469], Loss: 0.2797, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [39/50], Step [366/469], Loss: 0.4542, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [39/50], Step [367/469], Loss: 0.3093, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [39/50], Step [368/469], Loss: 0.2813, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [39/50], Step [369/469], Loss: 0.3674, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [39/50], Step [370/469], Loss: 0.3689, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [371/469], Loss: 0.2302, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [39/50], Step [372/469], Loss: 0.3035, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [39/50], Step [373/469], Loss: 0.2973, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [374/469], Loss: 0.3305, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [39/50], Step [375/469], Loss: 0.3364, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [39/50], Step [376/469], Loss: 0.6725, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [39/50], Step [377/469], Loss: 0.2737, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [39/50], Step [378/469], Loss: 0.3850, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [39/50], Step [379/469], Loss: 0.2561, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [39/50], Step [380/469], Loss: 0.3206, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [39/50], Step [381/469], Loss: 0.2358, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [39/50], Step [382/469], Loss: 0.3034, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [39/50], Step [383/469], Loss: 0.2626, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [39/50], Step [384/469], Loss: 0.5087, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [39/50], Step [385/469], Loss: 0.4599, batch time: 0.67, accuracy:  89.06%\n",
      "Epoch [39/50], Step [386/469], Loss: 0.4762, batch time: 0.61, accuracy:  85.94%\n",
      "Epoch [39/50], Step [387/469], Loss: 0.3710, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [39/50], Step [388/469], Loss: 0.3822, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [39/50], Step [389/469], Loss: 0.2445, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [39/50], Step [390/469], Loss: 0.3018, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [39/50], Step [391/469], Loss: 0.3362, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [39/50], Step [392/469], Loss: 0.3125, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [39/50], Step [393/469], Loss: 0.3769, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [39/50], Step [394/469], Loss: 0.3575, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [39/50], Step [395/469], Loss: 0.3239, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [39/50], Step [396/469], Loss: 0.2228, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [39/50], Step [397/469], Loss: 0.2784, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [39/50], Step [398/469], Loss: 0.2767, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [39/50], Step [399/469], Loss: 0.4138, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [39/50], Step [400/469], Loss: 0.2537, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [39/50], Step [401/469], Loss: 0.3896, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [39/50], Step [402/469], Loss: 0.3620, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [39/50], Step [403/469], Loss: 0.4057, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [39/50], Step [404/469], Loss: 0.3945, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [39/50], Step [405/469], Loss: 0.4945, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [39/50], Step [406/469], Loss: 0.4297, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [39/50], Step [407/469], Loss: 0.3733, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [39/50], Step [408/469], Loss: 0.4173, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [409/469], Loss: 0.3588, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [39/50], Step [410/469], Loss: 0.3360, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [39/50], Step [411/469], Loss: 0.3036, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [39/50], Step [412/469], Loss: 0.2654, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [39/50], Step [413/469], Loss: 0.4352, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [39/50], Step [414/469], Loss: 0.3398, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [39/50], Step [415/469], Loss: 0.1826, batch time: 0.58, accuracy:  96.88%\n",
      "Epoch [39/50], Step [416/469], Loss: 0.3190, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [39/50], Step [417/469], Loss: 0.3884, batch time: 0.65, accuracy:  87.50%\n",
      "Epoch [39/50], Step [418/469], Loss: 0.2540, batch time: 0.62, accuracy:  94.53%\n",
      "Epoch [39/50], Step [419/469], Loss: 0.4888, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [39/50], Step [420/469], Loss: 0.3632, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [39/50], Step [421/469], Loss: 0.1975, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [39/50], Step [422/469], Loss: 0.3489, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [39/50], Step [423/469], Loss: 0.2856, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [39/50], Step [424/469], Loss: 0.3474, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [39/50], Step [425/469], Loss: 0.2720, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [39/50], Step [426/469], Loss: 0.4432, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [39/50], Step [427/469], Loss: 0.3903, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [39/50], Step [428/469], Loss: 0.4083, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [39/50], Step [429/469], Loss: 0.3969, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [39/50], Step [430/469], Loss: 0.3099, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [39/50], Step [431/469], Loss: 0.3336, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [39/50], Step [432/469], Loss: 0.2445, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [39/50], Step [433/469], Loss: 0.3083, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [39/50], Step [434/469], Loss: 0.2078, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [39/50], Step [435/469], Loss: 0.2513, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [39/50], Step [436/469], Loss: 0.3098, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [39/50], Step [437/469], Loss: 0.3095, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [39/50], Step [438/469], Loss: 0.3133, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [39/50], Step [439/469], Loss: 0.3159, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [39/50], Step [440/469], Loss: 0.4112, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [39/50], Step [441/469], Loss: 0.3756, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [39/50], Step [442/469], Loss: 0.4515, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [39/50], Step [443/469], Loss: 0.3968, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [39/50], Step [444/469], Loss: 0.3487, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [39/50], Step [445/469], Loss: 0.4203, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [39/50], Step [446/469], Loss: 0.2967, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [39/50], Step [447/469], Loss: 0.2964, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [39/50], Step [448/469], Loss: 0.3969, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [39/50], Step [449/469], Loss: 0.4307, batch time: 0.79, accuracy:  84.38%\n",
      "Epoch [39/50], Step [450/469], Loss: 0.3042, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [39/50], Step [451/469], Loss: 0.4476, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [39/50], Step [452/469], Loss: 0.2287, batch time: 0.67, accuracy:  92.97%\n",
      "Epoch [39/50], Step [453/469], Loss: 0.2866, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [39/50], Step [454/469], Loss: 0.2403, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [39/50], Step [455/469], Loss: 0.2930, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [39/50], Step [456/469], Loss: 0.3294, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [39/50], Step [457/469], Loss: 0.2920, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [39/50], Step [458/469], Loss: 0.3117, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [39/50], Step [459/469], Loss: 0.3247, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [39/50], Step [460/469], Loss: 0.3425, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [39/50], Step [461/469], Loss: 0.3219, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [39/50], Step [462/469], Loss: 0.5066, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [39/50], Step [463/469], Loss: 0.4234, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [39/50], Step [464/469], Loss: 0.4131, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [39/50], Step [465/469], Loss: 0.1825, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [39/50], Step [466/469], Loss: 0.3354, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [39/50], Step [467/469], Loss: 0.3958, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [39/50], Step [468/469], Loss: 0.2527, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [39/50], Step [469/469], Loss: 0.2911, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [40/50], Step [1/469], Loss: 0.4408, batch time: 0.57, accuracy:  85.16%\n",
      "Epoch [40/50], Step [2/469], Loss: 0.2738, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [40/50], Step [3/469], Loss: 0.3363, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [40/50], Step [4/469], Loss: 0.4133, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [40/50], Step [5/469], Loss: 0.2605, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [40/50], Step [6/469], Loss: 0.3762, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [40/50], Step [7/469], Loss: 0.3322, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [40/50], Step [8/469], Loss: 0.3460, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [40/50], Step [9/469], Loss: 0.3419, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [40/50], Step [10/469], Loss: 0.4830, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [40/50], Step [11/469], Loss: 0.4151, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [40/50], Step [12/469], Loss: 0.3142, batch time: 0.94, accuracy:  90.62%\n",
      "Epoch [40/50], Step [13/469], Loss: 0.3445, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [40/50], Step [14/469], Loss: 0.2212, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [40/50], Step [15/469], Loss: 0.3054, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [40/50], Step [16/469], Loss: 0.3798, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [40/50], Step [17/469], Loss: 0.1867, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [40/50], Step [18/469], Loss: 0.4431, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [40/50], Step [19/469], Loss: 0.4914, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [40/50], Step [20/469], Loss: 0.2881, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [40/50], Step [21/469], Loss: 0.3287, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [40/50], Step [22/469], Loss: 0.2594, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [40/50], Step [23/469], Loss: 0.3099, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [40/50], Step [24/469], Loss: 0.2676, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [25/469], Loss: 0.2946, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [40/50], Step [26/469], Loss: 0.3034, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [40/50], Step [27/469], Loss: 0.4180, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [40/50], Step [28/469], Loss: 0.2665, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [40/50], Step [29/469], Loss: 0.3381, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [40/50], Step [30/469], Loss: 0.3445, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [40/50], Step [31/469], Loss: 0.3072, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [40/50], Step [32/469], Loss: 0.2059, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [40/50], Step [33/469], Loss: 0.3097, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [40/50], Step [34/469], Loss: 0.2916, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [35/469], Loss: 0.3672, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [40/50], Step [36/469], Loss: 0.2901, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [37/469], Loss: 0.3227, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [40/50], Step [38/469], Loss: 0.5202, batch time: 0.53, accuracy:  82.81%\n",
      "Epoch [40/50], Step [39/469], Loss: 0.3200, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [40/50], Step [40/469], Loss: 0.3521, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [40/50], Step [41/469], Loss: 0.3201, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [40/50], Step [42/469], Loss: 0.4122, batch time: 0.75, accuracy:  86.72%\n",
      "Epoch [40/50], Step [43/469], Loss: 0.2811, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [40/50], Step [44/469], Loss: 0.3243, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [40/50], Step [45/469], Loss: 0.4438, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [40/50], Step [46/469], Loss: 0.3128, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [40/50], Step [47/469], Loss: 0.1743, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [40/50], Step [48/469], Loss: 0.3192, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [40/50], Step [49/469], Loss: 0.3407, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [40/50], Step [50/469], Loss: 0.4217, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [40/50], Step [51/469], Loss: 0.2227, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [40/50], Step [52/469], Loss: 0.3309, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [40/50], Step [53/469], Loss: 0.2133, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [40/50], Step [54/469], Loss: 0.3463, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [40/50], Step [55/469], Loss: 0.4946, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [40/50], Step [56/469], Loss: 0.3214, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [40/50], Step [57/469], Loss: 0.2729, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [40/50], Step [58/469], Loss: 0.2451, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [40/50], Step [59/469], Loss: 0.2851, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [40/50], Step [60/469], Loss: 0.3937, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [61/469], Loss: 0.2183, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [40/50], Step [62/469], Loss: 0.2700, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [40/50], Step [63/469], Loss: 0.2295, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [40/50], Step [64/469], Loss: 0.2719, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [40/50], Step [65/469], Loss: 0.2181, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [40/50], Step [66/469], Loss: 0.2563, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [40/50], Step [67/469], Loss: 0.1731, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [40/50], Step [68/469], Loss: 0.3373, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [69/469], Loss: 0.3078, batch time: 0.51, accuracy:  96.09%\n",
      "Epoch [40/50], Step [70/469], Loss: 0.2202, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [40/50], Step [71/469], Loss: 0.3857, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [40/50], Step [72/469], Loss: 0.3789, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [40/50], Step [73/469], Loss: 0.2029, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [40/50], Step [74/469], Loss: 0.2317, batch time: 0.60, accuracy:  96.09%\n",
      "Epoch [40/50], Step [75/469], Loss: 0.2204, batch time: 0.65, accuracy:  91.41%\n",
      "Epoch [40/50], Step [76/469], Loss: 0.2805, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [40/50], Step [77/469], Loss: 0.3192, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [40/50], Step [78/469], Loss: 0.3407, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [40/50], Step [79/469], Loss: 0.3948, batch time: 0.62, accuracy:  85.94%\n",
      "Epoch [40/50], Step [80/469], Loss: 0.1895, batch time: 0.55, accuracy:  96.09%\n",
      "Epoch [40/50], Step [81/469], Loss: 0.1950, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [40/50], Step [82/469], Loss: 0.2116, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [40/50], Step [83/469], Loss: 0.2625, batch time: 0.50, accuracy:  96.09%\n",
      "Epoch [40/50], Step [84/469], Loss: 0.4049, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [40/50], Step [85/469], Loss: 0.2674, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [40/50], Step [86/469], Loss: 0.3285, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [40/50], Step [87/469], Loss: 0.3581, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [40/50], Step [88/469], Loss: 0.4769, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [89/469], Loss: 0.3629, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [40/50], Step [90/469], Loss: 0.4488, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [40/50], Step [91/469], Loss: 0.4318, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [40/50], Step [92/469], Loss: 0.3314, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [40/50], Step [93/469], Loss: 0.2482, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [40/50], Step [94/469], Loss: 0.2599, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [40/50], Step [95/469], Loss: 0.3748, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [40/50], Step [96/469], Loss: 0.4637, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [40/50], Step [97/469], Loss: 0.3029, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [40/50], Step [98/469], Loss: 0.2326, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [40/50], Step [99/469], Loss: 0.3799, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [40/50], Step [100/469], Loss: 0.2399, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [40/50], Step [101/469], Loss: 0.3732, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [40/50], Step [102/469], Loss: 0.2574, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [40/50], Step [103/469], Loss: 0.2790, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [104/469], Loss: 0.3936, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [40/50], Step [105/469], Loss: 0.4124, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [40/50], Step [106/469], Loss: 0.3502, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [40/50], Step [107/469], Loss: 0.5279, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [40/50], Step [108/469], Loss: 0.3195, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [40/50], Step [109/469], Loss: 0.2863, batch time: 0.65, accuracy:  92.19%\n",
      "Epoch [40/50], Step [110/469], Loss: 0.2242, batch time: 0.64, accuracy:  93.75%\n",
      "Epoch [40/50], Step [111/469], Loss: 0.2591, batch time: 0.65, accuracy:  91.41%\n",
      "Epoch [40/50], Step [112/469], Loss: 0.3717, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [40/50], Step [113/469], Loss: 0.3453, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [40/50], Step [114/469], Loss: 0.4041, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [40/50], Step [115/469], Loss: 0.2830, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [40/50], Step [116/469], Loss: 0.3824, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [40/50], Step [117/469], Loss: 0.3322, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [40/50], Step [118/469], Loss: 0.3116, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [40/50], Step [119/469], Loss: 0.2019, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [40/50], Step [120/469], Loss: 0.3093, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [40/50], Step [121/469], Loss: 0.2727, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [40/50], Step [122/469], Loss: 0.5070, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [40/50], Step [123/469], Loss: 0.3667, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [40/50], Step [124/469], Loss: 0.4463, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [40/50], Step [125/469], Loss: 0.3208, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [40/50], Step [126/469], Loss: 0.2401, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [40/50], Step [127/469], Loss: 0.4973, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [40/50], Step [128/469], Loss: 0.2415, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [40/50], Step [129/469], Loss: 0.4341, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [40/50], Step [130/469], Loss: 0.5594, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [40/50], Step [131/469], Loss: 0.2672, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [40/50], Step [132/469], Loss: 0.4050, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [40/50], Step [133/469], Loss: 0.3918, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [40/50], Step [134/469], Loss: 0.4683, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [40/50], Step [135/469], Loss: 0.2036, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [40/50], Step [136/469], Loss: 0.3114, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [40/50], Step [137/469], Loss: 0.1737, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [40/50], Step [138/469], Loss: 0.4491, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [40/50], Step [139/469], Loss: 0.3469, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [40/50], Step [140/469], Loss: 0.2424, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [40/50], Step [141/469], Loss: 0.2624, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [40/50], Step [142/469], Loss: 0.3467, batch time: 0.82, accuracy:  89.06%\n",
      "Epoch [40/50], Step [143/469], Loss: 0.2667, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [40/50], Step [144/469], Loss: 0.3725, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [40/50], Step [145/469], Loss: 0.4593, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [40/50], Step [146/469], Loss: 0.2158, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [40/50], Step [147/469], Loss: 0.3074, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [40/50], Step [148/469], Loss: 0.3325, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [40/50], Step [149/469], Loss: 0.5423, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [40/50], Step [150/469], Loss: 0.2750, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [40/50], Step [151/469], Loss: 0.2870, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [40/50], Step [152/469], Loss: 0.3130, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [40/50], Step [153/469], Loss: 0.3541, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [154/469], Loss: 0.3500, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [40/50], Step [155/469], Loss: 0.2572, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [156/469], Loss: 0.3244, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [40/50], Step [157/469], Loss: 0.3290, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [40/50], Step [158/469], Loss: 0.3401, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [40/50], Step [159/469], Loss: 0.2237, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [40/50], Step [160/469], Loss: 0.2642, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [40/50], Step [161/469], Loss: 0.3407, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [40/50], Step [162/469], Loss: 0.3690, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [40/50], Step [163/469], Loss: 0.1889, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [40/50], Step [164/469], Loss: 0.2110, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [40/50], Step [165/469], Loss: 0.4317, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [40/50], Step [166/469], Loss: 0.2749, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [40/50], Step [167/469], Loss: 0.3265, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [40/50], Step [168/469], Loss: 0.2433, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [40/50], Step [169/469], Loss: 0.2191, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [40/50], Step [170/469], Loss: 0.4296, batch time: 0.80, accuracy:  85.16%\n",
      "Epoch [40/50], Step [171/469], Loss: 0.3227, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [40/50], Step [172/469], Loss: 0.3649, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [40/50], Step [173/469], Loss: 0.3812, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [40/50], Step [174/469], Loss: 0.3945, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [40/50], Step [175/469], Loss: 0.3646, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [40/50], Step [176/469], Loss: 0.2886, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [40/50], Step [177/469], Loss: 0.3755, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [40/50], Step [178/469], Loss: 0.3180, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [40/50], Step [179/469], Loss: 0.3488, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [40/50], Step [180/469], Loss: 0.2324, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [40/50], Step [181/469], Loss: 0.2603, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [40/50], Step [182/469], Loss: 0.2622, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [40/50], Step [183/469], Loss: 0.3410, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [184/469], Loss: 0.3292, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [40/50], Step [185/469], Loss: 0.2704, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [40/50], Step [186/469], Loss: 0.2350, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [40/50], Step [187/469], Loss: 0.3278, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [40/50], Step [188/469], Loss: 0.3561, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [40/50], Step [189/469], Loss: 0.4591, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [40/50], Step [190/469], Loss: 0.4166, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [40/50], Step [191/469], Loss: 0.3354, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [40/50], Step [192/469], Loss: 0.2479, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [40/50], Step [193/469], Loss: 0.1751, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [40/50], Step [194/469], Loss: 0.2987, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [195/469], Loss: 0.1729, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [40/50], Step [196/469], Loss: 0.2756, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [40/50], Step [197/469], Loss: 0.2084, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [40/50], Step [198/469], Loss: 0.2810, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [40/50], Step [199/469], Loss: 0.1968, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [40/50], Step [200/469], Loss: 0.2912, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [40/50], Step [201/469], Loss: 0.2062, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [40/50], Step [202/469], Loss: 0.2620, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [40/50], Step [203/469], Loss: 0.3106, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [204/469], Loss: 0.2536, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [40/50], Step [205/469], Loss: 0.2335, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [40/50], Step [206/469], Loss: 0.2648, batch time: 0.63, accuracy:  90.62%\n",
      "Epoch [40/50], Step [207/469], Loss: 0.4548, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [40/50], Step [208/469], Loss: 0.3122, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [40/50], Step [209/469], Loss: 0.2020, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [40/50], Step [210/469], Loss: 0.2077, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [40/50], Step [211/469], Loss: 0.3536, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [40/50], Step [212/469], Loss: 0.2779, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [40/50], Step [213/469], Loss: 0.2615, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [40/50], Step [214/469], Loss: 0.2013, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [40/50], Step [215/469], Loss: 0.3017, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [40/50], Step [216/469], Loss: 0.3134, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [40/50], Step [217/469], Loss: 0.5047, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [40/50], Step [218/469], Loss: 0.3375, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [40/50], Step [219/469], Loss: 0.3692, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [40/50], Step [220/469], Loss: 0.3719, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [40/50], Step [221/469], Loss: 0.3637, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [40/50], Step [222/469], Loss: 0.2632, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [40/50], Step [223/469], Loss: 0.3684, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [40/50], Step [224/469], Loss: 0.2778, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [40/50], Step [225/469], Loss: 0.3540, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [40/50], Step [226/469], Loss: 0.3954, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [40/50], Step [227/469], Loss: 0.3027, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [40/50], Step [228/469], Loss: 0.2619, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [40/50], Step [229/469], Loss: 0.3555, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [40/50], Step [230/469], Loss: 0.5385, batch time: 0.71, accuracy:  87.50%\n",
      "Epoch [40/50], Step [231/469], Loss: 0.4860, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [40/50], Step [232/469], Loss: 0.2562, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [40/50], Step [233/469], Loss: 0.2616, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [40/50], Step [234/469], Loss: 0.3667, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [40/50], Step [235/469], Loss: 0.2750, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [236/469], Loss: 0.4303, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [40/50], Step [237/469], Loss: 0.5683, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [40/50], Step [238/469], Loss: 0.4931, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [40/50], Step [239/469], Loss: 0.3381, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [40/50], Step [240/469], Loss: 0.4704, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [40/50], Step [241/469], Loss: 0.2953, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [40/50], Step [242/469], Loss: 0.1558, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [40/50], Step [243/469], Loss: 0.2972, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [40/50], Step [244/469], Loss: 0.4620, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [40/50], Step [245/469], Loss: 0.3300, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [40/50], Step [246/469], Loss: 0.3299, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [40/50], Step [247/469], Loss: 0.2102, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [40/50], Step [248/469], Loss: 0.3190, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [40/50], Step [249/469], Loss: 0.2694, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [40/50], Step [250/469], Loss: 0.2881, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [40/50], Step [251/469], Loss: 0.2981, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [40/50], Step [252/469], Loss: 0.2327, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [40/50], Step [253/469], Loss: 0.2217, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [40/50], Step [254/469], Loss: 0.4357, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [40/50], Step [255/469], Loss: 0.4227, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [40/50], Step [256/469], Loss: 0.2839, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [40/50], Step [257/469], Loss: 0.3125, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [40/50], Step [258/469], Loss: 0.2187, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [40/50], Step [259/469], Loss: 0.3518, batch time: 0.65, accuracy:  90.62%\n",
      "Epoch [40/50], Step [260/469], Loss: 0.4088, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [40/50], Step [261/469], Loss: 0.2030, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [40/50], Step [262/469], Loss: 0.3735, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [40/50], Step [263/469], Loss: 0.3014, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [40/50], Step [264/469], Loss: 0.4010, batch time: 0.64, accuracy:  87.50%\n",
      "Epoch [40/50], Step [265/469], Loss: 0.4073, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [40/50], Step [266/469], Loss: 0.2510, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [40/50], Step [267/469], Loss: 0.3529, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [40/50], Step [268/469], Loss: 0.3288, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [40/50], Step [269/469], Loss: 0.2381, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [40/50], Step [270/469], Loss: 0.2538, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [40/50], Step [271/469], Loss: 0.3115, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [40/50], Step [272/469], Loss: 0.3922, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [40/50], Step [273/469], Loss: 0.2859, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [40/50], Step [274/469], Loss: 0.2533, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [40/50], Step [275/469], Loss: 0.3605, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [276/469], Loss: 0.2655, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [40/50], Step [277/469], Loss: 0.3511, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [40/50], Step [278/469], Loss: 0.2378, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [40/50], Step [279/469], Loss: 0.4587, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [40/50], Step [280/469], Loss: 0.3190, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [40/50], Step [281/469], Loss: 0.4916, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [40/50], Step [282/469], Loss: 0.4215, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [40/50], Step [283/469], Loss: 0.3074, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [40/50], Step [284/469], Loss: 0.5244, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [40/50], Step [285/469], Loss: 0.3346, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [40/50], Step [286/469], Loss: 0.2138, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [40/50], Step [287/469], Loss: 0.3555, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [40/50], Step [288/469], Loss: 0.3383, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [289/469], Loss: 0.2215, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [40/50], Step [290/469], Loss: 0.3643, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [40/50], Step [291/469], Loss: 0.3217, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [40/50], Step [292/469], Loss: 0.4651, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [40/50], Step [293/469], Loss: 0.3493, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [40/50], Step [294/469], Loss: 0.2755, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [40/50], Step [295/469], Loss: 0.2514, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [40/50], Step [296/469], Loss: 0.3966, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [40/50], Step [297/469], Loss: 0.4049, batch time: 0.63, accuracy:  89.84%\n",
      "Epoch [40/50], Step [298/469], Loss: 0.3595, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [40/50], Step [299/469], Loss: 0.2217, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [40/50], Step [300/469], Loss: 0.3185, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [40/50], Step [301/469], Loss: 0.2787, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [40/50], Step [302/469], Loss: 0.2263, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [40/50], Step [303/469], Loss: 0.2921, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [40/50], Step [304/469], Loss: 0.4244, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [40/50], Step [305/469], Loss: 0.3018, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [40/50], Step [306/469], Loss: 0.2703, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [40/50], Step [307/469], Loss: 0.3039, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [308/469], Loss: 0.3081, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [40/50], Step [309/469], Loss: 0.2889, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [40/50], Step [310/469], Loss: 0.3362, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [40/50], Step [311/469], Loss: 0.4889, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [40/50], Step [312/469], Loss: 0.2754, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [313/469], Loss: 0.2924, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [40/50], Step [314/469], Loss: 0.3256, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [40/50], Step [315/469], Loss: 0.3153, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [40/50], Step [316/469], Loss: 0.2232, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [40/50], Step [317/469], Loss: 0.3533, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [40/50], Step [318/469], Loss: 0.3430, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [40/50], Step [319/469], Loss: 0.1744, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [40/50], Step [320/469], Loss: 0.3828, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [40/50], Step [321/469], Loss: 0.4724, batch time: 0.54, accuracy:  85.16%\n",
      "Epoch [40/50], Step [322/469], Loss: 0.4278, batch time: 0.66, accuracy:  89.06%\n",
      "Epoch [40/50], Step [323/469], Loss: 0.2840, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [40/50], Step [324/469], Loss: 0.4261, batch time: 0.59, accuracy:  85.16%\n",
      "Epoch [40/50], Step [325/469], Loss: 0.2994, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [40/50], Step [326/469], Loss: 0.1574, batch time: 0.61, accuracy:  96.09%\n",
      "Epoch [40/50], Step [327/469], Loss: 0.4782, batch time: 0.76, accuracy:  86.72%\n",
      "Epoch [40/50], Step [328/469], Loss: 0.3194, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [40/50], Step [329/469], Loss: 0.3624, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [40/50], Step [330/469], Loss: 0.2891, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [40/50], Step [331/469], Loss: 0.4340, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [40/50], Step [332/469], Loss: 0.3383, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [40/50], Step [333/469], Loss: 0.5521, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [40/50], Step [334/469], Loss: 0.4095, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [40/50], Step [335/469], Loss: 0.2286, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [40/50], Step [336/469], Loss: 0.5356, batch time: 0.45, accuracy:  84.38%\n",
      "Epoch [40/50], Step [337/469], Loss: 0.2687, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [40/50], Step [338/469], Loss: 0.2357, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [40/50], Step [339/469], Loss: 0.4222, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [40/50], Step [340/469], Loss: 0.2419, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [40/50], Step [341/469], Loss: 0.2546, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [40/50], Step [342/469], Loss: 0.4308, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [40/50], Step [343/469], Loss: 0.3434, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [40/50], Step [344/469], Loss: 0.2967, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [40/50], Step [345/469], Loss: 0.3404, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [40/50], Step [346/469], Loss: 0.3774, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [40/50], Step [347/469], Loss: 0.3810, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [40/50], Step [348/469], Loss: 0.4283, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [40/50], Step [349/469], Loss: 0.4001, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [40/50], Step [350/469], Loss: 0.3319, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [40/50], Step [351/469], Loss: 0.3026, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [40/50], Step [352/469], Loss: 0.2922, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [353/469], Loss: 0.4141, batch time: 0.55, accuracy:  84.38%\n",
      "Epoch [40/50], Step [354/469], Loss: 0.1583, batch time: 0.61, accuracy:  95.31%\n",
      "Epoch [40/50], Step [355/469], Loss: 0.2863, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [40/50], Step [356/469], Loss: 0.3499, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [40/50], Step [357/469], Loss: 0.3512, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [40/50], Step [358/469], Loss: 0.2783, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [40/50], Step [359/469], Loss: 0.4853, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [40/50], Step [360/469], Loss: 0.2128, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [40/50], Step [361/469], Loss: 0.4253, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [40/50], Step [362/469], Loss: 0.2579, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [40/50], Step [363/469], Loss: 0.2838, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [40/50], Step [364/469], Loss: 0.3277, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [40/50], Step [365/469], Loss: 0.3194, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [40/50], Step [366/469], Loss: 0.2644, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [40/50], Step [367/469], Loss: 0.3697, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [40/50], Step [368/469], Loss: 0.6173, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [40/50], Step [369/469], Loss: 0.4367, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [40/50], Step [370/469], Loss: 0.2479, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [40/50], Step [371/469], Loss: 0.3445, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [40/50], Step [372/469], Loss: 0.2122, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [40/50], Step [373/469], Loss: 0.2603, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [40/50], Step [374/469], Loss: 0.2620, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [40/50], Step [375/469], Loss: 0.5024, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [40/50], Step [376/469], Loss: 0.2853, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [40/50], Step [377/469], Loss: 0.3764, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [40/50], Step [378/469], Loss: 0.3888, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [40/50], Step [379/469], Loss: 0.3389, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [40/50], Step [380/469], Loss: 0.2096, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [40/50], Step [381/469], Loss: 0.3154, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [40/50], Step [382/469], Loss: 0.2553, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [40/50], Step [383/469], Loss: 0.4640, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [40/50], Step [384/469], Loss: 0.2600, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [40/50], Step [385/469], Loss: 0.4207, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [40/50], Step [386/469], Loss: 0.3376, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [40/50], Step [387/469], Loss: 0.5079, batch time: 0.77, accuracy:  86.72%\n",
      "Epoch [40/50], Step [388/469], Loss: 0.3027, batch time: 0.67, accuracy:  89.84%\n",
      "Epoch [40/50], Step [389/469], Loss: 0.1867, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [40/50], Step [390/469], Loss: 0.3301, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [40/50], Step [391/469], Loss: 0.4005, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [392/469], Loss: 0.4289, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [40/50], Step [393/469], Loss: 0.2446, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [40/50], Step [394/469], Loss: 0.6636, batch time: 0.48, accuracy:  81.25%\n",
      "Epoch [40/50], Step [395/469], Loss: 0.3206, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [40/50], Step [396/469], Loss: 0.5209, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [40/50], Step [397/469], Loss: 0.3049, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [40/50], Step [398/469], Loss: 0.2766, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [40/50], Step [399/469], Loss: 0.2346, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [40/50], Step [400/469], Loss: 0.3732, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [40/50], Step [401/469], Loss: 0.3198, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [40/50], Step [402/469], Loss: 0.4212, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [403/469], Loss: 0.2772, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [40/50], Step [404/469], Loss: 0.2901, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [40/50], Step [405/469], Loss: 0.3680, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [40/50], Step [406/469], Loss: 0.3805, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [40/50], Step [407/469], Loss: 0.2816, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [40/50], Step [408/469], Loss: 0.3495, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [40/50], Step [409/469], Loss: 0.4870, batch time: 0.58, accuracy:  86.72%\n",
      "Epoch [40/50], Step [410/469], Loss: 0.3809, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [40/50], Step [411/469], Loss: 0.3874, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [40/50], Step [412/469], Loss: 0.1637, batch time: 0.55, accuracy:  95.31%\n",
      "Epoch [40/50], Step [413/469], Loss: 0.3295, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [414/469], Loss: 0.2646, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [40/50], Step [415/469], Loss: 0.3345, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [40/50], Step [416/469], Loss: 0.4037, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [40/50], Step [417/469], Loss: 0.4492, batch time: 0.84, accuracy:  85.16%\n",
      "Epoch [40/50], Step [418/469], Loss: 0.4791, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [40/50], Step [419/469], Loss: 0.1825, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [40/50], Step [420/469], Loss: 0.2792, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [40/50], Step [421/469], Loss: 0.2662, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [40/50], Step [422/469], Loss: 0.4119, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [40/50], Step [423/469], Loss: 0.2855, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [40/50], Step [424/469], Loss: 0.3599, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [40/50], Step [425/469], Loss: 0.3071, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [40/50], Step [426/469], Loss: 0.3308, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [40/50], Step [427/469], Loss: 0.2089, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [40/50], Step [428/469], Loss: 0.2705, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [40/50], Step [429/469], Loss: 0.3360, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [40/50], Step [430/469], Loss: 0.2788, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [431/469], Loss: 0.2929, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [40/50], Step [432/469], Loss: 0.3833, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [40/50], Step [433/469], Loss: 0.3780, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [40/50], Step [434/469], Loss: 0.3465, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [40/50], Step [435/469], Loss: 0.2029, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [40/50], Step [436/469], Loss: 0.3511, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [40/50], Step [437/469], Loss: 0.1896, batch time: 0.66, accuracy:  92.97%\n",
      "Epoch [40/50], Step [438/469], Loss: 0.4331, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [40/50], Step [439/469], Loss: 0.2937, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [40/50], Step [440/469], Loss: 0.2090, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [40/50], Step [441/469], Loss: 0.2903, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [40/50], Step [442/469], Loss: 0.2363, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [40/50], Step [443/469], Loss: 0.2748, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [40/50], Step [444/469], Loss: 0.3305, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [40/50], Step [445/469], Loss: 0.3500, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [40/50], Step [446/469], Loss: 0.2804, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [40/50], Step [447/469], Loss: 0.3101, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [448/469], Loss: 0.2581, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [40/50], Step [449/469], Loss: 0.3205, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [450/469], Loss: 0.3855, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [40/50], Step [451/469], Loss: 0.2551, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [40/50], Step [452/469], Loss: 0.2691, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [40/50], Step [453/469], Loss: 0.4165, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [40/50], Step [454/469], Loss: 0.4360, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [40/50], Step [455/469], Loss: 0.3899, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [40/50], Step [456/469], Loss: 0.3302, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [40/50], Step [457/469], Loss: 0.3665, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [40/50], Step [458/469], Loss: 0.1314, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [40/50], Step [459/469], Loss: 0.1762, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [40/50], Step [460/469], Loss: 0.3088, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [40/50], Step [461/469], Loss: 0.4093, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [40/50], Step [462/469], Loss: 0.3331, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [40/50], Step [463/469], Loss: 0.3006, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [40/50], Step [464/469], Loss: 0.2840, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [40/50], Step [465/469], Loss: 0.4069, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [40/50], Step [466/469], Loss: 0.2393, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [40/50], Step [467/469], Loss: 0.4188, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [40/50], Step [468/469], Loss: 0.4198, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [40/50], Step [469/469], Loss: 0.2645, batch time: 0.46, accuracy:  91.67%\n",
      "Epoch [41/50], Step [1/469], Loss: 0.2585, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [2/469], Loss: 0.3026, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [41/50], Step [3/469], Loss: 0.1639, batch time: 0.47, accuracy:  96.88%\n",
      "Epoch [41/50], Step [4/469], Loss: 0.2976, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [5/469], Loss: 0.2451, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [41/50], Step [6/469], Loss: 0.5319, batch time: 0.57, accuracy:  83.59%\n",
      "Epoch [41/50], Step [7/469], Loss: 0.2189, batch time: 0.62, accuracy:  92.97%\n",
      "Epoch [41/50], Step [8/469], Loss: 0.3887, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [41/50], Step [9/469], Loss: 0.3835, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [41/50], Step [10/469], Loss: 0.3555, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [41/50], Step [11/469], Loss: 0.4321, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [41/50], Step [12/469], Loss: 0.2940, batch time: 0.62, accuracy:  86.72%\n",
      "Epoch [41/50], Step [13/469], Loss: 0.2158, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [41/50], Step [14/469], Loss: 0.3050, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [41/50], Step [15/469], Loss: 0.2399, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [41/50], Step [16/469], Loss: 0.2371, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [41/50], Step [17/469], Loss: 0.2880, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [41/50], Step [18/469], Loss: 0.2882, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [41/50], Step [19/469], Loss: 0.3435, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [20/469], Loss: 0.2533, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [41/50], Step [21/469], Loss: 0.2388, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [41/50], Step [22/469], Loss: 0.2774, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [41/50], Step [23/469], Loss: 0.2457, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [41/50], Step [24/469], Loss: 0.3059, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [41/50], Step [25/469], Loss: 0.3124, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [41/50], Step [26/469], Loss: 0.2849, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [27/469], Loss: 0.2417, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [41/50], Step [28/469], Loss: 0.4390, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [41/50], Step [29/469], Loss: 0.2675, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [30/469], Loss: 0.4121, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [41/50], Step [31/469], Loss: 0.3088, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [41/50], Step [32/469], Loss: 0.3150, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [41/50], Step [33/469], Loss: 0.4093, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [41/50], Step [34/469], Loss: 0.4525, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [41/50], Step [35/469], Loss: 0.3026, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [41/50], Step [36/469], Loss: 0.1812, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [41/50], Step [37/469], Loss: 0.3004, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [41/50], Step [38/469], Loss: 0.4806, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [41/50], Step [39/469], Loss: 0.5204, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [41/50], Step [40/469], Loss: 0.2171, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [41/50], Step [41/469], Loss: 0.4076, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [41/50], Step [42/469], Loss: 0.3327, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [41/50], Step [43/469], Loss: 0.3392, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [41/50], Step [44/469], Loss: 0.2573, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [41/50], Step [45/469], Loss: 0.4011, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [41/50], Step [46/469], Loss: 0.2376, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [41/50], Step [47/469], Loss: 0.1811, batch time: 0.67, accuracy:  92.97%\n",
      "Epoch [41/50], Step [48/469], Loss: 0.2598, batch time: 0.62, accuracy:  93.75%\n",
      "Epoch [41/50], Step [49/469], Loss: 0.2795, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [41/50], Step [50/469], Loss: 0.3252, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [41/50], Step [51/469], Loss: 0.3764, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [41/50], Step [52/469], Loss: 0.2034, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [41/50], Step [53/469], Loss: 0.3157, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [41/50], Step [54/469], Loss: 0.2838, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [41/50], Step [55/469], Loss: 0.2779, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [41/50], Step [56/469], Loss: 0.2780, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [41/50], Step [57/469], Loss: 0.2174, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [41/50], Step [58/469], Loss: 0.3423, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [41/50], Step [59/469], Loss: 0.4179, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [41/50], Step [60/469], Loss: 0.4570, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [41/50], Step [61/469], Loss: 0.2085, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [41/50], Step [62/469], Loss: 0.3755, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [41/50], Step [63/469], Loss: 0.1949, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [41/50], Step [64/469], Loss: 0.2605, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [65/469], Loss: 0.3016, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [41/50], Step [66/469], Loss: 0.2859, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [41/50], Step [67/469], Loss: 0.2523, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [41/50], Step [68/469], Loss: 0.3087, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [41/50], Step [69/469], Loss: 0.3481, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [41/50], Step [70/469], Loss: 0.3438, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [41/50], Step [71/469], Loss: 0.2387, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [41/50], Step [72/469], Loss: 0.2974, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [41/50], Step [73/469], Loss: 0.4775, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [41/50], Step [74/469], Loss: 0.2625, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [41/50], Step [75/469], Loss: 0.2860, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [41/50], Step [76/469], Loss: 0.4568, batch time: 0.69, accuracy:  87.50%\n",
      "Epoch [41/50], Step [77/469], Loss: 0.2479, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [41/50], Step [78/469], Loss: 0.2558, batch time: 0.79, accuracy:  92.19%\n",
      "Epoch [41/50], Step [79/469], Loss: 0.2884, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [41/50], Step [80/469], Loss: 0.3191, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [41/50], Step [81/469], Loss: 0.2824, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [41/50], Step [82/469], Loss: 0.2874, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [41/50], Step [83/469], Loss: 0.1695, batch time: 0.70, accuracy:  96.09%\n",
      "Epoch [41/50], Step [84/469], Loss: 0.1533, batch time: 0.51, accuracy:  96.09%\n",
      "Epoch [41/50], Step [85/469], Loss: 0.2056, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [41/50], Step [86/469], Loss: 0.5284, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [41/50], Step [87/469], Loss: 0.1832, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [41/50], Step [88/469], Loss: 0.3068, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [41/50], Step [89/469], Loss: 0.3778, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [41/50], Step [90/469], Loss: 0.2682, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [41/50], Step [91/469], Loss: 0.3240, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [41/50], Step [92/469], Loss: 0.2564, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [93/469], Loss: 0.2928, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [41/50], Step [94/469], Loss: 0.3391, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [41/50], Step [95/469], Loss: 0.3225, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [41/50], Step [96/469], Loss: 0.2917, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [41/50], Step [97/469], Loss: 0.2989, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [98/469], Loss: 0.5337, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [41/50], Step [99/469], Loss: 0.3403, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [41/50], Step [100/469], Loss: 0.2890, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [41/50], Step [101/469], Loss: 0.2177, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [41/50], Step [102/469], Loss: 0.3185, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [41/50], Step [103/469], Loss: 0.3055, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [41/50], Step [104/469], Loss: 0.3352, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [41/50], Step [105/469], Loss: 0.3706, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [41/50], Step [106/469], Loss: 0.5317, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [41/50], Step [107/469], Loss: 0.3284, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [41/50], Step [108/469], Loss: 0.3794, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [41/50], Step [109/469], Loss: 0.3608, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [41/50], Step [110/469], Loss: 0.3822, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [41/50], Step [111/469], Loss: 0.5039, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [41/50], Step [112/469], Loss: 0.2794, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [41/50], Step [113/469], Loss: 0.4710, batch time: 0.58, accuracy:  85.94%\n",
      "Epoch [41/50], Step [114/469], Loss: 0.3454, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [115/469], Loss: 0.3131, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [41/50], Step [116/469], Loss: 0.3577, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [117/469], Loss: 0.2703, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [41/50], Step [118/469], Loss: 0.3335, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [41/50], Step [119/469], Loss: 0.1973, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [41/50], Step [120/469], Loss: 0.3397, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [121/469], Loss: 0.2633, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [41/50], Step [122/469], Loss: 0.4755, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [41/50], Step [123/469], Loss: 0.2295, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [41/50], Step [124/469], Loss: 0.2865, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [41/50], Step [125/469], Loss: 0.1637, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [41/50], Step [126/469], Loss: 0.2807, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [41/50], Step [127/469], Loss: 0.2507, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [41/50], Step [128/469], Loss: 0.3700, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [41/50], Step [129/469], Loss: 0.3486, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [41/50], Step [130/469], Loss: 0.3818, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [41/50], Step [131/469], Loss: 0.3314, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [41/50], Step [132/469], Loss: 0.2011, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [41/50], Step [133/469], Loss: 0.3781, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [41/50], Step [134/469], Loss: 0.5181, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [41/50], Step [135/469], Loss: 0.5366, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [41/50], Step [136/469], Loss: 0.4277, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [41/50], Step [137/469], Loss: 0.3460, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [41/50], Step [138/469], Loss: 0.4349, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [41/50], Step [139/469], Loss: 0.4053, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [41/50], Step [140/469], Loss: 0.5035, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [41/50], Step [141/469], Loss: 0.2547, batch time: 0.81, accuracy:  92.97%\n",
      "Epoch [41/50], Step [142/469], Loss: 0.3414, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [41/50], Step [143/469], Loss: 0.3751, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [41/50], Step [144/469], Loss: 0.3728, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [41/50], Step [145/469], Loss: 0.3231, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [41/50], Step [146/469], Loss: 0.3956, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [41/50], Step [147/469], Loss: 0.2777, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [41/50], Step [148/469], Loss: 0.2440, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [41/50], Step [149/469], Loss: 0.3385, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [41/50], Step [150/469], Loss: 0.2697, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [41/50], Step [151/469], Loss: 0.3925, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [41/50], Step [152/469], Loss: 0.3029, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [41/50], Step [153/469], Loss: 0.3376, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [41/50], Step [154/469], Loss: 0.2840, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [41/50], Step [155/469], Loss: 0.2392, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [41/50], Step [156/469], Loss: 0.3831, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [41/50], Step [157/469], Loss: 0.3551, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [158/469], Loss: 0.4266, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [41/50], Step [159/469], Loss: 0.3768, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [41/50], Step [160/469], Loss: 0.3767, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [41/50], Step [161/469], Loss: 0.3916, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [41/50], Step [162/469], Loss: 0.2715, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [41/50], Step [163/469], Loss: 0.2880, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [41/50], Step [164/469], Loss: 0.3915, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [41/50], Step [165/469], Loss: 0.2820, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [41/50], Step [166/469], Loss: 0.3278, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [41/50], Step [167/469], Loss: 0.2848, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [41/50], Step [168/469], Loss: 0.2360, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [41/50], Step [169/469], Loss: 0.3156, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [41/50], Step [170/469], Loss: 0.1986, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [41/50], Step [171/469], Loss: 0.2685, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [41/50], Step [172/469], Loss: 0.2290, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [41/50], Step [173/469], Loss: 0.2566, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [41/50], Step [174/469], Loss: 0.2732, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [41/50], Step [175/469], Loss: 0.3011, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [41/50], Step [176/469], Loss: 0.2211, batch time: 0.62, accuracy:  93.75%\n",
      "Epoch [41/50], Step [177/469], Loss: 0.4290, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [41/50], Step [178/469], Loss: 0.1890, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [41/50], Step [179/469], Loss: 0.2525, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [41/50], Step [180/469], Loss: 0.3729, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [41/50], Step [181/469], Loss: 0.4080, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [41/50], Step [182/469], Loss: 0.3131, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [41/50], Step [183/469], Loss: 0.4546, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [41/50], Step [184/469], Loss: 0.2173, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [41/50], Step [185/469], Loss: 0.4477, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [41/50], Step [186/469], Loss: 0.3154, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [41/50], Step [187/469], Loss: 0.2927, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [41/50], Step [188/469], Loss: 0.3868, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [189/469], Loss: 0.3076, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [41/50], Step [190/469], Loss: 0.2821, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [41/50], Step [191/469], Loss: 0.3529, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [41/50], Step [192/469], Loss: 0.3121, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [41/50], Step [193/469], Loss: 0.3639, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [41/50], Step [194/469], Loss: 0.2154, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [41/50], Step [195/469], Loss: 0.2719, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [41/50], Step [196/469], Loss: 0.2099, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [41/50], Step [197/469], Loss: 0.2080, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [41/50], Step [198/469], Loss: 0.3212, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [41/50], Step [199/469], Loss: 0.5253, batch time: 0.44, accuracy:  85.16%\n",
      "Epoch [41/50], Step [200/469], Loss: 0.3115, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [41/50], Step [201/469], Loss: 0.2342, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [41/50], Step [202/469], Loss: 0.4259, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [41/50], Step [203/469], Loss: 0.2811, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [204/469], Loss: 0.4826, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [41/50], Step [205/469], Loss: 0.3202, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [41/50], Step [206/469], Loss: 0.2694, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [41/50], Step [207/469], Loss: 0.3556, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [41/50], Step [208/469], Loss: 0.3638, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [41/50], Step [209/469], Loss: 0.4674, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [41/50], Step [210/469], Loss: 0.4823, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [41/50], Step [211/469], Loss: 0.3108, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [41/50], Step [212/469], Loss: 0.3056, batch time: 0.66, accuracy:  92.97%\n",
      "Epoch [41/50], Step [213/469], Loss: 0.3714, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [41/50], Step [214/469], Loss: 0.2343, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [41/50], Step [215/469], Loss: 0.2545, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [41/50], Step [216/469], Loss: 0.3634, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [41/50], Step [217/469], Loss: 0.2335, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [218/469], Loss: 0.2149, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [41/50], Step [219/469], Loss: 0.2157, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [41/50], Step [220/469], Loss: 0.3334, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [41/50], Step [221/469], Loss: 0.3449, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [222/469], Loss: 0.2814, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [41/50], Step [223/469], Loss: 0.3760, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [41/50], Step [224/469], Loss: 0.2770, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [41/50], Step [225/469], Loss: 0.2810, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [41/50], Step [226/469], Loss: 0.2495, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [41/50], Step [227/469], Loss: 0.2871, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [41/50], Step [228/469], Loss: 0.2793, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [41/50], Step [229/469], Loss: 0.1672, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [41/50], Step [230/469], Loss: 0.4017, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [41/50], Step [231/469], Loss: 0.3196, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [41/50], Step [232/469], Loss: 0.3476, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [41/50], Step [233/469], Loss: 0.3938, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [41/50], Step [234/469], Loss: 0.3125, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [41/50], Step [235/469], Loss: 0.2408, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [41/50], Step [236/469], Loss: 0.3663, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [41/50], Step [237/469], Loss: 0.4122, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [238/469], Loss: 0.2934, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [41/50], Step [239/469], Loss: 0.3772, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [41/50], Step [240/469], Loss: 0.3838, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [41/50], Step [241/469], Loss: 0.3247, batch time: 0.65, accuracy:  90.62%\n",
      "Epoch [41/50], Step [242/469], Loss: 0.4238, batch time: 0.70, accuracy:  88.28%\n",
      "Epoch [41/50], Step [243/469], Loss: 0.2170, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [41/50], Step [244/469], Loss: 0.1842, batch time: 0.67, accuracy:  92.19%\n",
      "Epoch [41/50], Step [245/469], Loss: 0.3601, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [41/50], Step [246/469], Loss: 0.3853, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [41/50], Step [247/469], Loss: 0.2749, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [41/50], Step [248/469], Loss: 0.2505, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [41/50], Step [249/469], Loss: 0.2519, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [41/50], Step [250/469], Loss: 0.2327, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [41/50], Step [251/469], Loss: 0.2986, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [41/50], Step [252/469], Loss: 0.3038, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [41/50], Step [253/469], Loss: 0.4785, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [41/50], Step [254/469], Loss: 0.2937, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [255/469], Loss: 0.4334, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [41/50], Step [256/469], Loss: 0.3159, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [41/50], Step [257/469], Loss: 0.3353, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [258/469], Loss: 0.3994, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [259/469], Loss: 0.3275, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [41/50], Step [260/469], Loss: 0.4105, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [41/50], Step [261/469], Loss: 0.3331, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [41/50], Step [262/469], Loss: 0.3593, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [41/50], Step [263/469], Loss: 0.3265, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [41/50], Step [264/469], Loss: 0.3164, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [41/50], Step [265/469], Loss: 0.2522, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [41/50], Step [266/469], Loss: 0.2119, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [41/50], Step [267/469], Loss: 0.2899, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [41/50], Step [268/469], Loss: 0.2845, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [41/50], Step [269/469], Loss: 0.5576, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [41/50], Step [270/469], Loss: 0.3478, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [41/50], Step [271/469], Loss: 0.2002, batch time: 0.75, accuracy:  93.75%\n",
      "Epoch [41/50], Step [272/469], Loss: 0.3662, batch time: 0.87, accuracy:  89.84%\n",
      "Epoch [41/50], Step [273/469], Loss: 0.3763, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [41/50], Step [274/469], Loss: 0.3533, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [41/50], Step [275/469], Loss: 0.2684, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [41/50], Step [276/469], Loss: 0.3673, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [41/50], Step [277/469], Loss: 0.2934, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [41/50], Step [278/469], Loss: 0.2845, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [41/50], Step [279/469], Loss: 0.5431, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [41/50], Step [280/469], Loss: 0.3395, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [41/50], Step [281/469], Loss: 0.3258, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [41/50], Step [282/469], Loss: 0.2705, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [41/50], Step [283/469], Loss: 0.3325, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [41/50], Step [284/469], Loss: 0.2421, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [41/50], Step [285/469], Loss: 0.3455, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [41/50], Step [286/469], Loss: 0.3641, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [41/50], Step [287/469], Loss: 0.3216, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [41/50], Step [288/469], Loss: 0.4773, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [41/50], Step [289/469], Loss: 0.5445, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [41/50], Step [290/469], Loss: 0.4540, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [41/50], Step [291/469], Loss: 0.2617, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [292/469], Loss: 0.3903, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [41/50], Step [293/469], Loss: 0.3300, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [41/50], Step [294/469], Loss: 0.1984, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [41/50], Step [295/469], Loss: 0.3787, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [41/50], Step [296/469], Loss: 0.3827, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [41/50], Step [297/469], Loss: 0.3180, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [41/50], Step [298/469], Loss: 0.2879, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [41/50], Step [299/469], Loss: 0.3231, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [41/50], Step [300/469], Loss: 0.3329, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [41/50], Step [301/469], Loss: 0.2128, batch time: 0.62, accuracy:  95.31%\n",
      "Epoch [41/50], Step [302/469], Loss: 0.1979, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [41/50], Step [303/469], Loss: 0.3636, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [41/50], Step [304/469], Loss: 0.2431, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [41/50], Step [305/469], Loss: 0.5569, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [41/50], Step [306/469], Loss: 0.1989, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [41/50], Step [307/469], Loss: 0.3712, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [41/50], Step [308/469], Loss: 0.2816, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [41/50], Step [309/469], Loss: 0.2930, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [41/50], Step [310/469], Loss: 0.2413, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [41/50], Step [311/469], Loss: 0.2187, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [41/50], Step [312/469], Loss: 0.3144, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [41/50], Step [313/469], Loss: 0.2505, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [41/50], Step [314/469], Loss: 0.1922, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [41/50], Step [315/469], Loss: 0.2939, batch time: 0.71, accuracy:  90.62%\n",
      "Epoch [41/50], Step [316/469], Loss: 0.2653, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [41/50], Step [317/469], Loss: 0.3295, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [41/50], Step [318/469], Loss: 0.3958, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [41/50], Step [319/469], Loss: 0.4919, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [41/50], Step [320/469], Loss: 0.3894, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [321/469], Loss: 0.2285, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [41/50], Step [322/469], Loss: 0.1974, batch time: 0.49, accuracy:  96.88%\n",
      "Epoch [41/50], Step [323/469], Loss: 0.3683, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [41/50], Step [324/469], Loss: 0.2217, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [41/50], Step [325/469], Loss: 0.4242, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [41/50], Step [326/469], Loss: 0.4994, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [41/50], Step [327/469], Loss: 0.4512, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [41/50], Step [328/469], Loss: 0.2744, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [41/50], Step [329/469], Loss: 0.2420, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [41/50], Step [330/469], Loss: 0.3101, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [41/50], Step [331/469], Loss: 0.2315, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [41/50], Step [332/469], Loss: 0.2317, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [41/50], Step [333/469], Loss: 0.1519, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [41/50], Step [334/469], Loss: 0.2865, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [41/50], Step [335/469], Loss: 0.3568, batch time: 0.60, accuracy:  85.94%\n",
      "Epoch [41/50], Step [336/469], Loss: 0.2324, batch time: 0.66, accuracy:  90.62%\n",
      "Epoch [41/50], Step [337/469], Loss: 0.3516, batch time: 0.64, accuracy:  90.62%\n",
      "Epoch [41/50], Step [338/469], Loss: 0.2660, batch time: 0.74, accuracy:  91.41%\n",
      "Epoch [41/50], Step [339/469], Loss: 0.2586, batch time: 0.69, accuracy:  92.19%\n",
      "Epoch [41/50], Step [340/469], Loss: 0.3158, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [41/50], Step [341/469], Loss: 0.2994, batch time: 0.63, accuracy:  92.97%\n",
      "Epoch [41/50], Step [342/469], Loss: 0.3543, batch time: 0.66, accuracy:  90.62%\n",
      "Epoch [41/50], Step [343/469], Loss: 0.1796, batch time: 0.59, accuracy:  95.31%\n",
      "Epoch [41/50], Step [344/469], Loss: 0.2816, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [41/50], Step [345/469], Loss: 0.2694, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [41/50], Step [346/469], Loss: 0.2893, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [41/50], Step [347/469], Loss: 0.2486, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [41/50], Step [348/469], Loss: 0.3178, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [41/50], Step [349/469], Loss: 0.3590, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [41/50], Step [350/469], Loss: 0.3870, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [41/50], Step [351/469], Loss: 0.2758, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [41/50], Step [352/469], Loss: 0.3187, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [41/50], Step [353/469], Loss: 0.3900, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [41/50], Step [354/469], Loss: 0.2394, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [41/50], Step [355/469], Loss: 0.3411, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [41/50], Step [356/469], Loss: 0.3553, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [41/50], Step [357/469], Loss: 0.1846, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [41/50], Step [358/469], Loss: 0.2231, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [41/50], Step [359/469], Loss: 0.3139, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [41/50], Step [360/469], Loss: 0.3665, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [41/50], Step [361/469], Loss: 0.2042, batch time: 0.57, accuracy:  93.75%\n",
      "Epoch [41/50], Step [362/469], Loss: 0.2473, batch time: 0.68, accuracy:  92.97%\n",
      "Epoch [41/50], Step [363/469], Loss: 0.2913, batch time: 0.65, accuracy:  89.84%\n",
      "Epoch [41/50], Step [364/469], Loss: 0.3360, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [41/50], Step [365/469], Loss: 0.2517, batch time: 0.72, accuracy:  92.97%\n",
      "Epoch [41/50], Step [366/469], Loss: 0.2600, batch time: 0.76, accuracy:  94.53%\n",
      "Epoch [41/50], Step [367/469], Loss: 0.3727, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [41/50], Step [368/469], Loss: 0.3495, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [41/50], Step [369/469], Loss: 0.3000, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [41/50], Step [370/469], Loss: 0.4212, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [41/50], Step [371/469], Loss: 0.2544, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [41/50], Step [372/469], Loss: 0.2699, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [41/50], Step [373/469], Loss: 0.3316, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [41/50], Step [374/469], Loss: 0.2885, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [41/50], Step [375/469], Loss: 0.3788, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [41/50], Step [376/469], Loss: 0.5186, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [41/50], Step [377/469], Loss: 0.3687, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [41/50], Step [378/469], Loss: 0.3007, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [41/50], Step [379/469], Loss: 0.3088, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [41/50], Step [380/469], Loss: 0.3990, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [41/50], Step [381/469], Loss: 0.2696, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [41/50], Step [382/469], Loss: 0.3781, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [41/50], Step [383/469], Loss: 0.4543, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [41/50], Step [384/469], Loss: 0.3284, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [41/50], Step [385/469], Loss: 0.4633, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [41/50], Step [386/469], Loss: 0.2701, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [41/50], Step [387/469], Loss: 0.4204, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [41/50], Step [388/469], Loss: 0.2470, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [41/50], Step [389/469], Loss: 0.3061, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [41/50], Step [390/469], Loss: 0.2054, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [41/50], Step [391/469], Loss: 0.2267, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [41/50], Step [392/469], Loss: 0.2952, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [41/50], Step [393/469], Loss: 0.3013, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [41/50], Step [394/469], Loss: 0.4441, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [41/50], Step [395/469], Loss: 0.2198, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [41/50], Step [396/469], Loss: 0.5225, batch time: 0.58, accuracy:  85.16%\n",
      "Epoch [41/50], Step [397/469], Loss: 0.2436, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [41/50], Step [398/469], Loss: 0.1984, batch time: 0.58, accuracy:  92.97%\n",
      "Epoch [41/50], Step [399/469], Loss: 0.2949, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [41/50], Step [400/469], Loss: 0.3443, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [41/50], Step [401/469], Loss: 0.4600, batch time: 0.48, accuracy:  84.38%\n",
      "Epoch [41/50], Step [402/469], Loss: 0.2830, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [41/50], Step [403/469], Loss: 0.3293, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [41/50], Step [404/469], Loss: 0.3375, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [41/50], Step [405/469], Loss: 0.3804, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [41/50], Step [406/469], Loss: 0.2919, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [41/50], Step [407/469], Loss: 0.2809, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [41/50], Step [408/469], Loss: 0.2937, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [41/50], Step [409/469], Loss: 0.3081, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [41/50], Step [410/469], Loss: 0.3308, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [41/50], Step [411/469], Loss: 0.3489, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [41/50], Step [412/469], Loss: 0.1821, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [41/50], Step [413/469], Loss: 0.3777, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [41/50], Step [414/469], Loss: 0.3841, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [41/50], Step [415/469], Loss: 0.4095, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [41/50], Step [416/469], Loss: 0.3174, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [41/50], Step [417/469], Loss: 0.2623, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [41/50], Step [418/469], Loss: 0.2334, batch time: 0.59, accuracy:  95.31%\n",
      "Epoch [41/50], Step [419/469], Loss: 0.4721, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [41/50], Step [420/469], Loss: 0.2504, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [41/50], Step [421/469], Loss: 0.3246, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [41/50], Step [422/469], Loss: 0.4744, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [41/50], Step [423/469], Loss: 0.4407, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [41/50], Step [424/469], Loss: 0.2914, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [41/50], Step [425/469], Loss: 0.3228, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [41/50], Step [426/469], Loss: 0.3832, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [41/50], Step [427/469], Loss: 0.4201, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [41/50], Step [428/469], Loss: 0.2569, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [41/50], Step [429/469], Loss: 0.3354, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [41/50], Step [430/469], Loss: 0.2434, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [41/50], Step [431/469], Loss: 0.2495, batch time: 0.66, accuracy:  91.41%\n",
      "Epoch [41/50], Step [432/469], Loss: 0.3967, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [41/50], Step [433/469], Loss: 0.1853, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [41/50], Step [434/469], Loss: 0.3194, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [41/50], Step [435/469], Loss: 0.3699, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [41/50], Step [436/469], Loss: 0.4039, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [41/50], Step [437/469], Loss: 0.3533, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [41/50], Step [438/469], Loss: 0.2291, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [41/50], Step [439/469], Loss: 0.3650, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [41/50], Step [440/469], Loss: 0.2444, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [41/50], Step [441/469], Loss: 0.2933, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [41/50], Step [442/469], Loss: 0.2824, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [41/50], Step [443/469], Loss: 0.4377, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [41/50], Step [444/469], Loss: 0.3239, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [41/50], Step [445/469], Loss: 0.2801, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [41/50], Step [446/469], Loss: 0.2990, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [41/50], Step [447/469], Loss: 0.3785, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [41/50], Step [448/469], Loss: 0.4772, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [41/50], Step [449/469], Loss: 0.2609, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [41/50], Step [450/469], Loss: 0.3448, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [41/50], Step [451/469], Loss: 0.4289, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [41/50], Step [452/469], Loss: 0.2389, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [41/50], Step [453/469], Loss: 0.4560, batch time: 0.52, accuracy:  84.38%\n",
      "Epoch [41/50], Step [454/469], Loss: 0.5326, batch time: 0.52, accuracy:  85.94%\n",
      "Epoch [41/50], Step [455/469], Loss: 0.2793, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [41/50], Step [456/469], Loss: 0.3835, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [41/50], Step [457/469], Loss: 0.2387, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [41/50], Step [458/469], Loss: 0.3533, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [41/50], Step [459/469], Loss: 0.3027, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [41/50], Step [460/469], Loss: 0.4582, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [41/50], Step [461/469], Loss: 0.2067, batch time: 0.56, accuracy:  94.53%\n",
      "Epoch [41/50], Step [462/469], Loss: 0.3233, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [41/50], Step [463/469], Loss: 0.4020, batch time: 0.71, accuracy:  86.72%\n",
      "Epoch [41/50], Step [464/469], Loss: 0.3057, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [41/50], Step [465/469], Loss: 0.2684, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [41/50], Step [466/469], Loss: 0.4018, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [41/50], Step [467/469], Loss: 0.3578, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [41/50], Step [468/469], Loss: 0.2862, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [41/50], Step [469/469], Loss: 0.3888, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [42/50], Step [1/469], Loss: 0.1843, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [42/50], Step [2/469], Loss: 0.3042, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [42/50], Step [3/469], Loss: 0.2889, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [42/50], Step [4/469], Loss: 0.1987, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [42/50], Step [5/469], Loss: 0.3494, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [42/50], Step [6/469], Loss: 0.2596, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [42/50], Step [7/469], Loss: 0.2474, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [42/50], Step [8/469], Loss: 0.2917, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [9/469], Loss: 0.2293, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [42/50], Step [10/469], Loss: 0.3338, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [11/469], Loss: 0.3014, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [12/469], Loss: 0.2381, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [13/469], Loss: 0.2608, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [14/469], Loss: 0.3117, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [42/50], Step [15/469], Loss: 0.2354, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [42/50], Step [16/469], Loss: 0.1816, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [42/50], Step [17/469], Loss: 0.3618, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [42/50], Step [18/469], Loss: 0.3868, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [42/50], Step [19/469], Loss: 0.3577, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [42/50], Step [20/469], Loss: 0.3095, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [21/469], Loss: 0.4066, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [42/50], Step [22/469], Loss: 0.3140, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [42/50], Step [23/469], Loss: 0.3835, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [42/50], Step [24/469], Loss: 0.2006, batch time: 0.59, accuracy:  94.53%\n",
      "Epoch [42/50], Step [25/469], Loss: 0.3771, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [42/50], Step [26/469], Loss: 0.2438, batch time: 0.79, accuracy:  92.97%\n",
      "Epoch [42/50], Step [27/469], Loss: 0.3748, batch time: 0.56, accuracy:  82.81%\n",
      "Epoch [42/50], Step [28/469], Loss: 0.2861, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [42/50], Step [29/469], Loss: 0.4022, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [42/50], Step [30/469], Loss: 0.2463, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [42/50], Step [31/469], Loss: 0.3419, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [42/50], Step [32/469], Loss: 0.3352, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [42/50], Step [33/469], Loss: 0.3489, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [34/469], Loss: 0.4317, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [42/50], Step [35/469], Loss: 0.2243, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [42/50], Step [36/469], Loss: 0.3251, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [42/50], Step [37/469], Loss: 0.2438, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [42/50], Step [38/469], Loss: 0.3571, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [42/50], Step [39/469], Loss: 0.2026, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [42/50], Step [40/469], Loss: 0.2874, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [42/50], Step [41/469], Loss: 0.2519, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [42/50], Step [42/469], Loss: 0.1578, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [42/50], Step [43/469], Loss: 0.3742, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [42/50], Step [44/469], Loss: 0.3593, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [45/469], Loss: 0.4112, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [42/50], Step [46/469], Loss: 0.3185, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [42/50], Step [47/469], Loss: 0.2066, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [48/469], Loss: 0.2251, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [42/50], Step [49/469], Loss: 0.2128, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [42/50], Step [50/469], Loss: 0.3819, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [42/50], Step [51/469], Loss: 0.2254, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [42/50], Step [52/469], Loss: 0.3008, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [42/50], Step [53/469], Loss: 0.3067, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [54/469], Loss: 0.2475, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [42/50], Step [55/469], Loss: 0.3592, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [42/50], Step [56/469], Loss: 0.3132, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [42/50], Step [57/469], Loss: 0.3250, batch time: 0.80, accuracy:  89.06%\n",
      "Epoch [42/50], Step [58/469], Loss: 0.3636, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [42/50], Step [59/469], Loss: 0.3197, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [42/50], Step [60/469], Loss: 0.3681, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [42/50], Step [61/469], Loss: 0.3560, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [42/50], Step [62/469], Loss: 0.2984, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [42/50], Step [63/469], Loss: 0.3592, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [64/469], Loss: 0.2544, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [65/469], Loss: 0.3214, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [42/50], Step [66/469], Loss: 0.1929, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [42/50], Step [67/469], Loss: 0.1496, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [42/50], Step [68/469], Loss: 0.2647, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [42/50], Step [69/469], Loss: 0.2820, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [42/50], Step [70/469], Loss: 0.2041, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [42/50], Step [71/469], Loss: 0.3352, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [42/50], Step [72/469], Loss: 0.2752, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [42/50], Step [73/469], Loss: 0.2356, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [42/50], Step [74/469], Loss: 0.2994, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [42/50], Step [75/469], Loss: 0.3876, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [42/50], Step [76/469], Loss: 0.2970, batch time: 0.65, accuracy:  93.75%\n",
      "Epoch [42/50], Step [77/469], Loss: 0.2613, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [42/50], Step [78/469], Loss: 0.2805, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [42/50], Step [79/469], Loss: 0.4971, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [42/50], Step [80/469], Loss: 0.4210, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [42/50], Step [81/469], Loss: 0.2607, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [42/50], Step [82/469], Loss: 0.3930, batch time: 0.53, accuracy:  85.94%\n",
      "Epoch [42/50], Step [83/469], Loss: 0.2263, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [42/50], Step [84/469], Loss: 0.2518, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [42/50], Step [85/469], Loss: 0.4491, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [42/50], Step [86/469], Loss: 0.3564, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [42/50], Step [87/469], Loss: 0.3399, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [42/50], Step [88/469], Loss: 0.2283, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [42/50], Step [89/469], Loss: 0.4072, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [42/50], Step [90/469], Loss: 0.2717, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [42/50], Step [91/469], Loss: 0.3634, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [42/50], Step [92/469], Loss: 0.4103, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [42/50], Step [93/469], Loss: 0.2191, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [42/50], Step [94/469], Loss: 0.3156, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [42/50], Step [95/469], Loss: 0.2477, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [96/469], Loss: 0.3994, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [42/50], Step [97/469], Loss: 0.4197, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [42/50], Step [98/469], Loss: 0.3477, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [42/50], Step [99/469], Loss: 0.3689, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [42/50], Step [100/469], Loss: 0.2888, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [42/50], Step [101/469], Loss: 0.2206, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [42/50], Step [102/469], Loss: 0.3549, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [42/50], Step [103/469], Loss: 0.4059, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [42/50], Step [104/469], Loss: 0.4313, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [42/50], Step [105/469], Loss: 0.3752, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [42/50], Step [106/469], Loss: 0.3072, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [42/50], Step [107/469], Loss: 0.3844, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [42/50], Step [108/469], Loss: 0.2697, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [42/50], Step [109/469], Loss: 0.3160, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [42/50], Step [110/469], Loss: 0.3297, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [42/50], Step [111/469], Loss: 0.2144, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [112/469], Loss: 0.2070, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [42/50], Step [113/469], Loss: 0.3949, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [42/50], Step [114/469], Loss: 0.2648, batch time: 0.69, accuracy:  91.41%\n",
      "Epoch [42/50], Step [115/469], Loss: 0.3090, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [42/50], Step [116/469], Loss: 0.4589, batch time: 0.65, accuracy:  89.84%\n",
      "Epoch [42/50], Step [117/469], Loss: 0.3465, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [42/50], Step [118/469], Loss: 0.2742, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [42/50], Step [119/469], Loss: 0.3436, batch time: 0.80, accuracy:  89.06%\n",
      "Epoch [42/50], Step [120/469], Loss: 0.3884, batch time: 0.76, accuracy:  87.50%\n",
      "Epoch [42/50], Step [121/469], Loss: 0.3484, batch time: 0.67, accuracy:  86.72%\n",
      "Epoch [42/50], Step [122/469], Loss: 0.3326, batch time: 0.77, accuracy:  92.97%\n",
      "Epoch [42/50], Step [123/469], Loss: 0.2359, batch time: 0.78, accuracy:  93.75%\n",
      "Epoch [42/50], Step [124/469], Loss: 0.3435, batch time: 0.84, accuracy:  89.06%\n",
      "Epoch [42/50], Step [125/469], Loss: 0.2370, batch time: 0.81, accuracy:  92.97%\n",
      "Epoch [42/50], Step [126/469], Loss: 0.2351, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [42/50], Step [127/469], Loss: 0.2041, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [42/50], Step [128/469], Loss: 0.2444, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [42/50], Step [129/469], Loss: 0.2644, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [42/50], Step [130/469], Loss: 0.3074, batch time: 0.65, accuracy:  88.28%\n",
      "Epoch [42/50], Step [131/469], Loss: 0.4472, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [42/50], Step [132/469], Loss: 0.2984, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [42/50], Step [133/469], Loss: 0.2812, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [42/50], Step [134/469], Loss: 0.2387, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [42/50], Step [135/469], Loss: 0.2149, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [42/50], Step [136/469], Loss: 0.3611, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [42/50], Step [137/469], Loss: 0.4876, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [42/50], Step [138/469], Loss: 0.2082, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [42/50], Step [139/469], Loss: 0.2934, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [42/50], Step [140/469], Loss: 0.2077, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [42/50], Step [141/469], Loss: 0.2513, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [42/50], Step [142/469], Loss: 0.3167, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [42/50], Step [143/469], Loss: 0.4539, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [42/50], Step [144/469], Loss: 0.3282, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [145/469], Loss: 0.4028, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [42/50], Step [146/469], Loss: 0.2909, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [42/50], Step [147/469], Loss: 0.4087, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [42/50], Step [148/469], Loss: 0.3034, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [42/50], Step [149/469], Loss: 0.2347, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [42/50], Step [150/469], Loss: 0.2046, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [42/50], Step [151/469], Loss: 0.2970, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [42/50], Step [152/469], Loss: 0.3256, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [42/50], Step [153/469], Loss: 0.2433, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [42/50], Step [154/469], Loss: 0.3716, batch time: 0.75, accuracy:  87.50%\n",
      "Epoch [42/50], Step [155/469], Loss: 0.3800, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [42/50], Step [156/469], Loss: 0.4115, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [42/50], Step [157/469], Loss: 0.4057, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [42/50], Step [158/469], Loss: 0.4792, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [42/50], Step [159/469], Loss: 0.3528, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [42/50], Step [160/469], Loss: 0.4383, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [42/50], Step [161/469], Loss: 0.3282, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [42/50], Step [162/469], Loss: 0.2376, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [163/469], Loss: 0.3101, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [42/50], Step [164/469], Loss: 0.2727, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [42/50], Step [165/469], Loss: 0.3369, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [42/50], Step [166/469], Loss: 0.4327, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [42/50], Step [167/469], Loss: 0.2231, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [42/50], Step [168/469], Loss: 0.2681, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [42/50], Step [169/469], Loss: 0.3132, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [42/50], Step [170/469], Loss: 0.2540, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [42/50], Step [171/469], Loss: 0.2814, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [42/50], Step [172/469], Loss: 0.3243, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [42/50], Step [173/469], Loss: 0.3548, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [42/50], Step [174/469], Loss: 0.4246, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [42/50], Step [175/469], Loss: 0.2844, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [176/469], Loss: 0.3265, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [42/50], Step [177/469], Loss: 0.4001, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [42/50], Step [178/469], Loss: 0.2899, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [42/50], Step [179/469], Loss: 0.3105, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [42/50], Step [180/469], Loss: 0.3461, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [42/50], Step [181/469], Loss: 0.3561, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [42/50], Step [182/469], Loss: 0.3162, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [42/50], Step [183/469], Loss: 0.2952, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [42/50], Step [184/469], Loss: 0.3067, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [42/50], Step [185/469], Loss: 0.3278, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [42/50], Step [186/469], Loss: 0.2497, batch time: 0.72, accuracy:  91.41%\n",
      "Epoch [42/50], Step [187/469], Loss: 0.3033, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [42/50], Step [188/469], Loss: 0.3992, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [42/50], Step [189/469], Loss: 0.3023, batch time: 0.64, accuracy:  94.53%\n",
      "Epoch [42/50], Step [190/469], Loss: 0.4558, batch time: 0.63, accuracy:  87.50%\n",
      "Epoch [42/50], Step [191/469], Loss: 0.4390, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [42/50], Step [192/469], Loss: 0.2401, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [42/50], Step [193/469], Loss: 0.3183, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [194/469], Loss: 0.4207, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [42/50], Step [195/469], Loss: 0.2035, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [42/50], Step [196/469], Loss: 0.2660, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [42/50], Step [197/469], Loss: 0.2646, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [42/50], Step [198/469], Loss: 0.2768, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [199/469], Loss: 0.3886, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [42/50], Step [200/469], Loss: 0.3727, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [42/50], Step [201/469], Loss: 0.3088, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [42/50], Step [202/469], Loss: 0.2161, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [203/469], Loss: 0.2384, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [42/50], Step [204/469], Loss: 0.3256, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [205/469], Loss: 0.3237, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [42/50], Step [206/469], Loss: 0.3368, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [42/50], Step [207/469], Loss: 0.4242, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [42/50], Step [208/469], Loss: 0.3708, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [209/469], Loss: 0.2732, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [42/50], Step [210/469], Loss: 0.1998, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [42/50], Step [211/469], Loss: 0.2880, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [212/469], Loss: 0.2025, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [213/469], Loss: 0.4719, batch time: 0.46, accuracy:  84.38%\n",
      "Epoch [42/50], Step [214/469], Loss: 0.1896, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [42/50], Step [215/469], Loss: 0.2653, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [42/50], Step [216/469], Loss: 0.4349, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [42/50], Step [217/469], Loss: 0.2689, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [42/50], Step [218/469], Loss: 0.4469, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [42/50], Step [219/469], Loss: 0.3993, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [42/50], Step [220/469], Loss: 0.3706, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [42/50], Step [221/469], Loss: 0.2376, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [42/50], Step [222/469], Loss: 0.2123, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [42/50], Step [223/469], Loss: 0.3788, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [42/50], Step [224/469], Loss: 0.1661, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [42/50], Step [225/469], Loss: 0.2430, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [42/50], Step [226/469], Loss: 0.3320, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [42/50], Step [227/469], Loss: 0.3314, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [42/50], Step [228/469], Loss: 0.1824, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [42/50], Step [229/469], Loss: 0.3169, batch time: 0.65, accuracy:  90.62%\n",
      "Epoch [42/50], Step [230/469], Loss: 0.2323, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [42/50], Step [231/469], Loss: 0.3234, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [42/50], Step [232/469], Loss: 0.4013, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [42/50], Step [233/469], Loss: 0.2155, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [42/50], Step [234/469], Loss: 0.3707, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [42/50], Step [235/469], Loss: 0.2656, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [42/50], Step [236/469], Loss: 0.2482, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [42/50], Step [237/469], Loss: 0.2747, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [238/469], Loss: 0.1620, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [42/50], Step [239/469], Loss: 0.2125, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [240/469], Loss: 0.2392, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [42/50], Step [241/469], Loss: 0.2813, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [42/50], Step [242/469], Loss: 0.2592, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [42/50], Step [243/469], Loss: 0.3745, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [42/50], Step [244/469], Loss: 0.2994, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [245/469], Loss: 0.3480, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [42/50], Step [246/469], Loss: 0.4722, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [42/50], Step [247/469], Loss: 0.2763, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [42/50], Step [248/469], Loss: 0.6121, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [42/50], Step [249/469], Loss: 0.3360, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [42/50], Step [250/469], Loss: 0.2165, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [42/50], Step [251/469], Loss: 0.3782, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [252/469], Loss: 0.1882, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [253/469], Loss: 0.1415, batch time: 0.49, accuracy:  96.09%\n",
      "Epoch [42/50], Step [254/469], Loss: 0.3766, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [42/50], Step [255/469], Loss: 0.1869, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [42/50], Step [256/469], Loss: 0.3320, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [42/50], Step [257/469], Loss: 0.4570, batch time: 0.51, accuracy:  83.59%\n",
      "Epoch [42/50], Step [258/469], Loss: 0.2452, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [42/50], Step [259/469], Loss: 0.3111, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [42/50], Step [260/469], Loss: 0.2785, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [42/50], Step [261/469], Loss: 0.2443, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [42/50], Step [262/469], Loss: 0.2168, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [42/50], Step [263/469], Loss: 0.2546, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [42/50], Step [264/469], Loss: 0.2288, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [42/50], Step [265/469], Loss: 0.3102, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [42/50], Step [266/469], Loss: 0.2506, batch time: 0.63, accuracy:  94.53%\n",
      "Epoch [42/50], Step [267/469], Loss: 0.2589, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [268/469], Loss: 0.3826, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [42/50], Step [269/469], Loss: 0.4712, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [42/50], Step [270/469], Loss: 0.2521, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [42/50], Step [271/469], Loss: 0.3161, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [42/50], Step [272/469], Loss: 0.1961, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [42/50], Step [273/469], Loss: 0.2339, batch time: 0.50, accuracy:  96.09%\n",
      "Epoch [42/50], Step [274/469], Loss: 0.4037, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [42/50], Step [275/469], Loss: 0.4008, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [42/50], Step [276/469], Loss: 0.2560, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [42/50], Step [277/469], Loss: 0.3710, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [42/50], Step [278/469], Loss: 0.3642, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [42/50], Step [279/469], Loss: 0.3129, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [42/50], Step [280/469], Loss: 0.2861, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [42/50], Step [281/469], Loss: 0.3156, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [42/50], Step [282/469], Loss: 0.3220, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [283/469], Loss: 0.1472, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [42/50], Step [284/469], Loss: 0.3727, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [42/50], Step [285/469], Loss: 0.2796, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [42/50], Step [286/469], Loss: 0.2650, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [42/50], Step [287/469], Loss: 0.2319, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [42/50], Step [288/469], Loss: 0.3177, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [42/50], Step [289/469], Loss: 0.2934, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [42/50], Step [290/469], Loss: 0.2665, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [42/50], Step [291/469], Loss: 0.2794, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [42/50], Step [292/469], Loss: 0.2445, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [42/50], Step [293/469], Loss: 0.3303, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [294/469], Loss: 0.2591, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [42/50], Step [295/469], Loss: 0.3531, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [296/469], Loss: 0.2660, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [42/50], Step [297/469], Loss: 0.3525, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [42/50], Step [298/469], Loss: 0.3206, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [42/50], Step [299/469], Loss: 0.5250, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [42/50], Step [300/469], Loss: 0.3277, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [42/50], Step [301/469], Loss: 0.2362, batch time: 0.68, accuracy:  89.06%\n",
      "Epoch [42/50], Step [302/469], Loss: 0.2575, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [42/50], Step [303/469], Loss: 0.5161, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [42/50], Step [304/469], Loss: 0.2955, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [42/50], Step [305/469], Loss: 0.2437, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [42/50], Step [306/469], Loss: 0.1871, batch time: 0.69, accuracy:  95.31%\n",
      "Epoch [42/50], Step [307/469], Loss: 0.2052, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [42/50], Step [308/469], Loss: 0.2951, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [42/50], Step [309/469], Loss: 0.3982, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [42/50], Step [310/469], Loss: 0.2477, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [42/50], Step [311/469], Loss: 0.1690, batch time: 0.48, accuracy:  96.88%\n",
      "Epoch [42/50], Step [312/469], Loss: 0.2472, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [42/50], Step [313/469], Loss: 0.2491, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [42/50], Step [314/469], Loss: 0.3052, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [42/50], Step [315/469], Loss: 0.4058, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [42/50], Step [316/469], Loss: 0.4582, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [42/50], Step [317/469], Loss: 0.2940, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [318/469], Loss: 0.3011, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [319/469], Loss: 0.3542, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [42/50], Step [320/469], Loss: 0.2397, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [42/50], Step [321/469], Loss: 0.3332, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [42/50], Step [322/469], Loss: 0.2559, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [42/50], Step [323/469], Loss: 0.2599, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [324/469], Loss: 0.4852, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [42/50], Step [325/469], Loss: 0.3457, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [42/50], Step [326/469], Loss: 0.6645, batch time: 0.53, accuracy:  84.38%\n",
      "Epoch [42/50], Step [327/469], Loss: 0.2810, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [42/50], Step [328/469], Loss: 0.2402, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [42/50], Step [329/469], Loss: 0.2678, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [42/50], Step [330/469], Loss: 0.3066, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [42/50], Step [331/469], Loss: 0.4424, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [42/50], Step [332/469], Loss: 0.2757, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [42/50], Step [333/469], Loss: 0.3246, batch time: 0.79, accuracy:  89.84%\n",
      "Epoch [42/50], Step [334/469], Loss: 0.5018, batch time: 0.70, accuracy:  85.94%\n",
      "Epoch [42/50], Step [335/469], Loss: 0.4069, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [42/50], Step [336/469], Loss: 0.2435, batch time: 0.73, accuracy:  92.19%\n",
      "Epoch [42/50], Step [337/469], Loss: 0.3252, batch time: 0.78, accuracy:  89.84%\n",
      "Epoch [42/50], Step [338/469], Loss: 0.3631, batch time: 0.78, accuracy:  88.28%\n",
      "Epoch [42/50], Step [339/469], Loss: 0.2594, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [42/50], Step [340/469], Loss: 0.4298, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [42/50], Step [341/469], Loss: 0.2968, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [42/50], Step [342/469], Loss: 0.3460, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [42/50], Step [343/469], Loss: 0.3127, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [42/50], Step [344/469], Loss: 0.2570, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [42/50], Step [345/469], Loss: 0.1657, batch time: 0.56, accuracy:  95.31%\n",
      "Epoch [42/50], Step [346/469], Loss: 0.4005, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [42/50], Step [347/469], Loss: 0.2156, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [42/50], Step [348/469], Loss: 0.4530, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [42/50], Step [349/469], Loss: 0.2932, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [42/50], Step [350/469], Loss: 0.3758, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [42/50], Step [351/469], Loss: 0.2108, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [42/50], Step [352/469], Loss: 0.3680, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [42/50], Step [353/469], Loss: 0.3264, batch time: 0.65, accuracy:  88.28%\n",
      "Epoch [42/50], Step [354/469], Loss: 0.3934, batch time: 0.68, accuracy:  88.28%\n",
      "Epoch [42/50], Step [355/469], Loss: 0.4071, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [42/50], Step [356/469], Loss: 0.3517, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [42/50], Step [357/469], Loss: 0.2487, batch time: 0.64, accuracy:  92.97%\n",
      "Epoch [42/50], Step [358/469], Loss: 0.3087, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [42/50], Step [359/469], Loss: 0.3758, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [42/50], Step [360/469], Loss: 0.2533, batch time: 0.78, accuracy:  91.41%\n",
      "Epoch [42/50], Step [361/469], Loss: 0.2835, batch time: 0.96, accuracy:  91.41%\n",
      "Epoch [42/50], Step [362/469], Loss: 0.4466, batch time: 0.67, accuracy:  85.16%\n",
      "Epoch [42/50], Step [363/469], Loss: 0.4076, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [42/50], Step [364/469], Loss: 0.3814, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [42/50], Step [365/469], Loss: 0.3551, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [42/50], Step [366/469], Loss: 0.3344, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [42/50], Step [367/469], Loss: 0.2195, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [42/50], Step [368/469], Loss: 0.2788, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [42/50], Step [369/469], Loss: 0.2946, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [42/50], Step [370/469], Loss: 0.2916, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [371/469], Loss: 0.2804, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [42/50], Step [372/469], Loss: 0.2450, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [42/50], Step [373/469], Loss: 0.3298, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [374/469], Loss: 0.2795, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [375/469], Loss: 0.3108, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [376/469], Loss: 0.2919, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [42/50], Step [377/469], Loss: 0.3621, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [42/50], Step [378/469], Loss: 0.2210, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [379/469], Loss: 0.3033, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [42/50], Step [380/469], Loss: 0.2666, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [42/50], Step [381/469], Loss: 0.4934, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [42/50], Step [382/469], Loss: 0.3080, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [42/50], Step [383/469], Loss: 0.3254, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [42/50], Step [384/469], Loss: 0.2587, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [42/50], Step [385/469], Loss: 0.3606, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [42/50], Step [386/469], Loss: 0.2365, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [42/50], Step [387/469], Loss: 0.3081, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [42/50], Step [388/469], Loss: 0.2808, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [42/50], Step [389/469], Loss: 0.3325, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [42/50], Step [390/469], Loss: 0.2659, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [42/50], Step [391/469], Loss: 0.2627, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [42/50], Step [392/469], Loss: 0.4218, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [42/50], Step [393/469], Loss: 0.4879, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [42/50], Step [394/469], Loss: 0.3150, batch time: 0.95, accuracy:  92.19%\n",
      "Epoch [42/50], Step [395/469], Loss: 0.4199, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [42/50], Step [396/469], Loss: 0.3394, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [42/50], Step [397/469], Loss: 0.3556, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [42/50], Step [398/469], Loss: 0.5063, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [42/50], Step [399/469], Loss: 0.2767, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [42/50], Step [400/469], Loss: 0.5027, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [42/50], Step [401/469], Loss: 0.3050, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [42/50], Step [402/469], Loss: 0.3146, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [403/469], Loss: 0.3383, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [42/50], Step [404/469], Loss: 0.3060, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [42/50], Step [405/469], Loss: 0.2245, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [42/50], Step [406/469], Loss: 0.2360, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [42/50], Step [407/469], Loss: 0.2568, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [42/50], Step [408/469], Loss: 0.4300, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [42/50], Step [409/469], Loss: 0.4050, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [410/469], Loss: 0.3948, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [42/50], Step [411/469], Loss: 0.3105, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [42/50], Step [412/469], Loss: 0.2632, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [42/50], Step [413/469], Loss: 0.2560, batch time: 0.56, accuracy:  94.53%\n",
      "Epoch [42/50], Step [414/469], Loss: 0.4382, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [42/50], Step [415/469], Loss: 0.4087, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [42/50], Step [416/469], Loss: 0.3868, batch time: 0.65, accuracy:  89.06%\n",
      "Epoch [42/50], Step [417/469], Loss: 0.2901, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [42/50], Step [418/469], Loss: 0.3715, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [42/50], Step [419/469], Loss: 0.3028, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [42/50], Step [420/469], Loss: 0.3476, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [42/50], Step [421/469], Loss: 0.2586, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [42/50], Step [422/469], Loss: 0.2768, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [42/50], Step [423/469], Loss: 0.2905, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [42/50], Step [424/469], Loss: 0.3219, batch time: 0.62, accuracy:  87.50%\n",
      "Epoch [42/50], Step [425/469], Loss: 0.3032, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [42/50], Step [426/469], Loss: 0.2847, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [42/50], Step [427/469], Loss: 0.3663, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [42/50], Step [428/469], Loss: 0.2588, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [42/50], Step [429/469], Loss: 0.3922, batch time: 0.61, accuracy:  85.16%\n",
      "Epoch [42/50], Step [430/469], Loss: 0.2799, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [42/50], Step [431/469], Loss: 0.2948, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [42/50], Step [432/469], Loss: 0.3870, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [433/469], Loss: 0.3716, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [42/50], Step [434/469], Loss: 0.3301, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [42/50], Step [435/469], Loss: 0.3063, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [42/50], Step [436/469], Loss: 0.3039, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [42/50], Step [437/469], Loss: 0.4979, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [42/50], Step [438/469], Loss: 0.4080, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [42/50], Step [439/469], Loss: 0.2782, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [42/50], Step [440/469], Loss: 0.5751, batch time: 0.44, accuracy:  79.69%\n",
      "Epoch [42/50], Step [441/469], Loss: 0.4303, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [42/50], Step [442/469], Loss: 0.2882, batch time: 0.58, accuracy:  92.97%\n",
      "Epoch [42/50], Step [443/469], Loss: 0.3082, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [42/50], Step [444/469], Loss: 0.1663, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [42/50], Step [445/469], Loss: 0.4853, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [42/50], Step [446/469], Loss: 0.3020, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [447/469], Loss: 0.3682, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [42/50], Step [448/469], Loss: 0.2716, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [42/50], Step [449/469], Loss: 0.2528, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [42/50], Step [450/469], Loss: 0.2821, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [42/50], Step [451/469], Loss: 0.2740, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [42/50], Step [452/469], Loss: 0.3203, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [453/469], Loss: 0.2591, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [42/50], Step [454/469], Loss: 0.5475, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [42/50], Step [455/469], Loss: 0.4032, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [42/50], Step [456/469], Loss: 0.2526, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [42/50], Step [457/469], Loss: 0.5045, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [42/50], Step [458/469], Loss: 0.3046, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [42/50], Step [459/469], Loss: 0.1392, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [42/50], Step [460/469], Loss: 0.4246, batch time: 1.10, accuracy:  85.16%\n",
      "Epoch [42/50], Step [461/469], Loss: 0.4815, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [42/50], Step [462/469], Loss: 0.1850, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [42/50], Step [463/469], Loss: 0.3368, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [42/50], Step [464/469], Loss: 0.3291, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [42/50], Step [465/469], Loss: 0.3480, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [42/50], Step [466/469], Loss: 0.3487, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [42/50], Step [467/469], Loss: 0.1661, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [42/50], Step [468/469], Loss: 0.4210, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [42/50], Step [469/469], Loss: 0.3240, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [1/469], Loss: 0.4987, batch time: 0.45, accuracy:  82.81%\n",
      "Epoch [43/50], Step [2/469], Loss: 0.1895, batch time: 0.51, accuracy:  96.88%\n",
      "Epoch [43/50], Step [3/469], Loss: 0.4602, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [43/50], Step [4/469], Loss: 0.1788, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [43/50], Step [5/469], Loss: 0.2544, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [6/469], Loss: 0.3794, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [43/50], Step [7/469], Loss: 0.2720, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [43/50], Step [8/469], Loss: 0.2508, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [43/50], Step [9/469], Loss: 0.3426, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [43/50], Step [10/469], Loss: 0.4286, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [43/50], Step [11/469], Loss: 0.3909, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [43/50], Step [12/469], Loss: 0.3351, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [43/50], Step [13/469], Loss: 0.1733, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [43/50], Step [14/469], Loss: 0.1921, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [43/50], Step [15/469], Loss: 0.4102, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [43/50], Step [16/469], Loss: 0.3318, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [43/50], Step [17/469], Loss: 0.2801, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [43/50], Step [18/469], Loss: 0.4204, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [43/50], Step [19/469], Loss: 0.1875, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [43/50], Step [20/469], Loss: 0.2502, batch time: 0.77, accuracy:  92.97%\n",
      "Epoch [43/50], Step [21/469], Loss: 0.3884, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [22/469], Loss: 0.3379, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [43/50], Step [23/469], Loss: 0.4061, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [43/50], Step [24/469], Loss: 0.3234, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [25/469], Loss: 0.3033, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [26/469], Loss: 0.2662, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [43/50], Step [27/469], Loss: 0.3095, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [43/50], Step [28/469], Loss: 0.2809, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [43/50], Step [29/469], Loss: 0.3489, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [43/50], Step [30/469], Loss: 0.1892, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [43/50], Step [31/469], Loss: 0.2308, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [43/50], Step [32/469], Loss: 0.2541, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [33/469], Loss: 0.5143, batch time: 0.54, accuracy:  82.81%\n",
      "Epoch [43/50], Step [34/469], Loss: 0.3388, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [43/50], Step [35/469], Loss: 0.2911, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [43/50], Step [36/469], Loss: 0.4168, batch time: 0.55, accuracy:  86.72%\n",
      "Epoch [43/50], Step [37/469], Loss: 0.2352, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [43/50], Step [38/469], Loss: 0.2343, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [43/50], Step [39/469], Loss: 0.1794, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [43/50], Step [40/469], Loss: 0.3733, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [43/50], Step [41/469], Loss: 0.3273, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [43/50], Step [42/469], Loss: 0.2664, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [43/469], Loss: 0.3905, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [43/50], Step [44/469], Loss: 0.3013, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [43/50], Step [45/469], Loss: 0.4092, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [43/50], Step [46/469], Loss: 0.3065, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [47/469], Loss: 0.3281, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [43/50], Step [48/469], Loss: 0.2438, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [49/469], Loss: 0.3185, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [50/469], Loss: 0.3158, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [51/469], Loss: 0.2723, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [43/50], Step [52/469], Loss: 0.1880, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [43/50], Step [53/469], Loss: 0.3518, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [43/50], Step [54/469], Loss: 0.3238, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [43/50], Step [55/469], Loss: 0.3954, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [43/50], Step [56/469], Loss: 0.2948, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [43/50], Step [57/469], Loss: 0.3346, batch time: 0.60, accuracy:  85.94%\n",
      "Epoch [43/50], Step [58/469], Loss: 0.3751, batch time: 0.73, accuracy:  90.62%\n",
      "Epoch [43/50], Step [59/469], Loss: 0.2622, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [43/50], Step [60/469], Loss: 0.2461, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [43/50], Step [61/469], Loss: 0.2557, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [43/50], Step [62/469], Loss: 0.2488, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [43/50], Step [63/469], Loss: 0.3980, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [43/50], Step [64/469], Loss: 0.2485, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [43/50], Step [65/469], Loss: 0.3028, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [66/469], Loss: 0.2104, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [67/469], Loss: 0.3932, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [43/50], Step [68/469], Loss: 0.2466, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [43/50], Step [69/469], Loss: 0.2895, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [43/50], Step [70/469], Loss: 0.4621, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [43/50], Step [71/469], Loss: 0.2068, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [72/469], Loss: 0.4743, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [43/50], Step [73/469], Loss: 0.3785, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [74/469], Loss: 0.3859, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [43/50], Step [75/469], Loss: 0.2081, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [43/50], Step [76/469], Loss: 0.2477, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [77/469], Loss: 0.4145, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [43/50], Step [78/469], Loss: 0.2488, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [43/50], Step [79/469], Loss: 0.2584, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [43/50], Step [80/469], Loss: 0.1580, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [43/50], Step [81/469], Loss: 0.3172, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [82/469], Loss: 0.2479, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [43/50], Step [83/469], Loss: 0.3555, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [43/50], Step [84/469], Loss: 0.4603, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [43/50], Step [85/469], Loss: 0.3266, batch time: 1.01, accuracy:  93.75%\n",
      "Epoch [43/50], Step [86/469], Loss: 0.2799, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [43/50], Step [87/469], Loss: 0.2454, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [43/50], Step [88/469], Loss: 0.3330, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [43/50], Step [89/469], Loss: 0.3540, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [90/469], Loss: 0.2075, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [43/50], Step [91/469], Loss: 0.2828, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [43/50], Step [92/469], Loss: 0.1936, batch time: 0.56, accuracy:  94.53%\n",
      "Epoch [43/50], Step [93/469], Loss: 0.3276, batch time: 0.66, accuracy:  89.06%\n",
      "Epoch [43/50], Step [94/469], Loss: 0.1825, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [43/50], Step [95/469], Loss: 0.3826, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [43/50], Step [96/469], Loss: 0.2819, batch time: 0.63, accuracy:  89.84%\n",
      "Epoch [43/50], Step [97/469], Loss: 0.2732, batch time: 0.65, accuracy:  92.19%\n",
      "Epoch [43/50], Step [98/469], Loss: 0.3171, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [43/50], Step [99/469], Loss: 0.2923, batch time: 0.68, accuracy:  89.84%\n",
      "Epoch [43/50], Step [100/469], Loss: 0.3160, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [43/50], Step [101/469], Loss: 0.1997, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [43/50], Step [102/469], Loss: 0.3552, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [43/50], Step [103/469], Loss: 0.2961, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [43/50], Step [104/469], Loss: 0.2806, batch time: 0.62, accuracy:  91.41%\n",
      "Epoch [43/50], Step [105/469], Loss: 0.2327, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [43/50], Step [106/469], Loss: 0.2104, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [43/50], Step [107/469], Loss: 0.3078, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [43/50], Step [108/469], Loss: 0.3947, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [43/50], Step [109/469], Loss: 0.1999, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [43/50], Step [110/469], Loss: 0.4182, batch time: 0.75, accuracy:  89.84%\n",
      "Epoch [43/50], Step [111/469], Loss: 0.2792, batch time: 0.81, accuracy:  91.41%\n",
      "Epoch [43/50], Step [112/469], Loss: 0.3197, batch time: 0.76, accuracy:  90.62%\n",
      "Epoch [43/50], Step [113/469], Loss: 0.3126, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [43/50], Step [114/469], Loss: 0.2652, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [43/50], Step [115/469], Loss: 0.2938, batch time: 0.81, accuracy:  90.62%\n",
      "Epoch [43/50], Step [116/469], Loss: 0.2734, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [43/50], Step [117/469], Loss: 0.2095, batch time: 0.69, accuracy:  94.53%\n",
      "Epoch [43/50], Step [118/469], Loss: 0.4189, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [43/50], Step [119/469], Loss: 0.2427, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [43/50], Step [120/469], Loss: 0.4971, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [43/50], Step [121/469], Loss: 0.1930, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [43/50], Step [122/469], Loss: 0.2880, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [43/50], Step [123/469], Loss: 0.2926, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [124/469], Loss: 0.3086, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [43/50], Step [125/469], Loss: 0.2294, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [43/50], Step [126/469], Loss: 0.2531, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [43/50], Step [127/469], Loss: 0.3280, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [43/50], Step [128/469], Loss: 0.4101, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [129/469], Loss: 0.2569, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [43/50], Step [130/469], Loss: 0.2037, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [131/469], Loss: 0.3915, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [43/50], Step [132/469], Loss: 0.2786, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [133/469], Loss: 0.4158, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [43/50], Step [134/469], Loss: 0.2314, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [135/469], Loss: 0.3969, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [136/469], Loss: 0.2708, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [137/469], Loss: 0.3163, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [43/50], Step [138/469], Loss: 0.2520, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [43/50], Step [139/469], Loss: 0.3961, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [43/50], Step [140/469], Loss: 0.2931, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [141/469], Loss: 0.2934, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [142/469], Loss: 0.3363, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [43/50], Step [143/469], Loss: 0.3680, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [43/50], Step [144/469], Loss: 0.3980, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [43/50], Step [145/469], Loss: 0.2832, batch time: 0.81, accuracy:  92.19%\n",
      "Epoch [43/50], Step [146/469], Loss: 0.2865, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [147/469], Loss: 0.3672, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [148/469], Loss: 0.3054, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [149/469], Loss: 0.2284, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [150/469], Loss: 0.3143, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [43/50], Step [151/469], Loss: 0.2825, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [152/469], Loss: 0.2713, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [153/469], Loss: 0.2697, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [43/50], Step [154/469], Loss: 0.3537, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [43/50], Step [155/469], Loss: 0.3729, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [43/50], Step [156/469], Loss: 0.5344, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [157/469], Loss: 0.2674, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [158/469], Loss: 0.2921, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [43/50], Step [159/469], Loss: 0.2011, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [160/469], Loss: 0.4061, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [43/50], Step [161/469], Loss: 0.2802, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [43/50], Step [162/469], Loss: 0.1832, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [43/50], Step [163/469], Loss: 0.2541, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [43/50], Step [164/469], Loss: 0.2813, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [43/50], Step [165/469], Loss: 0.3132, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [166/469], Loss: 0.2200, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [167/469], Loss: 0.3240, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [168/469], Loss: 0.5435, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [43/50], Step [169/469], Loss: 0.2511, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [43/50], Step [170/469], Loss: 0.3141, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [43/50], Step [171/469], Loss: 0.2494, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [172/469], Loss: 0.2680, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [43/50], Step [173/469], Loss: 0.2795, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [43/50], Step [174/469], Loss: 0.3496, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [43/50], Step [175/469], Loss: 0.3180, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [43/50], Step [176/469], Loss: 0.2721, batch time: 0.68, accuracy:  92.19%\n",
      "Epoch [43/50], Step [177/469], Loss: 0.2096, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [43/50], Step [178/469], Loss: 0.3869, batch time: 0.70, accuracy:  95.31%\n",
      "Epoch [43/50], Step [179/469], Loss: 0.2383, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [180/469], Loss: 0.2702, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [43/50], Step [181/469], Loss: 0.2752, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [182/469], Loss: 0.6220, batch time: 0.46, accuracy:  82.81%\n",
      "Epoch [43/50], Step [183/469], Loss: 0.4928, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [43/50], Step [184/469], Loss: 0.3694, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [43/50], Step [185/469], Loss: 0.1734, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [43/50], Step [186/469], Loss: 0.1797, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [43/50], Step [187/469], Loss: 0.2766, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [43/50], Step [188/469], Loss: 0.2912, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [43/50], Step [189/469], Loss: 0.3547, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [43/50], Step [190/469], Loss: 0.4345, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [43/50], Step [191/469], Loss: 0.2806, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [43/50], Step [192/469], Loss: 0.4057, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [193/469], Loss: 0.2637, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [194/469], Loss: 0.2606, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [43/50], Step [195/469], Loss: 0.2660, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [196/469], Loss: 0.3002, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [43/50], Step [197/469], Loss: 0.3460, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [43/50], Step [198/469], Loss: 0.2939, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [199/469], Loss: 0.3303, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [200/469], Loss: 0.2521, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [43/50], Step [201/469], Loss: 0.2888, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [43/50], Step [202/469], Loss: 0.3667, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [43/50], Step [203/469], Loss: 0.1795, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [43/50], Step [204/469], Loss: 0.3115, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [43/50], Step [205/469], Loss: 0.2619, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [43/50], Step [206/469], Loss: 0.2299, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [43/50], Step [207/469], Loss: 0.3539, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [43/50], Step [208/469], Loss: 0.3083, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [43/50], Step [209/469], Loss: 0.2946, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [43/50], Step [210/469], Loss: 0.1770, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [43/50], Step [211/469], Loss: 0.3141, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [43/50], Step [212/469], Loss: 0.2298, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [43/50], Step [213/469], Loss: 0.2384, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [43/50], Step [214/469], Loss: 0.2371, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [43/50], Step [215/469], Loss: 0.3474, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [43/50], Step [216/469], Loss: 0.2305, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [217/469], Loss: 0.2391, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [218/469], Loss: 0.3480, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [43/50], Step [219/469], Loss: 0.1592, batch time: 0.45, accuracy:  96.88%\n",
      "Epoch [43/50], Step [220/469], Loss: 0.3775, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [43/50], Step [221/469], Loss: 0.2807, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [222/469], Loss: 0.3787, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [43/50], Step [223/469], Loss: 0.2199, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [224/469], Loss: 0.2121, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [43/50], Step [225/469], Loss: 0.2232, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [43/50], Step [226/469], Loss: 0.2196, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [227/469], Loss: 0.3081, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [43/50], Step [228/469], Loss: 0.3254, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [229/469], Loss: 0.3053, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [43/50], Step [230/469], Loss: 0.3032, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [43/50], Step [231/469], Loss: 0.3146, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [43/50], Step [232/469], Loss: 0.3140, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [233/469], Loss: 0.2821, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [43/50], Step [234/469], Loss: 0.2976, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [235/469], Loss: 0.2646, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [236/469], Loss: 0.3124, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [237/469], Loss: 0.3665, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [238/469], Loss: 0.2943, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [239/469], Loss: 0.2482, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [240/469], Loss: 0.3353, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [43/50], Step [241/469], Loss: 0.3258, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [43/50], Step [242/469], Loss: 0.3305, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [43/50], Step [243/469], Loss: 0.3757, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [43/50], Step [244/469], Loss: 0.2320, batch time: 0.86, accuracy:  92.97%\n",
      "Epoch [43/50], Step [245/469], Loss: 0.4103, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [43/50], Step [246/469], Loss: 0.3880, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [43/50], Step [247/469], Loss: 0.2589, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [43/50], Step [248/469], Loss: 0.2579, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [43/50], Step [249/469], Loss: 0.3252, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [43/50], Step [250/469], Loss: 0.2457, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [251/469], Loss: 0.2569, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [43/50], Step [252/469], Loss: 0.2548, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [43/50], Step [253/469], Loss: 0.4858, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [43/50], Step [254/469], Loss: 0.2747, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [255/469], Loss: 0.3044, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [256/469], Loss: 0.3027, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [43/50], Step [257/469], Loss: 0.3869, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [43/50], Step [258/469], Loss: 0.3090, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [259/469], Loss: 0.4205, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [43/50], Step [260/469], Loss: 0.3349, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [261/469], Loss: 0.3408, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [43/50], Step [262/469], Loss: 0.3334, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [263/469], Loss: 0.2125, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [43/50], Step [264/469], Loss: 0.5719, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [43/50], Step [265/469], Loss: 0.3794, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [43/50], Step [266/469], Loss: 0.3375, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [267/469], Loss: 0.3416, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [43/50], Step [268/469], Loss: 0.3309, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [269/469], Loss: 0.2094, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [43/50], Step [270/469], Loss: 0.2581, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [43/50], Step [271/469], Loss: 0.2361, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [272/469], Loss: 0.1951, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [43/50], Step [273/469], Loss: 0.3898, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [43/50], Step [274/469], Loss: 0.4550, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [43/50], Step [275/469], Loss: 0.4566, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [43/50], Step [276/469], Loss: 0.2746, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [43/50], Step [277/469], Loss: 0.4041, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [43/50], Step [278/469], Loss: 0.2018, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [43/50], Step [279/469], Loss: 0.2730, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [43/50], Step [280/469], Loss: 0.2638, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [43/50], Step [281/469], Loss: 0.3914, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [282/469], Loss: 0.2394, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [43/50], Step [283/469], Loss: 0.2761, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [43/50], Step [284/469], Loss: 0.2335, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [43/50], Step [285/469], Loss: 0.2981, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [286/469], Loss: 0.2834, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [43/50], Step [287/469], Loss: 0.3348, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [288/469], Loss: 0.3054, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [289/469], Loss: 0.2601, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [290/469], Loss: 0.3229, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [43/50], Step [291/469], Loss: 0.2875, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [292/469], Loss: 0.2073, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [43/50], Step [293/469], Loss: 0.2935, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [43/50], Step [294/469], Loss: 0.3461, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [295/469], Loss: 0.3244, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [296/469], Loss: 0.1619, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [43/50], Step [297/469], Loss: 0.2270, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [298/469], Loss: 0.2945, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [43/50], Step [299/469], Loss: 0.4214, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [300/469], Loss: 0.5046, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [43/50], Step [301/469], Loss: 0.2983, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [43/50], Step [302/469], Loss: 0.2632, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [303/469], Loss: 0.3657, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [43/50], Step [304/469], Loss: 0.3117, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [43/50], Step [305/469], Loss: 0.4936, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [43/50], Step [306/469], Loss: 0.3253, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [43/50], Step [307/469], Loss: 0.2597, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [43/50], Step [308/469], Loss: 0.2825, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [43/50], Step [309/469], Loss: 0.2399, batch time: 0.72, accuracy:  95.31%\n",
      "Epoch [43/50], Step [310/469], Loss: 0.2582, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [311/469], Loss: 0.3004, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [43/50], Step [312/469], Loss: 0.2760, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [43/50], Step [313/469], Loss: 0.2681, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [43/50], Step [314/469], Loss: 0.3748, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [43/50], Step [315/469], Loss: 0.1788, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [43/50], Step [316/469], Loss: 0.3509, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [317/469], Loss: 0.2051, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [318/469], Loss: 0.3460, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [43/50], Step [319/469], Loss: 0.2284, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [43/50], Step [320/469], Loss: 0.3268, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [43/50], Step [321/469], Loss: 0.3486, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [43/50], Step [322/469], Loss: 0.3304, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [43/50], Step [323/469], Loss: 0.3365, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [43/50], Step [324/469], Loss: 0.3012, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [43/50], Step [325/469], Loss: 0.4216, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [43/50], Step [326/469], Loss: 0.2347, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [43/50], Step [327/469], Loss: 0.2971, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [43/50], Step [328/469], Loss: 0.3736, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [43/50], Step [329/469], Loss: 0.3231, batch time: 0.62, accuracy:  89.06%\n",
      "Epoch [43/50], Step [330/469], Loss: 0.2761, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [43/50], Step [331/469], Loss: 0.2126, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [43/50], Step [332/469], Loss: 0.3799, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [43/50], Step [333/469], Loss: 0.2955, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [43/50], Step [334/469], Loss: 0.3849, batch time: 0.68, accuracy:  88.28%\n",
      "Epoch [43/50], Step [335/469], Loss: 0.3194, batch time: 0.71, accuracy:  89.06%\n",
      "Epoch [43/50], Step [336/469], Loss: 0.3497, batch time: 0.71, accuracy:  90.62%\n",
      "Epoch [43/50], Step [337/469], Loss: 0.3356, batch time: 0.62, accuracy:  91.41%\n",
      "Epoch [43/50], Step [338/469], Loss: 0.4174, batch time: 0.69, accuracy:  89.84%\n",
      "Epoch [43/50], Step [339/469], Loss: 0.3544, batch time: 0.73, accuracy:  91.41%\n",
      "Epoch [43/50], Step [340/469], Loss: 0.3662, batch time: 0.71, accuracy:  89.84%\n",
      "Epoch [43/50], Step [341/469], Loss: 0.4109, batch time: 0.74, accuracy:  89.84%\n",
      "Epoch [43/50], Step [342/469], Loss: 0.2998, batch time: 0.73, accuracy:  90.62%\n",
      "Epoch [43/50], Step [343/469], Loss: 0.2853, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [43/50], Step [344/469], Loss: 0.3030, batch time: 0.69, accuracy:  89.84%\n",
      "Epoch [43/50], Step [345/469], Loss: 0.2469, batch time: 0.69, accuracy:  92.19%\n",
      "Epoch [43/50], Step [346/469], Loss: 0.2397, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [43/50], Step [347/469], Loss: 0.3396, batch time: 0.63, accuracy:  92.19%\n",
      "Epoch [43/50], Step [348/469], Loss: 0.2857, batch time: 0.72, accuracy:  92.97%\n",
      "Epoch [43/50], Step [349/469], Loss: 0.2080, batch time: 0.67, accuracy:  94.53%\n",
      "Epoch [43/50], Step [350/469], Loss: 0.2462, batch time: 0.70, accuracy:  92.19%\n",
      "Epoch [43/50], Step [351/469], Loss: 0.3451, batch time: 0.70, accuracy:  88.28%\n",
      "Epoch [43/50], Step [352/469], Loss: 0.3210, batch time: 0.79, accuracy:  89.84%\n",
      "Epoch [43/50], Step [353/469], Loss: 0.3319, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [43/50], Step [354/469], Loss: 0.2429, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [43/50], Step [355/469], Loss: 0.2976, batch time: 0.79, accuracy:  92.97%\n",
      "Epoch [43/50], Step [356/469], Loss: 0.3687, batch time: 0.85, accuracy:  92.97%\n",
      "Epoch [43/50], Step [357/469], Loss: 0.3599, batch time: 0.78, accuracy:  91.41%\n",
      "Epoch [43/50], Step [358/469], Loss: 0.3993, batch time: 0.68, accuracy:  92.19%\n",
      "Epoch [43/50], Step [359/469], Loss: 0.2918, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [43/50], Step [360/469], Loss: 0.3104, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [43/50], Step [361/469], Loss: 0.3136, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [362/469], Loss: 0.2770, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [43/50], Step [363/469], Loss: 0.3228, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [364/469], Loss: 0.2983, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [365/469], Loss: 0.5312, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [43/50], Step [366/469], Loss: 0.3944, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [43/50], Step [367/469], Loss: 0.2742, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [43/50], Step [368/469], Loss: 0.3095, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [43/50], Step [369/469], Loss: 0.3477, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [43/50], Step [370/469], Loss: 0.2285, batch time: 0.43, accuracy:  95.31%\n",
      "Epoch [43/50], Step [371/469], Loss: 0.2081, batch time: 0.57, accuracy:  95.31%\n",
      "Epoch [43/50], Step [372/469], Loss: 0.3711, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [43/50], Step [373/469], Loss: 0.3115, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [43/50], Step [374/469], Loss: 0.1790, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [43/50], Step [375/469], Loss: 0.4424, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [376/469], Loss: 0.3708, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [43/50], Step [377/469], Loss: 0.3395, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [378/469], Loss: 0.4656, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [43/50], Step [379/469], Loss: 0.1953, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [43/50], Step [380/469], Loss: 0.2952, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [43/50], Step [381/469], Loss: 0.2376, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [382/469], Loss: 0.2868, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [43/50], Step [383/469], Loss: 0.2574, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [43/50], Step [384/469], Loss: 0.3005, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [43/50], Step [385/469], Loss: 0.1533, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [43/50], Step [386/469], Loss: 0.3549, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [387/469], Loss: 0.3563, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [388/469], Loss: 0.3383, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [43/50], Step [389/469], Loss: 0.1603, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [43/50], Step [390/469], Loss: 0.3517, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [391/469], Loss: 0.4052, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [392/469], Loss: 0.4061, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [43/50], Step [393/469], Loss: 0.2949, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [43/50], Step [394/469], Loss: 0.2495, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [43/50], Step [395/469], Loss: 0.3546, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [43/50], Step [396/469], Loss: 0.2734, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [397/469], Loss: 0.2819, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [43/50], Step [398/469], Loss: 0.2480, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [43/50], Step [399/469], Loss: 0.3145, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [43/50], Step [400/469], Loss: 0.2652, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [43/50], Step [401/469], Loss: 0.2819, batch time: 0.67, accuracy:  92.19%\n",
      "Epoch [43/50], Step [402/469], Loss: 0.2329, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [43/50], Step [403/469], Loss: 0.2564, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [43/50], Step [404/469], Loss: 0.5222, batch time: 0.61, accuracy:  86.72%\n",
      "Epoch [43/50], Step [405/469], Loss: 0.2781, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [43/50], Step [406/469], Loss: 0.3270, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [407/469], Loss: 0.2399, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [43/50], Step [408/469], Loss: 0.2464, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [43/50], Step [409/469], Loss: 0.3375, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [43/50], Step [410/469], Loss: 0.1870, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [43/50], Step [411/469], Loss: 0.3093, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [43/50], Step [412/469], Loss: 0.1148, batch time: 0.44, accuracy:  97.66%\n",
      "Epoch [43/50], Step [413/469], Loss: 0.2838, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [43/50], Step [414/469], Loss: 0.4106, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [43/50], Step [415/469], Loss: 0.3874, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [43/50], Step [416/469], Loss: 0.4235, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [43/50], Step [417/469], Loss: 0.3137, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [43/50], Step [418/469], Loss: 0.3560, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [43/50], Step [419/469], Loss: 0.2917, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [43/50], Step [420/469], Loss: 0.4394, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [43/50], Step [421/469], Loss: 0.2266, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [43/50], Step [422/469], Loss: 0.3099, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [43/50], Step [423/469], Loss: 0.2498, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [43/50], Step [424/469], Loss: 0.2757, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [43/50], Step [425/469], Loss: 0.3339, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [43/50], Step [426/469], Loss: 0.3641, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [43/50], Step [427/469], Loss: 0.1561, batch time: 0.53, accuracy:  95.31%\n",
      "Epoch [43/50], Step [428/469], Loss: 0.3333, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [43/50], Step [429/469], Loss: 0.4156, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [43/50], Step [430/469], Loss: 0.2201, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [431/469], Loss: 0.2468, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [43/50], Step [432/469], Loss: 0.3088, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [43/50], Step [433/469], Loss: 0.3692, batch time: 0.90, accuracy:  87.50%\n",
      "Epoch [43/50], Step [434/469], Loss: 0.3445, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [43/50], Step [435/469], Loss: 0.4779, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [43/50], Step [436/469], Loss: 0.2536, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [43/50], Step [437/469], Loss: 0.2973, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [43/50], Step [438/469], Loss: 0.4020, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [43/50], Step [439/469], Loss: 0.4566, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [43/50], Step [440/469], Loss: 0.1758, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [43/50], Step [441/469], Loss: 0.3470, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [43/50], Step [442/469], Loss: 0.3490, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [43/50], Step [443/469], Loss: 0.2650, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [43/50], Step [444/469], Loss: 0.4330, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [43/50], Step [445/469], Loss: 0.3371, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [43/50], Step [446/469], Loss: 0.3370, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [43/50], Step [447/469], Loss: 0.4546, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [43/50], Step [448/469], Loss: 0.3424, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [43/50], Step [449/469], Loss: 0.2150, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [43/50], Step [450/469], Loss: 0.3202, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [43/50], Step [451/469], Loss: 0.3307, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [43/50], Step [452/469], Loss: 0.2715, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [43/50], Step [453/469], Loss: 0.2747, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [43/50], Step [454/469], Loss: 0.3375, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [43/50], Step [455/469], Loss: 0.4105, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [43/50], Step [456/469], Loss: 0.2714, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [43/50], Step [457/469], Loss: 0.2953, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [43/50], Step [458/469], Loss: 0.3162, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [43/50], Step [459/469], Loss: 0.3240, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [43/50], Step [460/469], Loss: 0.2418, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [43/50], Step [461/469], Loss: 0.2576, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [43/50], Step [462/469], Loss: 0.3317, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [43/50], Step [463/469], Loss: 0.3030, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [43/50], Step [464/469], Loss: 0.3810, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [43/50], Step [465/469], Loss: 0.2656, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [43/50], Step [466/469], Loss: 0.4071, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [43/50], Step [467/469], Loss: 0.2093, batch time: 0.53, accuracy:  96.09%\n",
      "Epoch [43/50], Step [468/469], Loss: 0.3063, batch time: 0.66, accuracy:  92.19%\n",
      "Epoch [43/50], Step [469/469], Loss: 0.3177, batch time: 0.48, accuracy:  91.67%\n",
      "Epoch [44/50], Step [1/469], Loss: 0.3113, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [44/50], Step [2/469], Loss: 0.4838, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [44/50], Step [3/469], Loss: 0.2998, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [44/50], Step [4/469], Loss: 0.2710, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [44/50], Step [5/469], Loss: 0.2312, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [6/469], Loss: 0.2447, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [7/469], Loss: 0.1965, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [44/50], Step [8/469], Loss: 0.2438, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [9/469], Loss: 0.2773, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [44/50], Step [10/469], Loss: 0.4754, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [44/50], Step [11/469], Loss: 0.3114, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [44/50], Step [12/469], Loss: 0.2612, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [13/469], Loss: 0.4007, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [44/50], Step [14/469], Loss: 0.1974, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [15/469], Loss: 0.3453, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [44/50], Step [16/469], Loss: 0.3363, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [17/469], Loss: 0.3500, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [44/50], Step [18/469], Loss: 0.2675, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [44/50], Step [19/469], Loss: 0.2732, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [44/50], Step [20/469], Loss: 0.1786, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [44/50], Step [21/469], Loss: 0.2307, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [44/50], Step [22/469], Loss: 0.3660, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [23/469], Loss: 0.3461, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [44/50], Step [24/469], Loss: 0.4237, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [44/50], Step [25/469], Loss: 0.3397, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [26/469], Loss: 0.1953, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [44/50], Step [27/469], Loss: 0.3156, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [44/50], Step [28/469], Loss: 0.4501, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [44/50], Step [29/469], Loss: 0.2009, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [44/50], Step [30/469], Loss: 0.3380, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [44/50], Step [31/469], Loss: 0.4324, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [44/50], Step [32/469], Loss: 0.2503, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [44/50], Step [33/469], Loss: 0.3161, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [44/50], Step [34/469], Loss: 0.2602, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [44/50], Step [35/469], Loss: 0.3058, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [44/50], Step [36/469], Loss: 0.3817, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [44/50], Step [37/469], Loss: 0.2795, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [44/50], Step [38/469], Loss: 0.2641, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [44/50], Step [39/469], Loss: 0.2050, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [40/469], Loss: 0.2723, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [44/50], Step [41/469], Loss: 0.4522, batch time: 0.66, accuracy:  88.28%\n",
      "Epoch [44/50], Step [42/469], Loss: 0.2221, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [44/50], Step [43/469], Loss: 0.2192, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [44/469], Loss: 0.2715, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [44/50], Step [45/469], Loss: 0.3116, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [46/469], Loss: 0.4585, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [44/50], Step [47/469], Loss: 0.2294, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [44/50], Step [48/469], Loss: 0.2205, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [44/50], Step [49/469], Loss: 0.2969, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [44/50], Step [50/469], Loss: 0.2685, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [44/50], Step [51/469], Loss: 0.3311, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [44/50], Step [52/469], Loss: 0.5572, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [44/50], Step [53/469], Loss: 0.2942, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [44/50], Step [54/469], Loss: 0.3776, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [44/50], Step [55/469], Loss: 0.2716, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [44/50], Step [56/469], Loss: 0.2295, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [44/50], Step [57/469], Loss: 0.3024, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [44/50], Step [58/469], Loss: 0.2614, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [44/50], Step [59/469], Loss: 0.2532, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [44/50], Step [60/469], Loss: 0.2381, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [44/50], Step [61/469], Loss: 0.2432, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [44/50], Step [62/469], Loss: 0.2100, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [44/50], Step [63/469], Loss: 0.3092, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [44/50], Step [64/469], Loss: 0.2073, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [44/50], Step [65/469], Loss: 0.3276, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [44/50], Step [66/469], Loss: 0.3909, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [44/50], Step [67/469], Loss: 0.3440, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [44/50], Step [68/469], Loss: 0.3651, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [44/50], Step [69/469], Loss: 0.2009, batch time: 0.61, accuracy:  96.09%\n",
      "Epoch [44/50], Step [70/469], Loss: 0.3378, batch time: 0.61, accuracy:  89.06%\n",
      "Epoch [44/50], Step [71/469], Loss: 0.2390, batch time: 0.61, accuracy:  93.75%\n",
      "Epoch [44/50], Step [72/469], Loss: 0.4145, batch time: 0.70, accuracy:  88.28%\n",
      "Epoch [44/50], Step [73/469], Loss: 0.3723, batch time: 0.77, accuracy:  90.62%\n",
      "Epoch [44/50], Step [74/469], Loss: 0.2325, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [44/50], Step [75/469], Loss: 0.2652, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [44/50], Step [76/469], Loss: 0.1843, batch time: 0.53, accuracy:  96.09%\n",
      "Epoch [44/50], Step [77/469], Loss: 0.3022, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [44/50], Step [78/469], Loss: 0.2860, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [44/50], Step [79/469], Loss: 0.3522, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [44/50], Step [80/469], Loss: 0.4416, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [44/50], Step [81/469], Loss: 0.5323, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [44/50], Step [82/469], Loss: 0.3098, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [44/50], Step [83/469], Loss: 0.2501, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [44/50], Step [84/469], Loss: 0.3422, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [85/469], Loss: 0.2522, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [44/50], Step [86/469], Loss: 0.1959, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [44/50], Step [87/469], Loss: 0.3046, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [44/50], Step [88/469], Loss: 0.2594, batch time: 0.61, accuracy:  93.75%\n",
      "Epoch [44/50], Step [89/469], Loss: 0.3544, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [44/50], Step [90/469], Loss: 0.2548, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [44/50], Step [91/469], Loss: 0.3834, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [44/50], Step [92/469], Loss: 0.3288, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [44/50], Step [93/469], Loss: 0.2553, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [44/50], Step [94/469], Loss: 0.3350, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [44/50], Step [95/469], Loss: 0.2967, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [44/50], Step [96/469], Loss: 0.2745, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [97/469], Loss: 0.2125, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [44/50], Step [98/469], Loss: 0.3757, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [44/50], Step [99/469], Loss: 0.3459, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [44/50], Step [100/469], Loss: 0.2634, batch time: 0.82, accuracy:  92.97%\n",
      "Epoch [44/50], Step [101/469], Loss: 0.2649, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [44/50], Step [102/469], Loss: 0.2910, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [44/50], Step [103/469], Loss: 0.2272, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [44/50], Step [104/469], Loss: 0.3578, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [44/50], Step [105/469], Loss: 0.4546, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [44/50], Step [106/469], Loss: 0.2164, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [107/469], Loss: 0.3355, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [44/50], Step [108/469], Loss: 0.3735, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [44/50], Step [109/469], Loss: 0.3436, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [44/50], Step [110/469], Loss: 0.3876, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [44/50], Step [111/469], Loss: 0.2591, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [44/50], Step [112/469], Loss: 0.2554, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [113/469], Loss: 0.2219, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [114/469], Loss: 0.2307, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [115/469], Loss: 0.2365, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [44/50], Step [116/469], Loss: 0.3464, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [117/469], Loss: 0.2523, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [44/50], Step [118/469], Loss: 0.2922, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [119/469], Loss: 0.3412, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [44/50], Step [120/469], Loss: 0.3978, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [44/50], Step [121/469], Loss: 0.2460, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [44/50], Step [122/469], Loss: 0.3324, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [44/50], Step [123/469], Loss: 0.2845, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [44/50], Step [124/469], Loss: 0.2145, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [44/50], Step [125/469], Loss: 0.3467, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [44/50], Step [126/469], Loss: 0.3507, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [44/50], Step [127/469], Loss: 0.3349, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [44/50], Step [128/469], Loss: 0.3479, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [44/50], Step [129/469], Loss: 0.2578, batch time: 0.73, accuracy:  88.28%\n",
      "Epoch [44/50], Step [130/469], Loss: 0.2723, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [44/50], Step [131/469], Loss: 0.2990, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [44/50], Step [132/469], Loss: 0.2738, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [133/469], Loss: 0.1775, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [44/50], Step [134/469], Loss: 0.4525, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [44/50], Step [135/469], Loss: 0.2520, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [44/50], Step [136/469], Loss: 0.2730, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [44/50], Step [137/469], Loss: 0.5143, batch time: 0.51, accuracy:  85.94%\n",
      "Epoch [44/50], Step [138/469], Loss: 0.3803, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [44/50], Step [139/469], Loss: 0.3499, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [44/50], Step [140/469], Loss: 0.3311, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [44/50], Step [141/469], Loss: 0.1978, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [44/50], Step [142/469], Loss: 0.4040, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [44/50], Step [143/469], Loss: 0.3098, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [44/50], Step [144/469], Loss: 0.2975, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [44/50], Step [145/469], Loss: 0.2158, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [44/50], Step [146/469], Loss: 0.2534, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [147/469], Loss: 0.2984, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [44/50], Step [148/469], Loss: 0.3521, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [44/50], Step [149/469], Loss: 0.2393, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [44/50], Step [150/469], Loss: 0.2221, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [151/469], Loss: 0.2346, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [44/50], Step [152/469], Loss: 0.3904, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [44/50], Step [153/469], Loss: 0.3579, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [44/50], Step [154/469], Loss: 0.3836, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [44/50], Step [155/469], Loss: 0.1795, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [44/50], Step [156/469], Loss: 0.2581, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [44/50], Step [157/469], Loss: 0.2395, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [44/50], Step [158/469], Loss: 0.3013, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [44/50], Step [159/469], Loss: 0.3227, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [44/50], Step [160/469], Loss: 0.4685, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [44/50], Step [161/469], Loss: 0.3000, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [44/50], Step [162/469], Loss: 0.3111, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [44/50], Step [163/469], Loss: 0.3159, batch time: 0.58, accuracy:  87.50%\n",
      "Epoch [44/50], Step [164/469], Loss: 0.2897, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [44/50], Step [165/469], Loss: 0.2773, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [44/50], Step [166/469], Loss: 0.2629, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [167/469], Loss: 0.3021, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [44/50], Step [168/469], Loss: 0.2880, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [169/469], Loss: 0.3457, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [44/50], Step [170/469], Loss: 0.2451, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [44/50], Step [171/469], Loss: 0.2935, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [44/50], Step [172/469], Loss: 0.2567, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [44/50], Step [173/469], Loss: 0.1835, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [44/50], Step [174/469], Loss: 0.1922, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [44/50], Step [175/469], Loss: 0.4641, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [44/50], Step [176/469], Loss: 0.3293, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [44/50], Step [177/469], Loss: 0.2642, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [44/50], Step [178/469], Loss: 0.4232, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [44/50], Step [179/469], Loss: 0.2447, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [180/469], Loss: 0.1537, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [44/50], Step [181/469], Loss: 0.2694, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [182/469], Loss: 0.3579, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [44/50], Step [183/469], Loss: 0.4018, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [44/50], Step [184/469], Loss: 0.2661, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [185/469], Loss: 0.2409, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [186/469], Loss: 0.2452, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [187/469], Loss: 0.3417, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [44/50], Step [188/469], Loss: 0.3751, batch time: 0.64, accuracy:  86.72%\n",
      "Epoch [44/50], Step [189/469], Loss: 0.5444, batch time: 0.64, accuracy:  84.38%\n",
      "Epoch [44/50], Step [190/469], Loss: 0.3473, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [44/50], Step [191/469], Loss: 0.2980, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [44/50], Step [192/469], Loss: 0.3331, batch time: 0.71, accuracy:  91.41%\n",
      "Epoch [44/50], Step [193/469], Loss: 0.3393, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [44/50], Step [194/469], Loss: 0.3888, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [44/50], Step [195/469], Loss: 0.1521, batch time: 0.49, accuracy:  96.09%\n",
      "Epoch [44/50], Step [196/469], Loss: 0.3130, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [44/50], Step [197/469], Loss: 0.2210, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [44/50], Step [198/469], Loss: 0.2249, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [199/469], Loss: 0.2619, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [44/50], Step [200/469], Loss: 0.2873, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [201/469], Loss: 0.3101, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [202/469], Loss: 0.2782, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [203/469], Loss: 0.3365, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [204/469], Loss: 0.2875, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [44/50], Step [205/469], Loss: 0.2928, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [44/50], Step [206/469], Loss: 0.3196, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [44/50], Step [207/469], Loss: 0.3526, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [44/50], Step [208/469], Loss: 0.4371, batch time: 0.52, accuracy:  85.16%\n",
      "Epoch [44/50], Step [209/469], Loss: 0.4995, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [44/50], Step [210/469], Loss: 0.2413, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [44/50], Step [211/469], Loss: 0.4476, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [44/50], Step [212/469], Loss: 0.3440, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [44/50], Step [213/469], Loss: 0.4274, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [44/50], Step [214/469], Loss: 0.2670, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [44/50], Step [215/469], Loss: 0.2877, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [44/50], Step [216/469], Loss: 0.2704, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [44/50], Step [217/469], Loss: 0.2864, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [44/50], Step [218/469], Loss: 0.2207, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [44/50], Step [219/469], Loss: 0.3178, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [44/50], Step [220/469], Loss: 0.3022, batch time: 0.65, accuracy:  89.84%\n",
      "Epoch [44/50], Step [221/469], Loss: 0.2920, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [44/50], Step [222/469], Loss: 0.1701, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [44/50], Step [223/469], Loss: 0.2814, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [44/50], Step [224/469], Loss: 0.1358, batch time: 0.60, accuracy:  95.31%\n",
      "Epoch [44/50], Step [225/469], Loss: 0.3020, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [44/50], Step [226/469], Loss: 0.2266, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [44/50], Step [227/469], Loss: 0.4002, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [44/50], Step [228/469], Loss: 0.3245, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [44/50], Step [229/469], Loss: 0.3149, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [44/50], Step [230/469], Loss: 0.2268, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [44/50], Step [231/469], Loss: 0.4682, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [44/50], Step [232/469], Loss: 0.2251, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [44/50], Step [233/469], Loss: 0.2410, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [44/50], Step [234/469], Loss: 0.3393, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [44/50], Step [235/469], Loss: 0.2750, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [44/50], Step [236/469], Loss: 0.2322, batch time: 0.53, accuracy:  96.09%\n",
      "Epoch [44/50], Step [237/469], Loss: 0.3649, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [44/50], Step [238/469], Loss: 0.3911, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [44/50], Step [239/469], Loss: 0.2708, batch time: 0.53, accuracy:  96.88%\n",
      "Epoch [44/50], Step [240/469], Loss: 0.2609, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [44/50], Step [241/469], Loss: 0.2623, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [44/50], Step [242/469], Loss: 0.2908, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [44/50], Step [243/469], Loss: 0.3004, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [44/50], Step [244/469], Loss: 0.1890, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [44/50], Step [245/469], Loss: 0.2289, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [44/50], Step [246/469], Loss: 0.3839, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [44/50], Step [247/469], Loss: 0.3326, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [44/50], Step [248/469], Loss: 0.4105, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [44/50], Step [249/469], Loss: 0.2523, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [250/469], Loss: 0.2130, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [44/50], Step [251/469], Loss: 0.2525, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [44/50], Step [252/469], Loss: 0.2754, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [44/50], Step [253/469], Loss: 0.3490, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [44/50], Step [254/469], Loss: 0.1943, batch time: 0.56, accuracy:  96.88%\n",
      "Epoch [44/50], Step [255/469], Loss: 0.2723, batch time: 0.59, accuracy:  89.84%\n",
      "Epoch [44/50], Step [256/469], Loss: 0.2964, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [44/50], Step [257/469], Loss: 0.2405, batch time: 0.60, accuracy:  92.19%\n",
      "Epoch [44/50], Step [258/469], Loss: 0.2253, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [44/50], Step [259/469], Loss: 0.2668, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [44/50], Step [260/469], Loss: 0.4222, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [44/50], Step [261/469], Loss: 0.2415, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [44/50], Step [262/469], Loss: 0.2727, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [44/50], Step [263/469], Loss: 0.2472, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [44/50], Step [264/469], Loss: 0.3096, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [44/50], Step [265/469], Loss: 0.2723, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [44/50], Step [266/469], Loss: 0.3596, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [44/50], Step [267/469], Loss: 0.4194, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [44/50], Step [268/469], Loss: 0.3848, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [44/50], Step [269/469], Loss: 0.3184, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [270/469], Loss: 0.2305, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [44/50], Step [271/469], Loss: 0.2020, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [272/469], Loss: 0.1985, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [273/469], Loss: 0.3731, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [44/50], Step [274/469], Loss: 0.3170, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [44/50], Step [275/469], Loss: 0.1495, batch time: 0.55, accuracy:  95.31%\n",
      "Epoch [44/50], Step [276/469], Loss: 0.1780, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [44/50], Step [277/469], Loss: 0.3544, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [278/469], Loss: 0.4439, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [44/50], Step [279/469], Loss: 0.2063, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [280/469], Loss: 0.3062, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [281/469], Loss: 0.2868, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [44/50], Step [282/469], Loss: 0.2658, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [44/50], Step [283/469], Loss: 0.2186, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [284/469], Loss: 0.2516, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [44/50], Step [285/469], Loss: 0.3173, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [44/50], Step [286/469], Loss: 0.2732, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [44/50], Step [287/469], Loss: 0.4071, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [44/50], Step [288/469], Loss: 0.3610, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [44/50], Step [289/469], Loss: 0.2864, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [290/469], Loss: 0.2450, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [44/50], Step [291/469], Loss: 0.4554, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [44/50], Step [292/469], Loss: 0.3058, batch time: 0.56, accuracy:  94.53%\n",
      "Epoch [44/50], Step [293/469], Loss: 0.3732, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [44/50], Step [294/469], Loss: 0.2241, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [44/50], Step [295/469], Loss: 0.2888, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [44/50], Step [296/469], Loss: 0.4033, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [44/50], Step [297/469], Loss: 0.2982, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [44/50], Step [298/469], Loss: 0.3173, batch time: 0.65, accuracy:  93.75%\n",
      "Epoch [44/50], Step [299/469], Loss: 0.2864, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [300/469], Loss: 0.3148, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [301/469], Loss: 0.2626, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [44/50], Step [302/469], Loss: 0.2559, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [44/50], Step [303/469], Loss: 0.3208, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [44/50], Step [304/469], Loss: 0.3424, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [305/469], Loss: 0.3359, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [44/50], Step [306/469], Loss: 0.2774, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [44/50], Step [307/469], Loss: 0.2918, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [44/50], Step [308/469], Loss: 0.3005, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [44/50], Step [309/469], Loss: 0.3693, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [310/469], Loss: 0.2712, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [44/50], Step [311/469], Loss: 0.4468, batch time: 0.47, accuracy:  83.59%\n",
      "Epoch [44/50], Step [312/469], Loss: 0.3253, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [44/50], Step [313/469], Loss: 0.3372, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [314/469], Loss: 0.3260, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [44/50], Step [315/469], Loss: 0.2529, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [44/50], Step [316/469], Loss: 0.4698, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [44/50], Step [317/469], Loss: 0.4084, batch time: 0.56, accuracy:  85.94%\n",
      "Epoch [44/50], Step [318/469], Loss: 0.2226, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [44/50], Step [319/469], Loss: 0.3897, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [44/50], Step [320/469], Loss: 0.4008, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [44/50], Step [321/469], Loss: 0.3526, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [44/50], Step [322/469], Loss: 0.3401, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [323/469], Loss: 0.2893, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [44/50], Step [324/469], Loss: 0.3535, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [44/50], Step [325/469], Loss: 0.3305, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [44/50], Step [326/469], Loss: 0.2767, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [44/50], Step [327/469], Loss: 0.2172, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [44/50], Step [328/469], Loss: 0.3789, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [44/50], Step [329/469], Loss: 0.3850, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [44/50], Step [330/469], Loss: 0.2682, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [44/50], Step [331/469], Loss: 0.5641, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [44/50], Step [332/469], Loss: 0.4166, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [44/50], Step [333/469], Loss: 0.3859, batch time: 0.56, accuracy:  86.72%\n",
      "Epoch [44/50], Step [334/469], Loss: 0.1960, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [44/50], Step [335/469], Loss: 0.2542, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [44/50], Step [336/469], Loss: 0.2959, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [44/50], Step [337/469], Loss: 0.3562, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [44/50], Step [338/469], Loss: 0.4049, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [44/50], Step [339/469], Loss: 0.3378, batch time: 0.50, accuracy:  84.38%\n",
      "Epoch [44/50], Step [340/469], Loss: 0.3637, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [44/50], Step [341/469], Loss: 0.2158, batch time: 0.49, accuracy:  95.31%\n",
      "Epoch [44/50], Step [342/469], Loss: 0.2429, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [44/50], Step [343/469], Loss: 0.2966, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [344/469], Loss: 0.2714, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [44/50], Step [345/469], Loss: 0.1762, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [44/50], Step [346/469], Loss: 0.1536, batch time: 0.49, accuracy:  96.09%\n",
      "Epoch [44/50], Step [347/469], Loss: 0.2293, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [44/50], Step [348/469], Loss: 0.2840, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [44/50], Step [349/469], Loss: 0.1963, batch time: 0.56, accuracy:  94.53%\n",
      "Epoch [44/50], Step [350/469], Loss: 0.3197, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [44/50], Step [351/469], Loss: 0.3654, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [44/50], Step [352/469], Loss: 0.2713, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [44/50], Step [353/469], Loss: 0.2387, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [44/50], Step [354/469], Loss: 0.3844, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [44/50], Step [355/469], Loss: 0.3162, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [44/50], Step [356/469], Loss: 0.2517, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [357/469], Loss: 0.3076, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [44/50], Step [358/469], Loss: 0.2765, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [44/50], Step [359/469], Loss: 0.1881, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [44/50], Step [360/469], Loss: 0.1944, batch time: 0.57, accuracy:  93.75%\n",
      "Epoch [44/50], Step [361/469], Loss: 0.2097, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [44/50], Step [362/469], Loss: 0.2244, batch time: 0.55, accuracy:  95.31%\n",
      "Epoch [44/50], Step [363/469], Loss: 0.2990, batch time: 0.59, accuracy:  93.75%\n",
      "Epoch [44/50], Step [364/469], Loss: 0.3719, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [44/50], Step [365/469], Loss: 0.2309, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [44/50], Step [366/469], Loss: 0.2554, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [44/50], Step [367/469], Loss: 0.2627, batch time: 0.57, accuracy:  86.72%\n",
      "Epoch [44/50], Step [368/469], Loss: 0.1978, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [44/50], Step [369/469], Loss: 0.3182, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [44/50], Step [370/469], Loss: 0.4077, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [44/50], Step [371/469], Loss: 0.2984, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [44/50], Step [372/469], Loss: 0.2002, batch time: 0.46, accuracy:  96.88%\n",
      "Epoch [44/50], Step [373/469], Loss: 0.2556, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [44/50], Step [374/469], Loss: 0.3613, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [44/50], Step [375/469], Loss: 0.3237, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [44/50], Step [376/469], Loss: 0.2145, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [377/469], Loss: 0.2027, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [44/50], Step [378/469], Loss: 0.2027, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [44/50], Step [379/469], Loss: 0.2291, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [44/50], Step [380/469], Loss: 0.3648, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [44/50], Step [381/469], Loss: 0.3501, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [44/50], Step [382/469], Loss: 0.4123, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [44/50], Step [383/469], Loss: 0.3663, batch time: 0.60, accuracy:  89.84%\n",
      "Epoch [44/50], Step [384/469], Loss: 0.2202, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [385/469], Loss: 0.3205, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [44/50], Step [386/469], Loss: 0.3901, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [44/50], Step [387/469], Loss: 0.3480, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [44/50], Step [388/469], Loss: 0.5511, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [44/50], Step [389/469], Loss: 0.4233, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [44/50], Step [390/469], Loss: 0.2578, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [44/50], Step [391/469], Loss: 0.2715, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [44/50], Step [392/469], Loss: 0.3018, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [44/50], Step [393/469], Loss: 0.3396, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [44/50], Step [394/469], Loss: 0.3146, batch time: 0.68, accuracy:  87.50%\n",
      "Epoch [44/50], Step [395/469], Loss: 0.2294, batch time: 0.72, accuracy:  92.97%\n",
      "Epoch [44/50], Step [396/469], Loss: 0.2080, batch time: 0.61, accuracy:  92.97%\n",
      "Epoch [44/50], Step [397/469], Loss: 0.2189, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [44/50], Step [398/469], Loss: 0.4222, batch time: 0.65, accuracy:  87.50%\n",
      "Epoch [44/50], Step [399/469], Loss: 0.3145, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [44/50], Step [400/469], Loss: 0.2775, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [44/50], Step [401/469], Loss: 0.3788, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [402/469], Loss: 0.3643, batch time: 0.48, accuracy:  85.16%\n",
      "Epoch [44/50], Step [403/469], Loss: 0.2619, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [44/50], Step [404/469], Loss: 0.2324, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [44/50], Step [405/469], Loss: 0.3576, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [44/50], Step [406/469], Loss: 0.2730, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [44/50], Step [407/469], Loss: 0.4617, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [44/50], Step [408/469], Loss: 0.2679, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [44/50], Step [409/469], Loss: 0.3338, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [44/50], Step [410/469], Loss: 0.4395, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [44/50], Step [411/469], Loss: 0.3985, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [44/50], Step [412/469], Loss: 0.4115, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [44/50], Step [413/469], Loss: 0.3513, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [44/50], Step [414/469], Loss: 0.3204, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [415/469], Loss: 0.2346, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [416/469], Loss: 0.3553, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [44/50], Step [417/469], Loss: 0.3193, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [44/50], Step [418/469], Loss: 0.3406, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [44/50], Step [419/469], Loss: 0.2544, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [44/50], Step [420/469], Loss: 0.2312, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [421/469], Loss: 0.3292, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [44/50], Step [422/469], Loss: 0.2488, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [44/50], Step [423/469], Loss: 0.3941, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [44/50], Step [424/469], Loss: 0.2923, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [44/50], Step [425/469], Loss: 0.4160, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [44/50], Step [426/469], Loss: 0.2993, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [44/50], Step [427/469], Loss: 0.1851, batch time: 0.54, accuracy:  96.09%\n",
      "Epoch [44/50], Step [428/469], Loss: 0.2626, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [44/50], Step [429/469], Loss: 0.2638, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [44/50], Step [430/469], Loss: 0.1526, batch time: 0.63, accuracy:  96.09%\n",
      "Epoch [44/50], Step [431/469], Loss: 0.3092, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [44/50], Step [432/469], Loss: 0.1888, batch time: 0.55, accuracy:  96.09%\n",
      "Epoch [44/50], Step [433/469], Loss: 0.2924, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [44/50], Step [434/469], Loss: 0.4311, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [44/50], Step [435/469], Loss: 0.2727, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [436/469], Loss: 0.3437, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [44/50], Step [437/469], Loss: 0.3137, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [44/50], Step [438/469], Loss: 0.4092, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [44/50], Step [439/469], Loss: 0.3174, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [440/469], Loss: 0.4617, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [44/50], Step [441/469], Loss: 0.2831, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [44/50], Step [442/469], Loss: 0.2519, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [44/50], Step [443/469], Loss: 0.4560, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [44/50], Step [444/469], Loss: 0.2434, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [44/50], Step [445/469], Loss: 0.1808, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [44/50], Step [446/469], Loss: 0.2348, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [44/50], Step [447/469], Loss: 0.3551, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [44/50], Step [448/469], Loss: 0.4142, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [44/50], Step [449/469], Loss: 0.1937, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [44/50], Step [450/469], Loss: 0.3088, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [44/50], Step [451/469], Loss: 0.2784, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [44/50], Step [452/469], Loss: 0.3085, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [44/50], Step [453/469], Loss: 0.2836, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [44/50], Step [454/469], Loss: 0.2947, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [44/50], Step [455/469], Loss: 0.2803, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [44/50], Step [456/469], Loss: 0.3952, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [44/50], Step [457/469], Loss: 0.2321, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [44/50], Step [458/469], Loss: 0.2705, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [44/50], Step [459/469], Loss: 0.2010, batch time: 0.52, accuracy:  95.31%\n",
      "Epoch [44/50], Step [460/469], Loss: 0.3337, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [44/50], Step [461/469], Loss: 0.3898, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [44/50], Step [462/469], Loss: 0.2495, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [44/50], Step [463/469], Loss: 0.2458, batch time: 0.68, accuracy:  94.53%\n",
      "Epoch [44/50], Step [464/469], Loss: 0.1730, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [44/50], Step [465/469], Loss: 0.4157, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [44/50], Step [466/469], Loss: 0.2565, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [44/50], Step [467/469], Loss: 0.2003, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [44/50], Step [468/469], Loss: 0.2996, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [44/50], Step [469/469], Loss: 0.3484, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [1/469], Loss: 0.3447, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [45/50], Step [2/469], Loss: 0.1641, batch time: 0.46, accuracy:  96.09%\n",
      "Epoch [45/50], Step [3/469], Loss: 0.1819, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [45/50], Step [4/469], Loss: 0.3774, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [45/50], Step [5/469], Loss: 0.3415, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [45/50], Step [6/469], Loss: 0.3034, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [45/50], Step [7/469], Loss: 0.2977, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [8/469], Loss: 0.4182, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [45/50], Step [9/469], Loss: 0.2396, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [45/50], Step [10/469], Loss: 0.3019, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [45/50], Step [11/469], Loss: 0.1996, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [45/50], Step [12/469], Loss: 0.2417, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [45/50], Step [13/469], Loss: 0.3871, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [45/50], Step [14/469], Loss: 0.3785, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [45/50], Step [15/469], Loss: 0.3138, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [45/50], Step [16/469], Loss: 0.3905, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [45/50], Step [17/469], Loss: 0.2230, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [45/50], Step [18/469], Loss: 0.3115, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [45/50], Step [19/469], Loss: 0.2650, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [45/50], Step [20/469], Loss: 0.1034, batch time: 0.49, accuracy:  96.88%\n",
      "Epoch [45/50], Step [21/469], Loss: 0.2584, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [45/50], Step [22/469], Loss: 0.3041, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [45/50], Step [23/469], Loss: 0.4351, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [45/50], Step [24/469], Loss: 0.3252, batch time: 0.61, accuracy:  89.84%\n",
      "Epoch [45/50], Step [25/469], Loss: 0.2434, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [45/50], Step [26/469], Loss: 0.2644, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [45/50], Step [27/469], Loss: 0.2986, batch time: 0.66, accuracy:  95.31%\n",
      "Epoch [45/50], Step [28/469], Loss: 0.2549, batch time: 0.69, accuracy:  89.06%\n",
      "Epoch [45/50], Step [29/469], Loss: 0.3174, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [45/50], Step [30/469], Loss: 0.1955, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [45/50], Step [31/469], Loss: 0.3341, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [45/50], Step [32/469], Loss: 0.3275, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [45/50], Step [33/469], Loss: 0.2848, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [45/50], Step [34/469], Loss: 0.1842, batch time: 0.55, accuracy:  95.31%\n",
      "Epoch [45/50], Step [35/469], Loss: 0.3571, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [45/50], Step [36/469], Loss: 0.4050, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [45/50], Step [37/469], Loss: 0.3784, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [45/50], Step [38/469], Loss: 0.2762, batch time: 0.66, accuracy:  89.84%\n",
      "Epoch [45/50], Step [39/469], Loss: 0.2415, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [45/50], Step [40/469], Loss: 0.4350, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [45/50], Step [41/469], Loss: 0.3695, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [45/50], Step [42/469], Loss: 0.3685, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [45/50], Step [43/469], Loss: 0.3616, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [45/50], Step [44/469], Loss: 0.3058, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [45/469], Loss: 0.2253, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [45/50], Step [46/469], Loss: 0.4085, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [45/50], Step [47/469], Loss: 0.2035, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [45/50], Step [48/469], Loss: 0.2900, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [45/50], Step [49/469], Loss: 0.1779, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [45/50], Step [50/469], Loss: 0.3739, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [45/50], Step [51/469], Loss: 0.3376, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [45/50], Step [52/469], Loss: 0.2375, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [45/50], Step [53/469], Loss: 0.2686, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [45/50], Step [54/469], Loss: 0.3125, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [45/50], Step [55/469], Loss: 0.2345, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [45/50], Step [56/469], Loss: 0.2773, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [45/50], Step [57/469], Loss: 0.1858, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [45/50], Step [58/469], Loss: 0.1930, batch time: 0.52, accuracy:  95.31%\n",
      "Epoch [45/50], Step [59/469], Loss: 0.2848, batch time: 0.65, accuracy:  94.53%\n",
      "Epoch [45/50], Step [60/469], Loss: 0.3460, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [45/50], Step [61/469], Loss: 0.2744, batch time: 0.67, accuracy:  92.19%\n",
      "Epoch [45/50], Step [62/469], Loss: 0.4665, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [45/50], Step [63/469], Loss: 0.1709, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [45/50], Step [64/469], Loss: 0.2525, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [65/469], Loss: 0.2334, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [45/50], Step [66/469], Loss: 0.3561, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [45/50], Step [67/469], Loss: 0.2577, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [45/50], Step [68/469], Loss: 0.2565, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [45/50], Step [69/469], Loss: 0.2062, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [45/50], Step [70/469], Loss: 0.3547, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [45/50], Step [71/469], Loss: 0.2968, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [45/50], Step [72/469], Loss: 0.1951, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [45/50], Step [73/469], Loss: 0.2224, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [45/50], Step [74/469], Loss: 0.2150, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [45/50], Step [75/469], Loss: 0.2630, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [76/469], Loss: 0.3410, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [45/50], Step [77/469], Loss: 0.3690, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [45/50], Step [78/469], Loss: 0.3677, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [45/50], Step [79/469], Loss: 0.2529, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [45/50], Step [80/469], Loss: 0.2966, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [45/50], Step [81/469], Loss: 0.2714, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [45/50], Step [82/469], Loss: 0.2085, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [45/50], Step [83/469], Loss: 0.4127, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [45/50], Step [84/469], Loss: 0.4029, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [45/50], Step [85/469], Loss: 0.3287, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [45/50], Step [86/469], Loss: 0.2923, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [45/50], Step [87/469], Loss: 0.2957, batch time: 0.66, accuracy:  92.97%\n",
      "Epoch [45/50], Step [88/469], Loss: 0.4477, batch time: 0.71, accuracy:  88.28%\n",
      "Epoch [45/50], Step [89/469], Loss: 0.2851, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [45/50], Step [90/469], Loss: 0.3916, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [45/50], Step [91/469], Loss: 0.2649, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [45/50], Step [92/469], Loss: 0.2917, batch time: 0.65, accuracy:  91.41%\n",
      "Epoch [45/50], Step [93/469], Loss: 0.3486, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [45/50], Step [94/469], Loss: 0.4376, batch time: 0.62, accuracy:  85.16%\n",
      "Epoch [45/50], Step [95/469], Loss: 0.3183, batch time: 0.65, accuracy:  89.06%\n",
      "Epoch [45/50], Step [96/469], Loss: 0.4172, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [45/50], Step [97/469], Loss: 0.3063, batch time: 0.69, accuracy:  90.62%\n",
      "Epoch [45/50], Step [98/469], Loss: 0.3349, batch time: 0.65, accuracy:  88.28%\n",
      "Epoch [45/50], Step [99/469], Loss: 0.2509, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [45/50], Step [100/469], Loss: 0.2193, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [45/50], Step [101/469], Loss: 0.3478, batch time: 0.63, accuracy:  89.84%\n",
      "Epoch [45/50], Step [102/469], Loss: 0.2281, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [45/50], Step [103/469], Loss: 0.2763, batch time: 0.65, accuracy:  92.19%\n",
      "Epoch [45/50], Step [104/469], Loss: 0.1924, batch time: 0.69, accuracy:  95.31%\n",
      "Epoch [45/50], Step [105/469], Loss: 0.2567, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [45/50], Step [106/469], Loss: 0.3357, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [45/50], Step [107/469], Loss: 0.2846, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [45/50], Step [108/469], Loss: 0.2320, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [45/50], Step [109/469], Loss: 0.2918, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [45/50], Step [110/469], Loss: 0.4295, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [45/50], Step [111/469], Loss: 0.2307, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [45/50], Step [112/469], Loss: 0.3740, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [45/50], Step [113/469], Loss: 0.2526, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [45/50], Step [114/469], Loss: 0.1827, batch time: 0.53, accuracy:  96.88%\n",
      "Epoch [45/50], Step [115/469], Loss: 0.4109, batch time: 0.57, accuracy:  85.94%\n",
      "Epoch [45/50], Step [116/469], Loss: 0.3872, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [45/50], Step [117/469], Loss: 0.3343, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [45/50], Step [118/469], Loss: 0.4041, batch time: 0.51, accuracy:  85.16%\n",
      "Epoch [45/50], Step [119/469], Loss: 0.3426, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [45/50], Step [120/469], Loss: 0.2343, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [45/50], Step [121/469], Loss: 0.2416, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [45/50], Step [122/469], Loss: 0.2830, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [45/50], Step [123/469], Loss: 0.3475, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [45/50], Step [124/469], Loss: 0.3490, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [45/50], Step [125/469], Loss: 0.3722, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [45/50], Step [126/469], Loss: 0.4031, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [45/50], Step [127/469], Loss: 0.3686, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [45/50], Step [128/469], Loss: 0.2872, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [45/50], Step [129/469], Loss: 0.3318, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [45/50], Step [130/469], Loss: 0.2205, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [45/50], Step [131/469], Loss: 0.4003, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [132/469], Loss: 0.3141, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [45/50], Step [133/469], Loss: 0.2676, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [45/50], Step [134/469], Loss: 0.2582, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [45/50], Step [135/469], Loss: 0.1987, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [45/50], Step [136/469], Loss: 0.3112, batch time: 0.61, accuracy:  92.97%\n",
      "Epoch [45/50], Step [137/469], Loss: 0.3776, batch time: 0.75, accuracy:  88.28%\n",
      "Epoch [45/50], Step [138/469], Loss: 0.4178, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [45/50], Step [139/469], Loss: 0.2437, batch time: 0.46, accuracy:  96.09%\n",
      "Epoch [45/50], Step [140/469], Loss: 0.2587, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [45/50], Step [141/469], Loss: 0.2484, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [45/50], Step [142/469], Loss: 0.3637, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [45/50], Step [143/469], Loss: 0.2980, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [45/50], Step [144/469], Loss: 0.3590, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [45/50], Step [145/469], Loss: 0.2475, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [45/50], Step [146/469], Loss: 0.4184, batch time: 0.54, accuracy:  86.72%\n",
      "Epoch [45/50], Step [147/469], Loss: 0.2896, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [45/50], Step [148/469], Loss: 0.1815, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [45/50], Step [149/469], Loss: 0.2688, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [150/469], Loss: 0.4242, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [45/50], Step [151/469], Loss: 0.3370, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [45/50], Step [152/469], Loss: 0.4596, batch time: 0.49, accuracy:  84.38%\n",
      "Epoch [45/50], Step [153/469], Loss: 0.1498, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [45/50], Step [154/469], Loss: 0.1532, batch time: 0.49, accuracy:  95.31%\n",
      "Epoch [45/50], Step [155/469], Loss: 0.2473, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [45/50], Step [156/469], Loss: 0.1719, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [45/50], Step [157/469], Loss: 0.5811, batch time: 0.53, accuracy:  85.16%\n",
      "Epoch [45/50], Step [158/469], Loss: 0.3929, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [45/50], Step [159/469], Loss: 0.3253, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [45/50], Step [160/469], Loss: 0.4099, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [45/50], Step [161/469], Loss: 0.2882, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [45/50], Step [162/469], Loss: 0.3298, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [45/50], Step [163/469], Loss: 0.2354, batch time: 0.62, accuracy:  92.97%\n",
      "Epoch [45/50], Step [164/469], Loss: 0.2466, batch time: 0.62, accuracy:  95.31%\n",
      "Epoch [45/50], Step [165/469], Loss: 0.2474, batch time: 0.66, accuracy:  92.19%\n",
      "Epoch [45/50], Step [166/469], Loss: 0.2313, batch time: 0.62, accuracy:  93.75%\n",
      "Epoch [45/50], Step [167/469], Loss: 0.2705, batch time: 0.64, accuracy:  92.97%\n",
      "Epoch [45/50], Step [168/469], Loss: 0.2977, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [45/50], Step [169/469], Loss: 0.2268, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [170/469], Loss: 0.3198, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [45/50], Step [171/469], Loss: 0.2065, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [45/50], Step [172/469], Loss: 0.2341, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [45/50], Step [173/469], Loss: 0.2567, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [174/469], Loss: 0.2592, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [45/50], Step [175/469], Loss: 0.4988, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [45/50], Step [176/469], Loss: 0.2762, batch time: 0.61, accuracy:  92.97%\n",
      "Epoch [45/50], Step [177/469], Loss: 0.2690, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [45/50], Step [178/469], Loss: 0.3959, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [45/50], Step [179/469], Loss: 0.2097, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [45/50], Step [180/469], Loss: 0.3736, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [45/50], Step [181/469], Loss: 0.2623, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [45/50], Step [182/469], Loss: 0.1732, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [45/50], Step [183/469], Loss: 0.3024, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [45/50], Step [184/469], Loss: 0.4045, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [45/50], Step [185/469], Loss: 0.2214, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [45/50], Step [186/469], Loss: 0.1478, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [45/50], Step [187/469], Loss: 0.4456, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [45/50], Step [188/469], Loss: 0.2833, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [45/50], Step [189/469], Loss: 0.1978, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [45/50], Step [190/469], Loss: 0.3650, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [191/469], Loss: 0.3262, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [45/50], Step [192/469], Loss: 0.3875, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [45/50], Step [193/469], Loss: 0.3563, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [45/50], Step [194/469], Loss: 0.4165, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [45/50], Step [195/469], Loss: 0.2762, batch time: 0.67, accuracy:  92.97%\n",
      "Epoch [45/50], Step [196/469], Loss: 0.4233, batch time: 0.65, accuracy:  87.50%\n",
      "Epoch [45/50], Step [197/469], Loss: 0.3447, batch time: 0.64, accuracy:  88.28%\n",
      "Epoch [45/50], Step [198/469], Loss: 0.5339, batch time: 0.70, accuracy:  84.38%\n",
      "Epoch [45/50], Step [199/469], Loss: 0.1841, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [45/50], Step [200/469], Loss: 0.3345, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [45/50], Step [201/469], Loss: 0.3691, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [45/50], Step [202/469], Loss: 0.3851, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [45/50], Step [203/469], Loss: 0.4024, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [45/50], Step [204/469], Loss: 0.1953, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [45/50], Step [205/469], Loss: 0.3199, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [206/469], Loss: 0.3408, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [45/50], Step [207/469], Loss: 0.3199, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [45/50], Step [208/469], Loss: 0.4531, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [45/50], Step [209/469], Loss: 0.3084, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [45/50], Step [210/469], Loss: 0.3279, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [211/469], Loss: 0.3815, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [45/50], Step [212/469], Loss: 0.2213, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [45/50], Step [213/469], Loss: 0.4154, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [45/50], Step [214/469], Loss: 0.2308, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [215/469], Loss: 0.2056, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [45/50], Step [216/469], Loss: 0.2021, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [45/50], Step [217/469], Loss: 0.2421, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [45/50], Step [218/469], Loss: 0.4423, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [45/50], Step [219/469], Loss: 0.5064, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [45/50], Step [220/469], Loss: 0.2533, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [45/50], Step [221/469], Loss: 0.2779, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [45/50], Step [222/469], Loss: 0.2833, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [45/50], Step [223/469], Loss: 0.3799, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [45/50], Step [224/469], Loss: 0.4240, batch time: 0.50, accuracy:  82.81%\n",
      "Epoch [45/50], Step [225/469], Loss: 0.2030, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [45/50], Step [226/469], Loss: 0.3311, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [45/50], Step [227/469], Loss: 0.3161, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [45/50], Step [228/469], Loss: 0.2797, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [45/50], Step [229/469], Loss: 0.3941, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [45/50], Step [230/469], Loss: 0.2683, batch time: 0.59, accuracy:  93.75%\n",
      "Epoch [45/50], Step [231/469], Loss: 0.3092, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [45/50], Step [232/469], Loss: 0.3295, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [45/50], Step [233/469], Loss: 0.4493, batch time: 0.60, accuracy:  83.59%\n",
      "Epoch [45/50], Step [234/469], Loss: 0.3720, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [45/50], Step [235/469], Loss: 0.2876, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [45/50], Step [236/469], Loss: 0.2662, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [45/50], Step [237/469], Loss: 0.3406, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [45/50], Step [238/469], Loss: 0.3418, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [45/50], Step [239/469], Loss: 0.2489, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [45/50], Step [240/469], Loss: 0.3038, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [45/50], Step [241/469], Loss: 0.4219, batch time: 0.46, accuracy:  85.94%\n",
      "Epoch [45/50], Step [242/469], Loss: 0.3216, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [243/469], Loss: 0.3674, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [45/50], Step [244/469], Loss: 0.2638, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [45/50], Step [245/469], Loss: 0.4624, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [45/50], Step [246/469], Loss: 0.2833, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [45/50], Step [247/469], Loss: 0.2438, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [45/50], Step [248/469], Loss: 0.3561, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [249/469], Loss: 0.3538, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [45/50], Step [250/469], Loss: 0.2719, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [251/469], Loss: 0.2343, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [45/50], Step [252/469], Loss: 0.3317, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [45/50], Step [253/469], Loss: 0.3070, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [45/50], Step [254/469], Loss: 0.2368, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [45/50], Step [255/469], Loss: 0.2867, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [256/469], Loss: 0.2281, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [45/50], Step [257/469], Loss: 0.3467, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [45/50], Step [258/469], Loss: 0.3185, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [45/50], Step [259/469], Loss: 0.1660, batch time: 0.60, accuracy:  96.09%\n",
      "Epoch [45/50], Step [260/469], Loss: 0.3261, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [45/50], Step [261/469], Loss: 0.3806, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [45/50], Step [262/469], Loss: 0.3791, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [45/50], Step [263/469], Loss: 0.1299, batch time: 0.61, accuracy:  97.66%\n",
      "Epoch [45/50], Step [264/469], Loss: 0.2617, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [45/50], Step [265/469], Loss: 0.3330, batch time: 0.63, accuracy:  89.84%\n",
      "Epoch [45/50], Step [266/469], Loss: 0.2113, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [45/50], Step [267/469], Loss: 0.2943, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [45/50], Step [268/469], Loss: 0.1722, batch time: 0.58, accuracy:  97.66%\n",
      "Epoch [45/50], Step [269/469], Loss: 0.3607, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [45/50], Step [270/469], Loss: 0.2560, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [45/50], Step [271/469], Loss: 0.3304, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [45/50], Step [272/469], Loss: 0.3449, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [45/50], Step [273/469], Loss: 0.2363, batch time: 0.62, accuracy:  94.53%\n",
      "Epoch [45/50], Step [274/469], Loss: 0.1969, batch time: 0.59, accuracy:  93.75%\n",
      "Epoch [45/50], Step [275/469], Loss: 0.2338, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [45/50], Step [276/469], Loss: 0.3448, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [45/50], Step [277/469], Loss: 0.2200, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [45/50], Step [278/469], Loss: 0.2601, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [45/50], Step [279/469], Loss: 0.2906, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [45/50], Step [280/469], Loss: 0.4670, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [45/50], Step [281/469], Loss: 0.3474, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [45/50], Step [282/469], Loss: 0.1685, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [45/50], Step [283/469], Loss: 0.2816, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [45/50], Step [284/469], Loss: 0.1672, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [45/50], Step [285/469], Loss: 0.4148, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [45/50], Step [286/469], Loss: 0.2637, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [45/50], Step [287/469], Loss: 0.4166, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [45/50], Step [288/469], Loss: 0.2601, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [45/50], Step [289/469], Loss: 0.3583, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [45/50], Step [290/469], Loss: 0.2801, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [45/50], Step [291/469], Loss: 0.3927, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [45/50], Step [292/469], Loss: 0.3339, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [45/50], Step [293/469], Loss: 0.2814, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [45/50], Step [294/469], Loss: 0.3886, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [45/50], Step [295/469], Loss: 0.2018, batch time: 0.56, accuracy:  96.09%\n",
      "Epoch [45/50], Step [296/469], Loss: 0.1853, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [45/50], Step [297/469], Loss: 0.2974, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [45/50], Step [298/469], Loss: 0.2608, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [45/50], Step [299/469], Loss: 0.2837, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [45/50], Step [300/469], Loss: 0.3909, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [45/50], Step [301/469], Loss: 0.2698, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [302/469], Loss: 0.1990, batch time: 0.55, accuracy:  95.31%\n",
      "Epoch [45/50], Step [303/469], Loss: 0.2980, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [45/50], Step [304/469], Loss: 0.4807, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [45/50], Step [305/469], Loss: 0.4267, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [45/50], Step [306/469], Loss: 0.2068, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [307/469], Loss: 0.2381, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [45/50], Step [308/469], Loss: 0.2919, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [45/50], Step [309/469], Loss: 0.3277, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [45/50], Step [310/469], Loss: 0.3741, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [45/50], Step [311/469], Loss: 0.2690, batch time: 0.73, accuracy:  92.19%\n",
      "Epoch [45/50], Step [312/469], Loss: 0.2714, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [45/50], Step [313/469], Loss: 0.2091, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [45/50], Step [314/469], Loss: 0.2489, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [45/50], Step [315/469], Loss: 0.2588, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [45/50], Step [316/469], Loss: 0.3603, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [45/50], Step [317/469], Loss: 0.2424, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [45/50], Step [318/469], Loss: 0.2596, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [45/50], Step [319/469], Loss: 0.4849, batch time: 0.46, accuracy:  83.59%\n",
      "Epoch [45/50], Step [320/469], Loss: 0.2780, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [45/50], Step [321/469], Loss: 0.1811, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [45/50], Step [322/469], Loss: 0.3194, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [45/50], Step [323/469], Loss: 0.2808, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [45/50], Step [324/469], Loss: 0.3146, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [45/50], Step [325/469], Loss: 0.2250, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [45/50], Step [326/469], Loss: 0.3076, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [45/50], Step [327/469], Loss: 0.3655, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [45/50], Step [328/469], Loss: 0.4150, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [45/50], Step [329/469], Loss: 0.2406, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [45/50], Step [330/469], Loss: 0.4227, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [45/50], Step [331/469], Loss: 0.1568, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [45/50], Step [332/469], Loss: 0.2752, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [45/50], Step [333/469], Loss: 0.3114, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [45/50], Step [334/469], Loss: 0.3626, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [45/50], Step [335/469], Loss: 0.3182, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [45/50], Step [336/469], Loss: 0.2892, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [45/50], Step [337/469], Loss: 0.2492, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [45/50], Step [338/469], Loss: 0.3889, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [45/50], Step [339/469], Loss: 0.2323, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [45/50], Step [340/469], Loss: 0.2810, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [45/50], Step [341/469], Loss: 0.2802, batch time: 0.60, accuracy:  87.50%\n",
      "Epoch [45/50], Step [342/469], Loss: 0.1627, batch time: 0.72, accuracy:  93.75%\n",
      "Epoch [45/50], Step [343/469], Loss: 0.2816, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [344/469], Loss: 0.3256, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [45/50], Step [345/469], Loss: 0.2683, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [45/50], Step [346/469], Loss: 0.2358, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [45/50], Step [347/469], Loss: 0.2445, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [45/50], Step [348/469], Loss: 0.2922, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [45/50], Step [349/469], Loss: 0.1949, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [45/50], Step [350/469], Loss: 0.4756, batch time: 0.57, accuracy:  85.16%\n",
      "Epoch [45/50], Step [351/469], Loss: 0.3296, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [45/50], Step [352/469], Loss: 0.2216, batch time: 0.52, accuracy:  96.09%\n",
      "Epoch [45/50], Step [353/469], Loss: 0.4256, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [45/50], Step [354/469], Loss: 0.3392, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [45/50], Step [355/469], Loss: 0.1939, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [45/50], Step [356/469], Loss: 0.3718, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [45/50], Step [357/469], Loss: 0.2770, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [45/50], Step [358/469], Loss: 0.2708, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [45/50], Step [359/469], Loss: 0.3492, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [45/50], Step [360/469], Loss: 0.2996, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [45/50], Step [361/469], Loss: 0.1721, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [45/50], Step [362/469], Loss: 0.3733, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [45/50], Step [363/469], Loss: 0.1932, batch time: 0.52, accuracy:  95.31%\n",
      "Epoch [45/50], Step [364/469], Loss: 0.3343, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [45/50], Step [365/469], Loss: 0.3127, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [45/50], Step [366/469], Loss: 0.3790, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [45/50], Step [367/469], Loss: 0.3671, batch time: 0.58, accuracy:  88.28%\n",
      "Epoch [45/50], Step [368/469], Loss: 0.2164, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [45/50], Step [369/469], Loss: 0.2865, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [45/50], Step [370/469], Loss: 0.2273, batch time: 0.59, accuracy:  93.75%\n",
      "Epoch [45/50], Step [371/469], Loss: 0.3457, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [45/50], Step [372/469], Loss: 0.1687, batch time: 0.57, accuracy:  96.09%\n",
      "Epoch [45/50], Step [373/469], Loss: 0.3276, batch time: 0.71, accuracy:  91.41%\n",
      "Epoch [45/50], Step [374/469], Loss: 0.4111, batch time: 0.66, accuracy:  87.50%\n",
      "Epoch [45/50], Step [375/469], Loss: 0.2809, batch time: 0.62, accuracy:  92.97%\n",
      "Epoch [45/50], Step [376/469], Loss: 0.3814, batch time: 0.65, accuracy:  85.94%\n",
      "Epoch [45/50], Step [377/469], Loss: 0.2226, batch time: 0.65, accuracy:  92.97%\n",
      "Epoch [45/50], Step [378/469], Loss: 0.2406, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [45/50], Step [379/469], Loss: 0.2181, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [45/50], Step [380/469], Loss: 0.3462, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [45/50], Step [381/469], Loss: 0.2016, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [45/50], Step [382/469], Loss: 0.2827, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [45/50], Step [383/469], Loss: 0.3244, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [45/50], Step [384/469], Loss: 0.4324, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [45/50], Step [385/469], Loss: 0.2427, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [45/50], Step [386/469], Loss: 0.4011, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [45/50], Step [387/469], Loss: 0.2085, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [45/50], Step [388/469], Loss: 0.2386, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [45/50], Step [389/469], Loss: 0.1622, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [45/50], Step [390/469], Loss: 0.3499, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [45/50], Step [391/469], Loss: 0.2883, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [45/50], Step [392/469], Loss: 0.1826, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [45/50], Step [393/469], Loss: 0.2593, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [45/50], Step [394/469], Loss: 0.3891, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [45/50], Step [395/469], Loss: 0.2102, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [45/50], Step [396/469], Loss: 0.3155, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [45/50], Step [397/469], Loss: 0.2331, batch time: 0.49, accuracy:  95.31%\n",
      "Epoch [45/50], Step [398/469], Loss: 0.3529, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [45/50], Step [399/469], Loss: 0.2488, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [45/50], Step [400/469], Loss: 0.2675, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [45/50], Step [401/469], Loss: 0.2314, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [45/50], Step [402/469], Loss: 0.2359, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [45/50], Step [403/469], Loss: 0.2288, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [45/50], Step [404/469], Loss: 0.1528, batch time: 0.52, accuracy:  95.31%\n",
      "Epoch [45/50], Step [405/469], Loss: 0.2139, batch time: 0.61, accuracy:  95.31%\n",
      "Epoch [45/50], Step [406/469], Loss: 0.3675, batch time: 0.63, accuracy:  84.38%\n",
      "Epoch [45/50], Step [407/469], Loss: 0.3199, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [45/50], Step [408/469], Loss: 0.3544, batch time: 0.66, accuracy:  89.06%\n",
      "Epoch [45/50], Step [409/469], Loss: 0.1916, batch time: 0.67, accuracy:  96.88%\n",
      "Epoch [45/50], Step [410/469], Loss: 0.3918, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [45/50], Step [411/469], Loss: 0.3048, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [45/50], Step [412/469], Loss: 0.4193, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [45/50], Step [413/469], Loss: 0.2480, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [414/469], Loss: 0.2276, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [45/50], Step [415/469], Loss: 0.4003, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [45/50], Step [416/469], Loss: 0.2324, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [45/50], Step [417/469], Loss: 0.2275, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [45/50], Step [418/469], Loss: 0.2042, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [45/50], Step [419/469], Loss: 0.2428, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [45/50], Step [420/469], Loss: 0.4156, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [45/50], Step [421/469], Loss: 0.1519, batch time: 0.57, accuracy:  96.09%\n",
      "Epoch [45/50], Step [422/469], Loss: 0.3951, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [45/50], Step [423/469], Loss: 0.2245, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [45/50], Step [424/469], Loss: 0.1753, batch time: 0.46, accuracy:  96.09%\n",
      "Epoch [45/50], Step [425/469], Loss: 0.2384, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [45/50], Step [426/469], Loss: 0.2482, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [45/50], Step [427/469], Loss: 0.2162, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [45/50], Step [428/469], Loss: 0.3507, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [45/50], Step [429/469], Loss: 0.4408, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [45/50], Step [430/469], Loss: 0.2542, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [45/50], Step [431/469], Loss: 0.2367, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [45/50], Step [432/469], Loss: 0.3825, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [433/469], Loss: 0.2688, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [45/50], Step [434/469], Loss: 0.2803, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [45/50], Step [435/469], Loss: 0.3313, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [45/50], Step [436/469], Loss: 0.2123, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [45/50], Step [437/469], Loss: 0.3646, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [45/50], Step [438/469], Loss: 0.3602, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [45/50], Step [439/469], Loss: 0.1996, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [45/50], Step [440/469], Loss: 0.4248, batch time: 0.60, accuracy:  88.28%\n",
      "Epoch [45/50], Step [441/469], Loss: 0.5382, batch time: 0.55, accuracy:  85.16%\n",
      "Epoch [45/50], Step [442/469], Loss: 0.3166, batch time: 0.65, accuracy:  91.41%\n",
      "Epoch [45/50], Step [443/469], Loss: 0.3120, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [45/50], Step [444/469], Loss: 0.3719, batch time: 0.55, accuracy:  85.94%\n",
      "Epoch [45/50], Step [445/469], Loss: 0.2923, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [45/50], Step [446/469], Loss: 0.3950, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [45/50], Step [447/469], Loss: 0.2469, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [45/50], Step [448/469], Loss: 0.2561, batch time: 0.52, accuracy:  96.09%\n",
      "Epoch [45/50], Step [449/469], Loss: 0.4367, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [45/50], Step [450/469], Loss: 0.2597, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [45/50], Step [451/469], Loss: 0.2865, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [45/50], Step [452/469], Loss: 0.2146, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [45/50], Step [453/469], Loss: 0.2589, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [45/50], Step [454/469], Loss: 0.3203, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [45/50], Step [455/469], Loss: 0.2195, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [45/50], Step [456/469], Loss: 0.2092, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [45/50], Step [457/469], Loss: 0.1403, batch time: 0.50, accuracy:  97.66%\n",
      "Epoch [45/50], Step [458/469], Loss: 0.2527, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [45/50], Step [459/469], Loss: 0.3356, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [45/50], Step [460/469], Loss: 0.3275, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [45/50], Step [461/469], Loss: 0.2170, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [45/50], Step [462/469], Loss: 0.2228, batch time: 0.59, accuracy:  92.97%\n",
      "Epoch [45/50], Step [463/469], Loss: 0.2786, batch time: 0.58, accuracy:  91.41%\n",
      "Epoch [45/50], Step [464/469], Loss: 0.4156, batch time: 0.54, accuracy:  84.38%\n",
      "Epoch [45/50], Step [465/469], Loss: 0.3803, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [45/50], Step [466/469], Loss: 0.3647, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [45/50], Step [467/469], Loss: 0.3450, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [45/50], Step [468/469], Loss: 0.4250, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [45/50], Step [469/469], Loss: 0.3014, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [46/50], Step [1/469], Loss: 0.3558, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [46/50], Step [2/469], Loss: 0.3771, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [46/50], Step [3/469], Loss: 0.3130, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [46/50], Step [4/469], Loss: 0.2617, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [46/50], Step [5/469], Loss: 0.3346, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [46/50], Step [6/469], Loss: 0.2845, batch time: 0.62, accuracy:  91.41%\n",
      "Epoch [46/50], Step [7/469], Loss: 0.4173, batch time: 0.63, accuracy:  89.06%\n",
      "Epoch [46/50], Step [8/469], Loss: 0.2614, batch time: 0.65, accuracy:  90.62%\n",
      "Epoch [46/50], Step [9/469], Loss: 0.2313, batch time: 0.57, accuracy:  96.09%\n",
      "Epoch [46/50], Step [10/469], Loss: 0.3994, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [46/50], Step [11/469], Loss: 0.3022, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [46/50], Step [12/469], Loss: 0.2944, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [46/50], Step [13/469], Loss: 0.2577, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [46/50], Step [14/469], Loss: 0.2960, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [46/50], Step [15/469], Loss: 0.3182, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [46/50], Step [16/469], Loss: 0.4227, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [46/50], Step [17/469], Loss: 0.3102, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [46/50], Step [18/469], Loss: 0.3155, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [46/50], Step [19/469], Loss: 0.2786, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [46/50], Step [20/469], Loss: 0.2385, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [46/50], Step [21/469], Loss: 0.2108, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [46/50], Step [22/469], Loss: 0.2106, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [46/50], Step [23/469], Loss: 0.2953, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [46/50], Step [24/469], Loss: 0.1838, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [46/50], Step [25/469], Loss: 0.3668, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [46/50], Step [26/469], Loss: 0.3192, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [46/50], Step [27/469], Loss: 0.2292, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [46/50], Step [28/469], Loss: 0.4197, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [46/50], Step [29/469], Loss: 0.3155, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [46/50], Step [30/469], Loss: 0.2401, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [46/50], Step [31/469], Loss: 0.2923, batch time: 0.56, accuracy:  92.97%\n",
      "Epoch [46/50], Step [32/469], Loss: 0.2827, batch time: 0.57, accuracy:  89.06%\n",
      "Epoch [46/50], Step [33/469], Loss: 0.2614, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [46/50], Step [34/469], Loss: 0.3827, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [46/50], Step [35/469], Loss: 0.3690, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [46/50], Step [36/469], Loss: 0.3151, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [46/50], Step [37/469], Loss: 0.2827, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [46/50], Step [38/469], Loss: 0.2996, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [46/50], Step [39/469], Loss: 0.2246, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [46/50], Step [40/469], Loss: 0.3152, batch time: 0.71, accuracy:  90.62%\n",
      "Epoch [46/50], Step [41/469], Loss: 0.3140, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [46/50], Step [42/469], Loss: 0.2308, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [46/50], Step [43/469], Loss: 0.2646, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [46/50], Step [44/469], Loss: 0.2174, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [46/50], Step [45/469], Loss: 0.3020, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [46/50], Step [46/469], Loss: 0.1654, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [46/50], Step [47/469], Loss: 0.3926, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [46/50], Step [48/469], Loss: 0.4278, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [46/50], Step [49/469], Loss: 0.3429, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [46/50], Step [50/469], Loss: 0.2404, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [46/50], Step [51/469], Loss: 0.2353, batch time: 0.46, accuracy:  96.88%\n",
      "Epoch [46/50], Step [52/469], Loss: 0.2478, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [46/50], Step [53/469], Loss: 0.3244, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [54/469], Loss: 0.3898, batch time: 0.47, accuracy:  85.16%\n",
      "Epoch [46/50], Step [55/469], Loss: 0.3037, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [46/50], Step [56/469], Loss: 0.2855, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [46/50], Step [57/469], Loss: 0.2596, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [46/50], Step [58/469], Loss: 0.2418, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [46/50], Step [59/469], Loss: 0.2572, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [46/50], Step [60/469], Loss: 0.2460, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [46/50], Step [61/469], Loss: 0.2333, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [46/50], Step [62/469], Loss: 0.2247, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [46/50], Step [63/469], Loss: 0.2093, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [46/50], Step [64/469], Loss: 0.2559, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [46/50], Step [65/469], Loss: 0.1451, batch time: 0.53, accuracy:  95.31%\n",
      "Epoch [46/50], Step [66/469], Loss: 0.3114, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [46/50], Step [67/469], Loss: 0.2697, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [46/50], Step [68/469], Loss: 0.2321, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [46/50], Step [69/469], Loss: 0.2697, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [46/50], Step [70/469], Loss: 0.2425, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [46/50], Step [71/469], Loss: 0.1522, batch time: 0.63, accuracy:  96.09%\n",
      "Epoch [46/50], Step [72/469], Loss: 0.2199, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [46/50], Step [73/469], Loss: 0.2879, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [46/50], Step [74/469], Loss: 0.4627, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [46/50], Step [75/469], Loss: 0.2575, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [46/50], Step [76/469], Loss: 0.2476, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [46/50], Step [77/469], Loss: 0.2920, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [46/50], Step [78/469], Loss: 0.1873, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [46/50], Step [79/469], Loss: 0.2808, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [80/469], Loss: 0.2856, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [46/50], Step [81/469], Loss: 0.3399, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [46/50], Step [82/469], Loss: 0.3091, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [46/50], Step [83/469], Loss: 0.2549, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [46/50], Step [84/469], Loss: 0.1939, batch time: 0.46, accuracy:  96.09%\n",
      "Epoch [46/50], Step [85/469], Loss: 0.3419, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [46/50], Step [86/469], Loss: 0.2030, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [46/50], Step [87/469], Loss: 0.3166, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [46/50], Step [88/469], Loss: 0.3075, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [46/50], Step [89/469], Loss: 0.2934, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [46/50], Step [90/469], Loss: 0.3623, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [46/50], Step [91/469], Loss: 0.4648, batch time: 0.56, accuracy:  84.38%\n",
      "Epoch [46/50], Step [92/469], Loss: 0.2438, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [46/50], Step [93/469], Loss: 0.2238, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [46/50], Step [94/469], Loss: 0.2283, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [46/50], Step [95/469], Loss: 0.2952, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [46/50], Step [96/469], Loss: 0.2242, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [46/50], Step [97/469], Loss: 0.2181, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [46/50], Step [98/469], Loss: 0.2896, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [46/50], Step [99/469], Loss: 0.2439, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [46/50], Step [100/469], Loss: 0.3167, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [46/50], Step [101/469], Loss: 0.2552, batch time: 0.62, accuracy:  92.19%\n",
      "Epoch [46/50], Step [102/469], Loss: 0.2963, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [46/50], Step [103/469], Loss: 0.3898, batch time: 0.54, accuracy:  85.94%\n",
      "Epoch [46/50], Step [104/469], Loss: 0.4645, batch time: 0.58, accuracy:  84.38%\n",
      "Epoch [46/50], Step [105/469], Loss: 0.3903, batch time: 0.64, accuracy:  91.41%\n",
      "Epoch [46/50], Step [106/469], Loss: 0.4500, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [46/50], Step [107/469], Loss: 0.2519, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [46/50], Step [108/469], Loss: 0.2276, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [46/50], Step [109/469], Loss: 0.4063, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [46/50], Step [110/469], Loss: 0.2993, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [46/50], Step [111/469], Loss: 0.1951, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [46/50], Step [112/469], Loss: 0.1625, batch time: 0.47, accuracy:  96.88%\n",
      "Epoch [46/50], Step [113/469], Loss: 0.2678, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [46/50], Step [114/469], Loss: 0.4121, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [46/50], Step [115/469], Loss: 0.3158, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [46/50], Step [116/469], Loss: 0.4144, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [46/50], Step [117/469], Loss: 0.3619, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [46/50], Step [118/469], Loss: 0.2871, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [46/50], Step [119/469], Loss: 0.3399, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [46/50], Step [120/469], Loss: 0.2725, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [46/50], Step [121/469], Loss: 0.2648, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [46/50], Step [122/469], Loss: 0.3118, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [46/50], Step [123/469], Loss: 0.3830, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [46/50], Step [124/469], Loss: 0.1443, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [46/50], Step [125/469], Loss: 0.3155, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [46/50], Step [126/469], Loss: 0.2827, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [46/50], Step [127/469], Loss: 0.1762, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [46/50], Step [128/469], Loss: 0.2323, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [46/50], Step [129/469], Loss: 0.1537, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [46/50], Step [130/469], Loss: 0.1948, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [46/50], Step [131/469], Loss: 0.2086, batch time: 0.61, accuracy:  94.53%\n",
      "Epoch [46/50], Step [132/469], Loss: 0.2369, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [46/50], Step [133/469], Loss: 0.3494, batch time: 0.59, accuracy:  93.75%\n",
      "Epoch [46/50], Step [134/469], Loss: 0.5309, batch time: 0.59, accuracy:  86.72%\n",
      "Epoch [46/50], Step [135/469], Loss: 0.3232, batch time: 0.56, accuracy:  93.75%\n",
      "Epoch [46/50], Step [136/469], Loss: 0.2354, batch time: 0.77, accuracy:  92.19%\n",
      "Epoch [46/50], Step [137/469], Loss: 0.3067, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [46/50], Step [138/469], Loss: 0.2863, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [46/50], Step [139/469], Loss: 0.3492, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [46/50], Step [140/469], Loss: 0.2355, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [46/50], Step [141/469], Loss: 0.2423, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [46/50], Step [142/469], Loss: 0.3266, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [46/50], Step [143/469], Loss: 0.3953, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [46/50], Step [144/469], Loss: 0.2251, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [46/50], Step [145/469], Loss: 0.2397, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [46/50], Step [146/469], Loss: 0.3557, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [46/50], Step [147/469], Loss: 0.2605, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [46/50], Step [148/469], Loss: 0.3243, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [46/50], Step [149/469], Loss: 0.1958, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [46/50], Step [150/469], Loss: 0.2467, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [46/50], Step [151/469], Loss: 0.2491, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [46/50], Step [152/469], Loss: 0.2743, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [46/50], Step [153/469], Loss: 0.6052, batch time: 0.58, accuracy:  78.91%\n",
      "Epoch [46/50], Step [154/469], Loss: 0.2025, batch time: 0.47, accuracy:  96.09%\n",
      "Epoch [46/50], Step [155/469], Loss: 0.1533, batch time: 0.52, accuracy:  95.31%\n",
      "Epoch [46/50], Step [156/469], Loss: 0.2995, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [46/50], Step [157/469], Loss: 0.2152, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [46/50], Step [158/469], Loss: 0.2561, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [46/50], Step [159/469], Loss: 0.3141, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [46/50], Step [160/469], Loss: 0.2294, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [46/50], Step [161/469], Loss: 0.2388, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [46/50], Step [162/469], Loss: 0.3580, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [46/50], Step [163/469], Loss: 0.2679, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [46/50], Step [164/469], Loss: 0.2684, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [46/50], Step [165/469], Loss: 0.3571, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [46/50], Step [166/469], Loss: 0.2453, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [46/50], Step [167/469], Loss: 0.2427, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [46/50], Step [168/469], Loss: 0.2766, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [46/50], Step [169/469], Loss: 0.2190, batch time: 0.65, accuracy:  92.97%\n",
      "Epoch [46/50], Step [170/469], Loss: 0.4194, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [46/50], Step [171/469], Loss: 0.2233, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [46/50], Step [172/469], Loss: 0.1998, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [46/50], Step [173/469], Loss: 0.2971, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [46/50], Step [174/469], Loss: 0.2923, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [46/50], Step [175/469], Loss: 0.2469, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [46/50], Step [176/469], Loss: 0.2410, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [46/50], Step [177/469], Loss: 0.2787, batch time: 0.57, accuracy:  91.41%\n",
      "Epoch [46/50], Step [178/469], Loss: 0.4186, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [46/50], Step [179/469], Loss: 0.3067, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [46/50], Step [180/469], Loss: 0.2293, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [46/50], Step [181/469], Loss: 0.2010, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [46/50], Step [182/469], Loss: 0.1554, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [46/50], Step [183/469], Loss: 0.3913, batch time: 0.52, accuracy:  87.50%\n",
      "Epoch [46/50], Step [184/469], Loss: 0.3430, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [46/50], Step [185/469], Loss: 0.1278, batch time: 0.50, accuracy:  96.09%\n",
      "Epoch [46/50], Step [186/469], Loss: 0.3021, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [46/50], Step [187/469], Loss: 0.4024, batch time: 0.57, accuracy:  88.28%\n",
      "Epoch [46/50], Step [188/469], Loss: 0.2796, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [46/50], Step [189/469], Loss: 0.2591, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [46/50], Step [190/469], Loss: 0.2837, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [46/50], Step [191/469], Loss: 0.2242, batch time: 0.59, accuracy:  93.75%\n",
      "Epoch [46/50], Step [192/469], Loss: 0.2413, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [46/50], Step [193/469], Loss: 0.3558, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [46/50], Step [194/469], Loss: 0.2770, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [46/50], Step [195/469], Loss: 0.3349, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [46/50], Step [196/469], Loss: 0.2420, batch time: 0.58, accuracy:  92.97%\n",
      "Epoch [46/50], Step [197/469], Loss: 0.2121, batch time: 0.62, accuracy:  94.53%\n",
      "Epoch [46/50], Step [198/469], Loss: 0.2729, batch time: 0.65, accuracy:  92.97%\n",
      "Epoch [46/50], Step [199/469], Loss: 0.1620, batch time: 0.63, accuracy:  93.75%\n",
      "Epoch [46/50], Step [200/469], Loss: 0.3161, batch time: 0.64, accuracy:  87.50%\n",
      "Epoch [46/50], Step [201/469], Loss: 0.2164, batch time: 0.52, accuracy:  92.97%\n",
      "Epoch [46/50], Step [202/469], Loss: 0.3513, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [46/50], Step [203/469], Loss: 0.3938, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [46/50], Step [204/469], Loss: 0.2653, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [46/50], Step [205/469], Loss: 0.2954, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [206/469], Loss: 0.4008, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [46/50], Step [207/469], Loss: 0.2527, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [46/50], Step [208/469], Loss: 0.2873, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [46/50], Step [209/469], Loss: 0.2746, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [46/50], Step [210/469], Loss: 0.1967, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [46/50], Step [211/469], Loss: 0.2174, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [46/50], Step [212/469], Loss: 0.2896, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [46/50], Step [213/469], Loss: 0.3449, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [46/50], Step [214/469], Loss: 0.3301, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [46/50], Step [215/469], Loss: 0.2362, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [46/50], Step [216/469], Loss: 0.3003, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [46/50], Step [217/469], Loss: 0.3632, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [46/50], Step [218/469], Loss: 0.1807, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [46/50], Step [219/469], Loss: 0.2472, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [46/50], Step [220/469], Loss: 0.2149, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [46/50], Step [221/469], Loss: 0.2736, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [46/50], Step [222/469], Loss: 0.2998, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [46/50], Step [223/469], Loss: 0.2979, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [46/50], Step [224/469], Loss: 0.2879, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [46/50], Step [225/469], Loss: 0.2887, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [46/50], Step [226/469], Loss: 0.2774, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [46/50], Step [227/469], Loss: 0.4724, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [46/50], Step [228/469], Loss: 0.3383, batch time: 0.64, accuracy:  86.72%\n",
      "Epoch [46/50], Step [229/469], Loss: 0.1571, batch time: 0.56, accuracy:  96.09%\n",
      "Epoch [46/50], Step [230/469], Loss: 0.3714, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [46/50], Step [231/469], Loss: 0.1583, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [46/50], Step [232/469], Loss: 0.3943, batch time: 0.61, accuracy:  87.50%\n",
      "Epoch [46/50], Step [233/469], Loss: 0.3440, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [46/50], Step [234/469], Loss: 0.2957, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [46/50], Step [235/469], Loss: 0.4423, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [46/50], Step [236/469], Loss: 0.3177, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [46/50], Step [237/469], Loss: 0.4209, batch time: 0.49, accuracy:  85.16%\n",
      "Epoch [46/50], Step [238/469], Loss: 0.2563, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [46/50], Step [239/469], Loss: 0.2444, batch time: 0.60, accuracy:  93.75%\n",
      "Epoch [46/50], Step [240/469], Loss: 0.3339, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [46/50], Step [241/469], Loss: 0.2865, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [46/50], Step [242/469], Loss: 0.2003, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [46/50], Step [243/469], Loss: 0.4399, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [46/50], Step [244/469], Loss: 0.2705, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [46/50], Step [245/469], Loss: 0.2206, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [46/50], Step [246/469], Loss: 0.3275, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [46/50], Step [247/469], Loss: 0.2540, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [46/50], Step [248/469], Loss: 0.2527, batch time: 0.62, accuracy:  92.97%\n",
      "Epoch [46/50], Step [249/469], Loss: 0.4399, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [46/50], Step [250/469], Loss: 0.3001, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [46/50], Step [251/469], Loss: 0.2525, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [46/50], Step [252/469], Loss: 0.2756, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [46/50], Step [253/469], Loss: 0.5628, batch time: 0.48, accuracy:  83.59%\n",
      "Epoch [46/50], Step [254/469], Loss: 0.4550, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [46/50], Step [255/469], Loss: 0.2501, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [46/50], Step [256/469], Loss: 0.2493, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [46/50], Step [257/469], Loss: 0.2468, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [46/50], Step [258/469], Loss: 0.3022, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [46/50], Step [259/469], Loss: 0.3135, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [46/50], Step [260/469], Loss: 0.2321, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [46/50], Step [261/469], Loss: 0.3913, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [46/50], Step [262/469], Loss: 0.2186, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [46/50], Step [263/469], Loss: 0.1849, batch time: 0.47, accuracy:  96.88%\n",
      "Epoch [46/50], Step [264/469], Loss: 0.2916, batch time: 0.50, accuracy:  86.72%\n",
      "Epoch [46/50], Step [265/469], Loss: 0.3074, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [46/50], Step [266/469], Loss: 0.2835, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [46/50], Step [267/469], Loss: 0.3801, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [46/50], Step [268/469], Loss: 0.3595, batch time: 0.67, accuracy:  89.06%\n",
      "Epoch [46/50], Step [269/469], Loss: 0.2886, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [46/50], Step [270/469], Loss: 0.3190, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [46/50], Step [271/469], Loss: 0.2146, batch time: 0.53, accuracy:  96.88%\n",
      "Epoch [46/50], Step [272/469], Loss: 0.2725, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [46/50], Step [273/469], Loss: 0.2276, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [46/50], Step [274/469], Loss: 0.2747, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [46/50], Step [275/469], Loss: 0.2596, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [46/50], Step [276/469], Loss: 0.3736, batch time: 0.49, accuracy:  87.50%\n",
      "Epoch [46/50], Step [277/469], Loss: 0.3321, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [46/50], Step [278/469], Loss: 0.3170, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [46/50], Step [279/469], Loss: 0.3998, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [46/50], Step [280/469], Loss: 0.4484, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [46/50], Step [281/469], Loss: 0.2613, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [46/50], Step [282/469], Loss: 0.3056, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [46/50], Step [283/469], Loss: 0.2818, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [46/50], Step [284/469], Loss: 0.3193, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [46/50], Step [285/469], Loss: 0.2863, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [46/50], Step [286/469], Loss: 0.2396, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [46/50], Step [287/469], Loss: 0.3209, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [46/50], Step [288/469], Loss: 0.2343, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [46/50], Step [289/469], Loss: 0.2317, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [290/469], Loss: 0.3542, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [46/50], Step [291/469], Loss: 0.2391, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [46/50], Step [292/469], Loss: 0.2782, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [46/50], Step [293/469], Loss: 0.1850, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [46/50], Step [294/469], Loss: 0.1828, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [46/50], Step [295/469], Loss: 0.2201, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [46/50], Step [296/469], Loss: 0.4726, batch time: 0.51, accuracy:  84.38%\n",
      "Epoch [46/50], Step [297/469], Loss: 0.3115, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [46/50], Step [298/469], Loss: 0.3504, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [46/50], Step [299/469], Loss: 0.1826, batch time: 0.55, accuracy:  96.09%\n",
      "Epoch [46/50], Step [300/469], Loss: 0.2822, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [46/50], Step [301/469], Loss: 0.6116, batch time: 0.57, accuracy:  87.50%\n",
      "Epoch [46/50], Step [302/469], Loss: 0.2161, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [46/50], Step [303/469], Loss: 0.2526, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [46/50], Step [304/469], Loss: 0.2768, batch time: 0.62, accuracy:  90.62%\n",
      "Epoch [46/50], Step [305/469], Loss: 0.3046, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [306/469], Loss: 0.2139, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [46/50], Step [307/469], Loss: 0.1678, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [46/50], Step [308/469], Loss: 0.3083, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [46/50], Step [309/469], Loss: 0.2419, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [46/50], Step [310/469], Loss: 0.3963, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [46/50], Step [311/469], Loss: 0.3167, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [312/469], Loss: 0.2687, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [313/469], Loss: 0.3788, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [46/50], Step [314/469], Loss: 0.3514, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [46/50], Step [315/469], Loss: 0.3764, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [46/50], Step [316/469], Loss: 0.2657, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [46/50], Step [317/469], Loss: 0.3015, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [318/469], Loss: 0.3033, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [46/50], Step [319/469], Loss: 0.2451, batch time: 0.46, accuracy:  96.88%\n",
      "Epoch [46/50], Step [320/469], Loss: 0.4090, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [46/50], Step [321/469], Loss: 0.2987, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [322/469], Loss: 0.3229, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [46/50], Step [323/469], Loss: 0.1727, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [324/469], Loss: 0.3325, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [46/50], Step [325/469], Loss: 0.2977, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [46/50], Step [326/469], Loss: 0.2202, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [46/50], Step [327/469], Loss: 0.2104, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [46/50], Step [328/469], Loss: 0.3582, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [46/50], Step [329/469], Loss: 0.2716, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [46/50], Step [330/469], Loss: 0.2376, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [46/50], Step [331/469], Loss: 0.2522, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [46/50], Step [332/469], Loss: 0.2805, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [46/50], Step [333/469], Loss: 0.2033, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [46/50], Step [334/469], Loss: 0.2896, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [46/50], Step [335/469], Loss: 0.2788, batch time: 0.73, accuracy:  91.41%\n",
      "Epoch [46/50], Step [336/469], Loss: 0.2863, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [46/50], Step [337/469], Loss: 0.3352, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [46/50], Step [338/469], Loss: 0.3840, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [46/50], Step [339/469], Loss: 0.1611, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [46/50], Step [340/469], Loss: 0.2584, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [46/50], Step [341/469], Loss: 0.4841, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [46/50], Step [342/469], Loss: 0.3222, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [46/50], Step [343/469], Loss: 0.2601, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [46/50], Step [344/469], Loss: 0.2095, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [345/469], Loss: 0.3602, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [46/50], Step [346/469], Loss: 0.2045, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [46/50], Step [347/469], Loss: 0.3890, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [46/50], Step [348/469], Loss: 0.3563, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [46/50], Step [349/469], Loss: 0.2311, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [350/469], Loss: 0.1707, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [46/50], Step [351/469], Loss: 0.2551, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [46/50], Step [352/469], Loss: 0.3647, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [46/50], Step [353/469], Loss: 0.2961, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [46/50], Step [354/469], Loss: 0.4213, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [46/50], Step [355/469], Loss: 0.2354, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [356/469], Loss: 0.3243, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [46/50], Step [357/469], Loss: 0.2122, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [46/50], Step [358/469], Loss: 0.2404, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [359/469], Loss: 0.2564, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [46/50], Step [360/469], Loss: 0.2732, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [46/50], Step [361/469], Loss: 0.2644, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [46/50], Step [362/469], Loss: 0.1857, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [46/50], Step [363/469], Loss: 0.2730, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [46/50], Step [364/469], Loss: 0.3319, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [46/50], Step [365/469], Loss: 0.1756, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [46/50], Step [366/469], Loss: 0.3334, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [46/50], Step [367/469], Loss: 0.2297, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [46/50], Step [368/469], Loss: 0.2986, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [46/50], Step [369/469], Loss: 0.3648, batch time: 0.61, accuracy:  90.62%\n",
      "Epoch [46/50], Step [370/469], Loss: 0.2217, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [46/50], Step [371/469], Loss: 0.1542, batch time: 0.55, accuracy:  96.88%\n",
      "Epoch [46/50], Step [372/469], Loss: 0.2676, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [46/50], Step [373/469], Loss: 0.4816, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [46/50], Step [374/469], Loss: 0.2178, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [46/50], Step [375/469], Loss: 0.3508, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [46/50], Step [376/469], Loss: 0.2315, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [377/469], Loss: 0.3770, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [46/50], Step [378/469], Loss: 0.3732, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [379/469], Loss: 0.2656, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [46/50], Step [380/469], Loss: 0.1904, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [46/50], Step [381/469], Loss: 0.2998, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [46/50], Step [382/469], Loss: 0.2334, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [383/469], Loss: 0.2961, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [384/469], Loss: 0.1861, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [46/50], Step [385/469], Loss: 0.3730, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [46/50], Step [386/469], Loss: 0.2666, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [46/50], Step [387/469], Loss: 0.1903, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [46/50], Step [388/469], Loss: 0.3646, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [46/50], Step [389/469], Loss: 0.2093, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [46/50], Step [390/469], Loss: 0.2282, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [391/469], Loss: 0.3831, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [392/469], Loss: 0.4566, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [46/50], Step [393/469], Loss: 0.3448, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [46/50], Step [394/469], Loss: 0.3748, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [46/50], Step [395/469], Loss: 0.1933, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [396/469], Loss: 0.4319, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [46/50], Step [397/469], Loss: 0.1823, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [46/50], Step [398/469], Loss: 0.2862, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [46/50], Step [399/469], Loss: 0.4122, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [46/50], Step [400/469], Loss: 0.3183, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [46/50], Step [401/469], Loss: 0.4855, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [46/50], Step [402/469], Loss: 0.2122, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [46/50], Step [403/469], Loss: 0.1923, batch time: 0.51, accuracy:  96.09%\n",
      "Epoch [46/50], Step [404/469], Loss: 0.2880, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [46/50], Step [405/469], Loss: 0.3323, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [46/50], Step [406/469], Loss: 0.2608, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [46/50], Step [407/469], Loss: 0.2005, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [46/50], Step [408/469], Loss: 0.2243, batch time: 0.59, accuracy:  93.75%\n",
      "Epoch [46/50], Step [409/469], Loss: 0.4109, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [46/50], Step [410/469], Loss: 0.1604, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [46/50], Step [411/469], Loss: 0.2499, batch time: 0.57, accuracy:  95.31%\n",
      "Epoch [46/50], Step [412/469], Loss: 0.3736, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [46/50], Step [413/469], Loss: 0.2275, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [46/50], Step [414/469], Loss: 0.3058, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [46/50], Step [415/469], Loss: 0.3675, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [46/50], Step [416/469], Loss: 0.2843, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [46/50], Step [417/469], Loss: 0.2595, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [46/50], Step [418/469], Loss: 0.5850, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [46/50], Step [419/469], Loss: 0.3642, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [46/50], Step [420/469], Loss: 0.3503, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [46/50], Step [421/469], Loss: 0.3297, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [46/50], Step [422/469], Loss: 0.3015, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [46/50], Step [423/469], Loss: 0.3350, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [46/50], Step [424/469], Loss: 0.3088, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [46/50], Step [425/469], Loss: 0.2187, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [46/50], Step [426/469], Loss: 0.3624, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [46/50], Step [427/469], Loss: 0.2776, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [46/50], Step [428/469], Loss: 0.2328, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [429/469], Loss: 0.2433, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [46/50], Step [430/469], Loss: 0.2726, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [46/50], Step [431/469], Loss: 0.2420, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [46/50], Step [432/469], Loss: 0.3164, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [46/50], Step [433/469], Loss: 0.2450, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [46/50], Step [434/469], Loss: 0.2343, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [435/469], Loss: 0.2555, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [46/50], Step [436/469], Loss: 0.3373, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [46/50], Step [437/469], Loss: 0.2237, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [46/50], Step [438/469], Loss: 0.3337, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [46/50], Step [439/469], Loss: 0.2930, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [46/50], Step [440/469], Loss: 0.4513, batch time: 0.49, accuracy:  86.72%\n",
      "Epoch [46/50], Step [441/469], Loss: 0.2465, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [46/50], Step [442/469], Loss: 0.3155, batch time: 0.60, accuracy:  90.62%\n",
      "Epoch [46/50], Step [443/469], Loss: 0.2437, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [46/50], Step [444/469], Loss: 0.3690, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [46/50], Step [445/469], Loss: 0.1909, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [46/50], Step [446/469], Loss: 0.3566, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [46/50], Step [447/469], Loss: 0.3280, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [46/50], Step [448/469], Loss: 0.3004, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [46/50], Step [449/469], Loss: 0.4846, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [46/50], Step [450/469], Loss: 0.4720, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [46/50], Step [451/469], Loss: 0.3505, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [46/50], Step [452/469], Loss: 0.1620, batch time: 0.46, accuracy:  96.09%\n",
      "Epoch [46/50], Step [453/469], Loss: 0.3429, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [46/50], Step [454/469], Loss: 0.2352, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [46/50], Step [455/469], Loss: 0.4399, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [46/50], Step [456/469], Loss: 0.5450, batch time: 0.49, accuracy:  83.59%\n",
      "Epoch [46/50], Step [457/469], Loss: 0.2512, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [46/50], Step [458/469], Loss: 0.4028, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [46/50], Step [459/469], Loss: 0.2640, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [46/50], Step [460/469], Loss: 0.2421, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [46/50], Step [461/469], Loss: 0.2801, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [46/50], Step [462/469], Loss: 0.4734, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [46/50], Step [463/469], Loss: 0.2936, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [46/50], Step [464/469], Loss: 0.3613, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [46/50], Step [465/469], Loss: 0.3581, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [46/50], Step [466/469], Loss: 0.2520, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [46/50], Step [467/469], Loss: 0.2558, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [46/50], Step [468/469], Loss: 0.1752, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [46/50], Step [469/469], Loss: 0.2347, batch time: 0.50, accuracy:  92.71%\n",
      "Epoch [47/50], Step [1/469], Loss: 0.3069, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [47/50], Step [2/469], Loss: 0.3932, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [47/50], Step [3/469], Loss: 0.3691, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [47/50], Step [4/469], Loss: 0.2417, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [5/469], Loss: 0.2063, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [47/50], Step [6/469], Loss: 0.3316, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [47/50], Step [7/469], Loss: 0.2855, batch time: 1.04, accuracy:  91.41%\n",
      "Epoch [47/50], Step [8/469], Loss: 0.3352, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [9/469], Loss: 0.3324, batch time: 0.58, accuracy:  89.06%\n",
      "Epoch [47/50], Step [10/469], Loss: 0.3292, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [11/469], Loss: 0.2331, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [12/469], Loss: 0.2567, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [47/50], Step [13/469], Loss: 0.4882, batch time: 0.43, accuracy:  85.94%\n",
      "Epoch [47/50], Step [14/469], Loss: 0.2445, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [15/469], Loss: 0.3944, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [16/469], Loss: 0.2743, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [17/469], Loss: 0.2148, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [18/469], Loss: 0.2005, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [47/50], Step [19/469], Loss: 0.1100, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [47/50], Step [20/469], Loss: 0.3543, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [21/469], Loss: 0.2848, batch time: 0.43, accuracy:  95.31%\n",
      "Epoch [47/50], Step [22/469], Loss: 0.4256, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [23/469], Loss: 0.1815, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [24/469], Loss: 0.4829, batch time: 0.43, accuracy:  83.59%\n",
      "Epoch [47/50], Step [25/469], Loss: 0.2669, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [26/469], Loss: 0.3709, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [47/50], Step [27/469], Loss: 0.3700, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [47/50], Step [28/469], Loss: 0.3755, batch time: 0.51, accuracy:  87.50%\n",
      "Epoch [47/50], Step [29/469], Loss: 0.2470, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [30/469], Loss: 0.2672, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [31/469], Loss: 0.2527, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [47/50], Step [32/469], Loss: 0.3912, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [33/469], Loss: 0.2415, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [47/50], Step [34/469], Loss: 0.1935, batch time: 0.52, accuracy:  95.31%\n",
      "Epoch [47/50], Step [35/469], Loss: 0.2291, batch time: 0.65, accuracy:  95.31%\n",
      "Epoch [47/50], Step [36/469], Loss: 0.1283, batch time: 0.57, accuracy:  96.88%\n",
      "Epoch [47/50], Step [37/469], Loss: 0.3340, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [47/50], Step [38/469], Loss: 0.2250, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [39/469], Loss: 0.3045, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [40/469], Loss: 0.2948, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [41/469], Loss: 0.2877, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [42/469], Loss: 0.3877, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [43/469], Loss: 0.3267, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [44/469], Loss: 0.1894, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [45/469], Loss: 0.4195, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [46/469], Loss: 0.3172, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [47/469], Loss: 0.3806, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [47/50], Step [48/469], Loss: 0.2558, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [49/469], Loss: 0.2847, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [50/469], Loss: 0.3309, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [51/469], Loss: 0.1841, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [47/50], Step [52/469], Loss: 0.2589, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [47/50], Step [53/469], Loss: 0.1941, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [54/469], Loss: 0.4015, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [47/50], Step [55/469], Loss: 0.2176, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [56/469], Loss: 0.1686, batch time: 0.48, accuracy:  96.88%\n",
      "Epoch [47/50], Step [57/469], Loss: 0.3525, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [47/50], Step [58/469], Loss: 0.3942, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [59/469], Loss: 0.2158, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [47/50], Step [60/469], Loss: 0.2456, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [61/469], Loss: 0.3469, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [47/50], Step [62/469], Loss: 0.2392, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [47/50], Step [63/469], Loss: 0.1946, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [47/50], Step [64/469], Loss: 0.2652, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [47/50], Step [65/469], Loss: 0.5784, batch time: 0.64, accuracy:  86.72%\n",
      "Epoch [47/50], Step [66/469], Loss: 0.3476, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [47/50], Step [67/469], Loss: 0.3095, batch time: 0.61, accuracy:  88.28%\n",
      "Epoch [47/50], Step [68/469], Loss: 0.3927, batch time: 0.60, accuracy:  89.06%\n",
      "Epoch [47/50], Step [69/469], Loss: 0.3625, batch time: 0.64, accuracy:  89.84%\n",
      "Epoch [47/50], Step [70/469], Loss: 0.2929, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [47/50], Step [71/469], Loss: 0.2712, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [47/50], Step [72/469], Loss: 0.3877, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [73/469], Loss: 0.3173, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [74/469], Loss: 0.2351, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [75/469], Loss: 0.2556, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [76/469], Loss: 0.2128, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [47/50], Step [77/469], Loss: 0.4366, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [47/50], Step [78/469], Loss: 0.2433, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [47/50], Step [79/469], Loss: 0.2150, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [47/50], Step [80/469], Loss: 0.1093, batch time: 0.49, accuracy:  96.09%\n",
      "Epoch [47/50], Step [81/469], Loss: 0.3306, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [47/50], Step [82/469], Loss: 0.3053, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [47/50], Step [83/469], Loss: 0.3220, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [84/469], Loss: 0.2038, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [47/50], Step [85/469], Loss: 0.2149, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [47/50], Step [86/469], Loss: 0.3339, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [87/469], Loss: 0.3199, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [47/50], Step [88/469], Loss: 0.1684, batch time: 0.56, accuracy:  95.31%\n",
      "Epoch [47/50], Step [89/469], Loss: 0.2599, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [47/50], Step [90/469], Loss: 0.2766, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [47/50], Step [91/469], Loss: 0.3779, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [47/50], Step [92/469], Loss: 0.3405, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [47/50], Step [93/469], Loss: 0.3726, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [47/50], Step [94/469], Loss: 0.4533, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [47/50], Step [95/469], Loss: 0.2932, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [47/50], Step [96/469], Loss: 0.2425, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [97/469], Loss: 0.2314, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [47/50], Step [98/469], Loss: 0.2013, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [47/50], Step [99/469], Loss: 0.4598, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [47/50], Step [100/469], Loss: 0.2051, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [47/50], Step [101/469], Loss: 0.3190, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [47/50], Step [102/469], Loss: 0.3008, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [47/50], Step [103/469], Loss: 0.2603, batch time: 0.57, accuracy:  92.97%\n",
      "Epoch [47/50], Step [104/469], Loss: 0.1960, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [47/50], Step [105/469], Loss: 0.3119, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [47/50], Step [106/469], Loss: 0.3865, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [47/50], Step [107/469], Loss: 0.1900, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [47/50], Step [108/469], Loss: 0.3556, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [47/50], Step [109/469], Loss: 0.3849, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [47/50], Step [110/469], Loss: 0.2741, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [111/469], Loss: 0.4386, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [47/50], Step [112/469], Loss: 0.2630, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [113/469], Loss: 0.2603, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [114/469], Loss: 0.2128, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [115/469], Loss: 0.2673, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [47/50], Step [116/469], Loss: 0.4259, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [117/469], Loss: 0.4724, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [118/469], Loss: 0.3864, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [47/50], Step [119/469], Loss: 0.2774, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [47/50], Step [120/469], Loss: 0.2429, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [121/469], Loss: 0.4527, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [47/50], Step [122/469], Loss: 0.4565, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [47/50], Step [123/469], Loss: 0.2797, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [124/469], Loss: 0.2810, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [47/50], Step [125/469], Loss: 0.3193, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [126/469], Loss: 0.2410, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [47/50], Step [127/469], Loss: 0.3773, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [128/469], Loss: 0.3196, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [129/469], Loss: 0.3529, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [47/50], Step [130/469], Loss: 0.1864, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [47/50], Step [131/469], Loss: 0.1880, batch time: 0.66, accuracy:  92.97%\n",
      "Epoch [47/50], Step [132/469], Loss: 0.3298, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [133/469], Loss: 0.3238, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [134/469], Loss: 0.2158, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [135/469], Loss: 0.3840, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [136/469], Loss: 0.3808, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [47/50], Step [137/469], Loss: 0.3627, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [47/50], Step [138/469], Loss: 0.2516, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [139/469], Loss: 0.3907, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [47/50], Step [140/469], Loss: 0.3041, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [47/50], Step [141/469], Loss: 0.2769, batch time: 0.57, accuracy:  92.19%\n",
      "Epoch [47/50], Step [142/469], Loss: 0.3535, batch time: 0.65, accuracy:  87.50%\n",
      "Epoch [47/50], Step [143/469], Loss: 0.3777, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [47/50], Step [144/469], Loss: 0.2184, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [47/50], Step [145/469], Loss: 0.2924, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [146/469], Loss: 0.2184, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [47/50], Step [147/469], Loss: 0.2961, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [148/469], Loss: 0.1873, batch time: 0.43, accuracy:  95.31%\n",
      "Epoch [47/50], Step [149/469], Loss: 0.4158, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [47/50], Step [150/469], Loss: 0.1924, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [47/50], Step [151/469], Loss: 0.2936, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [152/469], Loss: 0.2671, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [153/469], Loss: 0.2772, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [154/469], Loss: 0.3647, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [155/469], Loss: 0.1962, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [47/50], Step [156/469], Loss: 0.2621, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [157/469], Loss: 0.2420, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [158/469], Loss: 0.3701, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [159/469], Loss: 0.1981, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [160/469], Loss: 0.2606, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [161/469], Loss: 0.2366, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [162/469], Loss: 0.3139, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [163/469], Loss: 0.3780, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [47/50], Step [164/469], Loss: 0.2878, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [165/469], Loss: 0.2635, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [47/50], Step [166/469], Loss: 0.3352, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [47/50], Step [167/469], Loss: 0.2530, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [47/50], Step [168/469], Loss: 0.1475, batch time: 0.50, accuracy:  95.31%\n",
      "Epoch [47/50], Step [169/469], Loss: 0.2486, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [47/50], Step [170/469], Loss: 0.2572, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [47/50], Step [171/469], Loss: 0.2748, batch time: 0.56, accuracy:  89.84%\n",
      "Epoch [47/50], Step [172/469], Loss: 0.3324, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [47/50], Step [173/469], Loss: 0.2070, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [47/50], Step [174/469], Loss: 0.3751, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [47/50], Step [175/469], Loss: 0.1979, batch time: 0.70, accuracy:  93.75%\n",
      "Epoch [47/50], Step [176/469], Loss: 0.2859, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [47/50], Step [177/469], Loss: 0.2239, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [47/50], Step [178/469], Loss: 0.2509, batch time: 0.52, accuracy:  88.28%\n",
      "Epoch [47/50], Step [179/469], Loss: 0.1962, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [47/50], Step [180/469], Loss: 0.2412, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [47/50], Step [181/469], Loss: 0.3025, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [182/469], Loss: 0.2191, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [183/469], Loss: 0.2757, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [184/469], Loss: 0.1816, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [185/469], Loss: 0.5228, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [186/469], Loss: 0.3163, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [187/469], Loss: 0.2253, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [188/469], Loss: 0.2836, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [189/469], Loss: 0.2729, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [190/469], Loss: 0.3474, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [47/50], Step [191/469], Loss: 0.3097, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [47/50], Step [192/469], Loss: 0.2183, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [193/469], Loss: 0.2601, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [194/469], Loss: 0.2947, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [47/50], Step [195/469], Loss: 0.4015, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [47/50], Step [196/469], Loss: 0.4087, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [47/50], Step [197/469], Loss: 0.3098, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [198/469], Loss: 0.1519, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [47/50], Step [199/469], Loss: 0.2281, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [47/50], Step [200/469], Loss: 0.3442, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [201/469], Loss: 0.2483, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [47/50], Step [202/469], Loss: 0.3616, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [203/469], Loss: 0.1891, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [47/50], Step [204/469], Loss: 0.3355, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [47/50], Step [205/469], Loss: 0.3870, batch time: 0.50, accuracy:  85.94%\n",
      "Epoch [47/50], Step [206/469], Loss: 0.4871, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [47/50], Step [207/469], Loss: 0.3567, batch time: 0.59, accuracy:  87.50%\n",
      "Epoch [47/50], Step [208/469], Loss: 0.1961, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [47/50], Step [209/469], Loss: 0.2676, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [47/50], Step [210/469], Loss: 0.3408, batch time: 0.58, accuracy:  90.62%\n",
      "Epoch [47/50], Step [211/469], Loss: 0.3152, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [47/50], Step [212/469], Loss: 0.3580, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [47/50], Step [213/469], Loss: 0.3178, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [214/469], Loss: 0.2369, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [47/50], Step [215/469], Loss: 0.4597, batch time: 0.46, accuracy:  85.16%\n",
      "Epoch [47/50], Step [216/469], Loss: 0.1629, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [47/50], Step [217/469], Loss: 0.2940, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [218/469], Loss: 0.3919, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [47/50], Step [219/469], Loss: 0.2959, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [47/50], Step [220/469], Loss: 0.2731, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [221/469], Loss: 0.3014, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [222/469], Loss: 0.2165, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [223/469], Loss: 0.2612, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [224/469], Loss: 0.2736, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [47/50], Step [225/469], Loss: 0.3031, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [47/50], Step [226/469], Loss: 0.2330, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [227/469], Loss: 0.2953, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [228/469], Loss: 0.3091, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [229/469], Loss: 0.2162, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [230/469], Loss: 0.3909, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [47/50], Step [231/469], Loss: 0.2395, batch time: 0.48, accuracy:  95.31%\n",
      "Epoch [47/50], Step [232/469], Loss: 0.3211, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [47/50], Step [233/469], Loss: 0.3152, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [47/50], Step [234/469], Loss: 0.2654, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [47/50], Step [235/469], Loss: 0.4472, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [47/50], Step [236/469], Loss: 0.2164, batch time: 0.53, accuracy:  96.09%\n",
      "Epoch [47/50], Step [237/469], Loss: 0.3224, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [47/50], Step [238/469], Loss: 0.3977, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [47/50], Step [239/469], Loss: 0.2771, batch time: 0.85, accuracy:  94.53%\n",
      "Epoch [47/50], Step [240/469], Loss: 0.2399, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [47/50], Step [241/469], Loss: 0.4120, batch time: 0.51, accuracy:  86.72%\n",
      "Epoch [47/50], Step [242/469], Loss: 0.2530, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [47/50], Step [243/469], Loss: 0.1375, batch time: 0.48, accuracy:  96.09%\n",
      "Epoch [47/50], Step [244/469], Loss: 0.2661, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [245/469], Loss: 0.1668, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [47/50], Step [246/469], Loss: 0.2709, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [47/50], Step [247/469], Loss: 0.2296, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [47/50], Step [248/469], Loss: 0.3328, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [47/50], Step [249/469], Loss: 0.1959, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [47/50], Step [250/469], Loss: 0.3535, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [47/50], Step [251/469], Loss: 0.3644, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [47/50], Step [252/469], Loss: 0.1946, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [253/469], Loss: 0.3693, batch time: 0.65, accuracy:  89.06%\n",
      "Epoch [47/50], Step [254/469], Loss: 0.3333, batch time: 0.48, accuracy:  89.84%\n",
      "Epoch [47/50], Step [255/469], Loss: 0.3895, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [47/50], Step [256/469], Loss: 0.1455, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [47/50], Step [257/469], Loss: 0.2519, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [47/50], Step [258/469], Loss: 0.1676, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [47/50], Step [259/469], Loss: 0.3199, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [47/50], Step [260/469], Loss: 0.2616, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [261/469], Loss: 0.2150, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [47/50], Step [262/469], Loss: 0.3077, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [47/50], Step [263/469], Loss: 0.2497, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [47/50], Step [264/469], Loss: 0.1706, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [265/469], Loss: 0.2850, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [266/469], Loss: 0.5127, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [47/50], Step [267/469], Loss: 0.2663, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [47/50], Step [268/469], Loss: 0.3259, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [47/50], Step [269/469], Loss: 0.3262, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [47/50], Step [270/469], Loss: 0.2158, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [47/50], Step [271/469], Loss: 0.2626, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [47/50], Step [272/469], Loss: 0.3823, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [47/50], Step [273/469], Loss: 0.3802, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [274/469], Loss: 0.2487, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [47/50], Step [275/469], Loss: 0.5122, batch time: 0.44, accuracy:  84.38%\n",
      "Epoch [47/50], Step [276/469], Loss: 0.2648, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [47/50], Step [277/469], Loss: 0.2628, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [47/50], Step [278/469], Loss: 0.4414, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [47/50], Step [279/469], Loss: 0.3037, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [280/469], Loss: 0.4102, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [281/469], Loss: 0.3490, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [47/50], Step [282/469], Loss: 0.2949, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [47/50], Step [283/469], Loss: 0.3400, batch time: 0.48, accuracy:  86.72%\n",
      "Epoch [47/50], Step [284/469], Loss: 0.3743, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [47/50], Step [285/469], Loss: 0.3072, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [47/50], Step [286/469], Loss: 0.2959, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [47/50], Step [287/469], Loss: 0.2246, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [288/469], Loss: 0.2183, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [289/469], Loss: 0.2852, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [47/50], Step [290/469], Loss: 0.2492, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [47/50], Step [291/469], Loss: 0.2899, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [47/50], Step [292/469], Loss: 0.3815, batch time: 0.47, accuracy:  85.94%\n",
      "Epoch [47/50], Step [293/469], Loss: 0.3130, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [294/469], Loss: 0.4376, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [47/50], Step [295/469], Loss: 0.2035, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [296/469], Loss: 0.2590, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [297/469], Loss: 0.2617, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [298/469], Loss: 0.3292, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [299/469], Loss: 0.2509, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [47/50], Step [300/469], Loss: 0.2367, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [47/50], Step [301/469], Loss: 0.3000, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [47/50], Step [302/469], Loss: 0.3043, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [47/50], Step [303/469], Loss: 0.4355, batch time: 0.65, accuracy:  86.72%\n",
      "Epoch [47/50], Step [304/469], Loss: 0.2610, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [305/469], Loss: 0.2719, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [47/50], Step [306/469], Loss: 0.2120, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [307/469], Loss: 0.4466, batch time: 0.43, accuracy:  85.16%\n",
      "Epoch [47/50], Step [308/469], Loss: 0.4147, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [309/469], Loss: 0.2276, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [310/469], Loss: 0.2275, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [47/50], Step [311/469], Loss: 0.4248, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [47/50], Step [312/469], Loss: 0.3817, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [47/50], Step [313/469], Loss: 0.2599, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [47/50], Step [314/469], Loss: 0.2139, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [315/469], Loss: 0.2906, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [47/50], Step [316/469], Loss: 0.3402, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [317/469], Loss: 0.2733, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [47/50], Step [318/469], Loss: 0.1792, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [47/50], Step [319/469], Loss: 0.2153, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [47/50], Step [320/469], Loss: 0.2809, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [47/50], Step [321/469], Loss: 0.2882, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [47/50], Step [322/469], Loss: 0.2555, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [47/50], Step [323/469], Loss: 0.3626, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [47/50], Step [324/469], Loss: 0.2168, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [325/469], Loss: 0.2197, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [326/469], Loss: 0.3844, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [47/50], Step [327/469], Loss: 0.2258, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [328/469], Loss: 0.1974, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [47/50], Step [329/469], Loss: 0.3094, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [47/50], Step [330/469], Loss: 0.2931, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [331/469], Loss: 0.2044, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [47/50], Step [332/469], Loss: 0.2874, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [47/50], Step [333/469], Loss: 0.2504, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [47/50], Step [334/469], Loss: 0.2256, batch time: 0.53, accuracy:  95.31%\n",
      "Epoch [47/50], Step [335/469], Loss: 0.3174, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [47/50], Step [336/469], Loss: 0.3903, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [47/50], Step [337/469], Loss: 0.4072, batch time: 0.55, accuracy:  89.06%\n",
      "Epoch [47/50], Step [338/469], Loss: 0.3291, batch time: 0.61, accuracy:  92.19%\n",
      "Epoch [47/50], Step [339/469], Loss: 0.1772, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [47/50], Step [340/469], Loss: 0.2871, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [47/50], Step [341/469], Loss: 0.2701, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [342/469], Loss: 0.3459, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [47/50], Step [343/469], Loss: 0.2042, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [47/50], Step [344/469], Loss: 0.2476, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [47/50], Step [345/469], Loss: 0.2888, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [47/50], Step [346/469], Loss: 0.1902, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [47/50], Step [347/469], Loss: 0.3034, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [47/50], Step [348/469], Loss: 0.3254, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [47/50], Step [349/469], Loss: 0.3288, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [350/469], Loss: 0.1801, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [47/50], Step [351/469], Loss: 0.2548, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [47/50], Step [352/469], Loss: 0.4055, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [47/50], Step [353/469], Loss: 0.2164, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [47/50], Step [354/469], Loss: 0.4035, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [47/50], Step [355/469], Loss: 0.3283, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [356/469], Loss: 0.2114, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [47/50], Step [357/469], Loss: 0.1669, batch time: 0.46, accuracy:  96.88%\n",
      "Epoch [47/50], Step [358/469], Loss: 0.3873, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [359/469], Loss: 0.3121, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [360/469], Loss: 0.2539, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [361/469], Loss: 0.3808, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [362/469], Loss: 0.3937, batch time: 0.48, accuracy:  87.50%\n",
      "Epoch [47/50], Step [363/469], Loss: 0.1978, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [47/50], Step [364/469], Loss: 0.2657, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [47/50], Step [365/469], Loss: 0.2272, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [47/50], Step [366/469], Loss: 0.3436, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [47/50], Step [367/469], Loss: 0.2650, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [368/469], Loss: 0.1591, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [369/469], Loss: 0.3200, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [47/50], Step [370/469], Loss: 0.2275, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [47/50], Step [371/469], Loss: 0.2203, batch time: 0.61, accuracy:  92.97%\n",
      "Epoch [47/50], Step [372/469], Loss: 0.2551, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [47/50], Step [373/469], Loss: 0.1577, batch time: 0.54, accuracy:  96.09%\n",
      "Epoch [47/50], Step [374/469], Loss: 0.3285, batch time: 0.80, accuracy:  91.41%\n",
      "Epoch [47/50], Step [375/469], Loss: 0.3165, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [47/50], Step [376/469], Loss: 0.2327, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [47/50], Step [377/469], Loss: 0.2485, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [378/469], Loss: 0.2537, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [47/50], Step [379/469], Loss: 0.2990, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [380/469], Loss: 0.2919, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [47/50], Step [381/469], Loss: 0.2688, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [382/469], Loss: 0.2817, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [383/469], Loss: 0.3100, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [384/469], Loss: 0.3409, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [385/469], Loss: 0.3149, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [386/469], Loss: 0.3151, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [387/469], Loss: 0.3559, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [47/50], Step [388/469], Loss: 0.1866, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [389/469], Loss: 0.2291, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [47/50], Step [390/469], Loss: 0.3283, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [391/469], Loss: 0.2169, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [47/50], Step [392/469], Loss: 0.3190, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [393/469], Loss: 0.3851, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [47/50], Step [394/469], Loss: 0.2653, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [395/469], Loss: 0.2730, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [47/50], Step [396/469], Loss: 0.1487, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [47/50], Step [397/469], Loss: 0.2338, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [398/469], Loss: 0.3005, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [399/469], Loss: 0.2778, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [47/50], Step [400/469], Loss: 0.2351, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [47/50], Step [401/469], Loss: 0.4682, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [47/50], Step [402/469], Loss: 0.3203, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [47/50], Step [403/469], Loss: 0.2730, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [47/50], Step [404/469], Loss: 0.1954, batch time: 0.54, accuracy:  96.09%\n",
      "Epoch [47/50], Step [405/469], Loss: 0.2744, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [47/50], Step [406/469], Loss: 0.2300, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [47/50], Step [407/469], Loss: 0.2491, batch time: 0.65, accuracy:  90.62%\n",
      "Epoch [47/50], Step [408/469], Loss: 0.3338, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [47/50], Step [409/469], Loss: 0.2671, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [410/469], Loss: 0.1563, batch time: 0.47, accuracy:  95.31%\n",
      "Epoch [47/50], Step [411/469], Loss: 0.3492, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [47/50], Step [412/469], Loss: 0.2796, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [47/50], Step [413/469], Loss: 0.2638, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [47/50], Step [414/469], Loss: 0.1765, batch time: 0.50, accuracy:  96.88%\n",
      "Epoch [47/50], Step [415/469], Loss: 0.2407, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [416/469], Loss: 0.2816, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [47/50], Step [417/469], Loss: 0.2156, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [47/50], Step [418/469], Loss: 0.5164, batch time: 0.43, accuracy:  87.50%\n",
      "Epoch [47/50], Step [419/469], Loss: 0.2662, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [420/469], Loss: 0.2476, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [421/469], Loss: 0.2188, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [422/469], Loss: 0.2275, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [47/50], Step [423/469], Loss: 0.3437, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [47/50], Step [424/469], Loss: 0.3149, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [425/469], Loss: 0.2013, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [47/50], Step [426/469], Loss: 0.1625, batch time: 0.43, accuracy:  96.09%\n",
      "Epoch [47/50], Step [427/469], Loss: 0.3331, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [47/50], Step [428/469], Loss: 0.3438, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [47/50], Step [429/469], Loss: 0.2483, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [430/469], Loss: 0.2047, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [47/50], Step [431/469], Loss: 0.2747, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [432/469], Loss: 0.3149, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [433/469], Loss: 0.2377, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [434/469], Loss: 0.1618, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [47/50], Step [435/469], Loss: 0.2218, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [47/50], Step [436/469], Loss: 0.3213, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [47/50], Step [437/469], Loss: 0.3061, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [47/50], Step [438/469], Loss: 0.3211, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [47/50], Step [439/469], Loss: 0.3269, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [47/50], Step [440/469], Loss: 0.2989, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [47/50], Step [441/469], Loss: 0.2622, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [47/50], Step [442/469], Loss: 0.2818, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [47/50], Step [443/469], Loss: 0.1912, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [47/50], Step [444/469], Loss: 0.3686, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [47/50], Step [445/469], Loss: 0.3472, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [47/50], Step [446/469], Loss: 0.4052, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [47/50], Step [447/469], Loss: 0.2342, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [47/50], Step [448/469], Loss: 0.2705, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [449/469], Loss: 0.3117, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [47/50], Step [450/469], Loss: 0.1588, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [47/50], Step [451/469], Loss: 0.2412, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [47/50], Step [452/469], Loss: 0.1825, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [47/50], Step [453/469], Loss: 0.2334, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [47/50], Step [454/469], Loss: 0.2166, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [47/50], Step [455/469], Loss: 0.2841, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [47/50], Step [456/469], Loss: 0.3025, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [47/50], Step [457/469], Loss: 0.3252, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [47/50], Step [458/469], Loss: 0.3169, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [47/50], Step [459/469], Loss: 0.2834, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [460/469], Loss: 0.2631, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [47/50], Step [461/469], Loss: 0.3108, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [47/50], Step [462/469], Loss: 0.1807, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [47/50], Step [463/469], Loss: 0.2621, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [47/50], Step [464/469], Loss: 0.2340, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [47/50], Step [465/469], Loss: 0.2632, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [47/50], Step [466/469], Loss: 0.3343, batch time: 0.53, accuracy:  87.50%\n",
      "Epoch [47/50], Step [467/469], Loss: 0.3587, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [47/50], Step [468/469], Loss: 0.2631, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [47/50], Step [469/469], Loss: 0.2823, batch time: 0.44, accuracy:  92.71%\n",
      "Epoch [48/50], Step [1/469], Loss: 0.3932, batch time: 0.53, accuracy:  86.72%\n",
      "Epoch [48/50], Step [2/469], Loss: 0.2621, batch time: 0.56, accuracy:  95.31%\n",
      "Epoch [48/50], Step [3/469], Loss: 0.2626, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [48/50], Step [4/469], Loss: 0.2692, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [48/50], Step [5/469], Loss: 0.3229, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [48/50], Step [6/469], Loss: 0.3531, batch time: 0.70, accuracy:  89.06%\n",
      "Epoch [48/50], Step [7/469], Loss: 0.1766, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [48/50], Step [8/469], Loss: 0.3450, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [9/469], Loss: 0.4159, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [10/469], Loss: 0.4577, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [48/50], Step [11/469], Loss: 0.2654, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [48/50], Step [12/469], Loss: 0.1996, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [13/469], Loss: 0.1922, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [14/469], Loss: 0.3299, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [48/50], Step [15/469], Loss: 0.2571, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [48/50], Step [16/469], Loss: 0.3127, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [48/50], Step [17/469], Loss: 0.2580, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [48/50], Step [18/469], Loss: 0.1859, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [48/50], Step [19/469], Loss: 0.2996, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [48/50], Step [20/469], Loss: 0.2778, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [21/469], Loss: 0.3199, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [48/50], Step [22/469], Loss: 0.2168, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [23/469], Loss: 0.2187, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [48/50], Step [24/469], Loss: 0.2887, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [48/50], Step [25/469], Loss: 0.3240, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [48/50], Step [26/469], Loss: 0.2770, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [48/50], Step [27/469], Loss: 0.1993, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [28/469], Loss: 0.2949, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [48/50], Step [29/469], Loss: 0.2998, batch time: 0.63, accuracy:  88.28%\n",
      "Epoch [48/50], Step [30/469], Loss: 0.2687, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [48/50], Step [31/469], Loss: 0.2674, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [48/50], Step [32/469], Loss: 0.1866, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [48/50], Step [33/469], Loss: 0.4587, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [34/469], Loss: 0.2613, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [48/50], Step [35/469], Loss: 0.2671, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [36/469], Loss: 0.2899, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [37/469], Loss: 0.2619, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [48/50], Step [38/469], Loss: 0.3161, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [48/50], Step [39/469], Loss: 0.2696, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [48/50], Step [40/469], Loss: 0.3600, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [48/50], Step [41/469], Loss: 0.3317, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [48/50], Step [42/469], Loss: 0.2411, batch time: 0.64, accuracy:  92.19%\n",
      "Epoch [48/50], Step [43/469], Loss: 0.1643, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [48/50], Step [44/469], Loss: 0.3107, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [48/50], Step [45/469], Loss: 0.2945, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [46/469], Loss: 0.3076, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [48/50], Step [47/469], Loss: 0.2111, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [48/50], Step [48/469], Loss: 0.3793, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [49/469], Loss: 0.2585, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [50/469], Loss: 0.3209, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [48/50], Step [51/469], Loss: 0.3217, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [48/50], Step [52/469], Loss: 0.3115, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [48/50], Step [53/469], Loss: 0.1663, batch time: 0.45, accuracy:  96.88%\n",
      "Epoch [48/50], Step [54/469], Loss: 0.2837, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [48/50], Step [55/469], Loss: 0.2105, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [48/50], Step [56/469], Loss: 0.3464, batch time: 0.43, accuracy:  95.31%\n",
      "Epoch [48/50], Step [57/469], Loss: 0.2254, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [58/469], Loss: 0.4106, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [48/50], Step [59/469], Loss: 0.3186, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [48/50], Step [60/469], Loss: 0.3067, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [48/50], Step [61/469], Loss: 0.1288, batch time: 0.49, accuracy:  97.66%\n",
      "Epoch [48/50], Step [62/469], Loss: 0.3931, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [48/50], Step [63/469], Loss: 0.2226, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [48/50], Step [64/469], Loss: 0.2350, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [65/469], Loss: 0.2815, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [48/50], Step [66/469], Loss: 0.3165, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [67/469], Loss: 0.1523, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [48/50], Step [68/469], Loss: 0.1790, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [69/469], Loss: 0.2905, batch time: 0.48, accuracy:  92.97%\n",
      "Epoch [48/50], Step [70/469], Loss: 0.3846, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [48/50], Step [71/469], Loss: 0.2826, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [72/469], Loss: 0.2178, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [73/469], Loss: 0.3276, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [48/50], Step [74/469], Loss: 0.1427, batch time: 0.55, accuracy:  96.09%\n",
      "Epoch [48/50], Step [75/469], Loss: 0.3818, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [48/50], Step [76/469], Loss: 0.2259, batch time: 0.55, accuracy:  94.53%\n",
      "Epoch [48/50], Step [77/469], Loss: 0.3506, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [48/50], Step [78/469], Loss: 0.2985, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [48/50], Step [79/469], Loss: 0.3492, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [48/50], Step [80/469], Loss: 0.2598, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [48/50], Step [81/469], Loss: 0.2428, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [48/50], Step [82/469], Loss: 0.1693, batch time: 0.57, accuracy:  94.53%\n",
      "Epoch [48/50], Step [83/469], Loss: 0.2371, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [84/469], Loss: 0.2976, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [85/469], Loss: 0.2954, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [86/469], Loss: 0.3462, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [87/469], Loss: 0.3156, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [88/469], Loss: 0.2718, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [89/469], Loss: 0.3886, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [90/469], Loss: 0.3074, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [91/469], Loss: 0.1963, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [92/469], Loss: 0.3120, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [93/469], Loss: 0.2836, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [94/469], Loss: 0.3261, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [48/50], Step [95/469], Loss: 0.2231, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [48/50], Step [96/469], Loss: 0.3026, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [48/50], Step [97/469], Loss: 0.2159, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [98/469], Loss: 0.2567, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [48/50], Step [99/469], Loss: 0.4079, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [100/469], Loss: 0.2442, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [48/50], Step [101/469], Loss: 0.3244, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [102/469], Loss: 0.2947, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [103/469], Loss: 0.1750, batch time: 0.48, accuracy:  96.09%\n",
      "Epoch [48/50], Step [104/469], Loss: 0.3404, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [48/50], Step [105/469], Loss: 0.2321, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [48/50], Step [106/469], Loss: 0.1890, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [48/50], Step [107/469], Loss: 0.3878, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [108/469], Loss: 0.2470, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [48/50], Step [109/469], Loss: 0.3881, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [110/469], Loss: 0.3178, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [48/50], Step [111/469], Loss: 0.2507, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [48/50], Step [112/469], Loss: 0.2930, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [48/50], Step [113/469], Loss: 0.2831, batch time: 0.59, accuracy:  95.31%\n",
      "Epoch [48/50], Step [114/469], Loss: 0.2680, batch time: 0.74, accuracy:  91.41%\n",
      "Epoch [48/50], Step [115/469], Loss: 0.3867, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [48/50], Step [116/469], Loss: 0.2837, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [48/50], Step [117/469], Loss: 0.1466, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [48/50], Step [118/469], Loss: 0.2123, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [119/469], Loss: 0.2873, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [120/469], Loss: 0.2129, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [121/469], Loss: 0.1907, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [48/50], Step [122/469], Loss: 0.2365, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [48/50], Step [123/469], Loss: 0.3042, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [124/469], Loss: 0.2636, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [48/50], Step [125/469], Loss: 0.3135, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [126/469], Loss: 0.2072, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [127/469], Loss: 0.1961, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [48/50], Step [128/469], Loss: 0.4835, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [48/50], Step [129/469], Loss: 0.3091, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [48/50], Step [130/469], Loss: 0.3441, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [48/50], Step [131/469], Loss: 0.2621, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [132/469], Loss: 0.3279, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [48/50], Step [133/469], Loss: 0.4036, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [134/469], Loss: 0.2507, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [135/469], Loss: 0.3186, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [48/50], Step [136/469], Loss: 0.3362, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [137/469], Loss: 0.3300, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [138/469], Loss: 0.4535, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [48/50], Step [139/469], Loss: 0.3399, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [48/50], Step [140/469], Loss: 0.3947, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [48/50], Step [141/469], Loss: 0.2147, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [48/50], Step [142/469], Loss: 0.2503, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [48/50], Step [143/469], Loss: 0.3389, batch time: 0.79, accuracy:  93.75%\n",
      "Epoch [48/50], Step [144/469], Loss: 0.3209, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [145/469], Loss: 0.2381, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [146/469], Loss: 0.2518, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [147/469], Loss: 0.2866, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [48/50], Step [148/469], Loss: 0.2550, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [149/469], Loss: 0.2999, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [150/469], Loss: 0.1598, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [48/50], Step [151/469], Loss: 0.5395, batch time: 0.60, accuracy:  86.72%\n",
      "Epoch [48/50], Step [152/469], Loss: 0.3878, batch time: 0.50, accuracy:  85.16%\n",
      "Epoch [48/50], Step [153/469], Loss: 0.3236, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [154/469], Loss: 0.2629, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [48/50], Step [155/469], Loss: 0.2236, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [48/50], Step [156/469], Loss: 0.3249, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [157/469], Loss: 0.2270, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [158/469], Loss: 0.4277, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [159/469], Loss: 0.4444, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [160/469], Loss: 0.3136, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [48/50], Step [161/469], Loss: 0.3883, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [48/50], Step [162/469], Loss: 0.2885, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [48/50], Step [163/469], Loss: 0.2827, batch time: 0.50, accuracy:  94.53%\n",
      "Epoch [48/50], Step [164/469], Loss: 0.1795, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [48/50], Step [165/469], Loss: 0.3842, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [48/50], Step [166/469], Loss: 0.2278, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [167/469], Loss: 0.2913, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [48/50], Step [168/469], Loss: 0.2518, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [48/50], Step [169/469], Loss: 0.2179, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [48/50], Step [170/469], Loss: 0.2302, batch time: 0.52, accuracy:  90.62%\n",
      "Epoch [48/50], Step [171/469], Loss: 0.4980, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [172/469], Loss: 0.3266, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [48/50], Step [173/469], Loss: 0.3228, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [174/469], Loss: 0.2912, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [175/469], Loss: 0.3152, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [48/50], Step [176/469], Loss: 0.2361, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [177/469], Loss: 0.2898, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [178/469], Loss: 0.2377, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [48/50], Step [179/469], Loss: 0.2494, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [48/50], Step [180/469], Loss: 0.2730, batch time: 0.71, accuracy:  89.84%\n",
      "Epoch [48/50], Step [181/469], Loss: 0.1878, batch time: 0.43, accuracy:  95.31%\n",
      "Epoch [48/50], Step [182/469], Loss: 0.1504, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [48/50], Step [183/469], Loss: 0.4148, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [48/50], Step [184/469], Loss: 0.4263, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [185/469], Loss: 0.3212, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [186/469], Loss: 0.2727, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [187/469], Loss: 0.3128, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [188/469], Loss: 0.2019, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [48/50], Step [189/469], Loss: 0.2748, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [190/469], Loss: 0.3255, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [191/469], Loss: 0.2176, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [192/469], Loss: 0.2041, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [48/50], Step [193/469], Loss: 0.3172, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [194/469], Loss: 0.5671, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [195/469], Loss: 0.2833, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [196/469], Loss: 0.1625, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [48/50], Step [197/469], Loss: 0.4784, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [48/50], Step [198/469], Loss: 0.2829, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [199/469], Loss: 0.2894, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [200/469], Loss: 0.2695, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [201/469], Loss: 0.2144, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [48/50], Step [202/469], Loss: 0.1937, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [203/469], Loss: 0.2045, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [48/50], Step [204/469], Loss: 0.2559, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [205/469], Loss: 0.2380, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [206/469], Loss: 0.2552, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [207/469], Loss: 0.1938, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [208/469], Loss: 0.3824, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [209/469], Loss: 0.5196, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [48/50], Step [210/469], Loss: 0.1933, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [211/469], Loss: 0.3560, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [48/50], Step [212/469], Loss: 0.2507, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [48/50], Step [213/469], Loss: 0.3895, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [48/50], Step [214/469], Loss: 0.2425, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [48/50], Step [215/469], Loss: 0.1538, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [48/50], Step [216/469], Loss: 0.3536, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [48/50], Step [217/469], Loss: 0.2940, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [218/469], Loss: 0.3410, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [48/50], Step [219/469], Loss: 0.3775, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [220/469], Loss: 0.2825, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [221/469], Loss: 0.2705, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [48/50], Step [222/469], Loss: 0.3672, batch time: 0.45, accuracy:  85.16%\n",
      "Epoch [48/50], Step [223/469], Loss: 0.1880, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [224/469], Loss: 0.2658, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [225/469], Loss: 0.2385, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [226/469], Loss: 0.2911, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [227/469], Loss: 0.2708, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [48/50], Step [228/469], Loss: 0.2205, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [229/469], Loss: 0.2742, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [230/469], Loss: 0.1547, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [48/50], Step [231/469], Loss: 0.3041, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [232/469], Loss: 0.2889, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [233/469], Loss: 0.2606, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [48/50], Step [234/469], Loss: 0.2216, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [235/469], Loss: 0.3653, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [236/469], Loss: 0.4272, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [237/469], Loss: 0.3942, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [48/50], Step [238/469], Loss: 0.2558, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [48/50], Step [239/469], Loss: 0.2213, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [48/50], Step [240/469], Loss: 0.4296, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [48/50], Step [241/469], Loss: 0.2668, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [242/469], Loss: 0.2101, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [243/469], Loss: 0.2590, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [244/469], Loss: 0.3189, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [48/50], Step [245/469], Loss: 0.2220, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [48/50], Step [246/469], Loss: 0.2686, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [48/50], Step [247/469], Loss: 0.3941, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [48/50], Step [248/469], Loss: 0.3110, batch time: 0.55, accuracy:  91.41%\n",
      "Epoch [48/50], Step [249/469], Loss: 0.2735, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [48/50], Step [250/469], Loss: 0.2187, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [48/50], Step [251/469], Loss: 0.2295, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [48/50], Step [252/469], Loss: 0.2839, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [48/50], Step [253/469], Loss: 0.3095, batch time: 0.55, accuracy:  88.28%\n",
      "Epoch [48/50], Step [254/469], Loss: 0.4349, batch time: 0.49, accuracy:  82.81%\n",
      "Epoch [48/50], Step [255/469], Loss: 0.3286, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [48/50], Step [256/469], Loss: 0.2830, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [257/469], Loss: 0.2863, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [258/469], Loss: 0.3462, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [259/469], Loss: 0.5397, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [260/469], Loss: 0.4335, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [48/50], Step [261/469], Loss: 0.1848, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [48/50], Step [262/469], Loss: 0.2667, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [263/469], Loss: 0.3352, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [264/469], Loss: 0.2742, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [265/469], Loss: 0.4007, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [48/50], Step [266/469], Loss: 0.2219, batch time: 0.51, accuracy:  95.31%\n",
      "Epoch [48/50], Step [267/469], Loss: 0.3477, batch time: 0.51, accuracy:  88.28%\n",
      "Epoch [48/50], Step [268/469], Loss: 0.2311, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [269/469], Loss: 0.3096, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [270/469], Loss: 0.2791, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [271/469], Loss: 0.3538, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [272/469], Loss: 0.1205, batch time: 0.45, accuracy:  96.88%\n",
      "Epoch [48/50], Step [273/469], Loss: 0.2437, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [48/50], Step [274/469], Loss: 0.2446, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [48/50], Step [275/469], Loss: 0.3276, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [48/50], Step [276/469], Loss: 0.3974, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [48/50], Step [277/469], Loss: 0.3270, batch time: 0.59, accuracy:  89.06%\n",
      "Epoch [48/50], Step [278/469], Loss: 0.1674, batch time: 0.57, accuracy:  96.09%\n",
      "Epoch [48/50], Step [279/469], Loss: 0.4141, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [48/50], Step [280/469], Loss: 0.2597, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [48/50], Step [281/469], Loss: 0.3041, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [48/50], Step [282/469], Loss: 0.2832, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [48/50], Step [283/469], Loss: 0.1654, batch time: 0.53, accuracy:  96.09%\n",
      "Epoch [48/50], Step [284/469], Loss: 0.2591, batch time: 0.58, accuracy:  89.84%\n",
      "Epoch [48/50], Step [285/469], Loss: 0.2331, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [48/50], Step [286/469], Loss: 0.3016, batch time: 0.87, accuracy:  92.97%\n",
      "Epoch [48/50], Step [287/469], Loss: 0.2876, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [48/50], Step [288/469], Loss: 0.2593, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [289/469], Loss: 0.2982, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [290/469], Loss: 0.2215, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [291/469], Loss: 0.3917, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [292/469], Loss: 0.2283, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [48/50], Step [293/469], Loss: 0.2772, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [48/50], Step [294/469], Loss: 0.4564, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [295/469], Loss: 0.2637, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [296/469], Loss: 0.2664, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [297/469], Loss: 0.1137, batch time: 0.44, accuracy:  97.66%\n",
      "Epoch [48/50], Step [298/469], Loss: 0.2612, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [299/469], Loss: 0.2589, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [300/469], Loss: 0.1953, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [48/50], Step [301/469], Loss: 0.3716, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [302/469], Loss: 0.1193, batch time: 0.54, accuracy:  95.31%\n",
      "Epoch [48/50], Step [303/469], Loss: 0.2322, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [304/469], Loss: 0.1021, batch time: 0.45, accuracy:  96.88%\n",
      "Epoch [48/50], Step [305/469], Loss: 0.1993, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [48/50], Step [306/469], Loss: 0.3991, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [307/469], Loss: 0.3341, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [308/469], Loss: 0.3294, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [309/469], Loss: 0.2152, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [48/50], Step [310/469], Loss: 0.1904, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [48/50], Step [311/469], Loss: 0.3307, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [48/50], Step [312/469], Loss: 0.3325, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [313/469], Loss: 0.1723, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [314/469], Loss: 0.2629, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [315/469], Loss: 0.2922, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [48/50], Step [316/469], Loss: 0.2387, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [48/50], Step [317/469], Loss: 0.3026, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [48/50], Step [318/469], Loss: 0.3462, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [48/50], Step [319/469], Loss: 0.2128, batch time: 0.63, accuracy:  92.97%\n",
      "Epoch [48/50], Step [320/469], Loss: 0.3851, batch time: 0.44, accuracy:  83.59%\n",
      "Epoch [48/50], Step [321/469], Loss: 0.1930, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [322/469], Loss: 0.3037, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [48/50], Step [323/469], Loss: 0.1656, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [48/50], Step [324/469], Loss: 0.2605, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [325/469], Loss: 0.3024, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [48/50], Step [326/469], Loss: 0.3736, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [48/50], Step [327/469], Loss: 0.4230, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [48/50], Step [328/469], Loss: 0.1591, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [48/50], Step [329/469], Loss: 0.2533, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [48/50], Step [330/469], Loss: 0.3182, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [48/50], Step [331/469], Loss: 0.2018, batch time: 0.48, accuracy:  96.09%\n",
      "Epoch [48/50], Step [332/469], Loss: 0.3450, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [48/50], Step [333/469], Loss: 0.3011, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [48/50], Step [334/469], Loss: 0.1873, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [48/50], Step [335/469], Loss: 0.1643, batch time: 0.53, accuracy:  95.31%\n",
      "Epoch [48/50], Step [336/469], Loss: 0.2766, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [48/50], Step [337/469], Loss: 0.2459, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [48/50], Step [338/469], Loss: 0.3076, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [339/469], Loss: 0.1581, batch time: 0.47, accuracy:  98.44%\n",
      "Epoch [48/50], Step [340/469], Loss: 0.2727, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [341/469], Loss: 0.3509, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [342/469], Loss: 0.3201, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [343/469], Loss: 0.2206, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [344/469], Loss: 0.2267, batch time: 0.49, accuracy:  91.41%\n",
      "Epoch [48/50], Step [345/469], Loss: 0.3490, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [346/469], Loss: 0.3248, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [48/50], Step [347/469], Loss: 0.1973, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [348/469], Loss: 0.2311, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [48/50], Step [349/469], Loss: 0.4983, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [48/50], Step [350/469], Loss: 0.2676, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [48/50], Step [351/469], Loss: 0.3377, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [48/50], Step [352/469], Loss: 0.2768, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [48/50], Step [353/469], Loss: 0.2426, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [48/50], Step [354/469], Loss: 0.1678, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [48/50], Step [355/469], Loss: 0.3779, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [48/50], Step [356/469], Loss: 0.3023, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [48/50], Step [357/469], Loss: 0.3035, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [48/50], Step [358/469], Loss: 0.2022, batch time: 0.58, accuracy:  93.75%\n",
      "Epoch [48/50], Step [359/469], Loss: 0.1577, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [48/50], Step [360/469], Loss: 0.1360, batch time: 0.46, accuracy:  96.09%\n",
      "Epoch [48/50], Step [361/469], Loss: 0.1629, batch time: 0.50, accuracy:  97.66%\n",
      "Epoch [48/50], Step [362/469], Loss: 0.2655, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [48/50], Step [363/469], Loss: 0.4281, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [48/50], Step [364/469], Loss: 0.3203, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [365/469], Loss: 0.3005, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [48/50], Step [366/469], Loss: 0.4293, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [367/469], Loss: 0.3317, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [48/50], Step [368/469], Loss: 0.3647, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [48/50], Step [369/469], Loss: 0.3746, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [48/50], Step [370/469], Loss: 0.2880, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [371/469], Loss: 0.2117, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [48/50], Step [372/469], Loss: 0.3675, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [48/50], Step [373/469], Loss: 0.2792, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [48/50], Step [374/469], Loss: 0.4014, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [48/50], Step [375/469], Loss: 0.3526, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [376/469], Loss: 0.2078, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [48/50], Step [377/469], Loss: 0.3140, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [378/469], Loss: 0.3139, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [379/469], Loss: 0.2319, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [48/50], Step [380/469], Loss: 0.3162, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [48/50], Step [381/469], Loss: 0.3600, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [48/50], Step [382/469], Loss: 0.2119, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [48/50], Step [383/469], Loss: 0.3473, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [48/50], Step [384/469], Loss: 0.2597, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [385/469], Loss: 0.3529, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [386/469], Loss: 0.2902, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [48/50], Step [387/469], Loss: 0.1731, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [48/50], Step [388/469], Loss: 0.4397, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [48/50], Step [389/469], Loss: 0.2055, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [48/50], Step [390/469], Loss: 0.3430, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [48/50], Step [391/469], Loss: 0.2736, batch time: 0.65, accuracy:  90.62%\n",
      "Epoch [48/50], Step [392/469], Loss: 0.1850, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [48/50], Step [393/469], Loss: 0.2686, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [48/50], Step [394/469], Loss: 0.2531, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [395/469], Loss: 0.2136, batch time: 0.45, accuracy:  96.88%\n",
      "Epoch [48/50], Step [396/469], Loss: 0.2568, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [397/469], Loss: 0.3720, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [398/469], Loss: 0.1943, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [48/50], Step [399/469], Loss: 0.2746, batch time: 0.65, accuracy:  89.06%\n",
      "Epoch [48/50], Step [400/469], Loss: 0.1992, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [48/50], Step [401/469], Loss: 0.2820, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [402/469], Loss: 0.2936, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [48/50], Step [403/469], Loss: 0.2519, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [48/50], Step [404/469], Loss: 0.3366, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [48/50], Step [405/469], Loss: 0.2274, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [48/50], Step [406/469], Loss: 0.2619, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [407/469], Loss: 0.2273, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [48/50], Step [408/469], Loss: 0.2170, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [409/469], Loss: 0.2261, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [410/469], Loss: 0.1325, batch time: 0.45, accuracy:  97.66%\n",
      "Epoch [48/50], Step [411/469], Loss: 0.2148, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [412/469], Loss: 0.2457, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [48/50], Step [413/469], Loss: 0.2995, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [48/50], Step [414/469], Loss: 0.4172, batch time: 0.45, accuracy:  85.94%\n",
      "Epoch [48/50], Step [415/469], Loss: 0.2395, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [48/50], Step [416/469], Loss: 0.3261, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [48/50], Step [417/469], Loss: 0.3148, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [418/469], Loss: 0.1995, batch time: 0.50, accuracy:  91.41%\n",
      "Epoch [48/50], Step [419/469], Loss: 0.2332, batch time: 0.52, accuracy:  94.53%\n",
      "Epoch [48/50], Step [420/469], Loss: 0.3393, batch time: 0.54, accuracy:  89.06%\n",
      "Epoch [48/50], Step [421/469], Loss: 0.3477, batch time: 0.58, accuracy:  92.19%\n",
      "Epoch [48/50], Step [422/469], Loss: 0.2629, batch time: 0.56, accuracy:  90.62%\n",
      "Epoch [48/50], Step [423/469], Loss: 0.2002, batch time: 0.67, accuracy:  92.19%\n",
      "Epoch [48/50], Step [424/469], Loss: 0.2894, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [48/50], Step [425/469], Loss: 0.4593, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [48/50], Step [426/469], Loss: 0.2117, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [48/50], Step [427/469], Loss: 0.1213, batch time: 0.44, accuracy:  97.66%\n",
      "Epoch [48/50], Step [428/469], Loss: 0.2101, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [429/469], Loss: 0.3142, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [430/469], Loss: 0.2977, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [48/50], Step [431/469], Loss: 0.2453, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [432/469], Loss: 0.2926, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [48/50], Step [433/469], Loss: 0.4679, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [48/50], Step [434/469], Loss: 0.2944, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [435/469], Loss: 0.2806, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [48/50], Step [436/469], Loss: 0.1739, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [48/50], Step [437/469], Loss: 0.2325, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [438/469], Loss: 0.3195, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [439/469], Loss: 0.2011, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [440/469], Loss: 0.2371, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [48/50], Step [441/469], Loss: 0.2453, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [442/469], Loss: 0.3784, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [48/50], Step [443/469], Loss: 0.2817, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [48/50], Step [444/469], Loss: 0.2337, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [445/469], Loss: 0.2404, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [48/50], Step [446/469], Loss: 0.2223, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [447/469], Loss: 0.2478, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [48/50], Step [448/469], Loss: 0.4393, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [48/50], Step [449/469], Loss: 0.1984, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [48/50], Step [450/469], Loss: 0.2135, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [48/50], Step [451/469], Loss: 0.2526, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [48/50], Step [452/469], Loss: 0.2893, batch time: 0.54, accuracy:  88.28%\n",
      "Epoch [48/50], Step [453/469], Loss: 0.2463, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [48/50], Step [454/469], Loss: 0.2933, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [48/50], Step [455/469], Loss: 0.2671, batch time: 0.68, accuracy:  92.97%\n",
      "Epoch [48/50], Step [456/469], Loss: 0.1779, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [457/469], Loss: 0.3356, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [458/469], Loss: 0.3371, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [48/50], Step [459/469], Loss: 0.2567, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [460/469], Loss: 0.3423, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [48/50], Step [461/469], Loss: 0.2938, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [48/50], Step [462/469], Loss: 0.2517, batch time: 0.47, accuracy:  93.75%\n",
      "Epoch [48/50], Step [463/469], Loss: 0.2168, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [48/50], Step [464/469], Loss: 0.3346, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [48/50], Step [465/469], Loss: 0.3788, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [48/50], Step [466/469], Loss: 0.3482, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [48/50], Step [467/469], Loss: 0.1528, batch time: 0.43, accuracy:  96.09%\n",
      "Epoch [48/50], Step [468/469], Loss: 0.2264, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [48/50], Step [469/469], Loss: 0.3826, batch time: 0.45, accuracy:  91.67%\n",
      "Epoch [49/50], Step [1/469], Loss: 0.3573, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [49/50], Step [2/469], Loss: 0.2747, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [3/469], Loss: 0.2439, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [4/469], Loss: 0.5433, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [5/469], Loss: 0.3152, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [49/50], Step [6/469], Loss: 0.1950, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [7/469], Loss: 0.2540, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [49/50], Step [8/469], Loss: 0.2270, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [9/469], Loss: 0.3221, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [10/469], Loss: 0.3317, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [11/469], Loss: 0.2427, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [49/50], Step [12/469], Loss: 0.3068, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [13/469], Loss: 0.2957, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [49/50], Step [14/469], Loss: 0.2409, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [15/469], Loss: 0.2451, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [49/50], Step [16/469], Loss: 0.3594, batch time: 0.54, accuracy:  87.50%\n",
      "Epoch [49/50], Step [17/469], Loss: 0.3310, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [18/469], Loss: 0.3469, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [49/50], Step [19/469], Loss: 0.2678, batch time: 0.53, accuracy:  89.84%\n",
      "Epoch [49/50], Step [20/469], Loss: 0.2260, batch time: 0.56, accuracy:  91.41%\n",
      "Epoch [49/50], Step [21/469], Loss: 0.3796, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [22/469], Loss: 0.2156, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [23/469], Loss: 0.3640, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [49/50], Step [24/469], Loss: 0.3592, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [25/469], Loss: 0.2851, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [26/469], Loss: 0.3679, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [49/50], Step [27/469], Loss: 0.1260, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [49/50], Step [28/469], Loss: 0.3111, batch time: 0.50, accuracy:  92.97%\n",
      "Epoch [49/50], Step [29/469], Loss: 0.1183, batch time: 0.47, accuracy:  96.88%\n",
      "Epoch [49/50], Step [30/469], Loss: 0.2401, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [49/50], Step [31/469], Loss: 0.2205, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [49/50], Step [32/469], Loss: 0.3444, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [49/50], Step [33/469], Loss: 0.2711, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [49/50], Step [34/469], Loss: 0.2463, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [35/469], Loss: 0.2787, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [36/469], Loss: 0.3205, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [37/469], Loss: 0.2275, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [38/469], Loss: 0.3148, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [39/469], Loss: 0.2588, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [40/469], Loss: 0.2720, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [41/469], Loss: 0.2426, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [42/469], Loss: 0.3927, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [49/50], Step [43/469], Loss: 0.3244, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [44/469], Loss: 0.3021, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [49/50], Step [45/469], Loss: 0.2032, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [46/469], Loss: 0.2092, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [49/50], Step [47/469], Loss: 0.2684, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [48/469], Loss: 0.2373, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [49/50], Step [49/469], Loss: 0.3170, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [49/50], Step [50/469], Loss: 0.3183, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [49/50], Step [51/469], Loss: 0.1888, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [49/50], Step [52/469], Loss: 0.1214, batch time: 0.53, accuracy:  97.66%\n",
      "Epoch [49/50], Step [53/469], Loss: 0.4249, batch time: 0.55, accuracy:  87.50%\n",
      "Epoch [49/50], Step [54/469], Loss: 0.3455, batch time: 0.75, accuracy:  92.19%\n",
      "Epoch [49/50], Step [55/469], Loss: 0.1976, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [49/50], Step [56/469], Loss: 0.2326, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [49/50], Step [57/469], Loss: 0.3988, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [49/50], Step [58/469], Loss: 0.2169, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [59/469], Loss: 0.3115, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [49/50], Step [60/469], Loss: 0.5203, batch time: 0.48, accuracy:  85.94%\n",
      "Epoch [49/50], Step [61/469], Loss: 0.2762, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [49/50], Step [62/469], Loss: 0.2501, batch time: 0.52, accuracy:  89.84%\n",
      "Epoch [49/50], Step [63/469], Loss: 0.2333, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [49/50], Step [64/469], Loss: 0.3705, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [49/50], Step [65/469], Loss: 0.3422, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [66/469], Loss: 0.2757, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [67/469], Loss: 0.2911, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [49/50], Step [68/469], Loss: 0.2700, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [69/469], Loss: 0.3027, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [70/469], Loss: 0.2615, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [71/469], Loss: 0.3455, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [49/50], Step [72/469], Loss: 0.1894, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [73/469], Loss: 0.3415, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [49/50], Step [74/469], Loss: 0.2726, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [75/469], Loss: 0.1906, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [49/50], Step [76/469], Loss: 0.3455, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [49/50], Step [77/469], Loss: 0.2345, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [78/469], Loss: 0.1854, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [79/469], Loss: 0.3142, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [80/469], Loss: 0.2343, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [49/50], Step [81/469], Loss: 0.3247, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [49/50], Step [82/469], Loss: 0.2271, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [83/469], Loss: 0.1955, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [49/50], Step [84/469], Loss: 0.1406, batch time: 0.53, accuracy:  96.88%\n",
      "Epoch [49/50], Step [85/469], Loss: 0.2895, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [49/50], Step [86/469], Loss: 0.2676, batch time: 0.57, accuracy:  89.84%\n",
      "Epoch [49/50], Step [87/469], Loss: 0.2213, batch time: 0.63, accuracy:  92.97%\n",
      "Epoch [49/50], Step [88/469], Loss: 0.3117, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [49/50], Step [89/469], Loss: 0.2917, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [49/50], Step [90/469], Loss: 0.3244, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [91/469], Loss: 0.4523, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [49/50], Step [92/469], Loss: 0.3379, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [49/50], Step [93/469], Loss: 0.3516, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [94/469], Loss: 0.3623, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [95/469], Loss: 0.2725, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [96/469], Loss: 0.2338, batch time: 0.51, accuracy:  92.19%\n",
      "Epoch [49/50], Step [97/469], Loss: 0.2730, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [98/469], Loss: 0.3085, batch time: 0.50, accuracy:  90.62%\n",
      "Epoch [49/50], Step [99/469], Loss: 0.3456, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [49/50], Step [100/469], Loss: 0.3510, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [49/50], Step [101/469], Loss: 0.2502, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [49/50], Step [102/469], Loss: 0.1732, batch time: 0.51, accuracy:  96.09%\n",
      "Epoch [49/50], Step [103/469], Loss: 0.4473, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [49/50], Step [104/469], Loss: 0.2588, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [105/469], Loss: 0.1752, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [49/50], Step [106/469], Loss: 0.4673, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [49/50], Step [107/469], Loss: 0.3973, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [108/469], Loss: 0.2698, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [109/469], Loss: 0.3705, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [49/50], Step [110/469], Loss: 0.3161, batch time: 0.47, accuracy:  89.06%\n",
      "Epoch [49/50], Step [111/469], Loss: 0.2420, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [112/469], Loss: 0.2944, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [113/469], Loss: 0.3259, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [49/50], Step [114/469], Loss: 0.2312, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [115/469], Loss: 0.2531, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [116/469], Loss: 0.3457, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [49/50], Step [117/469], Loss: 0.3781, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [49/50], Step [118/469], Loss: 0.2994, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [49/50], Step [119/469], Loss: 0.1856, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [49/50], Step [120/469], Loss: 0.2700, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [49/50], Step [121/469], Loss: 0.2380, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [49/50], Step [122/469], Loss: 0.4515, batch time: 0.62, accuracy:  88.28%\n",
      "Epoch [49/50], Step [123/469], Loss: 0.3943, batch time: 0.56, accuracy:  88.28%\n",
      "Epoch [49/50], Step [124/469], Loss: 0.1759, batch time: 0.58, accuracy:  94.53%\n",
      "Epoch [49/50], Step [125/469], Loss: 0.4079, batch time: 0.62, accuracy:  89.84%\n",
      "Epoch [49/50], Step [126/469], Loss: 0.2552, batch time: 0.59, accuracy:  90.62%\n",
      "Epoch [49/50], Step [127/469], Loss: 0.2470, batch time: 0.57, accuracy:  90.62%\n",
      "Epoch [49/50], Step [128/469], Loss: 0.2916, batch time: 0.55, accuracy:  93.75%\n",
      "Epoch [49/50], Step [129/469], Loss: 0.3268, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [49/50], Step [130/469], Loss: 0.2634, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [131/469], Loss: 0.3457, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [49/50], Step [132/469], Loss: 0.2228, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [49/50], Step [133/469], Loss: 0.2330, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [134/469], Loss: 0.3602, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [49/50], Step [135/469], Loss: 0.2053, batch time: 0.52, accuracy:  96.09%\n",
      "Epoch [49/50], Step [136/469], Loss: 0.4013, batch time: 0.50, accuracy:  92.19%\n",
      "Epoch [49/50], Step [137/469], Loss: 0.3021, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [49/50], Step [138/469], Loss: 0.2174, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [49/50], Step [139/469], Loss: 0.2736, batch time: 0.53, accuracy:  91.41%\n",
      "Epoch [49/50], Step [140/469], Loss: 0.2493, batch time: 0.56, accuracy:  92.19%\n",
      "Epoch [49/50], Step [141/469], Loss: 0.2816, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [49/50], Step [142/469], Loss: 0.2974, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [49/50], Step [143/469], Loss: 0.3564, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [49/50], Step [144/469], Loss: 0.3477, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [49/50], Step [145/469], Loss: 0.2666, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [146/469], Loss: 0.1809, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [49/50], Step [147/469], Loss: 0.3907, batch time: 0.45, accuracy:  87.50%\n",
      "Epoch [49/50], Step [148/469], Loss: 0.2901, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [149/469], Loss: 0.2381, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [150/469], Loss: 0.2617, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [151/469], Loss: 0.1984, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [49/50], Step [152/469], Loss: 0.2847, batch time: 0.47, accuracy:  88.28%\n",
      "Epoch [49/50], Step [153/469], Loss: 0.2904, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [154/469], Loss: 0.3979, batch time: 0.46, accuracy:  86.72%\n",
      "Epoch [49/50], Step [155/469], Loss: 0.2943, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [49/50], Step [156/469], Loss: 0.2955, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [49/50], Step [157/469], Loss: 0.3764, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [49/50], Step [158/469], Loss: 0.2543, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [49/50], Step [159/469], Loss: 0.2095, batch time: 0.50, accuracy:  93.75%\n",
      "Epoch [49/50], Step [160/469], Loss: 0.2056, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [49/50], Step [161/469], Loss: 0.2571, batch time: 0.59, accuracy:  92.19%\n",
      "Epoch [49/50], Step [162/469], Loss: 0.1532, batch time: 0.60, accuracy:  94.53%\n",
      "Epoch [49/50], Step [163/469], Loss: 0.2257, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [49/50], Step [164/469], Loss: 0.3517, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [165/469], Loss: 0.1878, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [49/50], Step [166/469], Loss: 0.2317, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [49/50], Step [167/469], Loss: 0.3061, batch time: 0.46, accuracy:  87.50%\n",
      "Epoch [49/50], Step [168/469], Loss: 0.3610, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [169/469], Loss: 0.1555, batch time: 0.53, accuracy:  94.53%\n",
      "Epoch [49/50], Step [170/469], Loss: 0.4021, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [49/50], Step [171/469], Loss: 0.2102, batch time: 0.45, accuracy:  97.66%\n",
      "Epoch [49/50], Step [172/469], Loss: 0.3402, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [173/469], Loss: 0.4233, batch time: 0.50, accuracy:  87.50%\n",
      "Epoch [49/50], Step [174/469], Loss: 0.1545, batch time: 0.63, accuracy:  94.53%\n",
      "Epoch [49/50], Step [175/469], Loss: 0.2593, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [49/50], Step [176/469], Loss: 0.3701, batch time: 0.44, accuracy:  85.94%\n",
      "Epoch [49/50], Step [177/469], Loss: 0.2265, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [49/50], Step [178/469], Loss: 0.2624, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [179/469], Loss: 0.3372, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [49/50], Step [180/469], Loss: 0.1966, batch time: 0.55, accuracy:  96.09%\n",
      "Epoch [49/50], Step [181/469], Loss: 0.2556, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [49/50], Step [182/469], Loss: 0.3510, batch time: 0.50, accuracy:  89.06%\n",
      "Epoch [49/50], Step [183/469], Loss: 0.2065, batch time: 0.49, accuracy:  94.53%\n",
      "Epoch [49/50], Step [184/469], Loss: 0.2891, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [49/50], Step [185/469], Loss: 0.2326, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [49/50], Step [186/469], Loss: 0.3704, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [49/50], Step [187/469], Loss: 0.2972, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [188/469], Loss: 0.1732, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [49/50], Step [189/469], Loss: 0.3051, batch time: 0.46, accuracy:  90.62%\n",
      "Epoch [49/50], Step [190/469], Loss: 0.2361, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [191/469], Loss: 0.4021, batch time: 0.53, accuracy:  89.06%\n",
      "Epoch [49/50], Step [192/469], Loss: 0.3125, batch time: 0.82, accuracy:  90.62%\n",
      "Epoch [49/50], Step [193/469], Loss: 0.3041, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [49/50], Step [194/469], Loss: 0.1426, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [49/50], Step [195/469], Loss: 0.2314, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [196/469], Loss: 0.3445, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [197/469], Loss: 0.3147, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [198/469], Loss: 0.3216, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [199/469], Loss: 0.2790, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [49/50], Step [200/469], Loss: 0.2940, batch time: 0.55, accuracy:  92.97%\n",
      "Epoch [49/50], Step [201/469], Loss: 0.3413, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [49/50], Step [202/469], Loss: 0.2683, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [49/50], Step [203/469], Loss: 0.2189, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [204/469], Loss: 0.2391, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [205/469], Loss: 0.3577, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [49/50], Step [206/469], Loss: 0.3642, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [49/50], Step [207/469], Loss: 0.2896, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [208/469], Loss: 0.2035, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [49/50], Step [209/469], Loss: 0.2562, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [49/50], Step [210/469], Loss: 0.1776, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [211/469], Loss: 0.4654, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [212/469], Loss: 0.2131, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [49/50], Step [213/469], Loss: 0.2559, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [49/50], Step [214/469], Loss: 0.2952, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [49/50], Step [215/469], Loss: 0.3204, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [216/469], Loss: 0.2425, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [217/469], Loss: 0.2269, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [218/469], Loss: 0.2649, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [49/50], Step [219/469], Loss: 0.2541, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [220/469], Loss: 0.2131, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [49/50], Step [221/469], Loss: 0.2342, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [222/469], Loss: 0.2741, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [223/469], Loss: 0.2749, batch time: 0.49, accuracy:  89.84%\n",
      "Epoch [49/50], Step [224/469], Loss: 0.2079, batch time: 0.55, accuracy:  95.31%\n",
      "Epoch [49/50], Step [225/469], Loss: 0.2977, batch time: 0.55, accuracy:  89.84%\n",
      "Epoch [49/50], Step [226/469], Loss: 0.4583, batch time: 0.56, accuracy:  89.06%\n",
      "Epoch [49/50], Step [227/469], Loss: 0.2084, batch time: 0.66, accuracy:  96.88%\n",
      "Epoch [49/50], Step [228/469], Loss: 0.2387, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [229/469], Loss: 0.2197, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [230/469], Loss: 0.4523, batch time: 0.49, accuracy:  85.94%\n",
      "Epoch [49/50], Step [231/469], Loss: 0.2872, batch time: 0.47, accuracy:  91.41%\n",
      "Epoch [49/50], Step [232/469], Loss: 0.2605, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [233/469], Loss: 0.4315, batch time: 0.44, accuracy:  86.72%\n",
      "Epoch [49/50], Step [234/469], Loss: 0.4331, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [235/469], Loss: 0.2963, batch time: 0.47, accuracy:  90.62%\n",
      "Epoch [49/50], Step [236/469], Loss: 0.2143, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [49/50], Step [237/469], Loss: 0.2606, batch time: 0.49, accuracy:  90.62%\n",
      "Epoch [49/50], Step [238/469], Loss: 0.4139, batch time: 0.48, accuracy:  88.28%\n",
      "Epoch [49/50], Step [239/469], Loss: 0.2368, batch time: 0.51, accuracy:  93.75%\n",
      "Epoch [49/50], Step [240/469], Loss: 0.2574, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [49/50], Step [241/469], Loss: 0.4703, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [49/50], Step [242/469], Loss: 0.3686, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [243/469], Loss: 0.2634, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [244/469], Loss: 0.2720, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [245/469], Loss: 0.3025, batch time: 0.45, accuracy:  89.06%\n",
      "Epoch [49/50], Step [246/469], Loss: 0.2016, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [247/469], Loss: 0.1909, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [49/50], Step [248/469], Loss: 0.2327, batch time: 0.55, accuracy:  92.19%\n",
      "Epoch [49/50], Step [249/469], Loss: 0.3455, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [49/50], Step [250/469], Loss: 0.2208, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [251/469], Loss: 0.2570, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [252/469], Loss: 0.2582, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [253/469], Loss: 0.2701, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [49/50], Step [254/469], Loss: 0.2412, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [49/50], Step [255/469], Loss: 0.3379, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [256/469], Loss: 0.2968, batch time: 0.52, accuracy:  93.75%\n",
      "Epoch [49/50], Step [257/469], Loss: 0.2289, batch time: 0.49, accuracy:  92.97%\n",
      "Epoch [49/50], Step [258/469], Loss: 0.3321, batch time: 0.53, accuracy:  88.28%\n",
      "Epoch [49/50], Step [259/469], Loss: 0.2591, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [49/50], Step [260/469], Loss: 0.2630, batch time: 0.54, accuracy:  93.75%\n",
      "Epoch [49/50], Step [261/469], Loss: 0.2087, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [49/50], Step [262/469], Loss: 0.2621, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [49/50], Step [263/469], Loss: 0.4115, batch time: 0.54, accuracy:  90.62%\n",
      "Epoch [49/50], Step [264/469], Loss: 0.3020, batch time: 0.54, accuracy:  92.19%\n",
      "Epoch [49/50], Step [265/469], Loss: 0.3868, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [49/50], Step [266/469], Loss: 0.3911, batch time: 0.45, accuracy:  86.72%\n",
      "Epoch [49/50], Step [267/469], Loss: 0.2128, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [268/469], Loss: 0.2311, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [269/469], Loss: 0.3112, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [270/469], Loss: 0.2004, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [49/50], Step [271/469], Loss: 0.1261, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [49/50], Step [272/469], Loss: 0.1284, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [49/50], Step [273/469], Loss: 0.2971, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [49/50], Step [274/469], Loss: 0.2606, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [275/469], Loss: 0.3165, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [49/50], Step [276/469], Loss: 0.2538, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [277/469], Loss: 0.2977, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [49/50], Step [278/469], Loss: 0.4073, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [279/469], Loss: 0.2325, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [280/469], Loss: 0.1416, batch time: 0.45, accuracy:  95.31%\n",
      "Epoch [49/50], Step [281/469], Loss: 0.2778, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [49/50], Step [282/469], Loss: 0.2611, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [283/469], Loss: 0.2061, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [49/50], Step [284/469], Loss: 0.3588, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [49/50], Step [285/469], Loss: 0.1889, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [286/469], Loss: 0.2314, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [287/469], Loss: 0.2667, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [288/469], Loss: 0.2311, batch time: 0.51, accuracy:  90.62%\n",
      "Epoch [49/50], Step [289/469], Loss: 0.3259, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [290/469], Loss: 0.2669, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [49/50], Step [291/469], Loss: 0.2449, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [292/469], Loss: 0.1826, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [293/469], Loss: 0.2841, batch time: 0.50, accuracy:  89.84%\n",
      "Epoch [49/50], Step [294/469], Loss: 0.4514, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [49/50], Step [295/469], Loss: 0.2967, batch time: 0.51, accuracy:  89.06%\n",
      "Epoch [49/50], Step [296/469], Loss: 0.4946, batch time: 0.71, accuracy:  88.28%\n",
      "Epoch [49/50], Step [297/469], Loss: 0.3029, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [49/50], Step [298/469], Loss: 0.1510, batch time: 0.49, accuracy:  95.31%\n",
      "Epoch [49/50], Step [299/469], Loss: 0.2090, batch time: 0.58, accuracy:  92.97%\n",
      "Epoch [49/50], Step [300/469], Loss: 0.3517, batch time: 0.61, accuracy:  91.41%\n",
      "Epoch [49/50], Step [301/469], Loss: 0.1465, batch time: 0.59, accuracy:  95.31%\n",
      "Epoch [49/50], Step [302/469], Loss: 0.2116, batch time: 0.60, accuracy:  92.97%\n",
      "Epoch [49/50], Step [303/469], Loss: 0.3631, batch time: 0.64, accuracy:  88.28%\n",
      "Epoch [49/50], Step [304/469], Loss: 0.2689, batch time: 0.56, accuracy:  87.50%\n",
      "Epoch [49/50], Step [305/469], Loss: 0.3242, batch time: 0.59, accuracy:  88.28%\n",
      "Epoch [49/50], Step [306/469], Loss: 0.2637, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [49/50], Step [307/469], Loss: 0.3719, batch time: 0.46, accuracy:  89.84%\n",
      "Epoch [49/50], Step [308/469], Loss: 0.2345, batch time: 0.46, accuracy:  95.31%\n",
      "Epoch [49/50], Step [309/469], Loss: 0.3290, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [310/469], Loss: 0.1906, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [311/469], Loss: 0.3483, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [312/469], Loss: 0.1849, batch time: 0.51, accuracy:  94.53%\n",
      "Epoch [49/50], Step [313/469], Loss: 0.1957, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [49/50], Step [314/469], Loss: 0.2606, batch time: 0.53, accuracy:  92.19%\n",
      "Epoch [49/50], Step [315/469], Loss: 0.2287, batch time: 0.54, accuracy:  94.53%\n",
      "Epoch [49/50], Step [316/469], Loss: 0.3347, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [49/50], Step [317/469], Loss: 0.3322, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [49/50], Step [318/469], Loss: 0.1943, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [319/469], Loss: 0.1661, batch time: 0.47, accuracy:  94.53%\n",
      "Epoch [49/50], Step [320/469], Loss: 0.3315, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [49/50], Step [321/469], Loss: 0.3518, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [322/469], Loss: 0.2720, batch time: 0.45, accuracy:  93.75%\n",
      "Epoch [49/50], Step [323/469], Loss: 0.3114, batch time: 0.52, accuracy:  86.72%\n",
      "Epoch [49/50], Step [324/469], Loss: 0.2580, batch time: 0.53, accuracy:  92.97%\n",
      "Epoch [49/50], Step [325/469], Loss: 0.2896, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [49/50], Step [326/469], Loss: 0.2448, batch time: 0.48, accuracy:  92.19%\n",
      "Epoch [49/50], Step [327/469], Loss: 0.2873, batch time: 0.51, accuracy:  96.09%\n",
      "Epoch [49/50], Step [328/469], Loss: 0.2542, batch time: 0.51, accuracy:  91.41%\n",
      "Epoch [49/50], Step [329/469], Loss: 0.2173, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [49/50], Step [330/469], Loss: 0.2077, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [49/50], Step [331/469], Loss: 0.2605, batch time: 0.60, accuracy:  91.41%\n",
      "Epoch [49/50], Step [332/469], Loss: 0.4020, batch time: 1.20, accuracy:  90.62%\n",
      "Epoch [49/50], Step [333/469], Loss: 0.2270, batch time: 0.49, accuracy:  92.19%\n",
      "Epoch [49/50], Step [334/469], Loss: 0.2572, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [335/469], Loss: 0.2448, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [336/469], Loss: 0.2295, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [49/50], Step [337/469], Loss: 0.1904, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [338/469], Loss: 0.2776, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [49/50], Step [339/469], Loss: 0.3048, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [49/50], Step [340/469], Loss: 0.3488, batch time: 0.52, accuracy:  89.06%\n",
      "Epoch [49/50], Step [341/469], Loss: 0.2787, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [342/469], Loss: 0.2865, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [49/50], Step [343/469], Loss: 0.2173, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [344/469], Loss: 0.3626, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [345/469], Loss: 0.2348, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [346/469], Loss: 0.1793, batch time: 0.45, accuracy:  96.09%\n",
      "Epoch [49/50], Step [347/469], Loss: 0.2247, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [348/469], Loss: 0.1887, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [49/50], Step [349/469], Loss: 0.2061, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [350/469], Loss: 0.3454, batch time: 0.45, accuracy:  89.84%\n",
      "Epoch [49/50], Step [351/469], Loss: 0.3052, batch time: 0.51, accuracy:  89.84%\n",
      "Epoch [49/50], Step [352/469], Loss: 0.3848, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [353/469], Loss: 0.1497, batch time: 0.45, accuracy:  97.66%\n",
      "Epoch [49/50], Step [354/469], Loss: 0.1637, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [355/469], Loss: 0.2996, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [49/50], Step [356/469], Loss: 0.3720, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [49/50], Step [357/469], Loss: 0.3017, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [49/50], Step [358/469], Loss: 0.1324, batch time: 0.47, accuracy:  96.88%\n",
      "Epoch [49/50], Step [359/469], Loss: 0.2833, batch time: 0.54, accuracy:  89.84%\n",
      "Epoch [49/50], Step [360/469], Loss: 0.2507, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [361/469], Loss: 0.2097, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [362/469], Loss: 0.2807, batch time: 0.63, accuracy:  91.41%\n",
      "Epoch [49/50], Step [363/469], Loss: 0.1939, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [49/50], Step [364/469], Loss: 0.3503, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [49/50], Step [365/469], Loss: 0.2593, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [49/50], Step [366/469], Loss: 0.2469, batch time: 0.52, accuracy:  91.41%\n",
      "Epoch [49/50], Step [367/469], Loss: 0.3302, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [368/469], Loss: 0.3321, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [369/469], Loss: 0.2099, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [370/469], Loss: 0.3696, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [49/50], Step [371/469], Loss: 0.1796, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [372/469], Loss: 0.2189, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [49/50], Step [373/469], Loss: 0.2993, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [49/50], Step [374/469], Loss: 0.3359, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [49/50], Step [375/469], Loss: 0.1895, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [376/469], Loss: 0.3064, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [377/469], Loss: 0.1772, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [378/469], Loss: 0.1575, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [49/50], Step [379/469], Loss: 0.2340, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [49/50], Step [380/469], Loss: 0.2946, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [49/50], Step [381/469], Loss: 0.1903, batch time: 0.44, accuracy:  96.88%\n",
      "Epoch [49/50], Step [382/469], Loss: 0.4099, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [383/469], Loss: 0.3363, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [49/50], Step [384/469], Loss: 0.1885, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [49/50], Step [385/469], Loss: 0.3226, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [386/469], Loss: 0.1851, batch time: 0.45, accuracy:  92.19%\n",
      "Epoch [49/50], Step [387/469], Loss: 0.1618, batch time: 0.44, accuracy:  94.53%\n",
      "Epoch [49/50], Step [388/469], Loss: 0.3252, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [389/469], Loss: 0.2391, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [49/50], Step [390/469], Loss: 0.3646, batch time: 0.46, accuracy:  88.28%\n",
      "Epoch [49/50], Step [391/469], Loss: 0.4284, batch time: 0.47, accuracy:  87.50%\n",
      "Epoch [49/50], Step [392/469], Loss: 0.2455, batch time: 0.49, accuracy:  88.28%\n",
      "Epoch [49/50], Step [393/469], Loss: 0.2898, batch time: 0.53, accuracy:  90.62%\n",
      "Epoch [49/50], Step [394/469], Loss: 0.2269, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [49/50], Step [395/469], Loss: 0.1643, batch time: 0.53, accuracy:  93.75%\n",
      "Epoch [49/50], Step [396/469], Loss: 0.2074, batch time: 0.59, accuracy:  91.41%\n",
      "Epoch [49/50], Step [397/469], Loss: 0.3655, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [398/469], Loss: 0.2625, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [49/50], Step [399/469], Loss: 0.2441, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [400/469], Loss: 0.2037, batch time: 0.44, accuracy:  92.97%\n",
      "Epoch [49/50], Step [401/469], Loss: 0.2504, batch time: 0.45, accuracy:  91.41%\n",
      "Epoch [49/50], Step [402/469], Loss: 0.2937, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [403/469], Loss: 0.3913, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [404/469], Loss: 0.3165, batch time: 0.45, accuracy:  92.97%\n",
      "Epoch [49/50], Step [405/469], Loss: 0.4400, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [406/469], Loss: 0.1559, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [407/469], Loss: 0.4208, batch time: 0.45, accuracy:  90.62%\n",
      "Epoch [49/50], Step [408/469], Loss: 0.3284, batch time: 0.44, accuracy:  87.50%\n",
      "Epoch [49/50], Step [409/469], Loss: 0.2061, batch time: 0.44, accuracy:  95.31%\n",
      "Epoch [49/50], Step [410/469], Loss: 0.2739, batch time: 0.44, accuracy:  89.84%\n",
      "Epoch [49/50], Step [411/469], Loss: 0.2374, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [49/50], Step [412/469], Loss: 0.3271, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [49/50], Step [413/469], Loss: 0.3001, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [49/50], Step [414/469], Loss: 0.2845, batch time: 0.52, accuracy:  92.19%\n",
      "Epoch [49/50], Step [415/469], Loss: 0.3190, batch time: 0.46, accuracy:  92.19%\n",
      "Epoch [49/50], Step [416/469], Loss: 0.3257, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [417/469], Loss: 0.2162, batch time: 0.47, accuracy:  92.19%\n",
      "Epoch [49/50], Step [418/469], Loss: 0.3177, batch time: 0.44, accuracy:  88.28%\n",
      "Epoch [49/50], Step [419/469], Loss: 0.3054, batch time: 0.44, accuracy:  90.62%\n",
      "Epoch [49/50], Step [420/469], Loss: 0.2225, batch time: 0.46, accuracy:  93.75%\n",
      "Epoch [49/50], Step [421/469], Loss: 0.2571, batch time: 0.46, accuracy:  91.41%\n",
      "Epoch [49/50], Step [422/469], Loss: 0.2324, batch time: 0.46, accuracy:  92.97%\n",
      "Epoch [49/50], Step [423/469], Loss: 0.3873, batch time: 0.47, accuracy:  86.72%\n",
      "Epoch [49/50], Step [424/469], Loss: 0.2330, batch time: 0.54, accuracy:  92.97%\n",
      "Epoch [49/50], Step [425/469], Loss: 0.3180, batch time: 0.54, accuracy:  91.41%\n",
      "Epoch [49/50], Step [426/469], Loss: 0.4049, batch time: 0.55, accuracy:  90.62%\n",
      "Epoch [49/50], Step [427/469], Loss: 0.2235, batch time: 0.65, accuracy:  94.53%\n",
      "Epoch [49/50], Step [428/469], Loss: 0.2415, batch time: 0.44, accuracy:  92.19%\n",
      "Epoch [49/50], Step [429/469], Loss: 0.3621, batch time: 0.50, accuracy:  88.28%\n",
      "Epoch [49/50], Step [430/469], Loss: 0.2152, batch time: 0.44, accuracy:  93.75%\n",
      "Epoch [49/50], Step [431/469], Loss: 0.1879, batch time: 0.45, accuracy:  94.53%\n",
      "Epoch [49/50], Step [432/469], Loss: 0.2722, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [49/50], Step [433/469], Loss: 0.3557, batch time: 0.44, accuracy:  89.06%\n",
      "Epoch [49/50], Step [434/469], Loss: 0.4008, batch time: 0.43, accuracy:  86.72%\n",
      "Epoch [49/50], Step [435/469], Loss: 0.3284, batch time: 0.44, accuracy:  91.41%\n",
      "Epoch [49/50], Step [436/469], Loss: 0.2157, batch time: 0.45, accuracy:  88.28%\n",
      "Epoch [49/50], Step [437/469], Loss: 0.1512, batch time: 0.44, accuracy:  96.09%\n",
      "Epoch [49/50], Step [438/469], Loss: 0.1910, batch time: 0.46, accuracy:  94.53%\n",
      "Epoch [49/50], Step [439/469], Loss: 0.1535, batch time: 0.48, accuracy:  94.53%\n",
      "Epoch [49/50], Step [440/469], Loss: 0.1871, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [49/50], Step [441/469], Loss: 0.1555, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [49/50], Step [442/469], Loss: 0.3917, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [49/50], Step [443/469], Loss: 0.1394, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [49/50], Step [444/469], Loss: 0.3072, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [49/50], Step [445/469], Loss: 0.3183, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [49/50], Step [446/469], Loss: 0.2812, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [49/50], Step [447/469], Loss: 0.2439, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [49/50], Step [448/469], Loss: 0.1975, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [49/50], Step [449/469], Loss: 0.2988, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [49/50], Step [450/469], Loss: 0.2833, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [49/50], Step [451/469], Loss: 0.1754, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [49/50], Step [452/469], Loss: 0.2273, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [49/50], Step [453/469], Loss: 0.4014, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [49/50], Step [454/469], Loss: 0.2942, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [49/50], Step [455/469], Loss: 0.2024, batch time: 0.47, accuracy:  92.97%\n",
      "Epoch [49/50], Step [456/469], Loss: 0.3701, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [49/50], Step [457/469], Loss: 0.2887, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [49/50], Step [458/469], Loss: 0.2181, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [49/50], Step [459/469], Loss: 0.3763, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [49/50], Step [460/469], Loss: 0.2591, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [49/50], Step [461/469], Loss: 0.2774, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [49/50], Step [462/469], Loss: 0.2254, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [49/50], Step [463/469], Loss: 0.3328, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [49/50], Step [464/469], Loss: 0.4397, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [49/50], Step [465/469], Loss: 0.1785, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [49/50], Step [466/469], Loss: 0.2618, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [49/50], Step [467/469], Loss: 0.2398, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [49/50], Step [468/469], Loss: 0.2531, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [49/50], Step [469/469], Loss: 0.2394, batch time: 0.42, accuracy:  92.71%\n",
      "Epoch [50/50], Step [1/469], Loss: 0.3317, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [2/469], Loss: 0.2415, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [3/469], Loss: 0.1252, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [50/50], Step [4/469], Loss: 0.2101, batch time: 0.42, accuracy:  96.09%\n",
      "Epoch [50/50], Step [5/469], Loss: 0.2995, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [6/469], Loss: 0.2240, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [7/469], Loss: 0.2354, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [8/469], Loss: 0.2103, batch time: 0.42, accuracy:  96.09%\n",
      "Epoch [50/50], Step [9/469], Loss: 0.2559, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [10/469], Loss: 0.2626, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [11/469], Loss: 0.2659, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [12/469], Loss: 0.2625, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [50/50], Step [13/469], Loss: 0.2629, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [14/469], Loss: 0.2888, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [15/469], Loss: 0.3218, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [16/469], Loss: 0.2433, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [17/469], Loss: 0.2957, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [18/469], Loss: 0.3627, batch time: 0.42, accuracy:  85.16%\n",
      "Epoch [50/50], Step [19/469], Loss: 0.3823, batch time: 0.42, accuracy:  85.16%\n",
      "Epoch [50/50], Step [20/469], Loss: 0.2144, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [21/469], Loss: 0.2368, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [22/469], Loss: 0.1730, batch time: 0.41, accuracy:  96.09%\n",
      "Epoch [50/50], Step [23/469], Loss: 0.2209, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [24/469], Loss: 0.2759, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [25/469], Loss: 0.2348, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [50/50], Step [26/469], Loss: 0.2940, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [27/469], Loss: 0.2437, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [28/469], Loss: 0.2376, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [29/469], Loss: 0.2041, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [30/469], Loss: 0.2042, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [31/469], Loss: 0.2629, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [32/469], Loss: 0.3825, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [33/469], Loss: 0.2066, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [34/469], Loss: 0.3643, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [35/469], Loss: 0.3284, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [36/469], Loss: 0.2365, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [37/469], Loss: 0.3570, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [38/469], Loss: 0.2631, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [39/469], Loss: 0.3357, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [40/469], Loss: 0.2737, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [41/469], Loss: 0.3557, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [42/469], Loss: 0.1273, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [43/469], Loss: 0.2987, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [44/469], Loss: 0.3113, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [50/50], Step [45/469], Loss: 0.3496, batch time: 0.41, accuracy:  85.94%\n",
      "Epoch [50/50], Step [46/469], Loss: 0.2547, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [47/469], Loss: 0.1889, batch time: 0.42, accuracy:  96.88%\n",
      "Epoch [50/50], Step [48/469], Loss: 0.2129, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [49/469], Loss: 0.2922, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [50/469], Loss: 0.2387, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [51/469], Loss: 0.4841, batch time: 0.42, accuracy:  85.16%\n",
      "Epoch [50/50], Step [52/469], Loss: 0.2347, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [53/469], Loss: 0.2845, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [54/469], Loss: 0.2907, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [55/469], Loss: 0.2457, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [56/469], Loss: 0.2519, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [57/469], Loss: 0.1928, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [58/469], Loss: 0.2365, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [59/469], Loss: 0.3423, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [60/469], Loss: 0.2661, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [61/469], Loss: 0.1589, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [62/469], Loss: 0.2314, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [63/469], Loss: 0.2522, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [64/469], Loss: 0.3049, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [65/469], Loss: 0.2775, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [66/469], Loss: 0.1598, batch time: 0.41, accuracy:  96.09%\n",
      "Epoch [50/50], Step [67/469], Loss: 0.3231, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [68/469], Loss: 0.3012, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [69/469], Loss: 0.2399, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [70/469], Loss: 0.1844, batch time: 0.49, accuracy:  93.75%\n",
      "Epoch [50/50], Step [71/469], Loss: 0.2875, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [72/469], Loss: 0.1813, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [73/469], Loss: 0.2495, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [50/50], Step [74/469], Loss: 0.2889, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [75/469], Loss: 0.2815, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [76/469], Loss: 0.1613, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [77/469], Loss: 0.2514, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [78/469], Loss: 0.3578, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [79/469], Loss: 0.2967, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [80/469], Loss: 0.2557, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [81/469], Loss: 0.2500, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [82/469], Loss: 0.2986, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [83/469], Loss: 0.3225, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [84/469], Loss: 0.2517, batch time: 0.46, accuracy:  89.06%\n",
      "Epoch [50/50], Step [85/469], Loss: 0.3031, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [86/469], Loss: 0.2409, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [87/469], Loss: 0.3910, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [88/469], Loss: 0.2871, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [89/469], Loss: 0.4271, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [90/469], Loss: 0.3232, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [91/469], Loss: 0.1380, batch time: 0.42, accuracy:  98.44%\n",
      "Epoch [50/50], Step [92/469], Loss: 0.3043, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [93/469], Loss: 0.2052, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [94/469], Loss: 0.2309, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [95/469], Loss: 0.2461, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [50/50], Step [96/469], Loss: 0.2285, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [97/469], Loss: 0.2538, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [98/469], Loss: 0.2201, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [99/469], Loss: 0.2433, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [100/469], Loss: 0.2192, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [101/469], Loss: 0.2614, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [102/469], Loss: 0.3810, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [50/50], Step [103/469], Loss: 0.2631, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [104/469], Loss: 0.2641, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [105/469], Loss: 0.1927, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [106/469], Loss: 0.1392, batch time: 0.41, accuracy:  96.09%\n",
      "Epoch [50/50], Step [107/469], Loss: 0.2635, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [50/50], Step [108/469], Loss: 0.3569, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [109/469], Loss: 0.1806, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [50/50], Step [110/469], Loss: 0.2702, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [111/469], Loss: 0.2399, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [112/469], Loss: 0.3607, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [113/469], Loss: 0.1562, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [114/469], Loss: 0.2246, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [115/469], Loss: 0.3916, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [50/50], Step [116/469], Loss: 0.1714, batch time: 0.42, accuracy:  96.09%\n",
      "Epoch [50/50], Step [117/469], Loss: 0.3022, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [50/50], Step [118/469], Loss: 0.2868, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [119/469], Loss: 0.2770, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [120/469], Loss: 0.2174, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [121/469], Loss: 0.3513, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [122/469], Loss: 0.2216, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [123/469], Loss: 0.2930, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [124/469], Loss: 0.2888, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [125/469], Loss: 0.2492, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [126/469], Loss: 0.3051, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [127/469], Loss: 0.1544, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [128/469], Loss: 0.3336, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [50/50], Step [129/469], Loss: 0.1592, batch time: 0.42, accuracy:  96.09%\n",
      "Epoch [50/50], Step [130/469], Loss: 0.2786, batch time: 0.48, accuracy:  89.06%\n",
      "Epoch [50/50], Step [131/469], Loss: 0.2725, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [132/469], Loss: 0.3058, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [133/469], Loss: 0.1981, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [134/469], Loss: 0.2918, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [135/469], Loss: 0.4601, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [136/469], Loss: 0.3000, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [137/469], Loss: 0.2259, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [138/469], Loss: 0.2374, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [139/469], Loss: 0.3527, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [140/469], Loss: 0.3114, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [141/469], Loss: 0.3080, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [142/469], Loss: 0.1807, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [143/469], Loss: 0.3543, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [144/469], Loss: 0.2002, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [145/469], Loss: 0.2625, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [146/469], Loss: 0.2731, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [147/469], Loss: 0.2308, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [148/469], Loss: 0.2215, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [149/469], Loss: 0.2527, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [150/469], Loss: 0.3898, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [151/469], Loss: 0.2668, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [152/469], Loss: 0.1708, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [153/469], Loss: 0.2966, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [154/469], Loss: 0.4706, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [155/469], Loss: 0.3050, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [156/469], Loss: 0.2277, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [157/469], Loss: 0.2723, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [158/469], Loss: 0.1290, batch time: 0.41, accuracy:  96.88%\n",
      "Epoch [50/50], Step [159/469], Loss: 0.3118, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [160/469], Loss: 0.3113, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [161/469], Loss: 0.3300, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [162/469], Loss: 0.2291, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [163/469], Loss: 0.3341, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [50/50], Step [164/469], Loss: 0.3921, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [165/469], Loss: 0.2750, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [166/469], Loss: 0.2389, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [167/469], Loss: 0.2445, batch time: 0.43, accuracy:  93.75%\n",
      "Epoch [50/50], Step [168/469], Loss: 0.3441, batch time: 0.41, accuracy:  87.50%\n",
      "Epoch [50/50], Step [169/469], Loss: 0.2544, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [170/469], Loss: 0.3667, batch time: 0.43, accuracy:  90.62%\n",
      "Epoch [50/50], Step [171/469], Loss: 0.2466, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [172/469], Loss: 0.3487, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [173/469], Loss: 0.2330, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [174/469], Loss: 0.2062, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [175/469], Loss: 0.2806, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [176/469], Loss: 0.2742, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [177/469], Loss: 0.1943, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [178/469], Loss: 0.3376, batch time: 0.48, accuracy:  93.75%\n",
      "Epoch [50/50], Step [179/469], Loss: 0.3187, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [180/469], Loss: 0.2469, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [181/469], Loss: 0.2467, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [182/469], Loss: 0.1563, batch time: 0.41, accuracy:  96.88%\n",
      "Epoch [50/50], Step [183/469], Loss: 0.2253, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [184/469], Loss: 0.3205, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [185/469], Loss: 0.1875, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [186/469], Loss: 0.2246, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [187/469], Loss: 0.2737, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [188/469], Loss: 0.3508, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [189/469], Loss: 0.3502, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [50/50], Step [190/469], Loss: 0.3537, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [50/50], Step [191/469], Loss: 0.3679, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [192/469], Loss: 0.2261, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [50/50], Step [193/469], Loss: 0.3340, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [194/469], Loss: 0.4071, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [195/469], Loss: 0.3031, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [196/469], Loss: 0.2768, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [50/50], Step [197/469], Loss: 0.2187, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [198/469], Loss: 0.3512, batch time: 0.42, accuracy:  85.16%\n",
      "Epoch [50/50], Step [199/469], Loss: 0.1531, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [50/50], Step [200/469], Loss: 0.2721, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [201/469], Loss: 0.4071, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [202/469], Loss: 0.3337, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [203/469], Loss: 0.2958, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [204/469], Loss: 0.3778, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [205/469], Loss: 0.3178, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [206/469], Loss: 0.2998, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [207/469], Loss: 0.2754, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [208/469], Loss: 0.3935, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [50/50], Step [209/469], Loss: 0.3569, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [210/469], Loss: 0.1888, batch time: 0.42, accuracy:  96.09%\n",
      "Epoch [50/50], Step [211/469], Loss: 0.2666, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [212/469], Loss: 0.4407, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [213/469], Loss: 0.2361, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [214/469], Loss: 0.2772, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [215/469], Loss: 0.2973, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [216/469], Loss: 0.2227, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [217/469], Loss: 0.2670, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [218/469], Loss: 0.3186, batch time: 0.48, accuracy:  90.62%\n",
      "Epoch [50/50], Step [219/469], Loss: 0.2743, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [220/469], Loss: 0.2304, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [221/469], Loss: 0.3679, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [50/50], Step [222/469], Loss: 0.1699, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [223/469], Loss: 0.3901, batch time: 0.47, accuracy:  89.84%\n",
      "Epoch [50/50], Step [224/469], Loss: 0.3581, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [225/469], Loss: 0.2373, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [226/469], Loss: 0.2412, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [227/469], Loss: 0.2657, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [228/469], Loss: 0.2612, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [229/469], Loss: 0.3558, batch time: 0.41, accuracy:  85.94%\n",
      "Epoch [50/50], Step [230/469], Loss: 0.2706, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [231/469], Loss: 0.1929, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [232/469], Loss: 0.2576, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [50/50], Step [233/469], Loss: 0.4252, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [234/469], Loss: 0.1841, batch time: 0.42, accuracy:  96.09%\n",
      "Epoch [50/50], Step [235/469], Loss: 0.3142, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [236/469], Loss: 0.1614, batch time: 0.43, accuracy:  96.09%\n",
      "Epoch [50/50], Step [237/469], Loss: 0.2661, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [50/50], Step [238/469], Loss: 0.1859, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [239/469], Loss: 0.4257, batch time: 0.41, accuracy:  85.94%\n",
      "Epoch [50/50], Step [240/469], Loss: 0.1966, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [241/469], Loss: 0.3345, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [242/469], Loss: 0.1852, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [243/469], Loss: 0.3663, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [244/469], Loss: 0.3584, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [50/50], Step [245/469], Loss: 0.3245, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [246/469], Loss: 0.3296, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [247/469], Loss: 0.3041, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [248/469], Loss: 0.1982, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [249/469], Loss: 0.2457, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [250/469], Loss: 0.3886, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [251/469], Loss: 0.1965, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [252/469], Loss: 0.2669, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [253/469], Loss: 0.3468, batch time: 0.48, accuracy:  91.41%\n",
      "Epoch [50/50], Step [254/469], Loss: 0.2246, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [255/469], Loss: 0.2008, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [256/469], Loss: 0.2758, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [257/469], Loss: 0.3186, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [258/469], Loss: 0.3186, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [259/469], Loss: 0.3022, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [260/469], Loss: 0.3190, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [261/469], Loss: 0.1551, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [262/469], Loss: 0.2480, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [263/469], Loss: 0.2013, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [264/469], Loss: 0.3430, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [265/469], Loss: 0.4677, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [266/469], Loss: 0.3029, batch time: 0.41, accuracy:  87.50%\n",
      "Epoch [50/50], Step [267/469], Loss: 0.3703, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [50/50], Step [268/469], Loss: 0.2119, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [269/469], Loss: 0.2532, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [270/469], Loss: 0.2188, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [271/469], Loss: 0.3038, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [272/469], Loss: 0.2196, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [273/469], Loss: 0.2347, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [274/469], Loss: 0.2846, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [275/469], Loss: 0.2409, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [276/469], Loss: 0.2412, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [277/469], Loss: 0.3629, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [278/469], Loss: 0.2279, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [279/469], Loss: 0.3070, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [50/50], Step [280/469], Loss: 0.2834, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [281/469], Loss: 0.3309, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [282/469], Loss: 0.1687, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [283/469], Loss: 0.1897, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [284/469], Loss: 0.3500, batch time: 0.41, accuracy:  88.28%\n",
      "Epoch [50/50], Step [285/469], Loss: 0.2499, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [286/469], Loss: 0.1859, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [287/469], Loss: 0.2945, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [288/469], Loss: 0.3267, batch time: 0.41, accuracy:  90.62%\n",
      "Epoch [50/50], Step [289/469], Loss: 0.1638, batch time: 0.41, accuracy:  96.09%\n",
      "Epoch [50/50], Step [290/469], Loss: 0.1977, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [291/469], Loss: 0.2842, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [292/469], Loss: 0.2563, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [293/469], Loss: 0.3372, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [50/50], Step [294/469], Loss: 0.1948, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [295/469], Loss: 0.1929, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [296/469], Loss: 0.1825, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [297/469], Loss: 0.2223, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [298/469], Loss: 0.2603, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [299/469], Loss: 0.1349, batch time: 0.42, accuracy:  96.88%\n",
      "Epoch [50/50], Step [300/469], Loss: 0.2723, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [301/469], Loss: 0.2639, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [302/469], Loss: 0.3292, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [303/469], Loss: 0.1809, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [50/50], Step [304/469], Loss: 0.2303, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [305/469], Loss: 0.1736, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [306/469], Loss: 0.1819, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [50/50], Step [307/469], Loss: 0.2627, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [50/50], Step [308/469], Loss: 0.2662, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [309/469], Loss: 0.3211, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [310/469], Loss: 0.3179, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [311/469], Loss: 0.3156, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [312/469], Loss: 0.3658, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [313/469], Loss: 0.3298, batch time: 0.41, accuracy:  89.06%\n",
      "Epoch [50/50], Step [314/469], Loss: 0.2962, batch time: 0.43, accuracy:  91.41%\n",
      "Epoch [50/50], Step [315/469], Loss: 0.2406, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [316/469], Loss: 0.4214, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [317/469], Loss: 0.3681, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [318/469], Loss: 0.3115, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [319/469], Loss: 0.3759, batch time: 0.41, accuracy:  85.94%\n",
      "Epoch [50/50], Step [320/469], Loss: 0.1905, batch time: 0.41, accuracy:  92.97%\n",
      "Epoch [50/50], Step [321/469], Loss: 0.1660, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [322/469], Loss: 0.5297, batch time: 0.42, accuracy:  84.38%\n",
      "Epoch [50/50], Step [323/469], Loss: 0.2137, batch time: 0.42, accuracy:  96.09%\n",
      "Epoch [50/50], Step [324/469], Loss: 0.1830, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [325/469], Loss: 0.2046, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [326/469], Loss: 0.2929, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [50/50], Step [327/469], Loss: 0.3595, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [328/469], Loss: 0.2651, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [329/469], Loss: 0.1633, batch time: 0.42, accuracy:  98.44%\n",
      "Epoch [50/50], Step [330/469], Loss: 0.2502, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [331/469], Loss: 0.2234, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [332/469], Loss: 0.2571, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [333/469], Loss: 0.3271, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [334/469], Loss: 0.2537, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [335/469], Loss: 0.3352, batch time: 0.43, accuracy:  88.28%\n",
      "Epoch [50/50], Step [336/469], Loss: 0.2255, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [337/469], Loss: 0.2076, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [338/469], Loss: 0.2378, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [339/469], Loss: 0.1774, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [340/469], Loss: 0.2942, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [341/469], Loss: 0.2744, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [342/469], Loss: 0.3163, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [343/469], Loss: 0.2033, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [344/469], Loss: 0.2682, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [345/469], Loss: 0.2875, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [346/469], Loss: 0.2605, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [347/469], Loss: 0.3117, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [348/469], Loss: 0.2780, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [349/469], Loss: 0.2062, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [350/469], Loss: 0.3305, batch time: 0.41, accuracy:  88.28%\n",
      "Epoch [50/50], Step [351/469], Loss: 0.2984, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [352/469], Loss: 0.3003, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [353/469], Loss: 0.2360, batch time: 0.41, accuracy:  86.72%\n",
      "Epoch [50/50], Step [354/469], Loss: 0.4437, batch time: 0.41, accuracy:  85.16%\n",
      "Epoch [50/50], Step [355/469], Loss: 0.1798, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [356/469], Loss: 0.1893, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [357/469], Loss: 0.4348, batch time: 0.41, accuracy:  88.28%\n",
      "Epoch [50/50], Step [358/469], Loss: 0.1278, batch time: 0.41, accuracy:  96.09%\n",
      "Epoch [50/50], Step [359/469], Loss: 0.1927, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [360/469], Loss: 0.2873, batch time: 0.41, accuracy:  95.31%\n",
      "Epoch [50/50], Step [361/469], Loss: 0.2694, batch time: 0.41, accuracy:  88.28%\n",
      "Epoch [50/50], Step [362/469], Loss: 0.5471, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [363/469], Loss: 0.2294, batch time: 0.51, accuracy:  92.97%\n",
      "Epoch [50/50], Step [364/469], Loss: 0.2686, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [365/469], Loss: 0.2128, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [366/469], Loss: 0.2571, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [367/469], Loss: 0.2457, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [368/469], Loss: 0.1928, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [369/469], Loss: 0.4263, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [370/469], Loss: 0.1613, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [50/50], Step [371/469], Loss: 0.1884, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [372/469], Loss: 0.2520, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [373/469], Loss: 0.2836, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [374/469], Loss: 0.4206, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [375/469], Loss: 0.2048, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [376/469], Loss: 0.4002, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [50/50], Step [377/469], Loss: 0.2087, batch time: 0.43, accuracy:  94.53%\n",
      "Epoch [50/50], Step [378/469], Loss: 0.2711, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [379/469], Loss: 0.1550, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [380/469], Loss: 0.4945, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [381/469], Loss: 0.2682, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [382/469], Loss: 0.3079, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [383/469], Loss: 0.1811, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [384/469], Loss: 0.2767, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [385/469], Loss: 0.2367, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [386/469], Loss: 0.2970, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [387/469], Loss: 0.4396, batch time: 0.49, accuracy:  89.06%\n",
      "Epoch [50/50], Step [388/469], Loss: 0.1657, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [389/469], Loss: 0.2585, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [390/469], Loss: 0.2368, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [391/469], Loss: 0.2755, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [392/469], Loss: 0.2974, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [393/469], Loss: 0.2410, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [394/469], Loss: 0.3670, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [395/469], Loss: 0.2947, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [396/469], Loss: 0.4100, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [397/469], Loss: 0.3386, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [398/469], Loss: 0.3624, batch time: 0.43, accuracy:  92.97%\n",
      "Epoch [50/50], Step [399/469], Loss: 0.2090, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [400/469], Loss: 0.1960, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [401/469], Loss: 0.2375, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [402/469], Loss: 0.3194, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [50/50], Step [403/469], Loss: 0.2507, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [404/469], Loss: 0.2441, batch time: 0.43, accuracy:  89.84%\n",
      "Epoch [50/50], Step [405/469], Loss: 0.2303, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [406/469], Loss: 0.1850, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [407/469], Loss: 0.3285, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [408/469], Loss: 0.1674, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [409/469], Loss: 0.2234, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [410/469], Loss: 0.2160, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [411/469], Loss: 0.3753, batch time: 0.42, accuracy:  86.72%\n",
      "Epoch [50/50], Step [412/469], Loss: 0.2908, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [413/469], Loss: 0.2490, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [414/469], Loss: 0.2371, batch time: 0.42, accuracy:  96.88%\n",
      "Epoch [50/50], Step [415/469], Loss: 0.1891, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [416/469], Loss: 0.2657, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [417/469], Loss: 0.2754, batch time: 0.41, accuracy:  88.28%\n",
      "Epoch [50/50], Step [418/469], Loss: 0.2710, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [419/469], Loss: 0.2532, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [420/469], Loss: 0.2561, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [421/469], Loss: 0.3552, batch time: 0.42, accuracy:  85.16%\n",
      "Epoch [50/50], Step [422/469], Loss: 0.2319, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [423/469], Loss: 0.1711, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [424/469], Loss: 0.1501, batch time: 0.41, accuracy:  96.88%\n",
      "Epoch [50/50], Step [425/469], Loss: 0.4290, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [426/469], Loss: 0.2502, batch time: 0.41, accuracy:  94.53%\n",
      "Epoch [50/50], Step [427/469], Loss: 0.2771, batch time: 0.41, accuracy:  91.41%\n",
      "Epoch [50/50], Step [428/469], Loss: 0.2516, batch time: 0.42, accuracy:  95.31%\n",
      "Epoch [50/50], Step [429/469], Loss: 0.1575, batch time: 0.41, accuracy:  96.09%\n",
      "Epoch [50/50], Step [430/469], Loss: 0.1914, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [431/469], Loss: 0.3986, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [432/469], Loss: 0.2848, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [433/469], Loss: 0.2256, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [434/469], Loss: 0.2651, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [435/469], Loss: 0.3836, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [436/469], Loss: 0.1849, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [437/469], Loss: 0.2826, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [438/469], Loss: 0.1961, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [439/469], Loss: 0.2352, batch time: 0.42, accuracy:  92.97%\n",
      "Epoch [50/50], Step [440/469], Loss: 0.3293, batch time: 0.43, accuracy:  89.06%\n",
      "Epoch [50/50], Step [441/469], Loss: 0.4827, batch time: 0.41, accuracy:  89.84%\n",
      "Epoch [50/50], Step [442/469], Loss: 0.2948, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [443/469], Loss: 0.2338, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [444/469], Loss: 0.2691, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [445/469], Loss: 0.3415, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [446/469], Loss: 0.3088, batch time: 0.41, accuracy:  88.28%\n",
      "Epoch [50/50], Step [447/469], Loss: 0.2642, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [448/469], Loss: 0.2260, batch time: 0.42, accuracy:  94.53%\n",
      "Epoch [50/50], Step [449/469], Loss: 0.3056, batch time: 0.41, accuracy:  92.19%\n",
      "Epoch [50/50], Step [450/469], Loss: 0.2333, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [451/469], Loss: 0.3267, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [452/469], Loss: 0.2758, batch time: 0.42, accuracy:  92.19%\n",
      "Epoch [50/50], Step [453/469], Loss: 0.4785, batch time: 0.42, accuracy:  87.50%\n",
      "Epoch [50/50], Step [454/469], Loss: 0.2411, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [455/469], Loss: 0.3256, batch time: 0.42, accuracy:  88.28%\n",
      "Epoch [50/50], Step [456/469], Loss: 0.3588, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [457/469], Loss: 0.2488, batch time: 0.43, accuracy:  92.19%\n",
      "Epoch [50/50], Step [458/469], Loss: 0.4805, batch time: 0.43, accuracy:  84.38%\n",
      "Epoch [50/50], Step [459/469], Loss: 0.3148, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [460/469], Loss: 0.2627, batch time: 0.42, accuracy:  89.84%\n",
      "Epoch [50/50], Step [461/469], Loss: 0.1513, batch time: 0.42, accuracy:  97.66%\n",
      "Epoch [50/50], Step [462/469], Loss: 0.3034, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [463/469], Loss: 0.3652, batch time: 0.42, accuracy:  89.06%\n",
      "Epoch [50/50], Step [464/469], Loss: 0.2789, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [465/469], Loss: 0.3020, batch time: 0.42, accuracy:  90.62%\n",
      "Epoch [50/50], Step [466/469], Loss: 0.2003, batch time: 0.42, accuracy:  93.75%\n",
      "Epoch [50/50], Step [467/469], Loss: 0.2064, batch time: 0.41, accuracy:  93.75%\n",
      "Epoch [50/50], Step [468/469], Loss: 0.3594, batch time: 0.42, accuracy:  91.41%\n",
      "Epoch [50/50], Step [469/469], Loss: 0.3326, batch time: 0.41, accuracy:  90.62%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "\n",
    "### (Optional) Start from pretrained model ##\n",
    "# model = torch.load('result_FF_mm_b1000_40_200_40/tq_mm_acc_70_bsf')\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "acc_list = [] \n",
    "acc_best = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        since_batch = time.time()\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # print(\"output: \", outputs)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        # log_loss = torch.log(loss + 1e-6)\n",
    "        \n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        acc = 100 * correct / total\n",
    "        acc_list.append(acc)\n",
    "        train_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "        np.array(loss_list).dump(\"L16/loss_list.dat\")\n",
    "        np.array(acc_list).dump(\"L16/acc_list.dat\")\n",
    "        if acc > acc_best:\n",
    "            torch.save(model, 'L16/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "            acc_best = acc\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if (i+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step = 1e-2                # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "# num_epochs = 1             # Number of training epochs\n",
    "# q_depth = 13             # Depth of the quantum circuit (number of variational layers)\n",
    "# gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "# q_delta = 0.1              # Initial spread of random quantum weights\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# #############################################\n",
    "# ### Training loop ###########################\n",
    "\n",
    "# ### (Optional) Start from pretrained model ##\n",
    "# # model = torch.load('result_FF_mm_b1000_40_200_40/tq_mm_acc_70_bsf')\n",
    "# # model.eval()  # Set the model to evaluation mode\n",
    "# #############################################\n",
    "\n",
    "# loss_list = [] \n",
    "# acc_list = [] \n",
    "# acc_best = 0\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#         since_batch = time.time()\n",
    "        \n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         optimizer.zero_grad()\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "#         # print(\"output: \", outputs)\n",
    "#         labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "#         # Compute loss\n",
    "#         loss = criterion(outputs, labels_one_hot)\n",
    "#         # log_loss = torch.log(loss + 1e-6)\n",
    "        \n",
    "#         loss_list.append(loss.cpu().detach().numpy())\n",
    "#         acc = 100 * correct / total\n",
    "#         acc_list.append(acc)\n",
    "#         train_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "#         # np.array(loss_list).dump(\"result_FF_mm_L38_b1000_40_200_40/loss_list.dat\")\n",
    "#         # np.array(acc_list).dump(\"result_FF_mm_L38_b1000_40_200_40/acc_list.dat\")\n",
    "#         if acc > acc_best:\n",
    "#             # torch.save(model, 'result_FF_mm_L38_b1000_40_200_40/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "#             acc_best = acc\n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "#         # if (i+1) % 100 == 0:\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "    \n",
    "#     train_loss /= len(train_loader)\n",
    "#     scheduler.step(train_loss)\n",
    "    \n",
    "# #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 91.81%\n",
      "Loss on the train set: 0.27\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 91.20%\n",
      "Loss on the test set: 0.28\n",
      "Generalization error: 0.00907141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Assuming testset is your original test dataset\n",
    "test_size = int(len(test_dataset) * 0.1)  # 80% of the original testset size\n",
    "validation_size = len(test_dataset) - test_size  # The remaining 20% for validation\n",
    "\n",
    "# Split the testset into new testset and validation set\n",
    "new_testset, validationset = random_split(test_dataset, [test_size, validation_size])\n",
    "\n",
    "# Create DataLoader for the new testset and validation set\n",
    "new_testloader = DataLoader(new_testset, batch_size=64, shuffle=True)\n",
    "validationloader = DataLoader(validationset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in new_testloader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
