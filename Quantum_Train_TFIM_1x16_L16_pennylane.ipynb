{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import code block \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    " \n",
    "# import quantum_datasets as qd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A Matter of Taste challenge :  \n",
    "### Building a phase identification classifier of the quantum many-body system. \n",
    "#### with \n",
    "\n",
    "## *Quantum-Train*:   \n",
    "### Rethinking Hybrid Quantum-Classical Machine Learning in the Model Compression Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of this notebook are sorted in the following manner:  \n",
    "1. Generate the training data and testing data from the PennyLane quantum dataset. \n",
    "2. Construct a Phase identification classifier by Pytorch, pure classically. \n",
    "3. Introduce the Quantum-Train (QT) concept, to train the same classical NN by a QNN and Mapping model, with polylog parameter reduction.\n",
    "4. The QT part of the code is contructed by TorchQuantum, the training and testing result will be shown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the training data and testing data from the PennyLane quantum dataset. \n",
    "\n",
    "<img src=\"images/phase_classifier.png\" width=\"1000px\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Ising chain data set\n",
    "Ising_chain_data_set = qml.data.load(\"qspin\", sysname=\"Ising\", periodicity=\"full\", lattice=\"chain\", layout=[\"1x16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the classical shadow measurement result and the corresponding basis into the single matrix, \n",
    "## where 25 samples are picked in each data. \n",
    "\n",
    "dataset_shadow_meas_and_basis = [] \n",
    "for h_value in range(100):\n",
    "    for slice_ in range(40):\n",
    "        sample_per_slice = 25\n",
    "        dataset_shadow_meas_and_basis.append(\n",
    "            \n",
    "            torch.cat(\n",
    "            (\n",
    "                torch.tensor(Ising_chain_data_set[0].shadow_meas[h_value][sample_per_slice*slice_:sample_per_slice*(slice_+1)]),\n",
    "                torch.tensor(Ising_chain_data_set[0].shadow_basis[h_value][sample_per_slice*slice_:sample_per_slice*(slice_+1)]),\n",
    "                # torch.full((sample_per_slice,), Ising_chain_data_set[0].parameters['h'][h_value]).unsqueeze(1)\n",
    "\n",
    "            ),\n",
    "            dim = 1).unsqueeze(0).float()\n",
    "        )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_shadow_meas_and_basis[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the label data, here we use the phase label as the target of the classifcation task. \n",
    "\n",
    "dataset_order_parameter = [] \n",
    "for h_value_index in range(100):\n",
    "    for slice_ in range(40):\n",
    "        dataset_order_parameter.append(\n",
    "            #torch.tensor(Ising_chain_data_set[0].parameters['h'][h_value_index]).float()\n",
    "            torch.tensor((1/8)*Ising_chain_data_set[0].order_params[h_value_index]).float()\n",
    "        )\n",
    "        \n",
    "dataset_phase_label = [] \n",
    "for h_value_index in range(100):\n",
    "    for slice_ in range(40):\n",
    "        h = Ising_chain_data_set[0].parameters['h'][h_value_index]\n",
    "        if h < 1:\n",
    "            dataset_phase_label.append(0)\n",
    "        elif h >= 1:\n",
    "            dataset_phase_label.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A function to generate the dataset that will be recognized by Pytorch\n",
    "\n",
    "\n",
    "class MatrixDataset(Dataset):\n",
    "    \"\"\"Matrix and label dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, matrices, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            matrices (list of numpy.ndarray or torch.Tensor): List of matrices.\n",
    "            labels (list of int): List of labels corresponding to each matrix.\n",
    "        \"\"\"\n",
    "        self.matrices = matrices\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        matrix = self.matrices[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert to torch.Tensor if not already\n",
    "        if not isinstance(matrix, torch.Tensor):\n",
    "            matrix = torch.tensor(matrix, dtype=torch.float32)\n",
    "\n",
    "        if not isinstance(label, torch.Tensor):\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return matrix, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = MatrixDataset(dataset_shadow_meas_and_basis, dataset_order_parameter)\n",
    "dataset = MatrixDataset(dataset_shadow_meas_and_basis, dataset_phase_label)\n",
    "\n",
    "\n",
    "## split the data for testing and training \n",
    "\n",
    "# Assuming 'dataset' is your initialized dataset\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% for training\n",
    "test_size = dataset_size - train_size  # 20% for testing\n",
    "\n",
    "# Calculate the interval for selecting test indices in the interleaved pattern\n",
    "# The +1 ensures that we round up, preventing the train set from being too small\n",
    "interval = int(dataset_size / test_size) + 1\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for i in range(dataset_size):\n",
    "    if i % interval == 0:\n",
    "        test_indices.append(i)\n",
    "    else:\n",
    "        train_indices.append(i)\n",
    "\n",
    "# Adjust the sizes in case of rounding issues\n",
    "while len(train_indices) > train_size:\n",
    "    # Move excess from train to test to maintain the size constraint\n",
    "    train_indices, test_indices = train_indices[:-1], test_indices + [train_indices[-1]]\n",
    "\n",
    "while len(test_indices) > test_size:\n",
    "    # Move excess from test to train if necessary\n",
    "    test_indices, train_indices = test_indices[:-1], train_indices + [test_indices[-1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a Phase identification classifier by Pytorch, pure classically. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [100/160], Loss: 0.4948\n",
      "Epoch [2/25], Step [100/160], Loss: 0.4000\n",
      "Epoch [3/25], Step [100/160], Loss: 0.2099\n",
      "Epoch [4/25], Step [100/160], Loss: 0.2498\n",
      "Epoch [5/25], Step [100/160], Loss: 0.1006\n",
      "Epoch [6/25], Step [100/160], Loss: 0.2019\n",
      "Epoch [7/25], Step [100/160], Loss: 0.0207\n",
      "Epoch [8/25], Step [100/160], Loss: 0.0374\n",
      "Epoch [9/25], Step [100/160], Loss: 0.0428\n",
      "Epoch [10/25], Step [100/160], Loss: 0.1002\n",
      "Epoch [11/25], Step [100/160], Loss: 0.0753\n",
      "Epoch [12/25], Step [100/160], Loss: 0.3724\n",
      "Epoch [13/25], Step [100/160], Loss: 0.0080\n",
      "Epoch [14/25], Step [100/160], Loss: 0.0048\n",
      "Epoch [15/25], Step [100/160], Loss: 0.0317\n",
      "Epoch [16/25], Step [100/160], Loss: 0.0003\n",
      "Epoch [17/25], Step [100/160], Loss: 0.0005\n",
      "Epoch [18/25], Step [100/160], Loss: 0.0004\n",
      "Epoch [19/25], Step [100/160], Loss: 0.0003\n",
      "Epoch [20/25], Step [100/160], Loss: 0.0000\n",
      "Epoch [21/25], Step [100/160], Loss: 0.0001\n",
      "Epoch [22/25], Step [100/160], Loss: 0.0002\n",
      "Epoch [23/25], Step [100/160], Loss: 0.0002\n",
      "Epoch [24/25], Step [100/160], Loss: 0.0002\n",
      "Epoch [25/25], Step [100/160], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "### model initialization ###\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 25\n",
    "\n",
    "\n",
    "# Define the CNN model (Phase identification classifier)\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)  # 1st conv layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Pooling layer\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)  # 2nd conv layer\n",
    "        self.fc1 = nn.Linear(5 * 3 * 12, 200)  \n",
    "        self.fc2 = nn.Linear(200, 2)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 100.00%\n",
      "Accuracy on the test set: 86.25%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum-Train (QT) concept could be summarized into the graph \n",
    "<img src=\"images/training_flow.png\" width=\"1000px\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first, we estimate how many qubits are required for the above Phase identification classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  39222\n",
      "Required qubit number:  16\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "dev = qml.device(\"lightning.gpu\", wires=n_qubits, batch_obs=True)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates.\n",
    "    \"\"\"\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "def RZ_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RZ(element, wires=idx)\n",
    "        \n",
    "def entangling_layer(nqubits):\n",
    "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
    "    \"\"\"\n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT\n",
    "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "\n",
    "def probs_to_weights(probs_):\n",
    "    \n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "####################\n",
    "\n",
    "\n",
    "# @qml.qnode(dev, diff_method=\"spsa\")\n",
    "# def quantum_net(q_weights_flat):\n",
    "#     \"\"\"\n",
    "#     The variational quantum circuit.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Reshape weights\n",
    "#     q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "#     # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "#     H_layer(n_qubits)\n",
    "#     # Repeated layer\n",
    "#     for i in range(q_depth):\n",
    "        \n",
    "#         # Parameterised layer\n",
    "#         if i%2 == 0:\n",
    "#             for y in range(n_qubits):\n",
    "#                 qml.RY(q_weights[i][y], wires=y)\n",
    "#         else:\n",
    "#             for z in range(n_qubits):\n",
    "#                 qml.RZ(q_weights[i][z], wires=z)\n",
    "\n",
    "#         # Control Z gates\n",
    "#         for y in range(n_qubits - 1):\n",
    "#             qml.CZ(wires=[y, y + 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "#     probs_ = qml.probs(wires=list(range(n_qubits)))\n",
    "    \n",
    "#     return probs_\n",
    "\n",
    "@qml.qnode(dev, diff_method=\"spsa\")\n",
    "# @qml.qnode(dev, diff_method=\"parameter-shift\")\n",
    "\n",
    "def quantum_net(q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "    H_layer(n_qubits)\n",
    "    # Repeated layer\n",
    "    for i in range(q_depth):\n",
    "        # Parameterised layer\n",
    "        if i%2 == 0:\n",
    "            for y in range(n_qubits):\n",
    "                qml.RY(q_weights[i][y], wires=y)\n",
    "        else:\n",
    "            for z in range(n_qubits):\n",
    "                qml.RZ(q_weights[i][z], wires=z)\n",
    "        for y in range(n_qubits - 1):\n",
    "            qml.CZ(wires=[y, y + 1])\n",
    "    \n",
    "\n",
    "    \n",
    "    # state_mag = qml.probs(wires=list(range(n_qubits)))\n",
    "\n",
    "    return qml.probs(wires=list(range(n_qubits)))#x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LewHybridNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing full quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "            X = self.input_layer(X)\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "            output = self.output_layer(X)\n",
    "            return output\n",
    "        \n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        # self.simple_cnn = SimpleCNN()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [10, 20, 10], 1).to(device)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        self.q_params.requires_grad = True\n",
    "        \n",
    "        easy_scale_coeff = 2**(n_qubit-1)\n",
    "        gamma = 0.1\n",
    "        beta  = 0.8\n",
    "        alpha = 0.3\n",
    "            \n",
    "        probs_ = quantum_net(self.q_params)\n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        x_ = torch.abs(probs_) ** 2\n",
    "        x_ = (beta*torch.tanh(gamma*easy_scale_coeff*x_))**(alpha) \n",
    "        x_ = x_ - torch.mean(x_)\n",
    "        x_.to(device)\n",
    "        \n",
    "        probs_ = x_ \n",
    "        # print(probs_)\n",
    "        \n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        # combined_data_torch = torch.cat((qubit_states_torch, probs_.unsqueeze(1)), dim=1)\n",
    "        # print(\"probs_:\", probs_)\n",
    "        # print(\"qubit_states_torch:\", qubit_states_torch)\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_.unsqueeze(1)), dim=1)\n",
    "        # print(\"combined_data_torch:\", combined_data_torch)\n",
    "        # input_size = combined_data_torch.size(1)\n",
    "\n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "\n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "    \n",
    "        return x #self.simple_cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  621\n",
      "# of trainable parameter in QNN model:  800\n",
      "# of trainable parameter in full model:  1421\n"
     ]
    }
   ],
   "source": [
    "step = 0.0004               # Learning rate\n",
    "batch_size = 100             # Number of samples for each training step\n",
    "num_epochs = 10             # Number of training epochs\n",
    "q_depth = 50                 # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "model = LewHybridNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=step)\n",
    "\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "#     optimizer, step_size=10, gamma=gamma_lr_scheduler\n",
    "# )\n",
    "\n",
    "\n",
    "num_trainable_params_QNN = sum(p.numel() for p in LewHybridNN.MappingModel(n_qubit+1,  [10, 20, 10], 1).parameters() if p.requires_grad)\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params_QNN)\n",
    "print(\"# of trainable parameter in QNN model: \", num_trainable_params - num_trainable_params_QNN)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/32], Loss: 4.2162, batch time: 3.16, accuracy:  73.00%\n",
      "Epoch [1/10], Step [2/32], Loss: 2.6094, batch time: 1.56, accuracy:  36.00%\n",
      "Epoch [1/10], Step [3/32], Loss: 4.2853, batch time: 1.52, accuracy:  76.00%\n",
      "Epoch [1/10], Step [4/32], Loss: 5.4918, batch time: 1.63, accuracy:  75.00%\n",
      "Epoch [1/10], Step [5/32], Loss: 2.1709, batch time: 1.52, accuracy:  68.00%\n",
      "Epoch [1/10], Step [6/32], Loss: 2.8437, batch time: 1.63, accuracy:  38.00%\n",
      "Epoch [1/10], Step [7/32], Loss: 2.7000, batch time: 1.55, accuracy:  39.00%\n",
      "Epoch [1/10], Step [8/32], Loss: 1.9771, batch time: 1.64, accuracy:  40.00%\n",
      "Epoch [1/10], Step [9/32], Loss: 2.9952, batch time: 1.53, accuracy:  70.00%\n",
      "Epoch [1/10], Step [10/32], Loss: 2.6896, batch time: 1.61, accuracy:  76.00%\n",
      "Epoch [1/10], Step [11/32], Loss: 2.5421, batch time: 1.63, accuracy:  79.00%\n",
      "Epoch [1/10], Step [12/32], Loss: 2.6582, batch time: 1.59, accuracy:  58.00%\n",
      "Epoch [1/10], Step [13/32], Loss: 1.6621, batch time: 1.67, accuracy:  47.00%\n",
      "Epoch [1/10], Step [14/32], Loss: 1.9477, batch time: 1.50, accuracy:  45.00%\n",
      "Epoch [1/10], Step [15/32], Loss: 1.8579, batch time: 1.58, accuracy:  40.00%\n",
      "Epoch [1/10], Step [16/32], Loss: 2.1166, batch time: 1.55, accuracy:  41.00%\n",
      "Epoch [1/10], Step [17/32], Loss: 1.8929, batch time: 1.55, accuracy:  47.00%\n",
      "Epoch [1/10], Step [18/32], Loss: 1.3005, batch time: 1.67, accuracy:  58.00%\n",
      "Epoch [1/10], Step [19/32], Loss: 1.3437, batch time: 1.65, accuracy:  73.00%\n",
      "Epoch [1/10], Step [20/32], Loss: 1.4573, batch time: 1.59, accuracy:  74.00%\n",
      "Epoch [1/10], Step [21/32], Loss: 1.5162, batch time: 1.53, accuracy:  76.00%\n",
      "Epoch [1/10], Step [22/32], Loss: 1.4435, batch time: 1.65, accuracy:  69.00%\n",
      "Epoch [1/10], Step [23/32], Loss: 1.0311, batch time: 1.60, accuracy:  74.00%\n",
      "Epoch [1/10], Step [24/32], Loss: 0.9487, batch time: 1.50, accuracy:  71.00%\n",
      "Epoch [1/10], Step [25/32], Loss: 1.1476, batch time: 1.61, accuracy:  59.00%\n",
      "Epoch [1/10], Step [26/32], Loss: 1.3520, batch time: 1.57, accuracy:  54.00%\n",
      "Epoch [1/10], Step [27/32], Loss: 1.0772, batch time: 1.67, accuracy:  56.00%\n",
      "Epoch [1/10], Step [28/32], Loss: 1.2671, batch time: 1.57, accuracy:  55.00%\n",
      "Epoch [1/10], Step [29/32], Loss: 1.0504, batch time: 1.65, accuracy:  60.00%\n",
      "Epoch [1/10], Step [30/32], Loss: 0.9933, batch time: 1.54, accuracy:  58.00%\n",
      "Epoch [1/10], Step [31/32], Loss: 0.9257, batch time: 1.63, accuracy:  61.00%\n",
      "Epoch [1/10], Step [32/32], Loss: 1.1268, batch time: 1.59, accuracy:  60.00%\n",
      "Epoch [2/10], Step [1/32], Loss: 1.0442, batch time: 1.56, accuracy:  67.00%\n",
      "Epoch [2/10], Step [2/32], Loss: 1.1740, batch time: 1.60, accuracy:  62.00%\n",
      "Epoch [2/10], Step [3/32], Loss: 1.1266, batch time: 1.54, accuracy:  56.00%\n",
      "Epoch [2/10], Step [4/32], Loss: 0.8936, batch time: 1.67, accuracy:  68.00%\n",
      "Epoch [2/10], Step [5/32], Loss: 0.9456, batch time: 1.61, accuracy:  65.00%\n",
      "Epoch [2/10], Step [6/32], Loss: 0.9061, batch time: 1.54, accuracy:  63.00%\n",
      "Epoch [2/10], Step [7/32], Loss: 1.0164, batch time: 1.68, accuracy:  56.00%\n",
      "Epoch [2/10], Step [8/32], Loss: 0.9542, batch time: 1.59, accuracy:  63.00%\n",
      "Epoch [2/10], Step [9/32], Loss: 1.0424, batch time: 1.65, accuracy:  60.00%\n",
      "Epoch [2/10], Step [10/32], Loss: 0.7881, batch time: 1.56, accuracy:  63.00%\n",
      "Epoch [2/10], Step [11/32], Loss: 0.9161, batch time: 1.63, accuracy:  68.00%\n",
      "Epoch [2/10], Step [12/32], Loss: 0.5625, batch time: 1.55, accuracy:  76.00%\n",
      "Epoch [2/10], Step [13/32], Loss: 0.7569, batch time: 1.55, accuracy:  68.00%\n",
      "Epoch [2/10], Step [14/32], Loss: 0.9337, batch time: 1.60, accuracy:  64.00%\n",
      "Epoch [2/10], Step [15/32], Loss: 0.7907, batch time: 1.54, accuracy:  70.00%\n",
      "Epoch [2/10], Step [16/32], Loss: 1.1343, batch time: 1.67, accuracy:  68.00%\n",
      "Epoch [2/10], Step [17/32], Loss: 0.7092, batch time: 1.55, accuracy:  66.00%\n",
      "Epoch [2/10], Step [18/32], Loss: 1.0107, batch time: 1.67, accuracy:  64.00%\n",
      "Epoch [2/10], Step [19/32], Loss: 0.7279, batch time: 1.54, accuracy:  74.00%\n",
      "Epoch [2/10], Step [20/32], Loss: 0.8798, batch time: 1.60, accuracy:  74.00%\n",
      "Epoch [2/10], Step [21/32], Loss: 0.8267, batch time: 1.59, accuracy:  71.00%\n",
      "Epoch [2/10], Step [22/32], Loss: 0.7714, batch time: 1.59, accuracy:  72.00%\n",
      "Epoch [2/10], Step [23/32], Loss: 0.7807, batch time: 1.60, accuracy:  76.00%\n",
      "Epoch [2/10], Step [24/32], Loss: 0.6693, batch time: 1.55, accuracy:  74.00%\n",
      "Epoch [2/10], Step [25/32], Loss: 0.7656, batch time: 1.65, accuracy:  67.00%\n",
      "Epoch [2/10], Step [26/32], Loss: 0.7733, batch time: 1.55, accuracy:  62.00%\n",
      "Epoch [2/10], Step [27/32], Loss: 0.6416, batch time: 1.53, accuracy:  60.00%\n",
      "Epoch [2/10], Step [28/32], Loss: 0.7305, batch time: 1.58, accuracy:  68.00%\n",
      "Epoch [2/10], Step [29/32], Loss: 0.7358, batch time: 1.59, accuracy:  65.00%\n",
      "Epoch [2/10], Step [30/32], Loss: 0.6593, batch time: 1.67, accuracy:  68.00%\n",
      "Epoch [2/10], Step [31/32], Loss: 0.7696, batch time: 1.61, accuracy:  68.00%\n",
      "Epoch [2/10], Step [32/32], Loss: 0.6935, batch time: 1.61, accuracy:  69.00%\n",
      "Epoch [3/10], Step [1/32], Loss: 0.6775, batch time: 1.59, accuracy:  69.00%\n",
      "Epoch [3/10], Step [2/32], Loss: 0.8045, batch time: 1.53, accuracy:  67.00%\n",
      "Epoch [3/10], Step [3/32], Loss: 0.6712, batch time: 1.63, accuracy:  73.00%\n",
      "Epoch [3/10], Step [4/32], Loss: 0.6752, batch time: 1.55, accuracy:  70.00%\n",
      "Epoch [3/10], Step [5/32], Loss: 0.7359, batch time: 1.66, accuracy:  72.00%\n",
      "Epoch [3/10], Step [6/32], Loss: 0.4566, batch time: 1.55, accuracy:  82.00%\n",
      "Epoch [3/10], Step [7/32], Loss: 0.6654, batch time: 1.71, accuracy:  73.00%\n",
      "Epoch [3/10], Step [8/32], Loss: 0.6644, batch time: 1.61, accuracy:  74.00%\n",
      "Epoch [3/10], Step [9/32], Loss: 0.4702, batch time: 1.54, accuracy:  80.00%\n",
      "Epoch [3/10], Step [10/32], Loss: 0.6236, batch time: 1.63, accuracy:  73.00%\n",
      "Epoch [3/10], Step [11/32], Loss: 0.7410, batch time: 1.56, accuracy:  62.00%\n",
      "Epoch [3/10], Step [12/32], Loss: 0.7064, batch time: 1.63, accuracy:  65.00%\n",
      "Epoch [3/10], Step [13/32], Loss: 0.5854, batch time: 1.54, accuracy:  70.00%\n",
      "Epoch [3/10], Step [14/32], Loss: 0.5452, batch time: 1.61, accuracy:  72.00%\n",
      "Epoch [3/10], Step [15/32], Loss: 0.6529, batch time: 1.60, accuracy:  65.00%\n",
      "Epoch [3/10], Step [16/32], Loss: 0.6681, batch time: 1.56, accuracy:  70.00%\n",
      "Epoch [3/10], Step [17/32], Loss: 0.6618, batch time: 1.60, accuracy:  69.00%\n",
      "Epoch [3/10], Step [18/32], Loss: 0.5982, batch time: 1.60, accuracy:  76.00%\n",
      "Epoch [3/10], Step [19/32], Loss: 0.6606, batch time: 1.69, accuracy:  72.00%\n",
      "Epoch [3/10], Step [20/32], Loss: 0.5605, batch time: 1.61, accuracy:  76.00%\n",
      "Epoch [3/10], Step [21/32], Loss: 0.5750, batch time: 1.65, accuracy:  68.00%\n",
      "Epoch [3/10], Step [22/32], Loss: 0.6239, batch time: 1.55, accuracy:  74.00%\n",
      "Epoch [3/10], Step [23/32], Loss: 0.7984, batch time: 1.57, accuracy:  68.00%\n",
      "Epoch [3/10], Step [24/32], Loss: 0.6657, batch time: 1.59, accuracy:  70.00%\n",
      "Epoch [3/10], Step [25/32], Loss: 0.6764, batch time: 1.55, accuracy:  69.00%\n",
      "Epoch [3/10], Step [26/32], Loss: 0.6208, batch time: 1.58, accuracy:  78.00%\n",
      "Epoch [3/10], Step [27/32], Loss: 0.5705, batch time: 1.61, accuracy:  75.00%\n",
      "Epoch [3/10], Step [28/32], Loss: 0.5856, batch time: 1.69, accuracy:  76.00%\n",
      "Epoch [3/10], Step [29/32], Loss: 0.5344, batch time: 1.57, accuracy:  80.00%\n",
      "Epoch [3/10], Step [30/32], Loss: 0.5228, batch time: 1.61, accuracy:  74.00%\n",
      "Epoch [3/10], Step [31/32], Loss: 0.5686, batch time: 1.67, accuracy:  78.00%\n",
      "Epoch [3/10], Step [32/32], Loss: 0.5776, batch time: 1.59, accuracy:  74.00%\n",
      "Epoch [4/10], Step [1/32], Loss: 0.6376, batch time: 1.64, accuracy:  75.00%\n",
      "Epoch [4/10], Step [2/32], Loss: 0.5350, batch time: 1.57, accuracy:  79.00%\n",
      "Epoch [4/10], Step [3/32], Loss: 0.6060, batch time: 1.63, accuracy:  73.00%\n",
      "Epoch [4/10], Step [4/32], Loss: 0.5851, batch time: 1.55, accuracy:  77.00%\n",
      "Epoch [4/10], Step [5/32], Loss: 0.5815, batch time: 1.63, accuracy:  68.00%\n",
      "Epoch [4/10], Step [6/32], Loss: 0.6597, batch time: 1.65, accuracy:  71.00%\n",
      "Epoch [4/10], Step [7/32], Loss: 0.6356, batch time: 1.58, accuracy:  74.00%\n",
      "Epoch [4/10], Step [8/32], Loss: 0.5944, batch time: 1.63, accuracy:  72.00%\n",
      "Epoch [4/10], Step [9/32], Loss: 0.5261, batch time: 1.63, accuracy:  73.00%\n",
      "Epoch [4/10], Step [10/32], Loss: 0.4295, batch time: 1.62, accuracy:  85.00%\n",
      "Epoch [4/10], Step [11/32], Loss: 0.6541, batch time: 1.56, accuracy:  73.00%\n",
      "Epoch [4/10], Step [12/32], Loss: 0.7254, batch time: 1.56, accuracy:  69.00%\n",
      "Epoch [4/10], Step [13/32], Loss: 0.5532, batch time: 1.62, accuracy:  76.00%\n",
      "Epoch [4/10], Step [14/32], Loss: 0.6616, batch time: 1.59, accuracy:  69.00%\n",
      "Epoch [4/10], Step [15/32], Loss: 0.6549, batch time: 1.59, accuracy:  68.00%\n",
      "Epoch [4/10], Step [16/32], Loss: 0.5235, batch time: 1.59, accuracy:  78.00%\n",
      "Epoch [4/10], Step [17/32], Loss: 0.5570, batch time: 1.59, accuracy:  72.00%\n",
      "Epoch [4/10], Step [18/32], Loss: 0.5939, batch time: 1.62, accuracy:  72.00%\n",
      "Epoch [4/10], Step [19/32], Loss: 0.5317, batch time: 1.52, accuracy:  76.00%\n",
      "Epoch [4/10], Step [20/32], Loss: 0.5790, batch time: 1.61, accuracy:  76.00%\n",
      "Epoch [4/10], Step [21/32], Loss: 0.4594, batch time: 1.52, accuracy:  79.00%\n",
      "Epoch [4/10], Step [22/32], Loss: 0.5857, batch time: 1.58, accuracy:  77.00%\n",
      "Epoch [4/10], Step [23/32], Loss: 0.6046, batch time: 1.60, accuracy:  76.00%\n",
      "Epoch [4/10], Step [24/32], Loss: 0.4290, batch time: 1.61, accuracy:  83.00%\n",
      "Epoch [4/10], Step [25/32], Loss: 0.5666, batch time: 1.59, accuracy:  74.00%\n",
      "Epoch [4/10], Step [26/32], Loss: 0.5272, batch time: 1.53, accuracy:  79.00%\n",
      "Epoch [4/10], Step [27/32], Loss: 0.5928, batch time: 1.67, accuracy:  77.00%\n",
      "Epoch [4/10], Step [28/32], Loss: 0.5402, batch time: 1.54, accuracy:  79.00%\n",
      "Epoch [4/10], Step [29/32], Loss: 0.4135, batch time: 1.69, accuracy:  84.00%\n",
      "Epoch [4/10], Step [30/32], Loss: 0.5768, batch time: 1.55, accuracy:  74.00%\n",
      "Epoch [4/10], Step [31/32], Loss: 0.4651, batch time: 1.57, accuracy:  77.00%\n",
      "Epoch [4/10], Step [32/32], Loss: 0.7441, batch time: 1.57, accuracy:  61.00%\n",
      "Epoch [5/10], Step [1/32], Loss: 0.5685, batch time: 1.56, accuracy:  72.00%\n",
      "Epoch [5/10], Step [2/32], Loss: 0.6563, batch time: 1.61, accuracy:  61.00%\n",
      "Epoch [5/10], Step [3/32], Loss: 0.6470, batch time: 1.55, accuracy:  65.00%\n",
      "Epoch [5/10], Step [4/32], Loss: 0.5181, batch time: 1.62, accuracy:  78.00%\n",
      "Epoch [5/10], Step [5/32], Loss: 0.5436, batch time: 1.51, accuracy:  77.00%\n",
      "Epoch [5/10], Step [6/32], Loss: 0.6301, batch time: 1.67, accuracy:  74.00%\n",
      "Epoch [5/10], Step [7/32], Loss: 0.6494, batch time: 1.55, accuracy:  73.00%\n",
      "Epoch [5/10], Step [8/32], Loss: 0.6061, batch time: 1.59, accuracy:  77.00%\n",
      "Epoch [5/10], Step [9/32], Loss: 0.5419, batch time: 1.63, accuracy:  77.00%\n",
      "Epoch [5/10], Step [10/32], Loss: 0.6080, batch time: 1.53, accuracy:  67.00%\n",
      "Epoch [5/10], Step [11/32], Loss: 0.5714, batch time: 1.64, accuracy:  74.00%\n",
      "Epoch [5/10], Step [12/32], Loss: 0.5862, batch time: 1.59, accuracy:  71.00%\n",
      "Epoch [5/10], Step [13/32], Loss: 0.6311, batch time: 1.67, accuracy:  68.00%\n",
      "Epoch [5/10], Step [14/32], Loss: 0.6233, batch time: 1.63, accuracy:  72.00%\n",
      "Epoch [5/10], Step [15/32], Loss: 0.5540, batch time: 1.61, accuracy:  72.00%\n",
      "Epoch [5/10], Step [16/32], Loss: 0.6181, batch time: 1.68, accuracy:  74.00%\n",
      "Epoch [5/10], Step [17/32], Loss: 0.6007, batch time: 1.55, accuracy:  72.00%\n",
      "Epoch [5/10], Step [18/32], Loss: 0.6239, batch time: 1.68, accuracy:  71.00%\n",
      "Epoch [5/10], Step [19/32], Loss: 0.6150, batch time: 1.61, accuracy:  71.00%\n",
      "Epoch [5/10], Step [20/32], Loss: 0.5005, batch time: 1.67, accuracy:  75.00%\n",
      "Epoch [5/10], Step [21/32], Loss: 0.5675, batch time: 1.61, accuracy:  71.00%\n",
      "Epoch [5/10], Step [22/32], Loss: 0.5512, batch time: 1.53, accuracy:  77.00%\n",
      "Epoch [5/10], Step [23/32], Loss: 0.5563, batch time: 1.62, accuracy:  76.00%\n",
      "Epoch [5/10], Step [24/32], Loss: 0.4395, batch time: 1.54, accuracy:  84.00%\n",
      "Epoch [5/10], Step [25/32], Loss: 0.5138, batch time: 1.57, accuracy:  76.00%\n",
      "Epoch [5/10], Step [26/32], Loss: 0.5172, batch time: 1.57, accuracy:  77.00%\n",
      "Epoch [5/10], Step [27/32], Loss: 0.5468, batch time: 1.62, accuracy:  77.00%\n",
      "Epoch [5/10], Step [28/32], Loss: 0.4319, batch time: 1.54, accuracy:  85.00%\n",
      "Epoch [5/10], Step [29/32], Loss: 0.4824, batch time: 1.58, accuracy:  78.00%\n",
      "Epoch [5/10], Step [30/32], Loss: 0.5906, batch time: 1.67, accuracy:  73.00%\n",
      "Epoch [5/10], Step [31/32], Loss: 0.5275, batch time: 1.59, accuracy:  75.00%\n",
      "Epoch [5/10], Step [32/32], Loss: 0.5106, batch time: 1.64, accuracy:  75.00%\n",
      "Epoch [6/10], Step [1/32], Loss: 0.6088, batch time: 1.55, accuracy:  74.00%\n",
      "Epoch [6/10], Step [2/32], Loss: 0.5246, batch time: 1.71, accuracy:  82.00%\n",
      "Epoch [6/10], Step [3/32], Loss: 0.5634, batch time: 1.56, accuracy:  74.00%\n",
      "Epoch [6/10], Step [4/32], Loss: 0.5344, batch time: 1.60, accuracy:  80.00%\n",
      "Epoch [6/10], Step [5/32], Loss: 0.6198, batch time: 1.64, accuracy:  71.00%\n",
      "Epoch [6/10], Step [6/32], Loss: 0.5678, batch time: 1.57, accuracy:  75.00%\n",
      "Epoch [6/10], Step [7/32], Loss: 0.5628, batch time: 1.63, accuracy:  73.00%\n",
      "Epoch [6/10], Step [8/32], Loss: 0.5846, batch time: 1.54, accuracy:  77.00%\n",
      "Epoch [6/10], Step [9/32], Loss: 0.5400, batch time: 1.65, accuracy:  73.00%\n",
      "Epoch [6/10], Step [10/32], Loss: 0.4980, batch time: 1.54, accuracy:  76.00%\n",
      "Epoch [6/10], Step [11/32], Loss: 0.5289, batch time: 1.57, accuracy:  78.00%\n",
      "Epoch [6/10], Step [12/32], Loss: 0.5759, batch time: 1.64, accuracy:  71.00%\n",
      "Epoch [6/10], Step [13/32], Loss: 0.5768, batch time: 1.56, accuracy:  73.00%\n",
      "Epoch [6/10], Step [14/32], Loss: 0.4934, batch time: 1.63, accuracy:  83.00%\n",
      "Epoch [6/10], Step [15/32], Loss: 0.6301, batch time: 1.53, accuracy:  69.00%\n",
      "Epoch [6/10], Step [16/32], Loss: 0.5928, batch time: 1.62, accuracy:  74.00%\n",
      "Epoch [6/10], Step [17/32], Loss: 0.5129, batch time: 1.55, accuracy:  75.00%\n",
      "Epoch [6/10], Step [18/32], Loss: 0.4883, batch time: 1.55, accuracy:  78.00%\n",
      "Epoch [6/10], Step [19/32], Loss: 0.5436, batch time: 1.62, accuracy:  70.00%\n",
      "Epoch [6/10], Step [20/32], Loss: 0.5236, batch time: 1.60, accuracy:  75.00%\n",
      "Epoch [6/10], Step [21/32], Loss: 0.6090, batch time: 1.62, accuracy:  69.00%\n",
      "Epoch [6/10], Step [22/32], Loss: 0.5574, batch time: 1.56, accuracy:  73.00%\n",
      "Epoch [6/10], Step [23/32], Loss: 0.5559, batch time: 1.64, accuracy:  75.00%\n",
      "Epoch [6/10], Step [24/32], Loss: 0.5764, batch time: 1.61, accuracy:  70.00%\n",
      "Epoch [6/10], Step [25/32], Loss: 0.5330, batch time: 1.61, accuracy:  77.00%\n",
      "Epoch [6/10], Step [26/32], Loss: 0.5191, batch time: 1.70, accuracy:  74.00%\n",
      "Epoch [6/10], Step [27/32], Loss: 0.5069, batch time: 1.62, accuracy:  80.00%\n",
      "Epoch [6/10], Step [28/32], Loss: 0.4929, batch time: 1.67, accuracy:  83.00%\n",
      "Epoch [6/10], Step [29/32], Loss: 0.3835, batch time: 1.61, accuracy:  84.00%\n",
      "Epoch [6/10], Step [30/32], Loss: 0.4801, batch time: 1.66, accuracy:  79.00%\n",
      "Epoch [6/10], Step [31/32], Loss: 0.5077, batch time: 1.58, accuracy:  79.00%\n",
      "Epoch [6/10], Step [32/32], Loss: 0.5519, batch time: 1.58, accuracy:  74.00%\n",
      "Epoch [7/10], Step [1/32], Loss: 0.5408, batch time: 1.62, accuracy:  75.00%\n",
      "Epoch [7/10], Step [2/32], Loss: 0.4883, batch time: 1.64, accuracy:  82.00%\n",
      "Epoch [7/10], Step [3/32], Loss: 0.5584, batch time: 1.60, accuracy:  72.00%\n",
      "Epoch [7/10], Step [4/32], Loss: 0.5253, batch time: 1.55, accuracy:  74.00%\n",
      "Epoch [7/10], Step [5/32], Loss: 0.4849, batch time: 1.63, accuracy:  75.00%\n",
      "Epoch [7/10], Step [6/32], Loss: 0.6576, batch time: 1.51, accuracy:  67.00%\n",
      "Epoch [7/10], Step [7/32], Loss: 0.4973, batch time: 1.62, accuracy:  78.00%\n",
      "Epoch [7/10], Step [8/32], Loss: 0.5287, batch time: 1.65, accuracy:  74.00%\n",
      "Epoch [7/10], Step [9/32], Loss: 0.5889, batch time: 1.59, accuracy:  74.00%\n",
      "Epoch [7/10], Step [10/32], Loss: 0.5172, batch time: 1.62, accuracy:  77.00%\n",
      "Epoch [7/10], Step [11/32], Loss: 0.5993, batch time: 1.63, accuracy:  72.00%\n",
      "Epoch [7/10], Step [12/32], Loss: 0.5601, batch time: 1.59, accuracy:  73.00%\n",
      "Epoch [7/10], Step [13/32], Loss: 0.5360, batch time: 1.53, accuracy:  72.00%\n",
      "Epoch [7/10], Step [14/32], Loss: 0.6096, batch time: 1.55, accuracy:  66.00%\n",
      "Epoch [7/10], Step [15/32], Loss: 0.5110, batch time: 1.67, accuracy:  81.00%\n",
      "Epoch [7/10], Step [16/32], Loss: 0.5568, batch time: 1.57, accuracy:  77.00%\n",
      "Epoch [7/10], Step [17/32], Loss: 0.4752, batch time: 1.64, accuracy:  81.00%\n",
      "Epoch [7/10], Step [18/32], Loss: 0.5697, batch time: 1.56, accuracy:  75.00%\n",
      "Epoch [7/10], Step [19/32], Loss: 0.5018, batch time: 1.65, accuracy:  76.00%\n",
      "Epoch [7/10], Step [20/32], Loss: 0.6378, batch time: 1.59, accuracy:  71.00%\n",
      "Epoch [7/10], Step [21/32], Loss: 0.5725, batch time: 1.56, accuracy:  74.00%\n",
      "Epoch [7/10], Step [22/32], Loss: 0.5500, batch time: 1.64, accuracy:  80.00%\n",
      "Epoch [7/10], Step [23/32], Loss: 0.5731, batch time: 1.60, accuracy:  77.00%\n",
      "Epoch [7/10], Step [24/32], Loss: 0.5392, batch time: 1.68, accuracy:  75.00%\n",
      "Epoch [7/10], Step [25/32], Loss: 0.5942, batch time: 1.56, accuracy:  71.00%\n",
      "Epoch [7/10], Step [26/32], Loss: 0.4838, batch time: 1.63, accuracy:  77.00%\n",
      "Epoch [7/10], Step [27/32], Loss: 0.4572, batch time: 1.54, accuracy:  80.00%\n",
      "Epoch [7/10], Step [28/32], Loss: 0.5886, batch time: 1.62, accuracy:  74.00%\n",
      "Epoch [7/10], Step [29/32], Loss: 0.5262, batch time: 1.64, accuracy:  75.00%\n",
      "Epoch [7/10], Step [30/32], Loss: 0.5747, batch time: 1.56, accuracy:  74.00%\n",
      "Epoch [7/10], Step [31/32], Loss: 0.5673, batch time: 1.64, accuracy:  72.00%\n",
      "Epoch [7/10], Step [32/32], Loss: 0.5008, batch time: 1.56, accuracy:  80.00%\n",
      "Epoch [8/10], Step [1/32], Loss: 0.5062, batch time: 1.64, accuracy:  80.00%\n",
      "Epoch [8/10], Step [2/32], Loss: 0.5555, batch time: 1.55, accuracy:  74.00%\n",
      "Epoch [8/10], Step [3/32], Loss: 0.4925, batch time: 1.59, accuracy:  77.00%\n",
      "Epoch [8/10], Step [4/32], Loss: 0.4844, batch time: 1.60, accuracy:  78.00%\n",
      "Epoch [8/10], Step [5/32], Loss: 0.4237, batch time: 1.62, accuracy:  84.00%\n",
      "Epoch [8/10], Step [6/32], Loss: 0.5335, batch time: 1.67, accuracy:  77.00%\n",
      "Epoch [8/10], Step [7/32], Loss: 0.5725, batch time: 1.52, accuracy:  72.00%\n",
      "Epoch [8/10], Step [8/32], Loss: 0.5398, batch time: 1.60, accuracy:  76.00%\n",
      "Epoch [8/10], Step [9/32], Loss: 0.4987, batch time: 1.53, accuracy:  78.00%\n",
      "Epoch [8/10], Step [10/32], Loss: 0.5164, batch time: 1.61, accuracy:  77.00%\n",
      "Epoch [8/10], Step [11/32], Loss: 0.5219, batch time: 1.67, accuracy:  74.00%\n",
      "Epoch [8/10], Step [12/32], Loss: 0.4027, batch time: 1.61, accuracy:  86.00%\n",
      "Epoch [8/10], Step [13/32], Loss: 0.4629, batch time: 1.67, accuracy:  79.00%\n",
      "Epoch [8/10], Step [14/32], Loss: 0.6051, batch time: 1.57, accuracy:  73.00%\n",
      "Epoch [8/10], Step [15/32], Loss: 0.4951, batch time: 1.70, accuracy:  78.00%\n",
      "Epoch [8/10], Step [16/32], Loss: 0.5693, batch time: 1.57, accuracy:  77.00%\n",
      "Epoch [8/10], Step [17/32], Loss: 0.5482, batch time: 1.61, accuracy:  75.00%\n",
      "Epoch [8/10], Step [18/32], Loss: 0.5547, batch time: 1.63, accuracy:  79.00%\n",
      "Epoch [8/10], Step [19/32], Loss: 0.4703, batch time: 1.60, accuracy:  77.00%\n",
      "Epoch [8/10], Step [20/32], Loss: 0.5878, batch time: 1.65, accuracy:  76.00%\n",
      "Epoch [8/10], Step [21/32], Loss: 0.5894, batch time: 1.57, accuracy:  71.00%\n",
      "Epoch [8/10], Step [22/32], Loss: 0.5791, batch time: 1.62, accuracy:  70.00%\n",
      "Epoch [8/10], Step [23/32], Loss: 0.5905, batch time: 1.54, accuracy:  70.00%\n",
      "Epoch [8/10], Step [24/32], Loss: 0.6914, batch time: 1.54, accuracy:  62.00%\n",
      "Epoch [8/10], Step [25/32], Loss: 0.6605, batch time: 1.69, accuracy:  56.00%\n",
      "Epoch [8/10], Step [26/32], Loss: 0.6081, batch time: 1.54, accuracy:  70.00%\n",
      "Epoch [8/10], Step [27/32], Loss: 0.5993, batch time: 1.57, accuracy:  73.00%\n",
      "Epoch [8/10], Step [28/32], Loss: 0.4695, batch time: 1.59, accuracy:  81.00%\n",
      "Epoch [8/10], Step [29/32], Loss: 0.5532, batch time: 1.64, accuracy:  75.00%\n",
      "Epoch [8/10], Step [30/32], Loss: 0.6402, batch time: 1.61, accuracy:  72.00%\n",
      "Epoch [8/10], Step [31/32], Loss: 0.5665, batch time: 1.55, accuracy:  73.00%\n",
      "Epoch [8/10], Step [32/32], Loss: 0.5698, batch time: 1.64, accuracy:  76.00%\n",
      "Epoch [9/10], Step [1/32], Loss: 0.5893, batch time: 1.61, accuracy:  74.00%\n",
      "Epoch [9/10], Step [2/32], Loss: 0.5386, batch time: 1.67, accuracy:  75.00%\n",
      "Epoch [9/10], Step [3/32], Loss: 0.6207, batch time: 1.56, accuracy:  72.00%\n",
      "Epoch [9/10], Step [4/32], Loss: 0.6541, batch time: 1.64, accuracy:  71.00%\n",
      "Epoch [9/10], Step [5/32], Loss: 0.5991, batch time: 1.62, accuracy:  71.00%\n",
      "Epoch [9/10], Step [6/32], Loss: 0.5533, batch time: 1.61, accuracy:  74.00%\n",
      "Epoch [9/10], Step [7/32], Loss: 0.6030, batch time: 1.66, accuracy:  77.00%\n",
      "Epoch [9/10], Step [8/32], Loss: 0.5467, batch time: 1.53, accuracy:  81.00%\n",
      "Epoch [9/10], Step [9/32], Loss: 0.5393, batch time: 1.65, accuracy:  78.00%\n",
      "Epoch [9/10], Step [10/32], Loss: 0.5245, batch time: 1.59, accuracy:  77.00%\n",
      "Epoch [9/10], Step [11/32], Loss: 0.6138, batch time: 1.71, accuracy:  73.00%\n",
      "Epoch [9/10], Step [12/32], Loss: 0.4696, batch time: 1.58, accuracy:  77.00%\n",
      "Epoch [9/10], Step [13/32], Loss: 0.5403, batch time: 1.60, accuracy:  71.00%\n",
      "Epoch [9/10], Step [14/32], Loss: 0.5426, batch time: 1.69, accuracy:  79.00%\n",
      "Epoch [9/10], Step [15/32], Loss: 0.5976, batch time: 1.55, accuracy:  74.00%\n",
      "Epoch [9/10], Step [16/32], Loss: 0.5678, batch time: 1.65, accuracy:  73.00%\n",
      "Epoch [9/10], Step [17/32], Loss: 0.5185, batch time: 1.56, accuracy:  78.00%\n",
      "Epoch [9/10], Step [18/32], Loss: 0.5383, batch time: 1.58, accuracy:  76.00%\n",
      "Epoch [9/10], Step [19/32], Loss: 0.5018, batch time: 1.56, accuracy:  77.00%\n",
      "Epoch [9/10], Step [20/32], Loss: 0.5307, batch time: 1.55, accuracy:  75.00%\n",
      "Epoch [9/10], Step [21/32], Loss: 0.5096, batch time: 1.66, accuracy:  75.00%\n",
      "Epoch [9/10], Step [22/32], Loss: 0.5378, batch time: 1.60, accuracy:  73.00%\n",
      "Epoch [9/10], Step [23/32], Loss: 0.5501, batch time: 1.60, accuracy:  77.00%\n",
      "Epoch [9/10], Step [24/32], Loss: 0.5276, batch time: 1.60, accuracy:  80.00%\n",
      "Epoch [9/10], Step [25/32], Loss: 0.5477, batch time: 1.68, accuracy:  73.00%\n",
      "Epoch [9/10], Step [26/32], Loss: 0.5295, batch time: 1.63, accuracy:  77.00%\n",
      "Epoch [9/10], Step [27/32], Loss: 0.6216, batch time: 1.54, accuracy:  67.00%\n",
      "Epoch [9/10], Step [28/32], Loss: 0.5110, batch time: 1.65, accuracy:  80.00%\n",
      "Epoch [9/10], Step [29/32], Loss: 0.4805, batch time: 1.58, accuracy:  77.00%\n",
      "Epoch [9/10], Step [30/32], Loss: 0.5399, batch time: 1.65, accuracy:  70.00%\n",
      "Epoch [9/10], Step [31/32], Loss: 0.6097, batch time: 1.56, accuracy:  71.00%\n",
      "Epoch [9/10], Step [32/32], Loss: 0.4405, batch time: 1.64, accuracy:  86.00%\n",
      "Epoch [10/10], Step [1/32], Loss: 0.5018, batch time: 1.56, accuracy:  76.00%\n",
      "Epoch [10/10], Step [2/32], Loss: 0.6765, batch time: 1.60, accuracy:  67.00%\n",
      "Epoch [10/10], Step [3/32], Loss: 0.4737, batch time: 1.64, accuracy:  80.00%\n",
      "Epoch [10/10], Step [4/32], Loss: 0.4692, batch time: 1.60, accuracy:  82.00%\n",
      "Epoch [10/10], Step [5/32], Loss: 0.5322, batch time: 1.70, accuracy:  73.00%\n",
      "Epoch [10/10], Step [6/32], Loss: 0.5483, batch time: 1.61, accuracy:  76.00%\n",
      "Epoch [10/10], Step [7/32], Loss: 0.4511, batch time: 1.61, accuracy:  81.00%\n",
      "Epoch [10/10], Step [8/32], Loss: 0.5537, batch time: 1.61, accuracy:  73.00%\n",
      "Epoch [10/10], Step [9/32], Loss: 0.5608, batch time: 1.60, accuracy:  74.00%\n",
      "Epoch [10/10], Step [10/32], Loss: 0.5110, batch time: 1.62, accuracy:  79.00%\n",
      "Epoch [10/10], Step [11/32], Loss: 0.5177, batch time: 1.63, accuracy:  78.00%\n",
      "Epoch [10/10], Step [12/32], Loss: 0.5142, batch time: 1.64, accuracy:  76.00%\n",
      "Epoch [10/10], Step [13/32], Loss: 0.5240, batch time: 1.60, accuracy:  78.00%\n",
      "Epoch [10/10], Step [14/32], Loss: 0.5152, batch time: 1.67, accuracy:  77.00%\n",
      "Epoch [10/10], Step [15/32], Loss: 0.5443, batch time: 1.55, accuracy:  73.00%\n",
      "Epoch [10/10], Step [16/32], Loss: 0.5854, batch time: 1.52, accuracy:  76.00%\n",
      "Epoch [10/10], Step [17/32], Loss: 0.4896, batch time: 1.59, accuracy:  81.00%\n",
      "Epoch [10/10], Step [18/32], Loss: 0.5668, batch time: 1.53, accuracy:  71.00%\n",
      "Epoch [10/10], Step [19/32], Loss: 0.6505, batch time: 1.62, accuracy:  68.00%\n",
      "Epoch [10/10], Step [20/32], Loss: 0.5336, batch time: 1.55, accuracy:  75.00%\n",
      "Epoch [10/10], Step [21/32], Loss: 0.5059, batch time: 1.68, accuracy:  79.00%\n",
      "Epoch [10/10], Step [22/32], Loss: 0.4647, batch time: 1.60, accuracy:  81.00%\n",
      "Epoch [10/10], Step [23/32], Loss: 0.5657, batch time: 1.64, accuracy:  72.00%\n",
      "Epoch [10/10], Step [24/32], Loss: 0.6320, batch time: 1.68, accuracy:  69.00%\n",
      "Epoch [10/10], Step [25/32], Loss: 0.4371, batch time: 1.59, accuracy:  78.00%\n",
      "Epoch [10/10], Step [26/32], Loss: 0.5306, batch time: 1.63, accuracy:  76.00%\n",
      "Epoch [10/10], Step [27/32], Loss: 0.5905, batch time: 1.58, accuracy:  71.00%\n",
      "Epoch [10/10], Step [28/32], Loss: 0.5159, batch time: 1.63, accuracy:  82.00%\n",
      "Epoch [10/10], Step [29/32], Loss: 0.4919, batch time: 1.55, accuracy:  77.00%\n",
      "Epoch [10/10], Step [30/32], Loss: 0.5378, batch time: 1.59, accuracy:  72.00%\n",
      "Epoch [10/10], Step [31/32], Loss: 0.5668, batch time: 1.62, accuracy:  72.00%\n",
      "Epoch [10/10], Step [32/32], Loss: 0.5218, batch time: 1.59, accuracy:  77.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "\n",
    "### (Optional) Start from pretrained model ##\n",
    "# model = torch.load('result_FF_mm_b1000_40_200_40/tq_mm_acc_70_bsf')\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "acc_list = [] \n",
    "acc_best = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        since_batch = time.time()\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # print(\"output: \", outputs)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        # log_loss = torch.log(loss + 1e-6)\n",
    "        \n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        acc = 100 * correct / total\n",
    "        acc_list.append(acc)\n",
    "        train_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "        # np.array(loss_list).dump(\"result/TFIM_1x16/L16/loss_list.dat\")\n",
    "        # np.array(acc_list).dump(\"result/TFIM_1x16/L16/acc_list.dat\")\n",
    "        if acc > acc_best:\n",
    "            # torch.save(model, 'result/TFIM_1x16/L16/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "            acc_best = acc\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if (i+1) % 100 == 0: \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 76.75%\n",
      "Loss on the train set: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 80.25%\n",
      "Loss on the test set: 0.49\n",
      "Generalization error: -0.048273683\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
